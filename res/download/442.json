{
    "items": [
        {
            "tags": [
                "ios",
                "swift",
                "uilabel"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9487187,
                "user_type": "registered",
                "profile_image": "https://lh5.googleusercontent.com/-86i9_so3YWE/AAAAAAAAAAI/AAAAAAAADU0/qvG9AS9m9XI/photo.jpg?sz=128",
                "display_name": "Truls S&#248;nsteby",
                "link": "https://stackoverflow.com/users/9487187/truls-s%c3%b8nsteby"
            },
            "is_answered": false,
            "view_count": 31,
            "answer_count": 1,
            "score": -1,
            "last_activity_date": 1524165864,
            "creation_date": 1524163112,
            "last_edit_date": 1524165864,
            "question_id": 49928027,
            "body_markdown": "I am making a application which will &quot;fill in the blanks&quot; in a uilabel.text\r\nfrom a text file. I am kinda stuck on how to populate my text file with the array of words **chosenWords** String type. so far I am able to display the text and replace the &quot;blanks&quot; in my text file , with just a single word but I can&#39;t figure out how to use my chosenWords array to replace the &#167;&#167;&#167; in the text file with words from it. anyone able to help me out?\r\n\r\n    class GameVC: UIViewController {\r\n    \r\n        \r\n        @IBOutlet weak var storyLabel: UILabel!\r\n        \r\n        \r\n        override func viewDidLoad() {\r\n            super.viewDidLoad()\r\n        \r\n        \r\n          \r\n            if let Path = Bundle.main.url(forResource: &quot;fortelling1&quot;, withExtension: &quot;rtf&quot;) {\r\n                do {\r\n                    let attributedStringWithRtf: NSAttributedString = try NSAttributedString(url: Path, options: [NSAttributedString.DocumentReadingOptionKey.documentType: NSAttributedString.DocumentType.rtf], documentAttributes: nil)\r\n                    self.storyLabel.attributedText = attributedStringWithRtf\r\n                    self.storyLabel.font = UIFont(name: &quot;TimesNewRomanPS-BoldItalicMT&quot;,\r\n                                                  size: 30.0)\r\n                    \r\n                    storyLabel.text = storyLabel.text?.replacingOccurrences(of: &quot;&#167;&#167;&#167;&quot;, with: &quot;YES&quot;)\r\n                    \r\n                } catch let error {\r\n                    print(&quot;Got an error \\(error)&quot;)\r\n                }\r\n            }\r\n            \r\n        \r\n        }\r\n        \r\n    \r\n        override func didReceiveMemoryWarning() {\r\n            super.didReceiveMemoryWarning()\r\n            // Dispose of any resources that can be recreated.\r\n        }\r\n        \r\n    \r\n    \r\n    \r\n    }\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49928027/replacingoccurrences-with-string-from-array",
            "title": "replacingOccurrences with string from array",
            "body": "<p>I am making a application which will \"fill in the blanks\" in a uilabel.text\nfrom a text file. I am kinda stuck on how to populate my text file with the array of words <strong>chosenWords</strong> String type. so far I am able to display the text and replace the \"blanks\" in my text file , with just a single word but I can't figure out how to use my chosenWords array to replace the §§§ in the text file with words from it. anyone able to help me out?</p>\n\n<pre><code>class GameVC: UIViewController {\n\n\n    @IBOutlet weak var storyLabel: UILabel!\n\n\n    override func viewDidLoad() {\n        super.viewDidLoad()\n\n\n\n        if let Path = Bundle.main.url(forResource: \"fortelling1\", withExtension: \"rtf\") {\n            do {\n                let attributedStringWithRtf: NSAttributedString = try NSAttributedString(url: Path, options: [NSAttributedString.DocumentReadingOptionKey.documentType: NSAttributedString.DocumentType.rtf], documentAttributes: nil)\n                self.storyLabel.attributedText = attributedStringWithRtf\n                self.storyLabel.font = UIFont(name: \"TimesNewRomanPS-BoldItalicMT\",\n                                              size: 30.0)\n\n                storyLabel.text = storyLabel.text?.replacingOccurrences(of: \"§§§\", with: \"YES\")\n\n            } catch let error {\n                print(\"Got an error \\(error)\")\n            }\n        }\n\n\n    }\n\n\n    override func didReceiveMemoryWarning() {\n        super.didReceiveMemoryWarning()\n        // Dispose of any resources that can be recreated.\n    }\n\n\n\n\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "react-native",
                "expo"
            ],
            "owner": {
                "reputation": 1235,
                "user_id": 999525,
                "user_type": "registered",
                "accept_rate": 52,
                "profile_image": "https://www.gravatar.com/avatar/dcc4e708af332a6ebb6c2ad6653e92f0?s=128&d=identicon&r=PG",
                "display_name": "lito",
                "link": "https://stackoverflow.com/users/999525/lito"
            },
            "is_answered": false,
            "view_count": 9,
            "answer_count": 0,
            "score": -1,
            "last_activity_date": 1524165864,
            "creation_date": 1524164937,
            "last_edit_date": 1524165864,
            "question_id": 49928509,
            "body_markdown": "Where can I find a list of all release channels for an EXPO app?\r\n\r\nThe last developer left and we don&#39;t know the --release-channel in use. Is there any way to find out the --release-channel&#39;s there were about 6 or 7 we need to find out\r\n\r\n    exp publish --release-channel &lt;your-channel&gt;\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49928509/how-to-list-all-expo-release-channel",
            "title": "how to list all EXPO release-channel?",
            "body": "<p>Where can I find a list of all release channels for an EXPO app?</p>\n\n<p>The last developer left and we don't know the --release-channel in use. Is there any way to find out the --release-channel's there were about 6 or 7 we need to find out</p>\n\n<pre><code>exp publish --release-channel &lt;your-channel&gt;\n</code></pre>\n"
        },
        {
            "tags": [
                "python-2.7",
                "turtle-graphics"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9670211,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Ranger",
                "link": "https://stackoverflow.com/users/9670211/ranger"
            },
            "is_answered": false,
            "view_count": 9,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165859,
            "creation_date": 1524146866,
            "last_edit_date": 1524165859,
            "question_id": 49923198,
            "body_markdown": "Why is my code showing an error in turtle()?  I am using Python 2.7.13 Idle.  The query is regarding to draw a square using turtle:\r\n\r\n    import turtle\r\n    def draw_square():\r\n     window=turtle.Screen()\r\n     window.bgcolor(&quot;red&quot;)\r\n     brad= turtle.Turtle()\r\n     brad.shape(&quot;yellow&quot;) # move forward\r\n     brad.speed(2)# turn pen right 90 degrees\r\n     brad.forward(100)\r\n     brad.right(90)\r\n     brad.forward(100)\r\n     brad.right(90)\r\n     brad.forward(100)\r\n     brad.right(90)\r\n     brad.forward(100)\r\n     brad.right(90)\r\n    window.exitonclick()\r\n    draw_square()\r\n[1]: https://i.stack.imgur.com/hrnAx.png",
            "link": "https://stackoverflow.com/questions/49923198/error-using-turtle-under-python-2-7-idle",
            "title": "Error using turtle under Python 2.7 Idle",
            "body": "<p>Why is my code showing an error in turtle()?  I am using Python 2.7.13 Idle.  The query is regarding to draw a square using turtle:</p>\n\n<pre><code>import turtle\ndef draw_square():\n window=turtle.Screen()\n window.bgcolor(\"red\")\n brad= turtle.Turtle()\n brad.shape(\"yellow\") # move forward\n brad.speed(2)# turn pen right 90 degrees\n brad.forward(100)\n brad.right(90)\n brad.forward(100)\n brad.right(90)\n brad.forward(100)\n brad.right(90)\n brad.forward(100)\n brad.right(90)\nwindow.exitonclick()\ndraw_square()\n</code></pre>\n"
        },
        {
            "tags": [
                "graph",
                "neo4j",
                "neo4j-apoc"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 6437644,
                "user_type": "registered",
                "accept_rate": 25,
                "profile_image": "https://www.gravatar.com/avatar/52bf2c5697468e0e9049180a77696623?s=128&d=identicon&r=PG&f=1",
                "display_name": "KhribiHamza",
                "link": "https://stackoverflow.com/users/6437644/khribihamza"
            },
            "is_answered": false,
            "view_count": 15,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165851,
            "creation_date": 1524131794,
            "question_id": 49918097,
            "body_markdown": "I am trying to add a maxDepth for Dijkstra&#39;s search.\r\nI&#39;ve looked in the apoc procedures repo source code and found out that they pass the PathFinder alongside the startNode and enNode in WeightedPathResult.streamWeightedPathResult which calls the findAllPaths method of PathFinder interface to find all paths. \r\nI need to change the code in findAllPaths methods in order to break the search when path.length()&gt;maxDepth.But the probleme is that i can&#39;t find this methode overrode in any files.\r\nhere is a snippet of the apoc dijkstra procedure\r\n `  \r\n@Procedure\r\n@Description(&quot;apoc.algo.dijkstra(startNode, endNode, &#39;KNOWS|&lt;WORKS_WITH|IS_MANAGER_OF&gt;&#39;, &#39;distance&#39;, defaultValue, numberOfWantedResults) YIELD path,&quot; +\r\n            &quot; weight - run dijkstra with relationship property name as cost function&quot;)`\r\n\r\n     public Stream&lt;WeightedPathResult&gt; dijkstra(\r\n            @Name(&quot;startNode&quot;) Node startNode,\r\n            @Name(&quot;endNode&quot;) Node endNode,\r\n            @Name(&quot;relationshipTypesAndDirections&quot;) String relTypesAndDirs,\r\n            @Name(&quot;weightPropertyName&quot;) String weightPropertyName,\r\n            @Name(value = &quot;defaultWeight&quot;, defaultValue = &quot;NaN&quot;) double defaultWeight,\r\n            @Name(value = &quot;numberOfWantedPaths&quot;, defaultValue = &quot;1&quot;) long numberOfWantedPaths) {PathFinder&lt;WeightedPath&gt; algo = GraphAlgoFactory.dijkstra(\r\n                buildPathExpander(relTypesAndDirs),\r\n                (relationship, direction) -&gt; Util.toDouble(relationship.getProperty(weightPropertyName, defaultWeight)),\r\n                (int)numberOfWantedPaths\r\n        );\r\n        return WeightedPathResult.streamWeightedPathResult(startNode, endNode, algo);\r\n    }\r\n    \r\nAnd here is the streamWeightedPathResult method \r\n\r\n     public static Stream&lt;WeightedPathResult&gt; streamWeightedPathResult(Node startNode, Node endNode, PathFinder&lt;WeightedPath&gt; algo) {\r\n        Iterable&lt;WeightedPath&gt; allPaths = algo.findAllPaths(startNode, endNode);\r\n        return StreamSupport.stream(allPaths.spliterator(), false)\r\n                .map(WeightedPathResult::new);\r\n    }}\r\n    \r\nThey call the findAllPaths method from the PathFinder interface but it was not overrode so where can i do the changes on this method??",
            "link": "https://stackoverflow.com/questions/49918097/where-the-method-findallpaths-of-pathfinder-is-overrode-in-the-apoc-procedures-r",
            "title": "Where the method findAllPaths of PathFinder is Overrode in the apoc procedures repo?",
            "body": "<p>I am trying to add a maxDepth for Dijkstra's search.\nI've looked in the apoc procedures repo source code and found out that they pass the PathFinder alongside the startNode and enNode in WeightedPathResult.streamWeightedPathResult which calls the findAllPaths method of PathFinder interface to find all paths. \nI need to change the code in findAllPaths methods in order to break the search when path.length()>maxDepth.But the probleme is that i can't find this methode overrode in any files.\nhere is a snippet of the apoc dijkstra procedure\n <code>\n@Procedure\n@Description(\"apoc.algo.dijkstra(startNode, endNode, 'KNOWS|&lt;WORKS_WITH|IS_MANAGER_OF&gt;', 'distance', defaultValue, numberOfWantedResults) YIELD path,\" +\n            \" weight - run dijkstra with relationship property name as cost function\")</code></p>\n\n<pre><code> public Stream&lt;WeightedPathResult&gt; dijkstra(\n        @Name(\"startNode\") Node startNode,\n        @Name(\"endNode\") Node endNode,\n        @Name(\"relationshipTypesAndDirections\") String relTypesAndDirs,\n        @Name(\"weightPropertyName\") String weightPropertyName,\n        @Name(value = \"defaultWeight\", defaultValue = \"NaN\") double defaultWeight,\n        @Name(value = \"numberOfWantedPaths\", defaultValue = \"1\") long numberOfWantedPaths) {PathFinder&lt;WeightedPath&gt; algo = GraphAlgoFactory.dijkstra(\n            buildPathExpander(relTypesAndDirs),\n            (relationship, direction) -&gt; Util.toDouble(relationship.getProperty(weightPropertyName, defaultWeight)),\n            (int)numberOfWantedPaths\n    );\n    return WeightedPathResult.streamWeightedPathResult(startNode, endNode, algo);\n}\n</code></pre>\n\n<p>And here is the streamWeightedPathResult method </p>\n\n<pre><code> public static Stream&lt;WeightedPathResult&gt; streamWeightedPathResult(Node startNode, Node endNode, PathFinder&lt;WeightedPath&gt; algo) {\n    Iterable&lt;WeightedPath&gt; allPaths = algo.findAllPaths(startNode, endNode);\n    return StreamSupport.stream(allPaths.spliterator(), false)\n            .map(WeightedPathResult::new);\n}}\n</code></pre>\n\n<p>They call the findAllPaths method from the PathFinder interface but it was not overrode so where can i do the changes on this method??</p>\n"
        },
        {
            "tags": [
                "c",
                "programming-languages",
                "pascal",
                "language-design"
            ],
            "owner": {
                "reputation": 46,
                "user_id": 7585827,
                "user_type": "registered",
                "accept_rate": 80,
                "profile_image": "https://www.gravatar.com/avatar/6f2d68b0a70eef76bd9c892dd822b34b?s=128&d=identicon&r=PG&f=1",
                "display_name": "az0",
                "link": "https://stackoverflow.com/users/7585827/az0"
            },
            "is_answered": true,
            "view_count": 102,
            "closed_date": 1523426870,
            "answer_count": 1,
            "score": -3,
            "last_activity_date": 1524165849,
            "creation_date": 1523423643,
            "question_id": 49766963,
            "body_markdown": "Both languages have similar origins so I&#39;m wondering where this difference comes from.",
            "link": "https://stackoverflow.com/questions/49766963/why-does-c-use-asterisks-to-declare-pointers-and-not-carets-like-in-pascal",
            "closed_reason": "unclear what you&#39;re asking",
            "title": "Why does C use asterisks to declare pointers and not carets like in Pascal?",
            "body": "<p>Both languages have similar origins so I'm wondering where this difference comes from.</p>\n"
        },
        {
            "tags": [
                "c",
                "linux",
                "operating-system",
                "kernel",
                "elf"
            ],
            "owner": {
                "reputation": 148,
                "user_id": 4398197,
                "user_type": "registered",
                "accept_rate": 75,
                "profile_image": "https://www.gravatar.com/avatar/3662ed0ed3d3e8a2aee3856ce222f5d9?s=128&d=identicon&r=PG&f=1",
                "display_name": "Nemo_Sol",
                "link": "https://stackoverflow.com/users/4398197/nemo-sol"
            },
            "is_answered": false,
            "view_count": 23,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165847,
            "creation_date": 1524164264,
            "last_edit_date": 1524165847,
            "question_id": 49928344,
            "body_markdown": "I am attempting to implement KASLR in the xv6 kernel, so i need to recompile/link the kernel in a dynamic way(relocation table). \r\nSince the kernel is currently hardcoded, even if I change the kernel code and data mappings, the instructions will still reference hardcoded virtual addresses. I need a way for the instructions to reference other parts of the elf without hardcoded addresses. An example of this is below:\r\n This is a sample of how it looks after current compilation:\r\n\r\n    8010018e:\t83 ec 0c             \tsub    $0xc,%esp\r\n    80100191:\t68 a7 79 10 80       \tpush   $0x801079a7\r\n    80100196:\te8 b5 01 00 00       \tcall   80100350 &lt;panic&gt;\r\n    8010019b:\t90                   \tnop\r\n    8010019c:\t8d 74 26 00          \tlea    0x0(%esi,%eiz,1),%esi.\r\nAs you can see, the instructions such as the push instruction reference hardcoded v addresses($0x801079a7). This is because this elf is compiled in a static way with no relocations:(readelf printout)\r\n\r\n     Program Headers:\r\n        Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align\r\n        LOAD           0x001000 0x80100000 0x00100000 0x0b516 0x15668 RWE 0x1000\r\n        GNU_STACK      0x000000 0x00000000 0x00000000 0x00000 0x00000 RWE 0x10\r\n        Section to Segment mapping:\r\n        Segment Sections...\r\n        00     .text .rodata .stab .stabstr .data .bss\r\n        01\r\n        There is no dynamic section in this file.\r\n        There are no relocations in this file.\r\n\r\nI need advice on how to recompile a statically linked elf binary to one with relocation and then be able to map the kernel anywhere in virtual memory. Additionally, what would I have to modify in the bootloader for parsing the elf to load it correctly with relocation? Will I have to custom parse a GOT included in the kernel elf?\r\n\r\n\r\n   \r\nThe following is a linker script to compile the kernel and essentially set its base hardcoded virtual address: 0x80100000\r\n\r\n    \r\n    \r\n    OUTPUT_FORMAT(&quot;elf32-i386&quot;, &quot;elf32-i386&quot;, &quot;elf32-i386&quot;)\r\n    OUTPUT_ARCH(i386)\r\n    ENTRY(_start)\r\n    \r\n    SECTIONS\r\n    {\r\n    \t/* Link the kernel at this address: &quot;.&quot; means the current address */\r\n            /* Must be equal to KERNLINK */\r\n    \t. = 0x80100000;\r\n    \r\n    \t.text : AT(0x100000) {\r\n    \t\t*(.text .stub .text.* .gnu.linkonce.t.*)\r\n    \t}\r\n    \r\n    \tPROVIDE(etext = .);\t/* Define the &#39;etext&#39; symbol to this value */\r\n    \r\n    \t.rodata : {\r\n    \t\t*(.rodata .rodata.* .gnu.linkonce.r.*)\r\n    \t}\r\n    \r\n    \t/* Include debugging information in kernel memory */\r\n    \t.stab : {\r\n    \t\tPROVIDE(__STAB_BEGIN__ = .);\r\n    \t\t*(.stab);\r\n    \t\tPROVIDE(__STAB_END__ = .);\r\n    \t\tBYTE(0)\t\t/* Force the linker to allocate space\r\n    \t\t\t\t   for this section */\r\n    \t}\r\n    \r\n    \t.stabstr : {\r\n    \t\tPROVIDE(__STABSTR_BEGIN__ = .);\r\n    \t\t*(.stabstr);\r\n    \t\tPROVIDE(__STABSTR_END__ = .);\r\n    \t\tBYTE(0)\t\t/* Force the linker to allocate space\r\n    \t\t\t\t   for this section */\r\n    \t}\r\n    \r\n    \t/* Adjust the address for the data segment to the next page */\r\n    \t. = ALIGN(0x1000);\r\n    \r\n    \t/* Conventionally, Unix linkers provide pseudo-symbols\r\n    \t * etext, edata, and end, at the end of the text, data, and bss.\r\n    \t * For the kernel mapping, we need the address at the beginning\r\n    \t * of the data section, but that&#39;s not one of the conventional\r\n    \t * symbols, because the convention started before there was a\r\n    \t * read-only rodata section between text and data. */\r\n    \tPROVIDE(data = .);\r\n    \r\n    \t/* The data segment */\r\n    \t.data : {\r\n    \t\t*(.data)\r\n    \t}\r\n    \r\n    \tPROVIDE(edata = .);\r\n    \r\n    \t.bss : {\r\n    \t\t*(.bss)\r\n    \t}\r\n    \r\n    \tPROVIDE(end = .);\r\n    \r\n    \t/DISCARD/ : {\r\n    \t\t*(.eh_frame .note.GNU-stack)\r\n    \t}\r\n    }\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49928344/compile-dynamically-linked-kernel",
            "title": "Compile Dynamically Linked Kernel",
            "body": "<p>I am attempting to implement KASLR in the xv6 kernel, so i need to recompile/link the kernel in a dynamic way(relocation table). \nSince the kernel is currently hardcoded, even if I change the kernel code and data mappings, the instructions will still reference hardcoded virtual addresses. I need a way for the instructions to reference other parts of the elf without hardcoded addresses. An example of this is below:\n This is a sample of how it looks after current compilation:</p>\n\n<pre><code>8010018e:   83 ec 0c                sub    $0xc,%esp\n80100191:   68 a7 79 10 80          push   $0x801079a7\n80100196:   e8 b5 01 00 00          call   80100350 &lt;panic&gt;\n8010019b:   90                      nop\n8010019c:   8d 74 26 00             lea    0x0(%esi,%eiz,1),%esi.\n</code></pre>\n\n<p>As you can see, the instructions such as the push instruction reference hardcoded v addresses($0x801079a7). This is because this elf is compiled in a static way with no relocations:(readelf printout)</p>\n\n<pre><code> Program Headers:\n    Type           Offset   VirtAddr   PhysAddr   FileSiz MemSiz  Flg Align\n    LOAD           0x001000 0x80100000 0x00100000 0x0b516 0x15668 RWE 0x1000\n    GNU_STACK      0x000000 0x00000000 0x00000000 0x00000 0x00000 RWE 0x10\n    Section to Segment mapping:\n    Segment Sections...\n    00     .text .rodata .stab .stabstr .data .bss\n    01\n    There is no dynamic section in this file.\n    There are no relocations in this file.\n</code></pre>\n\n<p>I need advice on how to recompile a statically linked elf binary to one with relocation and then be able to map the kernel anywhere in virtual memory. Additionally, what would I have to modify in the bootloader for parsing the elf to load it correctly with relocation? Will I have to custom parse a GOT included in the kernel elf?</p>\n\n<p>The following is a linker script to compile the kernel and essentially set its base hardcoded virtual address: 0x80100000</p>\n\n<pre><code>OUTPUT_FORMAT(\"elf32-i386\", \"elf32-i386\", \"elf32-i386\")\nOUTPUT_ARCH(i386)\nENTRY(_start)\n\nSECTIONS\n{\n    /* Link the kernel at this address: \".\" means the current address */\n        /* Must be equal to KERNLINK */\n    . = 0x80100000;\n\n    .text : AT(0x100000) {\n        *(.text .stub .text.* .gnu.linkonce.t.*)\n    }\n\n    PROVIDE(etext = .); /* Define the 'etext' symbol to this value */\n\n    .rodata : {\n        *(.rodata .rodata.* .gnu.linkonce.r.*)\n    }\n\n    /* Include debugging information in kernel memory */\n    .stab : {\n        PROVIDE(__STAB_BEGIN__ = .);\n        *(.stab);\n        PROVIDE(__STAB_END__ = .);\n        BYTE(0)     /* Force the linker to allocate space\n                   for this section */\n    }\n\n    .stabstr : {\n        PROVIDE(__STABSTR_BEGIN__ = .);\n        *(.stabstr);\n        PROVIDE(__STABSTR_END__ = .);\n        BYTE(0)     /* Force the linker to allocate space\n                   for this section */\n    }\n\n    /* Adjust the address for the data segment to the next page */\n    . = ALIGN(0x1000);\n\n    /* Conventionally, Unix linkers provide pseudo-symbols\n     * etext, edata, and end, at the end of the text, data, and bss.\n     * For the kernel mapping, we need the address at the beginning\n     * of the data section, but that's not one of the conventional\n     * symbols, because the convention started before there was a\n     * read-only rodata section between text and data. */\n    PROVIDE(data = .);\n\n    /* The data segment */\n    .data : {\n        *(.data)\n    }\n\n    PROVIDE(edata = .);\n\n    .bss : {\n        *(.bss)\n    }\n\n    PROVIDE(end = .);\n\n    /DISCARD/ : {\n        *(.eh_frame .note.GNU-stack)\n    }\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "loops",
                "typescript",
                "angular",
                "condition",
                "ngfor"
            ],
            "owner": {
                "reputation": 1689,
                "user_id": 2196157,
                "user_type": "registered",
                "accept_rate": 70,
                "profile_image": "https://i.stack.imgur.com/hNJCe.jpg?s=128&g=1",
                "display_name": "Guillaume Le Mi&#232;re",
                "link": "https://stackoverflow.com/users/2196157/guillaume-le-mi%c3%a8re"
            },
            "is_answered": true,
            "view_count": 5503,
            "accepted_answer_id": 38753531,
            "answer_count": 2,
            "score": 2,
            "last_activity_date": 1524165844,
            "creation_date": 1470076563,
            "last_edit_date": 1524165535,
            "question_id": 38705800,
            "body_markdown": "I come here because after many hours googling, I didn&#39;t find a way to use an alternative stop condition for the loops made with the built-in directive : *ngFor.\r\n\r\nActually any *ngFor finish the loop with this condition : `index &lt; array.length`. I want to know if there is a way to end a loop with another condition like : `i &lt; myVariable`.\r\n\r\nIf you wonder why I want to do that, it&#39;s because I&#39;m working on a picture gallery working this way :\r\n\r\n    &lt;div *ngFor=&quot;let pic of pics; let i = index&quot;&gt;\r\n        &lt;div *ngIf=&quot;whichRowType(i) == 3&quot;&gt;\r\n            &lt;small&gt;pic[whichIndex(i)].id&lt;/small&gt;\r\n            &lt;small&gt;pic[currentIndex + 1].id&lt;/small&gt;\r\n            &lt;small&gt;pic[currentIndex + 2].id&lt;/small&gt;\r\n        &lt;/div&gt;\r\n    \r\n        &lt;div *ngIf=&quot;whichRowType(i) == 2&quot;&gt;\r\n            &lt;small&gt;pic[whichIndex(i)].id&lt;/small&gt;\r\n            &lt;small&gt;pic[currentIndex + 1].id&lt;/small&gt;\r\n        &lt;/div&gt;\r\n    \r\n        &lt;div *ngIf=&quot;whichRowType(i) == 1&quot;&gt;\r\n            &lt;small&gt;pic[whichIndex(i)].id&lt;/small&gt;\r\n        &lt;/div&gt;\r\n    &lt;/div&gt;\r\n\r\nIn this example, I create a row each 3 pics. I have three types of rows :\r\n - Display one pic,\r\n - Display two pics,\r\n - Display three pics.\r\n\r\nThe problem is, the index of my first picture on each row is always inferior to the index used to display the row. So if I want to be able to display all my pictures, I have to be able to change my ending condition of my *ngFor.\r\n\r\nThank you very much for your help!",
            "link": "https://stackoverflow.com/questions/38705800/angular-2-ngfor-is-there-a-way-to-use-an-alternative-end-condition",
            "title": "Angular 2 - *ngFor : Is there a way to use an alternative end condition?",
            "body": "<p>I come here because after many hours googling, I didn't find a way to use an alternative stop condition for the loops made with the built-in directive : *ngFor.</p>\n\n<p>Actually any *ngFor finish the loop with this condition : <code>index &lt; array.length</code>. I want to know if there is a way to end a loop with another condition like : <code>i &lt; myVariable</code>.</p>\n\n<p>If you wonder why I want to do that, it's because I'm working on a picture gallery working this way :</p>\n\n<pre><code>&lt;div *ngFor=\"let pic of pics; let i = index\"&gt;\n    &lt;div *ngIf=\"whichRowType(i) == 3\"&gt;\n        &lt;small&gt;pic[whichIndex(i)].id&lt;/small&gt;\n        &lt;small&gt;pic[currentIndex + 1].id&lt;/small&gt;\n        &lt;small&gt;pic[currentIndex + 2].id&lt;/small&gt;\n    &lt;/div&gt;\n\n    &lt;div *ngIf=\"whichRowType(i) == 2\"&gt;\n        &lt;small&gt;pic[whichIndex(i)].id&lt;/small&gt;\n        &lt;small&gt;pic[currentIndex + 1].id&lt;/small&gt;\n    &lt;/div&gt;\n\n    &lt;div *ngIf=\"whichRowType(i) == 1\"&gt;\n        &lt;small&gt;pic[whichIndex(i)].id&lt;/small&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n</code></pre>\n\n<p>In this example, I create a row each 3 pics. I have three types of rows :\n - Display one pic,\n - Display two pics,\n - Display three pics.</p>\n\n<p>The problem is, the index of my first picture on each row is always inferior to the index used to display the row. So if I want to be able to display all my pictures, I have to be able to change my ending condition of my *ngFor.</p>\n\n<p>Thank you very much for your help!</p>\n"
        },
        {
            "tags": [
                "node.js",
                "express",
                "asynchronous",
                "async-await"
            ],
            "owner": {
                "reputation": 15,
                "user_id": 8478827,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/10213096841152254/picture?type=large",
                "display_name": "JakeTheDane",
                "link": "https://stackoverflow.com/users/8478827/jakethedane"
            },
            "is_answered": true,
            "view_count": 31,
            "accepted_answer_id": 49928756,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1524165840,
            "creation_date": 1524163246,
            "question_id": 49928058,
            "body_markdown": "Okay, i am not entirely sure what i am doing wrong. \r\n\r\nI have to do multiple SQL query&#39;s, and i really don&#39;t want them all nested within each other. So i am trying to work with Async/Await so that i can call my query&#39;s as functions instead.\r\n\r\nThe thing is, that it seems like my function doesn&#39;t get to finish before it continues, although i have written await in front. \r\n\r\nIf i try to call my &quot;test&quot; function, it does return the string &quot;text&quot; for me to console log.\r\n\r\nI have also tried to add &quot;async&quot; in front of my &quot;get_all_events&quot; function. \r\n\r\nI hope someone can help me out\r\n\r\n    const db_connection = require(&#39;../../helpers/db/db_config.js&#39;).connect_local()\r\n    \r\n    module.exports = function (server) {\r\n        server.get(&#39;/events&#39;, async function(req, res, next) {\r\n                try {\r\n                    var event_data = await get_all_events()\r\n                    console.log(&quot;Try Catch CL: &quot;, event_data)\r\n                        \r\n                    res.render(&#39;public assets/pages/events&#39;, {\r\n                        event_data  : event_data\r\n                    });\r\n    \r\n                } catch (error) {\r\n                    \r\n                }      \r\n            }\r\n        );\r\n    }\r\n    function test(){\r\n        return &quot;test&quot;\r\n    }\r\n    function get_all_events () {\r\n        let sql_get_all_events = `\r\n            SELECT event_id, event_name, event_text, event_dateStart, event_dateEnd, event_imagePath, type_id, type_name, type_text, type_imagePath, type_color,seating_id\r\n            FROM \r\n                ((tb_events \r\n            INNER JOIN \r\n                tb_event_types ON type_id = fk_event_type)\r\n            INNER JOIN \r\n                tb_seating ON seating_id = fk_seating)`\r\n            \r\n        \r\n        \r\n        db_connection.query(sql_get_all_events, function (error, event_data) {\r\n            if (error) \r\n                throw(error)\r\n            else\r\n                return event_data\r\n        });\r\n    }\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49928058/node-js-express-asyn-await",
            "title": "Node.js Express Asyn/await",
            "body": "<p>Okay, i am not entirely sure what i am doing wrong. </p>\n\n<p>I have to do multiple SQL query's, and i really don't want them all nested within each other. So i am trying to work with Async/Await so that i can call my query's as functions instead.</p>\n\n<p>The thing is, that it seems like my function doesn't get to finish before it continues, although i have written await in front. </p>\n\n<p>If i try to call my \"test\" function, it does return the string \"text\" for me to console log.</p>\n\n<p>I have also tried to add \"async\" in front of my \"get_all_events\" function. </p>\n\n<p>I hope someone can help me out</p>\n\n<pre><code>const db_connection = require('../../helpers/db/db_config.js').connect_local()\n\nmodule.exports = function (server) {\n    server.get('/events', async function(req, res, next) {\n            try {\n                var event_data = await get_all_events()\n                console.log(\"Try Catch CL: \", event_data)\n\n                res.render('public assets/pages/events', {\n                    event_data  : event_data\n                });\n\n            } catch (error) {\n\n            }      \n        }\n    );\n}\nfunction test(){\n    return \"test\"\n}\nfunction get_all_events () {\n    let sql_get_all_events = `\n        SELECT event_id, event_name, event_text, event_dateStart, event_dateEnd, event_imagePath, type_id, type_name, type_text, type_imagePath, type_color,seating_id\n        FROM \n            ((tb_events \n        INNER JOIN \n            tb_event_types ON type_id = fk_event_type)\n        INNER JOIN \n            tb_seating ON seating_id = fk_seating)`\n\n\n\n    db_connection.query(sql_get_all_events, function (error, event_data) {\n        if (error) \n            throw(error)\n        else\n            return event_data\n    });\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "nginx",
                "centos"
            ],
            "owner": {
                "reputation": 146,
                "user_id": 3959744,
                "user_type": "registered",
                "accept_rate": 0,
                "profile_image": "https://i.stack.imgur.com/CBrLa.jpg?s=128&g=1",
                "display_name": "Ali Abbas",
                "link": "https://stackoverflow.com/users/3959744/ali-abbas"
            },
            "is_answered": false,
            "view_count": 120,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165839,
            "creation_date": 1491745032,
            "last_edit_date": 1524165839,
            "question_id": 43307329,
            "body_markdown": "I am facing an error of permission I am working on ruby on rails deployments on nginx. But I am not sure what is the glitch.\r\n\r\n&gt; [error] 10886#0: *6\r\n&gt; &quot;/home/deploy/projects/project_name/public/index.html&quot; is forbidden\r\n&gt; (13: Permission denied)\r\n\r\nHere is my vhost\r\n\r\n    server {\r\n        listen  80;\r\n        server_name    blog.test.com;\r\n        #return 301    http://blog.test.com$request_uri;\r\n    \r\n        #root /home/deploy/projects/project_name/public;\r\n    \r\n        \r\n    \t\r\n    \tlocation / {\r\n    \t\troot /home/deploy/projects/project_name/public;\r\n            #try_files $uri $uri/ /index.html;\r\n            index  index.html  index.htm;\t\r\n            autoindex on;\r\n            allow   127.0.0.1;\r\n        }\r\n    \r\n    }",
            "link": "https://stackoverflow.com/questions/43307329/permission-denied-forbidding-nginx-centos",
            "title": "Permission denied forbidding nginx centos",
            "body": "<p>I am facing an error of permission I am working on ruby on rails deployments on nginx. But I am not sure what is the glitch.</p>\n\n<blockquote>\n  <p>[error] 10886#0: *6\n  \"/home/deploy/projects/project_name/public/index.html\" is forbidden\n  (13: Permission denied)</p>\n</blockquote>\n\n<p>Here is my vhost</p>\n\n<pre><code>server {\n    listen  80;\n    server_name    blog.test.com;\n    #return 301    http://blog.test.com$request_uri;\n\n    #root /home/deploy/projects/project_name/public;\n\n\n\n    location / {\n        root /home/deploy/projects/project_name/public;\n        #try_files $uri $uri/ /index.html;\n        index  index.html  index.htm;   \n        autoindex on;\n        allow   127.0.0.1;\n    }\n\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "html",
                "image"
            ],
            "owner": {
                "reputation": 4770,
                "user_id": 70289,
                "user_type": "registered",
                "accept_rate": 85,
                "profile_image": "https://www.gravatar.com/avatar/9caa4e12ac7ee3ac5aef98fa4a351773?s=128&d=identicon&r=PG",
                "display_name": "Galilyou",
                "link": "https://stackoverflow.com/users/70289/galilyou"
            },
            "is_answered": true,
            "view_count": 160439,
            "accepted_answer_id": 980910,
            "answer_count": 19,
            "score": 172,
            "last_activity_date": 1524165836,
            "creation_date": 1244724178,
            "last_edit_date": 1482926262,
            "question_id": 980855,
            "body_markdown": "Is there any way to render a default image in an HTML `&lt;img&gt;` tag, in case the `src` attribute is invalid (using only HTML)?  If not, what would be your lightweight way to work around it? \r\n",
            "link": "https://stackoverflow.com/questions/980855/inputting-a-default-image-in-case-the-src-attribute-of-an-html-img-is-not-vali",
            "title": "Inputting a default image in case the src attribute of an html &lt;img&gt; is not valid?",
            "body": "<p>Is there any way to render a default image in an HTML <code>&lt;img&gt;</code> tag, in case the <code>src</code> attribute is invalid (using only HTML)?  If not, what would be your lightweight way to work around it? </p>\n"
        },
        {
            "tags": [
                "c",
                "multithreading",
                "segmentation-fault",
                "pthreads"
            ],
            "owner": {
                "reputation": 23,
                "user_id": 7379715,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/a066a8ff507fec2aa18f3074f4cf7e33?s=128&d=identicon&r=PG&f=1",
                "display_name": "LeVentilo",
                "link": "https://stackoverflow.com/users/7379715/leventilo"
            },
            "is_answered": false,
            "view_count": 32,
            "answer_count": 0,
            "score": -1,
            "last_activity_date": 1524165831,
            "creation_date": 1524156757,
            "last_edit_date": 1524165831,
            "question_id": 49926356,
            "body_markdown": "I&#39;m currently working on the &quot;Dining philosophers problem&quot; in C for a school exercise.\r\n\r\nIt&#39;s working quite well, except that the program segfaults once every 100 or so run... I tried printing and checking everywhere to find where it occurs, I found that it was in the loop creating the thread and initializing some values. \r\n\r\nThe problem is that it seems to occur randomly in this loop (sometimes after a function, sometimes while initializing a variable).\r\n\r\nI tried valgrind, but segfaults every time and it doesn&#39;t seem to find the line where it happens. Tried printing, with the &quot;random&quot; issue happening...\r\n\r\nHere&#39;s the code, I really hope someone can help me...\r\n\r\n    pthread_mutex_t **chopstick_tab;\r\n\r\n    int init_table_malloc_part(t_philo **table_philo, int count)\r\n    {\r\n            table_philo[count] = malloc(sizeof(t_philo));\r\n            chopstick_tab[count] = malloc(sizeof(pthread_mutex_t) * 100);\r\n            if (table_philo[count] == NULL || chopstick_tab[count] == NULL)\r\n                    return (FAIL);\r\n            return (SUCCESS);\r\n    }\r\n     \r\n    int init_table_of_phil(t_philo **table_philo, data_t *init)\r\n    {\r\n            table_philo = malloc(sizeof(t_philo *) * (init-&gt;nb_philo + 1));\r\n            chopstick_tab = malloc(sizeof(pthread_mutex_t *) *\r\n                                    (init-&gt;nb_philo + 1));\r\n            if (table_philo == NULL || chopstick_tab == NULL)\r\n                    return (FAIL);\r\n            table_philo[init-&gt;nb_philo] = NULL;\r\n            chopstick_tab[init-&gt;nb_philo] = NULL;\r\n            for (int count = 0; count &lt; init-&gt;nb_philo; count++) {\r\n                    if (init_table_malloc_part(table_philo, count) == FAIL)\r\n                            return (FAIL);\r\n                    table_philo[count]-&gt;phil_value = count;\r\n                    table_philo[count]-&gt;how_many_eat = init-&gt;nb_eating;\r\n                    table_philo[count]-&gt;phil_total_nbr = init-&gt;nb_philo;\r\n                    table_philo[count]-&gt;status = H_REST;\r\n                    pthread_mutex_init(chopstick_tab[count], NULL);\r\n                    pthread_create(&amp;(table_philo[count]-&gt;phil_thread), NULL,\r\n                                    &amp;philosophe_does, (void *)table_philo[count]);\r\n            }\r\n            join_philo(table_philo);\r\n            return (SUCCESS);\r\n    }\r\n\r\nHere are the structures used\r\n\r\n    typedef struct  s_data\r\n    {\r\n            int nb_philo;\r\n            int nb_eating;\r\n    } data_t;\r\n     \r\n    typedef struct  s_philo\r\n    {\r\n            int phil_value;\r\n            int how_many_eat;\r\n            int phil_total_nbr;\r\n            pthread_t phil_thread;\r\n            pthread_cond_t phil_cond;\r\n            int status;\r\n    }t_philo;\r\n\r\nThanks\r\n\r\nEdit:\r\n\r\nHere&#39;s philosophe_does\r\n\r\n    void *philosophe_does(void *data)\r\n    {\r\n            t_philo *current_philo = (t_philo *)data;\r\n            int count = current_philo-&gt;how_many_eat;\r\n            while (count != 0){\r\n                    if (current_philo-&gt;status == H_REST)\r\n                            count = take_decision(current_philo, count);\r\n                    else if (current_philo-&gt;status == H_THINK)\r\n                            count = eat(current_philo, count);\r\n                    else if (current_philo-&gt;status == H_EAT)\r\n                            rest(current_philo);\r\n            }\r\n            return (NULL);\r\n    }\r\n\r\n\r\nRunning under gdb shows:\r\n\r\n    Thread 26 &quot;philo&quot; received signal SIGSEGV, Segmentation fault.\r\n    [Switching to Thread 0x7fff9d7fa700 (LWP 19577)]\r\n    __GI___pthread_mutex_lock (mutex=0x0) at ../nptl/pthread_mutex_lock.c:67\r\n    67\t../nptl/pthread_mutex_lock.c: Aucun fichier ou dossier de ce type.\r\n    (gdb) bt\r\n    #0  __GI___pthread_mutex_lock (mutex=0x0) at ../nptl/pthread_mutex_lock.c:67\r\n    #1  0x00007ffff7bcfc93 in ?? () from /home/samuel/PSU_2017/PSU_philosopher_2017/lib/libriceferee.so\r\n    #2  0x00005555555554e1 in first_case_eat ()\r\n    #3  0x0000555555555725 in eat ()\r\n    #4  0x0000555555555903 in take_decision ()\r\n    #5  0x000055555555513d in philosophe_does ()\r\n    #6  0x00007ffff79b17fc in start_thread (arg=0x7fff9d7fa700) at pthread_create.c:465\r\n    #7  0x00007ffff76deb5f in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95",
            "link": "https://stackoverflow.com/questions/49926356/unable-to-find-where-the-segfault-occurs-multithreaded-program",
            "title": "Unable to find where the segfault occurs (multithreaded program)",
            "body": "<p>I'm currently working on the \"Dining philosophers problem\" in C for a school exercise.</p>\n\n<p>It's working quite well, except that the program segfaults once every 100 or so run... I tried printing and checking everywhere to find where it occurs, I found that it was in the loop creating the thread and initializing some values. </p>\n\n<p>The problem is that it seems to occur randomly in this loop (sometimes after a function, sometimes while initializing a variable).</p>\n\n<p>I tried valgrind, but segfaults every time and it doesn't seem to find the line where it happens. Tried printing, with the \"random\" issue happening...</p>\n\n<p>Here's the code, I really hope someone can help me...</p>\n\n<pre><code>pthread_mutex_t **chopstick_tab;\n\nint init_table_malloc_part(t_philo **table_philo, int count)\n{\n        table_philo[count] = malloc(sizeof(t_philo));\n        chopstick_tab[count] = malloc(sizeof(pthread_mutex_t) * 100);\n        if (table_philo[count] == NULL || chopstick_tab[count] == NULL)\n                return (FAIL);\n        return (SUCCESS);\n}\n\nint init_table_of_phil(t_philo **table_philo, data_t *init)\n{\n        table_philo = malloc(sizeof(t_philo *) * (init-&gt;nb_philo + 1));\n        chopstick_tab = malloc(sizeof(pthread_mutex_t *) *\n                                (init-&gt;nb_philo + 1));\n        if (table_philo == NULL || chopstick_tab == NULL)\n                return (FAIL);\n        table_philo[init-&gt;nb_philo] = NULL;\n        chopstick_tab[init-&gt;nb_philo] = NULL;\n        for (int count = 0; count &lt; init-&gt;nb_philo; count++) {\n                if (init_table_malloc_part(table_philo, count) == FAIL)\n                        return (FAIL);\n                table_philo[count]-&gt;phil_value = count;\n                table_philo[count]-&gt;how_many_eat = init-&gt;nb_eating;\n                table_philo[count]-&gt;phil_total_nbr = init-&gt;nb_philo;\n                table_philo[count]-&gt;status = H_REST;\n                pthread_mutex_init(chopstick_tab[count], NULL);\n                pthread_create(&amp;(table_philo[count]-&gt;phil_thread), NULL,\n                                &amp;philosophe_does, (void *)table_philo[count]);\n        }\n        join_philo(table_philo);\n        return (SUCCESS);\n}\n</code></pre>\n\n<p>Here are the structures used</p>\n\n<pre><code>typedef struct  s_data\n{\n        int nb_philo;\n        int nb_eating;\n} data_t;\n\ntypedef struct  s_philo\n{\n        int phil_value;\n        int how_many_eat;\n        int phil_total_nbr;\n        pthread_t phil_thread;\n        pthread_cond_t phil_cond;\n        int status;\n}t_philo;\n</code></pre>\n\n<p>Thanks</p>\n\n<p>Edit:</p>\n\n<p>Here's philosophe_does</p>\n\n<pre><code>void *philosophe_does(void *data)\n{\n        t_philo *current_philo = (t_philo *)data;\n        int count = current_philo-&gt;how_many_eat;\n        while (count != 0){\n                if (current_philo-&gt;status == H_REST)\n                        count = take_decision(current_philo, count);\n                else if (current_philo-&gt;status == H_THINK)\n                        count = eat(current_philo, count);\n                else if (current_philo-&gt;status == H_EAT)\n                        rest(current_philo);\n        }\n        return (NULL);\n}\n</code></pre>\n\n<p>Running under gdb shows:</p>\n\n<pre><code>Thread 26 \"philo\" received signal SIGSEGV, Segmentation fault.\n[Switching to Thread 0x7fff9d7fa700 (LWP 19577)]\n__GI___pthread_mutex_lock (mutex=0x0) at ../nptl/pthread_mutex_lock.c:67\n67  ../nptl/pthread_mutex_lock.c: Aucun fichier ou dossier de ce type.\n(gdb) bt\n#0  __GI___pthread_mutex_lock (mutex=0x0) at ../nptl/pthread_mutex_lock.c:67\n#1  0x00007ffff7bcfc93 in ?? () from /home/samuel/PSU_2017/PSU_philosopher_2017/lib/libriceferee.so\n#2  0x00005555555554e1 in first_case_eat ()\n#3  0x0000555555555725 in eat ()\n#4  0x0000555555555903 in take_decision ()\n#5  0x000055555555513d in philosophe_does ()\n#6  0x00007ffff79b17fc in start_thread (arg=0x7fff9d7fa700) at pthread_create.c:465\n#7  0x00007ffff76deb5f in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95\n</code></pre>\n"
        },
        {
            "tags": [
                "asp.net-core",
                "openid",
                "asp.net-authorization"
            ],
            "owner": {
                "reputation": 4783,
                "user_id": 1157952,
                "user_type": "registered",
                "accept_rate": 66,
                "profile_image": "https://i.stack.imgur.com/uO5Fk.jpg?s=128&g=1",
                "display_name": "Catalin",
                "link": "https://stackoverflow.com/users/1157952/catalin"
            },
            "is_answered": false,
            "view_count": 13,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165830,
            "creation_date": 1524147605,
            "last_edit_date": 1524148052,
            "question_id": 49923452,
            "body_markdown": "I implemented openId connect to an AspNetCore application.\r\n\r\nWhen the user logs-in, i want to read a flag from db, and abort the login workflow if the user is locked.\r\n\r\nThe only event where i have access to the OpenId claims is `OnTokenValidated`\r\n\r\nIs it possible to abort the &quot;login&quot; workflow from OpenId?\r\n\r\n    services\r\n    \t.AddOpenIdConnect(&quot;Auth0&quot;, options =&gt; {\r\n    \t\t// code removed for simplicity\r\n    \t\t\r\n    \t\toptions.Events = new OpenIdConnectEvents\r\n    \t\t{\r\n    \t\t\tOnTokenValidated = async context =&gt;\r\n    \t\t\t{\r\n    \t\t\t\tIUsersRepository usersRepository = context.HttpContext.RequestServices.GetService&lt;IUsersRepository&gt;();\r\n    \r\n    \t\t\t\tClaimsPrincipal principal = context.Principal;\r\n    \t\t\t\tstring userId = principal.Claims.First(p =&gt; p.Type == &quot;user_id&quot;).Value;\r\n    \r\n    \t\t\t\tvar user = usersRepository.GetByExternalProviderIdentifier(userId, false);\r\n    \t\t\t\tif(user.IsLocked == true)\r\n    \t\t\t\t{\r\n    \t\t\t\t\t// although i redirect the user, the cookies are already created, and the user is logged-in.\r\n\r\n                        // How can i abort the login workflow? ie. prevent the cookies from being saved\r\n    \t\t\t\t\tstring redirectUrl = $&quot;/Auth/Login?error={WebUtility.UrlEncode(&quot;Your account is locked&quot;)}&quot;;\r\n    \t\t\t\t\tcontext.Response.Redirect(redirectUrl);\r\n    \t\t\t\t}\r\n    \t\t\t\t\r\n    \t\t\t\treturn Task.FromResult(true);\r\n    \t\t\t}\r\n    \t\t};\r\n    \t});",
            "link": "https://stackoverflow.com/questions/49923452/openidconnect-abort-workflow",
            "title": "OpenIdConnect abort workflow",
            "body": "<p>I implemented openId connect to an AspNetCore application.</p>\n\n<p>When the user logs-in, i want to read a flag from db, and abort the login workflow if the user is locked.</p>\n\n<p>The only event where i have access to the OpenId claims is <code>OnTokenValidated</code></p>\n\n<p>Is it possible to abort the \"login\" workflow from OpenId?</p>\n\n<pre><code>services\n    .AddOpenIdConnect(\"Auth0\", options =&gt; {\n        // code removed for simplicity\n\n        options.Events = new OpenIdConnectEvents\n        {\n            OnTokenValidated = async context =&gt;\n            {\n                IUsersRepository usersRepository = context.HttpContext.RequestServices.GetService&lt;IUsersRepository&gt;();\n\n                ClaimsPrincipal principal = context.Principal;\n                string userId = principal.Claims.First(p =&gt; p.Type == \"user_id\").Value;\n\n                var user = usersRepository.GetByExternalProviderIdentifier(userId, false);\n                if(user.IsLocked == true)\n                {\n                    // although i redirect the user, the cookies are already created, and the user is logged-in.\n\n                    // How can i abort the login workflow? ie. prevent the cookies from being saved\n                    string redirectUrl = $\"/Auth/Login?error={WebUtility.UrlEncode(\"Your account is locked\")}\";\n                    context.Response.Redirect(redirectUrl);\n                }\n\n                return Task.FromResult(true);\n            }\n        };\n    });\n</code></pre>\n"
        },
        {
            "tags": [
                "c#",
                "uwp",
                "bluetooth-lowenergy"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 8850829,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/de3cbd03a61864e541140d0528cdace5?s=128&d=identicon&r=PG&f=1",
                "display_name": "4L3X",
                "link": "https://stackoverflow.com/users/8850829/4l3x"
            },
            "is_answered": true,
            "view_count": 24,
            "accepted_answer_id": 49928752,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165828,
            "creation_date": 1524144836,
            "question_id": 49922455,
            "body_markdown": "I want to interact with my Mi Band 2 via C#. First, i want to take battery level. I already connect my device with band, and i take some values, but i think this not what i need.\r\n[I found uuids of services and characteristics and examples on Java, here][1]\r\n\r\n\r\n  [1]: https://github.com/aashari/mi-band-2\r\n\r\nBut author can handle received data, i am not.\r\n\r\n                    BluetoothLEDevice bluetoothLEDevice = await BluetoothLEDevice.FromIdAsync(args.Id);\r\n\r\n                // Parse Basic Service by UUID\r\n                var result = await bluetoothLEDevice.GetGattServicesForUuidAsync(Guid.Parse(&quot;0000fee0-0000-1000-8000-00805f9b34fb&quot;));\r\n\r\n                // Parse Battery Info Characteristic of this service\r\n                var characteristic = await result.Services[0].GetCharacteristicsForUuidAsync(Guid.Parse(&quot;00000006-0000-3512-2118-0009af100700&quot;));\r\n                GattReadResult gattReadResult = await characteristic.Characteristics[0].ReadValueAsync();\r\n                byte[] data;\r\n\r\n                // Read received data to byteArray\r\n                CryptographicBuffer.CopyToByteArray(gattReadResult.Value, out data);\r\n\r\n\r\n                // Just convert it to string. I Receive HEX Value, but i don&#39;t know what it mean. It&#39;s not battery percentage.\r\n                // 0F-4F-00-E2-07-04-0E-10-27-11-0C-E2-07-04-0E-13-19-16-0C-64\r\n                Debug.WriteLine(BitConverter.ToString(data));\r\n\r\nI read in other forums what battery percent saved in first byte (data[0]), but i get wrong number, it&#39;s not Battery Level.\r\n\r\n\r\nbyte[] data saves 20 int values. **None of them not Battery Percentage**.\r\n\r\nAm i wrong? How i can take Battery level value? ",
            "link": "https://stackoverflow.com/questions/49922455/uwp-mi-band-2-how-to-take-a-value-from-characteriscic",
            "title": "UWP Mi Band 2 How to take a value from characteriscic",
            "body": "<p>I want to interact with my Mi Band 2 via C#. First, i want to take battery level. I already connect my device with band, and i take some values, but i think this not what i need.\n<a href=\"https://github.com/aashari/mi-band-2\" rel=\"nofollow noreferrer\">I found uuids of services and characteristics and examples on Java, here</a></p>\n\n<p>But author can handle received data, i am not.</p>\n\n<pre><code>                BluetoothLEDevice bluetoothLEDevice = await BluetoothLEDevice.FromIdAsync(args.Id);\n\n            // Parse Basic Service by UUID\n            var result = await bluetoothLEDevice.GetGattServicesForUuidAsync(Guid.Parse(\"0000fee0-0000-1000-8000-00805f9b34fb\"));\n\n            // Parse Battery Info Characteristic of this service\n            var characteristic = await result.Services[0].GetCharacteristicsForUuidAsync(Guid.Parse(\"00000006-0000-3512-2118-0009af100700\"));\n            GattReadResult gattReadResult = await characteristic.Characteristics[0].ReadValueAsync();\n            byte[] data;\n\n            // Read received data to byteArray\n            CryptographicBuffer.CopyToByteArray(gattReadResult.Value, out data);\n\n\n            // Just convert it to string. I Receive HEX Value, but i don't know what it mean. It's not battery percentage.\n            // 0F-4F-00-E2-07-04-0E-10-27-11-0C-E2-07-04-0E-13-19-16-0C-64\n            Debug.WriteLine(BitConverter.ToString(data));\n</code></pre>\n\n<p>I read in other forums what battery percent saved in first byte (data[0]), but i get wrong number, it's not Battery Level.</p>\n\n<p>byte[] data saves 20 int values. <strong>None of them not Battery Percentage</strong>.</p>\n\n<p>Am i wrong? How i can take Battery level value? </p>\n"
        },
        {
            "tags": [
                "hadoop",
                "hdfs",
                "ubuntu-16.04",
                "hadoop2",
                "namenode"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9483057,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/51318d4b498ebb8e409ec4c60a76a266?s=128&d=identicon&r=PG",
                "display_name": "user9483057",
                "link": "https://stackoverflow.com/users/9483057/user9483057"
            },
            "is_answered": false,
            "view_count": 15,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165822,
            "creation_date": 1520913448,
            "last_edit_date": 1520913940,
            "question_id": 49248117,
            "body_markdown": "I have Hadoop 2.9.0 on Ubuntu at\r\n\r\n    /usr/local/hadoop\r\nBut when I try `start-dfs.sh`\r\nNo error is shown while starting namenode\r\nBut when I type `jps`, only\r\n\r\n    10900 SecondaryNameNode\r\n    11047 Jps\r\n    10696 DataNode\r\nSeams to have started, not namenode\r\n\r\nThings tried:\r\n=&gt; Removed temp files and formatted namenode `hadoop namenode -format`\r\n\r\nterminal:\r\n\r\n    blaze@blazian:/tmp$ start-dfs.sh\r\n    Starting namenodes on [localhost]\r\n    blaze@localhost&#39;s password: \r\n    localhost: starting namenode, logging to /usr/local/hadoop/logs/hadoop-blaze-namenode-blazian.out\r\n    blaze@localhost&#39;s password: \r\n    localhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-blaze-datanode-blazian.out\r\n    Starting secondary namenodes [0.0.0.0]\r\n    blaze@0.0.0.0&#39;s password: \r\n    0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-blaze-secondarynamenode-blazian.out\r\n    blaze@blazian:/tmp$ jps\r\n    10900 SecondaryNameNode\r\n    11047 Jps\r\n    10696 DataNode\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49248117/everything-else-starting-on-hadoop-pseudo-distributed-except-namenode",
            "title": "Everything else starting on Hadoop pseudo-distributed except namenode",
            "body": "<p>I have Hadoop 2.9.0 on Ubuntu at</p>\n\n<pre><code>/usr/local/hadoop\n</code></pre>\n\n<p>But when I try <code>start-dfs.sh</code>\nNo error is shown while starting namenode\nBut when I type <code>jps</code>, only</p>\n\n<pre><code>10900 SecondaryNameNode\n11047 Jps\n10696 DataNode\n</code></pre>\n\n<p>Seams to have started, not namenode</p>\n\n<p>Things tried:\n=> Removed temp files and formatted namenode <code>hadoop namenode -format</code></p>\n\n<p>terminal:</p>\n\n<pre><code>blaze@blazian:/tmp$ start-dfs.sh\nStarting namenodes on [localhost]\nblaze@localhost's password: \nlocalhost: starting namenode, logging to /usr/local/hadoop/logs/hadoop-blaze-namenode-blazian.out\nblaze@localhost's password: \nlocalhost: starting datanode, logging to /usr/local/hadoop/logs/hadoop-blaze-datanode-blazian.out\nStarting secondary namenodes [0.0.0.0]\nblaze@0.0.0.0's password: \n0.0.0.0: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-blaze-secondarynamenode-blazian.out\nblaze@blazian:/tmp$ jps\n10900 SecondaryNameNode\n11047 Jps\n10696 DataNode\n</code></pre>\n"
        },
        {
            "tags": [
                "c++",
                "malloc"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9669173,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Niklas",
                "link": "https://stackoverflow.com/users/9669173/niklas"
            },
            "is_answered": false,
            "view_count": 30,
            "closed_date": 1524167195,
            "answer_count": 1,
            "score": -6,
            "last_activity_date": 1524165818,
            "creation_date": 1524163498,
            "question_id": 49928138,
            "body_markdown": "Hey guys I have to make a maximum sub sum program for my c++ course and I did it like they said in the pseudo code. It looks similar to the one I made last term in Java but every time I try to use this with a biger input the program stops and says this:\r\n&gt;maxtest: malloc.c:2394: sysmalloc: Assertion `(old_top == initial_top (av) &amp;&amp; old_size == 0) || ((unsigned long) (old_size) &gt;= MINSIZE &amp;&amp; prev_inuse (old_top) &amp;&amp; ((unsigned long) old_end &amp; (pagesize - 1)) == 0)&#39; failed.\r\nAborted (core dumped)\r\n\r\n\r\nI don&#39;t really know anything about malloc and my instructor didn&#39;t know why this happened either. \r\n\r\nThis program was run on ubuntu. It uses bash(?) to input the the test file and output in a new file. The test file is just composed of the length of the array and the content of the array. It looks something like this\r\n\r\n    4  -2 3 5 -9\r\n\r\nHere is the code.\r\n\r\n        #include&lt;iostream&gt;\r\n        #include&lt;stdio.h&gt;\r\n        #include&lt;vector&gt;\r\n        #include&lt;algorithm&gt;\r\n        using namespace std;\r\n\r\n\r\n        vector&lt;int&gt; maxC(vector&lt;int&gt; a);\r\n\r\n        //read the file, create an array for each sequence and call the \r\n        function\r\n        int main()\r\n        {\r\n            int l;\r\n            while(cin &gt;&gt; l)\r\n        {\r\n        if(l!=0)\r\n        {\r\n            //read the file and save it in the array\r\n            vector&lt;int&gt; a(l);\r\n            for(int i=0; i&lt;l;i++)\r\n            {\r\n                cin &gt;&gt; a[i];\r\n            }\r\n            //call the function and print the return value\r\n            vector&lt;int&gt; b=maxC(a);\r\n            cout &lt;&lt;&quot;(&quot;&lt;&lt; b[1] &lt;&lt; &quot;,&quot; &lt;&lt; b[2] &lt;&lt; &quot;,&quot; &lt;&lt; b[0] &lt;&lt; &quot;)\\r&quot; &lt;&lt;endl;\r\n        }else\r\n            cout &lt;&lt; &quot;(1,0,0)\\r&quot; &lt;&lt;endl;\r\n    }\r\n    return(0);\r\n    }\r\n\r\nThis is the actual function\r\n\r\n    int p=0;        //just a variable to see where it crashes\r\n    vector&lt;int&gt; maxC(vector&lt;int&gt; a)\r\n    {\r\n        vector&lt;int&gt; ret={0, 1, 0};      //standard return value\r\n        int n=a.size();\r\n\r\n        p++;\r\n        cout &lt;&lt; n &lt;&lt; &quot; &quot; &lt;&lt; p &lt;&lt;endl;\r\n\r\n        int m=n/2;      //middle of array\r\n        //base cases\r\n        if(n==0)\r\n        return(ret);\r\n\r\n    if(n==1 &amp;&amp; a[0]&gt;0)\r\n        return{a[0], 0, 0};\r\n\r\n    else if(n==1)\r\n        return{0, 1, 0};\r\n\r\n    //create left and right half of the input array\r\n    vector&lt;int&gt; l(m);\r\n    vector&lt;int&gt; r(n-m);\r\n\r\n    for(int i=0;i&lt;=m;i++)\r\n        l[i]=a[i];\r\n\r\n    for(int i=m+1;i&lt;n;i++)\r\n        r[i-m+1]=a[i];\r\n\r\n    //call the same function on the new arrays\r\n    vector&lt;int&gt; m1=maxC(l);\r\n    vector&lt;int&gt; m2=maxC(r);\r\n\r\n    //search the left half from the middle to find the longest sub sum from the middle\r\n    int mle=0, sle=0, li=0;\r\n    for(int i=m;i&gt;=0;i--)\r\n    {\r\n        sle+=a[i];\r\n        if(sle&gt;mle)\r\n        {\r\n            mle = sle;\r\n            li=i;\r\n        }\r\n    }\r\n    //same with the right half\r\n    int mri=0, sri=0, ri=0;\r\n    for(int i=m+1;i&lt;n;i++)\r\n    {\r\n        sri+=a[i];\r\n        if(sri&gt;mri)\r\n        {\r\n                mri = sri;\r\n                ri=i;\r\n            }\r\n        }\r\n        //search the maximum of the the left, right and middle and return it\r\n        int m3=mle+mri;\r\n        int maxi = max(m1[0],m2[0]);\r\n        maxi =max(maxi, m3);\r\n        if(maxi==m1[0])\r\n            ret=m1;\r\n        else if(maxi==m2[0])\r\n            ret=m2;\r\n        else if(maxi==m3)\r\n            ret={m3,li,ri};\r\n\r\n        return(ret);\r\n    }\r\n\r\nSorry for the shitty formatting of the code but I still have to complete some more assignments and don&#39;t have much time.",
            "link": "https://stackoverflow.com/questions/49928138/malloc-c2394-assertion-error-in-c",
            "closed_reason": "off-topic",
            "title": "malloc.c:2394 Assertion error in c++",
            "body": "<p>Hey guys I have to make a maximum sub sum program for my c++ course and I did it like they said in the pseudo code. It looks similar to the one I made last term in Java but every time I try to use this with a biger input the program stops and says this:</p>\n\n<blockquote>\n  <p>maxtest: malloc.c:2394: sysmalloc: Assertion `(old_top == initial_top (av) &amp;&amp; old_size == 0) || ((unsigned long) (old_size) >= MINSIZE &amp;&amp; prev_inuse (old_top) &amp;&amp; ((unsigned long) old_end &amp; (pagesize - 1)) == 0)' failed.\n  Aborted (core dumped)</p>\n</blockquote>\n\n<p>I don't really know anything about malloc and my instructor didn't know why this happened either. </p>\n\n<p>This program was run on ubuntu. It uses bash(?) to input the the test file and output in a new file. The test file is just composed of the length of the array and the content of the array. It looks something like this</p>\n\n<pre><code>4  -2 3 5 -9\n</code></pre>\n\n<p>Here is the code.</p>\n\n<pre><code>    #include&lt;iostream&gt;\n    #include&lt;stdio.h&gt;\n    #include&lt;vector&gt;\n    #include&lt;algorithm&gt;\n    using namespace std;\n\n\n    vector&lt;int&gt; maxC(vector&lt;int&gt; a);\n\n    //read the file, create an array for each sequence and call the \n    function\n    int main()\n    {\n        int l;\n        while(cin &gt;&gt; l)\n    {\n    if(l!=0)\n    {\n        //read the file and save it in the array\n        vector&lt;int&gt; a(l);\n        for(int i=0; i&lt;l;i++)\n        {\n            cin &gt;&gt; a[i];\n        }\n        //call the function and print the return value\n        vector&lt;int&gt; b=maxC(a);\n        cout &lt;&lt;\"(\"&lt;&lt; b[1] &lt;&lt; \",\" &lt;&lt; b[2] &lt;&lt; \",\" &lt;&lt; b[0] &lt;&lt; \")\\r\" &lt;&lt;endl;\n    }else\n        cout &lt;&lt; \"(1,0,0)\\r\" &lt;&lt;endl;\n}\nreturn(0);\n}\n</code></pre>\n\n<p>This is the actual function</p>\n\n<pre><code>int p=0;        //just a variable to see where it crashes\nvector&lt;int&gt; maxC(vector&lt;int&gt; a)\n{\n    vector&lt;int&gt; ret={0, 1, 0};      //standard return value\n    int n=a.size();\n\n    p++;\n    cout &lt;&lt; n &lt;&lt; \" \" &lt;&lt; p &lt;&lt;endl;\n\n    int m=n/2;      //middle of array\n    //base cases\n    if(n==0)\n    return(ret);\n\nif(n==1 &amp;&amp; a[0]&gt;0)\n    return{a[0], 0, 0};\n\nelse if(n==1)\n    return{0, 1, 0};\n\n//create left and right half of the input array\nvector&lt;int&gt; l(m);\nvector&lt;int&gt; r(n-m);\n\nfor(int i=0;i&lt;=m;i++)\n    l[i]=a[i];\n\nfor(int i=m+1;i&lt;n;i++)\n    r[i-m+1]=a[i];\n\n//call the same function on the new arrays\nvector&lt;int&gt; m1=maxC(l);\nvector&lt;int&gt; m2=maxC(r);\n\n//search the left half from the middle to find the longest sub sum from the middle\nint mle=0, sle=0, li=0;\nfor(int i=m;i&gt;=0;i--)\n{\n    sle+=a[i];\n    if(sle&gt;mle)\n    {\n        mle = sle;\n        li=i;\n    }\n}\n//same with the right half\nint mri=0, sri=0, ri=0;\nfor(int i=m+1;i&lt;n;i++)\n{\n    sri+=a[i];\n    if(sri&gt;mri)\n    {\n            mri = sri;\n            ri=i;\n        }\n    }\n    //search the maximum of the the left, right and middle and return it\n    int m3=mle+mri;\n    int maxi = max(m1[0],m2[0]);\n    maxi =max(maxi, m3);\n    if(maxi==m1[0])\n        ret=m1;\n    else if(maxi==m2[0])\n        ret=m2;\n    else if(maxi==m3)\n        ret={m3,li,ri};\n\n    return(ret);\n}\n</code></pre>\n\n<p>Sorry for the shitty formatting of the code but I still have to complete some more assignments and don't have much time.</p>\n"
        },
        {
            "tags": [
                "scala"
            ],
            "owner": {
                "reputation": 763,
                "user_id": 4353033,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/599e46280c78d89345d3dc1b150c00ef?s=128&d=identicon&r=PG&f=1",
                "display_name": "Anurag Sharma",
                "link": "https://stackoverflow.com/users/4353033/anurag-sharma"
            },
            "is_answered": true,
            "view_count": 41,
            "answer_count": 2,
            "score": 4,
            "last_activity_date": 1524165812,
            "creation_date": 1524125790,
            "question_id": 49916037,
            "body_markdown": "[![enter image description here][1]][1]\r\n\r\n\r\nI am referring to official [documentation][2]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/0vJLB.png\r\n  [2]: https://docs.scala-lang.org/overviews/collections/performance-characteristics.html\r\n\r\nwhich shows prepend complexity of Vector as &quot;effectively constant&quot; (eC). But my understanding is that for a vector, prepend would mean that all other indexes need to be adjusted as well which will make the operation O(n) or L (linear). Could anyone please explain how is prepend in vector eC (effectively constant).",
            "link": "https://stackoverflow.com/questions/49916037/prepend-complexity-of-scala-vector",
            "title": "Prepend complexity of scala vector",
            "body": "<p><a href=\"https://i.stack.imgur.com/0vJLB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0vJLB.png\" alt=\"enter image description here\"></a></p>\n\n<p>I am referring to official <a href=\"https://docs.scala-lang.org/overviews/collections/performance-characteristics.html\" rel=\"nofollow noreferrer\">documentation</a></p>\n\n<p>which shows prepend complexity of Vector as \"effectively constant\" (eC). But my understanding is that for a vector, prepend would mean that all other indexes need to be adjusted as well which will make the operation O(n) or L (linear). Could anyone please explain how is prepend in vector eC (effectively constant).</p>\n"
        },
        {
            "tags": [
                "c++",
                "opencl"
            ],
            "owner": {
                "reputation": 1950,
                "user_id": 982049,
                "user_type": "registered",
                "accept_rate": 98,
                "profile_image": "https://i.stack.imgur.com/eq1S9.jpg?s=128&g=1",
                "display_name": "Cool_Coder",
                "link": "https://stackoverflow.com/users/982049/cool-coder"
            },
            "is_answered": true,
            "view_count": 1300,
            "accepted_answer_id": 22119936,
            "answer_count": 4,
            "score": 4,
            "last_activity_date": 1524165809,
            "creation_date": 1393598584,
            "question_id": 22098210,
            "body_markdown": "I am currently learning OpencL and am finding it somewhat difficult to understand how it actually works.\r\nI am using MinGW compiler with ATI APP SDK.\r\nWhen I run the target I get error message\r\n\r\n![enter image description here][1]\r\n\r\nI have not placed any OpenCL.dll in the same folder as my application.\r\nNow searching a bit on Windows I can find this dll in\r\n\r\n    C:/Windows/SysWOW64\r\n    C:/Windows/System32/DriverStore/...\r\n    C:/Windows/System32\r\n    C:/Program Files(x86)/AMD APP SDK /...\r\n\r\nSo my question is how should I deploy my application?\r\nShould I distribute OpenCL.dll with my application?\r\n\r\n  [1]: http://i.stack.imgur.com/bdmwE.png",
            "link": "https://stackoverflow.com/questions/22098210/deploying-opencl-application",
            "title": "Deploying OpenCL application?",
            "body": "<p>I am currently learning OpencL and am finding it somewhat difficult to understand how it actually works.\nI am using MinGW compiler with ATI APP SDK.\nWhen I run the target I get error message</p>\n\n<p><img src=\"https://i.stack.imgur.com/bdmwE.png\" alt=\"enter image description here\"></p>\n\n<p>I have not placed any OpenCL.dll in the same folder as my application.\nNow searching a bit on Windows I can find this dll in</p>\n\n<pre><code>C:/Windows/SysWOW64\nC:/Windows/System32/DriverStore/...\nC:/Windows/System32\nC:/Program Files(x86)/AMD APP SDK /...\n</code></pre>\n\n<p>So my question is how should I deploy my application?\nShould I distribute OpenCL.dll with my application?</p>\n"
        },
        {
            "tags": [
                "c#",
                "algorithm"
            ],
            "owner": {
                "reputation": 1301,
                "user_id": 3394884,
                "user_type": "registered",
                "accept_rate": 68,
                "profile_image": "https://i.stack.imgur.com/LqQhR.png?s=128&g=1",
                "display_name": "kuskmen",
                "link": "https://stackoverflow.com/users/3394884/kuskmen"
            },
            "is_answered": true,
            "view_count": 80,
            "answer_count": 4,
            "score": -3,
            "last_activity_date": 1524165794,
            "creation_date": 1524086846,
            "last_edit_date": 1524088624,
            "question_id": 49909276,
            "body_markdown": "I want to solve following problem using Quicksort.\r\n\r\nI have *n* string in an array where each string is guaranteed to be positive positive number with no leading zeros and digits between 1 and 10^6 inclusive. I did it using regular quicksort with `BigInteger` struct but I&#39;ve got a lot of timeout cases which led me to think I need to optimize my way of comparisons and drop the parsing from `string[]` and back to `BigInteger[]` and back to `string[]` so I&#39;ve decided to sort it as it is. Here is my code:\r\n\r\n    static void swap(string[] array, int first, int second)\r\n    {\r\n        var temp = array[first];\r\n        array[first] = array[second];\r\n        array[second] = temp;\r\n    }\r\n\r\n    static void quickSort(string[] array, int left, int right)\r\n    {\r\n        if (left &gt;= right) return;\r\n        var pivot = array[(left + right) / 2];\r\n        var index = partition(array, left, right, pivot);\r\n        quickSort(array, left, index - 1);\r\n        quickSort(array, index, right);\r\n    }\r\n\r\n    static int partition(string[] array, int left, int right, string pivot)\r\n    {\r\n        while(left &lt;= right)\r\n        {\r\n            while (left &lt; array.Length &amp;&amp; !array[left].IsBigger(pivot)) left++;\r\n            while (right &lt; array.Length &amp;&amp; array[right].IsBigger(pivot)) right--;\r\n            if (left &lt;= right)\r\n            {\r\n                swap(array, left, right);\r\n                left++;\r\n                right--;\r\n            }\r\n        }\r\n\r\n        return left;\r\n    }\r\n\r\n    static bool IsBigger(this string a, string b)\r\n    {\r\n        if (a.Length &lt; b.Length) return false;\r\n        else if(a.Length &gt; b.Length) return true;\r\n\r\n        for (int i = 0; i &lt; a.Length; i++)\r\n        {\r\n            if (a[i] &gt; b[i]) return true;\r\n            else return false;\r\n        }\r\n\r\n        return false;\r\n    }\r\n\r\nBut then I am getting SO exception in `IsBigger` function when the input is so small as `[ &quot;31415926535897932384626433832795&quot;, &quot;1&quot;, &quot;3&quot;, &quot;10&quot;, &quot;3&quot;, &quot;5&quot; ]` and I can&#39;t seem to try why.\r\n\r\nThere is no funny moments calling quicksort - this is how I do it `quickSort(unsorted, 0, unsorted.Length - 1);`\r\n\r\n\r\n----------\r\n## What I&#39;ve tried so far ##\r\n\r\n - Sounds crazy but I&#39;ve tried to force .NET ensure that this method needs more stack size as to me everything looks okay by calling `RuntimeHelpers.EnsureSufficientExecutionStack();` in `IsBigger` but didn&#39;t work also.",
            "link": "https://stackoverflow.com/questions/49909276/why-am-i-getting-stackoverflow-exception-in-this-helper-function-of-quicksort",
            "title": "Why am I getting stackoverflow exception in this helper function of quicksort?",
            "body": "<p>I want to solve following problem using Quicksort.</p>\n\n<p>I have <em>n</em> string in an array where each string is guaranteed to be positive positive number with no leading zeros and digits between 1 and 10^6 inclusive. I did it using regular quicksort with <code>BigInteger</code> struct but I've got a lot of timeout cases which led me to think I need to optimize my way of comparisons and drop the parsing from <code>string[]</code> and back to <code>BigInteger[]</code> and back to <code>string[]</code> so I've decided to sort it as it is. Here is my code:</p>\n\n<pre><code>static void swap(string[] array, int first, int second)\n{\n    var temp = array[first];\n    array[first] = array[second];\n    array[second] = temp;\n}\n\nstatic void quickSort(string[] array, int left, int right)\n{\n    if (left &gt;= right) return;\n    var pivot = array[(left + right) / 2];\n    var index = partition(array, left, right, pivot);\n    quickSort(array, left, index - 1);\n    quickSort(array, index, right);\n}\n\nstatic int partition(string[] array, int left, int right, string pivot)\n{\n    while(left &lt;= right)\n    {\n        while (left &lt; array.Length &amp;&amp; !array[left].IsBigger(pivot)) left++;\n        while (right &lt; array.Length &amp;&amp; array[right].IsBigger(pivot)) right--;\n        if (left &lt;= right)\n        {\n            swap(array, left, right);\n            left++;\n            right--;\n        }\n    }\n\n    return left;\n}\n\nstatic bool IsBigger(this string a, string b)\n{\n    if (a.Length &lt; b.Length) return false;\n    else if(a.Length &gt; b.Length) return true;\n\n    for (int i = 0; i &lt; a.Length; i++)\n    {\n        if (a[i] &gt; b[i]) return true;\n        else return false;\n    }\n\n    return false;\n}\n</code></pre>\n\n<p>But then I am getting SO exception in <code>IsBigger</code> function when the input is so small as <code>[ \"31415926535897932384626433832795\", \"1\", \"3\", \"10\", \"3\", \"5\" ]</code> and I can't seem to try why.</p>\n\n<p>There is no funny moments calling quicksort - this is how I do it <code>quickSort(unsorted, 0, unsorted.Length - 1);</code></p>\n\n<hr>\n\n<h2>What I've tried so far</h2>\n\n<ul>\n<li>Sounds crazy but I've tried to force .NET ensure that this method needs more stack size as to me everything looks okay by calling <code>RuntimeHelpers.EnsureSufficientExecutionStack();</code> in <code>IsBigger</code> but didn't work also.</li>\n</ul>\n"
        },
        {
            "tags": [
                "c++",
                "kruskals-algorithm",
                "prims-algorithm"
            ],
            "owner": {
                "reputation": 15,
                "user_id": 2387629,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/6ea3f54cae9dd287516b9e13bb38b3d5?s=128&d=identicon&r=PG",
                "display_name": "Jordan Ward",
                "link": "https://stackoverflow.com/users/2387629/jordan-ward"
            },
            "is_answered": false,
            "view_count": 20,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165783,
            "creation_date": 1524165783,
            "question_id": 49928741,
            "body_markdown": "I wrote this program for my computer science class but my professor told us there is another algorithm called prim&#39;s algorithm. I want to convert my MST function written using Kruskal&#39;s algorithm to be written using Prim&#39;s algorithm and nothing else to be changed. Can someone help me out with this? Not sure if you will want to see all of my code so if you don&#39;t need to see some parts, let me know so I can edit this question. Thanks!\r\n\r\n    #include &lt;cstdio&gt;\r\n    #include &lt;iostream&gt;\r\n    #include &lt;algorithm&gt;\r\n    #include &lt;vector&gt;\r\n\r\n    using namespace std;\r\n\r\n    #define MAX 1000\r\n\r\n    struct Edge {\r\n\t    int c1, c2, w;\r\n    };\r\n\r\n    int parents[MAX + 5];\r\n    vector&lt;Edge&gt; graph; // Store the inputted graph (src, dest, weight).\r\n    vector&lt;Edge&gt; selected_edges; // Store the edges which is selected for the MST from given graph.\r\n\r\n    bool comp(const Edge&amp;, const Edge&amp;);\r\n    void make_set(int);\r\n    int findParent(int);\r\n    int Kruskal_MST(int);\r\n\r\n\r\n    int main() {\r\n\t    Edge e;\r\n\t    int cities, edges, testCases;\r\n\t\r\n\t    cin &gt;&gt; testCases;\r\n\t\r\n\t    for(int i = 0; i &lt; testCases; i++) {\r\n\t\t    cin &gt;&gt; cities;\r\n\t\t    cin &gt;&gt; edges;\r\n\t\r\n\t\t    for(int j = 0; j &lt; edges; j++) {\t\t\r\n\t\t\t    int city1, city2, weight;\r\n\t\t\t    cin &gt;&gt; city1 &gt;&gt; city2 &gt;&gt; weight;\r\n\t\t\r\n\t\t\t    e.c1 = city1;\r\n\t\t\t    e.c2 = city2;\r\n\t\t\t    e.w = weight;\r\n\t\t\t    graph.push_back(e);\r\n\t\t    }\r\n\t\r\n\t\t    int maxweight = Kruskal_MST(cities);\r\n\t\r\n\t\t    cout &lt;&lt; maxweight &lt;&lt; &quot;\\n&quot;;\r\n\t\r\n\t\t    for(int i = 0; i &lt; selected_edges.size(); i++) {\r\n\t\t\t    cout &lt;&lt; &quot;(&quot; &lt;&lt; selected_edges[i].c1 &lt;&lt; &quot;, &quot; &lt;&lt; selected_edges[i].c2 &lt;&lt; &quot;, &quot; &lt;&lt; selected_edges[i].w &lt;&lt; &quot;) &quot;;\r\n\t\t    }\r\n\t\t\r\n\t\tcout &lt;&lt; &quot;\\n&quot;;\r\n\t    }\r\n\t\r\n\t    return 0;\r\n    }\r\n\r\n    bool comp (const Edge&amp; l, const Edge&amp; r) {\r\n\t\r\n\t    return l.w &lt; r.w;\r\n    }\r\n\r\n    int Kruskal_MST(int cities) {\r\n\t\r\n\t    make_set(cities);\r\n\t\r\n\t    sort(graph.begin(), graph.end(), comp);\r\n\t\r\n\t    int edgeCounter = 0;\r\n\t    int maxweight = 0;\r\n\t    int len = graph.size();\r\n\t\r\n\t    for(int i = 0; i &lt; len; i++){\r\n\t\t\r\n\t\t    int parent_of_u = findParent(graph[i].c1);\r\n\t\t    int parent_of_v = findParent(graph[i].c2);\r\n\t\t\r\n\t\t    if(parent_of_u != parent_of_v) {\r\n\t\t\t    if(graph[i].w &gt; maxweight)\r\n\t\t\t\t    maxweight = graph[i].w;\r\n\t\t\t\r\n\t\t\t    parents[parent_of_u] = parent_of_v;\r\n\t\t\t    selected_edges.push_back(graph[i]);\r\n\t\t\t\r\n\t\t\t    edgeCounter++;\r\n\t\t\t    if(edgeCounter == cities - 1)\r\n\t\t\t\t    break;\r\n\t\t    }\r\n\t\t\r\n\t    }\r\n\t\r\n\t    return maxweight;\r\n    }\r\n\r\n    void make_set(int cities) {\r\n\t    for(int i = 1; i &lt;= cities; i++)\r\n\t\t    parents[i] = i;\r\n\t\r\n\t    return;\r\n    }\r\n\r\n    int findParent(int r) {\r\n\t    if(r == parents[r])\r\n\t\t    return r;\r\n\t\r\n\t    return parents[r] = findParent(parents[r]);\r\n    }\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49928741/how-to-convert-my-kruskal-mst-function-to-prims-algorithm",
            "title": "How to convert my Kruskal MST function to Prim&#39;s algorithm?",
            "body": "<p>I wrote this program for my computer science class but my professor told us there is another algorithm called prim's algorithm. I want to convert my MST function written using Kruskal's algorithm to be written using Prim's algorithm and nothing else to be changed. Can someone help me out with this? Not sure if you will want to see all of my code so if you don't need to see some parts, let me know so I can edit this question. Thanks!</p>\n\n<pre><code>#include &lt;cstdio&gt;\n#include &lt;iostream&gt;\n#include &lt;algorithm&gt;\n#include &lt;vector&gt;\n\nusing namespace std;\n\n#define MAX 1000\n\nstruct Edge {\n    int c1, c2, w;\n};\n\nint parents[MAX + 5];\nvector&lt;Edge&gt; graph; // Store the inputted graph (src, dest, weight).\nvector&lt;Edge&gt; selected_edges; // Store the edges which is selected for the MST from given graph.\n\nbool comp(const Edge&amp;, const Edge&amp;);\nvoid make_set(int);\nint findParent(int);\nint Kruskal_MST(int);\n\n\nint main() {\n    Edge e;\n    int cities, edges, testCases;\n\n    cin &gt;&gt; testCases;\n\n    for(int i = 0; i &lt; testCases; i++) {\n        cin &gt;&gt; cities;\n        cin &gt;&gt; edges;\n\n        for(int j = 0; j &lt; edges; j++) {        \n            int city1, city2, weight;\n            cin &gt;&gt; city1 &gt;&gt; city2 &gt;&gt; weight;\n\n            e.c1 = city1;\n            e.c2 = city2;\n            e.w = weight;\n            graph.push_back(e);\n        }\n\n        int maxweight = Kruskal_MST(cities);\n\n        cout &lt;&lt; maxweight &lt;&lt; \"\\n\";\n\n        for(int i = 0; i &lt; selected_edges.size(); i++) {\n            cout &lt;&lt; \"(\" &lt;&lt; selected_edges[i].c1 &lt;&lt; \", \" &lt;&lt; selected_edges[i].c2 &lt;&lt; \", \" &lt;&lt; selected_edges[i].w &lt;&lt; \") \";\n        }\n\n    cout &lt;&lt; \"\\n\";\n    }\n\n    return 0;\n}\n\nbool comp (const Edge&amp; l, const Edge&amp; r) {\n\n    return l.w &lt; r.w;\n}\n\nint Kruskal_MST(int cities) {\n\n    make_set(cities);\n\n    sort(graph.begin(), graph.end(), comp);\n\n    int edgeCounter = 0;\n    int maxweight = 0;\n    int len = graph.size();\n\n    for(int i = 0; i &lt; len; i++){\n\n        int parent_of_u = findParent(graph[i].c1);\n        int parent_of_v = findParent(graph[i].c2);\n\n        if(parent_of_u != parent_of_v) {\n            if(graph[i].w &gt; maxweight)\n                maxweight = graph[i].w;\n\n            parents[parent_of_u] = parent_of_v;\n            selected_edges.push_back(graph[i]);\n\n            edgeCounter++;\n            if(edgeCounter == cities - 1)\n                break;\n        }\n\n    }\n\n    return maxweight;\n}\n\nvoid make_set(int cities) {\n    for(int i = 1; i &lt;= cities; i++)\n        parents[i] = i;\n\n    return;\n}\n\nint findParent(int r) {\n    if(r == parents[r])\n        return r;\n\n    return parents[r] = findParent(parents[r]);\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "centos",
                "firewall",
                "firewalld"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9351387,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/2555699d1f473caab32011351999885c?s=128&d=identicon&r=PG&f=1",
                "display_name": "nemean lion",
                "link": "https://stackoverflow.com/users/9351387/nemean-lion"
            },
            "is_answered": false,
            "view_count": 6,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165763,
            "creation_date": 1524164339,
            "last_edit_date": 1524165763,
            "question_id": 49928372,
            "body_markdown": "I&#39;ve been put in charge of troubleshooting connection errors with a web application hosted on a company Centos 7 server.\r\n\r\nUpon initial inspection it turned out that the Firewalld settings for the active zone did not include http/https, and that \r\n\r\n    sudo firewall-cmd --permanent --add-service=http\r\n    sudo firewall-cmd --reload\r\n\r\nwould resolve the issue, but only temporarily, in spite of the `--permanent` flag.\r\n\r\nThe `--permanent` rule change persists through httpd and Firewalld restarts, but occasionally is overruled and reset to the default zone configuration, without http or https enabled, at specific points in the day.  \r\n\r\nIf anyone has any advice about what might be overruling Firewalld or how to diagnose this issue I would be most appreciative.",
            "link": "https://stackoverflow.com/questions/49928372/firewalld-zone-resetting",
            "title": "Firewalld zone resetting",
            "body": "<p>I've been put in charge of troubleshooting connection errors with a web application hosted on a company Centos 7 server.</p>\n\n<p>Upon initial inspection it turned out that the Firewalld settings for the active zone did not include http/https, and that </p>\n\n<pre><code>sudo firewall-cmd --permanent --add-service=http\nsudo firewall-cmd --reload\n</code></pre>\n\n<p>would resolve the issue, but only temporarily, in spite of the <code>--permanent</code> flag.</p>\n\n<p>The <code>--permanent</code> rule change persists through httpd and Firewalld restarts, but occasionally is overruled and reset to the default zone configuration, without http or https enabled, at specific points in the day.  </p>\n\n<p>If anyone has any advice about what might be overruling Firewalld or how to diagnose this issue I would be most appreciative.</p>\n"
        },
        {
            "tags": [
                "azure-data-lake"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 4436428,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/683727741/picture?type=large",
                "display_name": "Vipinkumar Jha",
                "link": "https://stackoverflow.com/users/4436428/vipinkumar-jha"
            },
            "is_answered": false,
            "view_count": 14,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165758,
            "creation_date": 1523968686,
            "question_id": 49878362,
            "body_markdown": "I have 3 folder on on prem servefr, and each folder having several files .\r\nmy aim to load the files from onprem server to data lake incrementally , so once we copied the file to data lake next time only new files need to be moved .\r\n\r\nthanks in advance\r\nvipin jha\r\n",
            "link": "https://stackoverflow.com/questions/49878362/azure-data-lake-incremental-copy-task-from-onprem-to-data-lake-storage",
            "title": "azure data lake incremental copy task from onprem to data lake storage",
            "body": "<p>I have 3 folder on on prem servefr, and each folder having several files .\nmy aim to load the files from onprem server to data lake incrementally , so once we copied the file to data lake next time only new files need to be moved .</p>\n\n<p>thanks in advance\nvipin jha</p>\n"
        },
        {
            "tags": [
                "python",
                "fabric"
            ],
            "owner": {
                "reputation": 3207,
                "user_id": 633961,
                "user_type": "registered",
                "accept_rate": 66,
                "profile_image": "https://i.stack.imgur.com/0c29q.jpg?s=128&g=1",
                "display_name": "guettli",
                "link": "https://stackoverflow.com/users/633961/guettli"
            },
            "is_answered": true,
            "view_count": 6502,
            "accepted_answer_id": 19338483,
            "answer_count": 3,
            "score": 11,
            "last_activity_date": 1524165757,
            "creation_date": 1381497041,
            "last_edit_date": 1397037350,
            "question_id": 19319014,
            "body_markdown": "I want to get the content of a remote file with fabric, without creating a temporary file.\r\n\r\n",
            "link": "https://stackoverflow.com/questions/19319014/how-to-get-the-content-of-a-remote-file-without-a-local-temporary-file-with-fabr",
            "title": "How to get the content of a remote file without a local temporary file with fabric",
            "body": "<p>I want to get the content of a remote file with fabric, without creating a temporary file.</p>\n"
        },
        {
            "tags": [
                "tweets"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 2105895,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/8d4f7cfc9662fcc664883318af14a0a1?s=128&d=identicon&r=PG",
                "display_name": "Don Baechtel",
                "link": "https://stackoverflow.com/users/2105895/don-baechtel"
            },
            "is_answered": false,
            "view_count": 9,
            "answer_count": 0,
            "score": -3,
            "last_activity_date": 1524165755,
            "creation_date": 1524165755,
            "question_id": 49928730,
            "body_markdown": "How come no one ever responds to my tweets to @azuresupport #azTechHelp ?\r\n\r\nWhy isn&#39;t this Azure support channel working?",
            "link": "https://stackoverflow.com/questions/49928730/no-response-to-tweets-azuresupport-aztechhelp",
            "title": "No Response to tweets @azuresupport #azTechHelp",
            "body": "<p>How come no one ever responds to my tweets to @azuresupport #azTechHelp ?</p>\n\n<p>Why isn't this Azure support channel working?</p>\n"
        },
        {
            "tags": [
                "android",
                "gradle",
                "dart",
                "flutter"
            ],
            "owner": {
                "reputation": 1244,
                "user_id": 1173794,
                "user_type": "registered",
                "accept_rate": 45,
                "profile_image": "https://www.gravatar.com/avatar/66d73a8a5284ac9cce9bc79983c93b43?s=128&d=identicon&r=PG",
                "display_name": "HotIceCream",
                "link": "https://stackoverflow.com/users/1173794/hoticecream"
            },
            "is_answered": true,
            "view_count": 15,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165744,
            "creation_date": 1524160941,
            "question_id": 49927441,
            "body_markdown": "I have an existing Android project.\r\nAlso, I created a new flutter project. I copied my project to it. Now I have such tree in the file system:\r\n\r\n\r\n    my_flutter_project/\r\n        android/\r\n            my_android_module_name/\r\n               src/...\r\n        lib/...\r\n        ios/...\r\n\r\nWhen I try to run flutter project I have such error:\r\n\r\n    No application found for TargetPlatform.android_arm64.\r\n    Is your project missing an android/app/src/main/AndroidManifest.xml?\r\n\r\nSo I should somewhere write `my_android_module_name` instead `app` but where?",
            "link": "https://stackoverflow.com/questions/49927441/use-custom-name-for-android-module-in-flutter-project",
            "title": "Use custom name for android module in flutter project",
            "body": "<p>I have an existing Android project.\nAlso, I created a new flutter project. I copied my project to it. Now I have such tree in the file system:</p>\n\n<pre><code>my_flutter_project/\n    android/\n        my_android_module_name/\n           src/...\n    lib/...\n    ios/...\n</code></pre>\n\n<p>When I try to run flutter project I have such error:</p>\n\n<pre><code>No application found for TargetPlatform.android_arm64.\nIs your project missing an android/app/src/main/AndroidManifest.xml?\n</code></pre>\n\n<p>So I should somewhere write <code>my_android_module_name</code> instead <code>app</code> but where?</p>\n"
        },
        {
            "tags": [
                "ios",
                "dynamic",
                "swift"
            ],
            "owner": {
                "reputation": 1958,
                "user_id": 770313,
                "user_type": "registered",
                "accept_rate": 75,
                "profile_image": "https://i.stack.imgur.com/Vjtmx.png?s=128&g=1",
                "display_name": "possen",
                "link": "https://stackoverflow.com/users/770313/possen"
            },
            "is_answered": true,
            "view_count": 1513,
            "accepted_answer_id": 26290606,
            "answer_count": 1,
            "score": 5,
            "last_activity_date": 1524165732,
            "creation_date": 1412903948,
            "last_edit_date": 1429913608,
            "question_id": 26290469,
            "body_markdown": "How do you instantiate a type dynamically based upon a lookup value in a dictionary in Swift? \r\n\r\n",
            "link": "https://stackoverflow.com/questions/26290469/create-a-swift-object-from-a-dictionary",
            "title": "Create a Swift Object from a Dictionary",
            "body": "<p>How do you instantiate a type dynamically based upon a lookup value in a dictionary in Swift? </p>\n"
        },
        {
            "tags": [
                "c#",
                "ironpython"
            ],
            "owner": {
                "reputation": 506,
                "user_id": 231238,
                "user_type": "registered",
                "accept_rate": 45,
                "profile_image": "https://www.gravatar.com/avatar/79eacf8ee1b8da82f5baffd6ba94054e?s=128&d=identicon&r=PG",
                "display_name": "LOST",
                "link": "https://stackoverflow.com/users/231238/lost"
            },
            "is_answered": false,
            "view_count": 12,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165730,
            "creation_date": 1524165730,
            "question_id": 49928724,
            "body_markdown": "I am trying to directly invoke IronPython&#39;s built-in modules from C#. It looks like I&#39;m missing some important initialization, that I can&#39;t find anywhere in the code.\r\n\r\nHere&#39;s what I do:\r\n\r\n    namespace py.consoleio\r\n    {\r\n        using IronPython.Runtime;\r\n        using Microsoft.Scripting.Hosting;\r\n        using Microsoft.Scripting.Hosting.Providers;\r\n        using Microsoft.Scripting.Runtime;\r\n    \r\n        public static class consoleio\r\n        {\r\n            public static string name;\r\n    \r\n            static void Main()\r\n            {\r\n                var setup = new ScriptRuntimeSetup();\r\n                setup.LanguageSetups.Add(\r\n                    IronPython.Hosting.Python.CreateLanguageSetup(null));\r\n                var dlrRuntime = new ScriptRuntime(setup);\r\n                var scriptDomainManager = HostingHelpers.GetDomainManager(dlrRuntime);\r\n                var pythonContext = new PythonContext(scriptDomainManager, null);\r\n                var context = new CodeContext(new PythonDictionary(), new ModuleContext(new PythonDictionary(), DefaultContext.DefaultPythonContext));\r\n                name = IronPython.Modules.Builtin.input(context, &quot;What is your name?\\n&quot;);\r\n                IronPython.Modules.Builtin.print(context, &quot;Hi, %s.&quot;, consoleio.name);\r\n                System.GC.KeepAlive(pythonContext);\r\n            }\r\n        }\r\n    }\r\n\r\nThat properly outputs &quot;What is your name?&quot;, but then crashes trying to decode input: unknown encoding: cp437.\r\n\r\nNow I&#39;ve already found, that encodings are initialized in Src/StdLib/Lib/encodings/__init__.py\r\nI can&#39;t find how it gets to loading this module in a normal IronPython run (e.g. a console host), so I can&#39;t reproduce it in C# program.\r\n\r\nMy goal here is to invoke IronPython functions without dynamic dispatch.",
            "link": "https://stackoverflow.com/questions/49928724/how-to-properly-setup-ironpython-to-directly-invoke-io-from-c",
            "title": "How to properly setup IronPython to directly invoke IO from C#?",
            "body": "<p>I am trying to directly invoke IronPython's built-in modules from C#. It looks like I'm missing some important initialization, that I can't find anywhere in the code.</p>\n\n<p>Here's what I do:</p>\n\n<pre><code>namespace py.consoleio\n{\n    using IronPython.Runtime;\n    using Microsoft.Scripting.Hosting;\n    using Microsoft.Scripting.Hosting.Providers;\n    using Microsoft.Scripting.Runtime;\n\n    public static class consoleio\n    {\n        public static string name;\n\n        static void Main()\n        {\n            var setup = new ScriptRuntimeSetup();\n            setup.LanguageSetups.Add(\n                IronPython.Hosting.Python.CreateLanguageSetup(null));\n            var dlrRuntime = new ScriptRuntime(setup);\n            var scriptDomainManager = HostingHelpers.GetDomainManager(dlrRuntime);\n            var pythonContext = new PythonContext(scriptDomainManager, null);\n            var context = new CodeContext(new PythonDictionary(), new ModuleContext(new PythonDictionary(), DefaultContext.DefaultPythonContext));\n            name = IronPython.Modules.Builtin.input(context, \"What is your name?\\n\");\n            IronPython.Modules.Builtin.print(context, \"Hi, %s.\", consoleio.name);\n            System.GC.KeepAlive(pythonContext);\n        }\n    }\n}\n</code></pre>\n\n<p>That properly outputs \"What is your name?\", but then crashes trying to decode input: unknown encoding: cp437.</p>\n\n<p>Now I've already found, that encodings are initialized in Src/StdLib/Lib/encodings/<strong>init</strong>.py\nI can't find how it gets to loading this module in a normal IronPython run (e.g. a console host), so I can't reproduce it in C# program.</p>\n\n<p>My goal here is to invoke IronPython functions without dynamic dispatch.</p>\n"
        },
        {
            "tags": [
                "python",
                "unit-testing"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 5352483,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e3dbaeb70e6883507ec898894c86847d?s=128&d=identicon&r=PG&f=1",
                "display_name": "X.S",
                "link": "https://stackoverflow.com/users/5352483/x-s"
            },
            "is_answered": false,
            "view_count": 17,
            "closed_date": 1524165922,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165725,
            "creation_date": 1524165725,
            "question_id": 49928723,
            "body_markdown": "How do I test for a re-raised exception in Python ?\r\n\r\nHere is my function that I want to test:\r\n\r\n    def myfunc(self):\r\n        try:\r\n            temp = otherfunc.get(&#39;key&#39;)\r\n        except KeyError as e:\r\n            raise CustomException\r\n\r\nHere is my test function (assuming otherfunc always raises KeyError):\r\n\r\n    def test_myfunc(self):\r\n        self.assertRaises(CustomException, myfunc())\r\n\r\nResults in error !\r\n\r\n        ======================================================================\r\n    ERROR: \r\n    ---------------------------------------------------------------------\r\n    Traceback (most recent call last):\r\n    KeyError\r\n\r\nI want to make sure that myfunc raises a CustomException when otherfunc raises KeyError. How can I do this ?",
            "link": "https://stackoverflow.com/questions/49928723/python-unit-test-re-raised-exception",
            "closed_reason": "duplicate",
            "title": "Python unit test re-raised exception",
            "body": "<p>How do I test for a re-raised exception in Python ?</p>\n\n<p>Here is my function that I want to test:</p>\n\n<pre><code>def myfunc(self):\n    try:\n        temp = otherfunc.get('key')\n    except KeyError as e:\n        raise CustomException\n</code></pre>\n\n<p>Here is my test function (assuming otherfunc always raises KeyError):</p>\n\n<pre><code>def test_myfunc(self):\n    self.assertRaises(CustomException, myfunc())\n</code></pre>\n\n<p>Results in error !</p>\n\n<pre><code>    ======================================================================\nERROR: \n---------------------------------------------------------------------\nTraceback (most recent call last):\nKeyError\n</code></pre>\n\n<p>I want to make sure that myfunc raises a CustomException when otherfunc raises KeyError. How can I do this ?</p>\n"
        },
        {
            "tags": [
                "python",
                "validation",
                "tensorflow",
                "dropout"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 6307437,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/6e7fc32a6e3abe444ccd0e74d4a3a105?s=128&d=identicon&r=PG&f=1",
                "display_name": "Manel Guzm&#225;n",
                "link": "https://stackoverflow.com/users/6307437/manel-guzm%c3%a1n"
            },
            "is_answered": false,
            "view_count": 54,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524165713,
            "creation_date": 1524012046,
            "last_edit_date": 1524098681,
            "question_id": 49889421,
            "body_markdown": "I have the following problem. \r\n\r\nI am trying to train a 3d CNN in tensorflow. I have separated the data in three data sets, train, validation and test. \r\n\r\nThe main problem is that when I test the validation set after 5 epoch of training the output of the model is the nearly the same for the 5 images.\r\n(this is the output of the last layer without any softmax)\r\n\r\n    2018-04-17 23:30:35.134318 Prediction: [[0.8185656  2.7571523 ]                     \r\n    [0.8200048  2.7590456 ]\r\n     [0.8185656  2.7571523 ]\r\n     [0.8200048  2.7590458 ]\r\n     [0.7751368  2.7532804 ]\r\n     [0.82061136 2.7588618 ]\r\n     [0.8130686  2.7821052 ]\r\n     [0.83537185 2.7514493 ]\r\n     [0.8200041  2.7590454 ]\r\n     [0.81701267 2.7519925 ]\r\n     [0.8424163  2.8674953 ]\r\n     [0.82000506 2.7590454 ]\r\n     [0.81999433 2.7590487 ]\r\n     [0.81701267 2.7519925 ]\r\n\r\nHowever, if i do the same for trainning set I get a conventional prediction.\r\n\r\nI have fully check the data sets and both are correct and in the same conditions. \r\n\r\nThis is my mode used to build the model and do the training:  \r\n\r\nclass Cnn3DMRI(object):\r\n\r\n\r\n    def weight_variable(self, shape):\r\n        initial = tf.truncated_normal(shape, stddev=0.1)\r\n        return tf.Variable(initial)\r\n\r\n    def bias_variable(self, shape):\r\n        initial = tf.constant(0.1, shape=shape)\r\n        return tf.Variable(initial)\r\n\r\n    def conv3d(self, x, W):\r\n        return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding=&#39;SAME&#39;)\r\n\r\n    def maxpool3d(self, x):\r\n        #                        size of window         movement of window\r\n        return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding=&#39;SAME&#39;)\r\n\r\n    def dense_to_one_hot(self, labels_dense, num_classes):\r\n        &quot;&quot;&quot;Convert class labels from scalars to one-hot vectors.&quot;&quot;&quot;\r\n        num_labels = labels_dense.shape[0]\r\n        index_offset = np.arange(num_labels) * num_classes\r\n        labels_one_hot = np.zeros((num_labels, num_classes))\r\n        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\r\n        return labels_one_hot\r\n\r\n\r\n    def wrapper_image(self, full_image_set, full_label_set, last_batch=0, batch_size=5):\r\n        batch_img = full_image_set[last_batch:batch_size+last_batch, :, :, :]\r\n        batch_label = full_label_set[last_batch:batch_size+last_batch]\r\n        return batch_img, batch_label, batch_size+last_batch\r\n\r\n\r\n    def convolutional_neural_network(self, x, img_sz, n_slices):\r\n        weights = {\r\n            &#39;W_conv1&#39;: self.weight_variable([6, 8, 8, 1, 32]),\r\n            &#39;W_conv2&#39;: self.weight_variable([2, 5, 5, 32, 48]),\r\n            &#39;W_conv3&#39;: self.weight_variable([2, 3, 3, 48, 64]),\r\n            &#39;W_conv4&#39;: self.weight_variable([2, 2, 2, 64, 64]),\r\n            &#39;W_fc&#39;: self.weight_variable([int(\r\n                math.ceil(n_slices / 8) * (math.ceil(img_sz / 8) * math.ceil(img_sz / 8) *\r\n                                            64)),\r\n                                          2048]),\r\n            &#39;W_fc2&#39;: self.weight_variable([2048, 1024]),\r\n            &#39;out&#39;: self.weight_variable([1024, 2])\r\n        }\r\n\r\n        biases = {\r\n            &#39;b_conv1&#39;: self.bias_variable([32]),\r\n            &#39;b_conv2&#39;: self.bias_variable([48]),\r\n            &#39;b_conv3&#39;: self.bias_variable([64]),\r\n            &#39;b_conv4&#39;: self.bias_variable([64]),\r\n            &#39;b_fc&#39;: self.bias_variable([2048]),\r\n            &#39;b_fc2&#39;: self.bias_variable([1024]),\r\n            &#39;out&#39;: self.bias_variable([2])\r\n        }\r\n\r\n        self.x_im = tf.reshape(x, shape=[-1, n_slices, img_sz, img_sz, 1])\r\n\r\n        conv1 = tf.tanh(self.conv3d(self.x_im, weights[&#39;W_conv1&#39;]) + biases[&#39;b_conv1&#39;])\r\n        conv1 =self.maxpool3d(conv1)\r\n\r\n        conv2 = tf.tanh(self.conv3d(conv1, weights[&#39;W_conv2&#39;]) + biases[&#39;b_conv2&#39;])\r\n        conv2 = self.maxpool3d(conv2)\r\n\r\n        conv3 = tf.tanh(self.conv3d(conv2, weights[&#39;W_conv3&#39;]) + biases[&#39;b_conv3&#39;])\r\n        conv3 = self.maxpool3d(conv3)\r\n        conv4 = tf.tanh(self.conv3d(conv3, weights[&#39;W_conv4&#39;]) + biases[&#39;b_conv4&#39;])\r\n\r\n        fc = tf.reshape(conv4, [-1,int(math.ceil(n_slices/8)*math.ceil(img_sz/8)*math.ceil(\r\n            img_sz/8))*64])\r\n        fc = tf.tanh(tf.matmul(fc, weights[&#39;W_fc&#39;])+biases[&#39;b_fc&#39;])\r\n        fc = tf.tanh(tf.matmul(fc, weights[&#39;W_fc2&#39;])+biases[&#39;b_fc2&#39;])\r\n        fc = tf.nn.dropout(fc, self.keep_prob)\r\n\r\n        output = tf.matmul(fc, weights[&#39;out&#39;])+biases[&#39;out&#39;]\r\n        return output\r\n\r\n    def test_validation_set(self, sess, data_validation, label_validation, valid_batch_size=60):\r\n\r\n        batch_img, batch_label, last_batch = self.wrapper_image(\r\n            data_validation, label_validation, self.last_valid_batch, valid_batch_size\r\n        )\r\n\r\n        \r\n        batch_label = self.dense_to_one_hot(\r\n            np.array(batch_label, dtype=np.int),2\r\n            ).astype(np.float32)\r\n\r\n\r\n        if last_batch+valid_batch_size &lt; len(label_validation):\r\n            self.last_valid_batch = last_batch\r\n        else:\r\n            self.last_valid_batch = 0\r\n\r\n        pred, c, validation_accuracy = sess.run(\r\n            [self.prediction, self.cost, self.accuracy], feed_dict={\r\n                self.x: batch_img, self.y_: batch_label, self.keep_prob: 1.0\r\n            }\r\n        )\r\n        \r\n\r\n        self.log(&quot;Prediction: &quot;+str(pred))\r\n        self.log(&quot;Label: &quot;+str(batch_label))\r\n\r\n        self.log(&quot;Validation accuracy: &quot;+str(validation_accuracy))\r\n        self.log(&quot;Validation cost: &quot;+str(c))\r\n        return validation_accuracy, c\r\n\r\n\r\n    def train_neural_network(self, data_img, labels,  data_validation, label_validation,\r\n                             batch_size, img_sz, n_slices, last_batch,\r\n                             keep_rate, model_path):\r\n\r\n        self.prediction = self.convolutional_neural_network(self.x, img_sz, n_slices)\r\n        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y_,\r\n                                                                      logits=self.prediction))\r\n        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\r\n        correct_prediction = tf.equal(tf.argmax(self.prediction, 1), tf.argmax(self.y_, 1))\r\n        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\n        hm_epochs = 1000\r\n        saver = tf.train.Saver(tf.trainable_variables())\r\n        epoch_loss = 0\r\n        epoch_loss_mean = []\r\n        n_epoch = 0\r\n        learning_rate = 1e-4\r\n        self.last_valid_batch = 0\r\n        min_valid_cost = 0\r\n        all_valid_cost = []\r\n        model_path_train = &#39;model_train/my_model.ckpt&#39;\r\n\r\n        with tf.Session() as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            if model_path:\r\n                pass\r\n                #saver.restore(sess, model_path_train)\r\n            while n_epoch &lt; hm_epochs:\r\n                if len(data_img)&gt;last_batch+batch_size:\r\n                    with tf.device(&#39;/cpu:0&#39;):\r\n                        #batch_img, batch_label, last_batch = self.get_image(\r\n                        #    data_img, labels, last_batch, batch_size, img_sz, n_slices\r\n                        #)\r\n                        batch_img, batch_label, last_batch = self.wrapper_image(data_img, labels, last_batch, batch_size)\r\n\r\n                    print &quot;Batch label images: &quot;+str(batch_label)\r\n                    batch_label = self.dense_to_one_hot(np.array(batch_label, dtype=np.int),\r\n                                                        2).astype(np.float32)\r\n                else:\r\n                    with tf.device(&#39;/cpu:0&#39;):\r\n                        restbatch = last_batch + batch_size - len(data_img)\r\n\r\n                        batch_img = np.concatenate((\r\n                            self.wrapper_image(data_img, labels, last_batch, len(data_img) -\r\n                                               last_batch)[0],\r\n                            self.wrapper_image(data_img, labels, last_batch, len(data_img) -\r\n                                               last_batch)[0]\r\n                        ))\r\n\r\n                        batch_label = np.concatenate((\r\n                            self.wrapper_image(data_img, labels, last_batch, len(data_img) -\r\n                                               last_batch)[1],\r\n                            self.wrapper_image(data_img, labels, last_batch, len(data_img) -\r\n                                               last_batch)[1]\r\n                        ))\r\n\r\n                    batch_label = self.dense_to_one_hot(np.array(batch_label, dtype=np.int),\r\n                                                        2).astype(\r\n                    np.float32)\r\n                    last_batch = restbatch\r\n\r\n                    ####### at the end of EACH EPOCH ###\r\n                    epoch_loss_mean.append(epoch_loss)\r\n                    print &quot;epoch loss mean: &quot;+str(epoch_loss_mean)\r\n                    epoch_loss = 0\r\n                    n_epoch += 1\r\n                    print &quot;n_epoch: &quot;+str(n_epoch)\r\n                    if model_path:\r\n                        saver.save(sess, model_path_train)\r\n\r\n                    if not n_epoch % 5:\r\n                        valid_accuracy, valid_cost = self.test_validation_set(sess,data_validation,\r\n                                                               label_validation, 60)\r\n                        if valid_cost &lt; min_valid_cost - 2:\r\n                            min_valid_cost = valid_cost\r\n                            if model_path:\r\n                                saver.save(sess, model_path)\r\n                        all_valid_cost.append(valid_cost)\r\n                        print all_valid_cost\r\n\r\n                    if self.last_valid_batch == 0:\r\n                        self.shufle_data(data_validation, label_validation)\r\n\r\n                    train_accuracy = self.accuracy.eval(\r\n                        feed_dict={self.x: batch_img, self.y_: batch_label, self.keep_prob: 1.0})\r\n                    print &quot;trainning accuracy: &quot; + str(train_accuracy)\r\n\r\n                    self.shufle_data(data_img, labels)\r\n\r\n                _, c, pred = sess.run(\r\n                    [optimizer, self.cost,], feed_dict={\r\n                        self.x: batch_img, self.y_: batch_label, self.keep_prob: keep_rate,\r\n                        self.learning_rate: learning_rate\r\n                    }\r\n                )\r\n\r\n                print &#39;epoch_loss: &#39;+str(c)\r\n\r\n\r\n\r\n    def main(self, data_dir, labels_dir, img_sz, n_slices, batch_size=5, last_batch=0, train=False,\r\n             model_path=None, keep_rate=0.5):\r\n        &quot;&quot;&quot;\r\n\r\n        Args:\r\n            data_dir(list): directories of the image to be tested\r\n            labels_dir: (str): directory of the csv file where the image are labeled, the index\r\n            colum is the number 2 and the labels header is &#39;Diag&#39;.\r\n            img_sz: the spatial image size the be transformed to. that is the sizes with which\r\n            the image will be trainned. width and hight must be the same\r\n            n_slices: the number of slices for the image to be trained\r\n            last_batch: the batch at which you want to start the trainning\r\n            train: boolean to set trainning: 0 or testing :1\r\n            model_path: the path where the model is saved, if there is no previous model you can\r\n            set a path here to start a new one.\r\n            keep_rate: the keep_probability of firing a node by means of dropout\r\n\r\n        Returns:\r\n\r\n        &quot;&quot;&quot;\r\n\r\n\r\n        self.train = train\r\n        data_path_trainning, label_trainning, data_path_validation, label_validation, \\\r\n        data_testing, label_testing = self.load_dataset(data_dir, labels_dir,)\r\n\r\n        data_trainning, label_trainning_final = self.load_image(data_path_trainning,\r\n                                                                label_trainning, img_sz, n_slices\r\n                                                                )\r\n\r\n        data_validation, label_validation_final = self.load_image(\r\n            data_path_validation, label_validation, img_sz, n_slices\r\n        )\r\n\r\n\r\n        self.x = tf.placeholder(tf.float32, shape=[None, n_slices, img_sz, img_sz]) #batch_size,\r\n        # image_Size\r\n        self.y_ = tf.placeholder(tf.float32, shape=[None, 3]) #batch_size, label_size\r\n        self.learning_rate = tf.placeholder(tf.float32)\r\n        self.keep_prob = tf.placeholder(tf.float32)\r\n        if train:\r\n            self.train_neural_network(data_trainning, label_trainning_final, data_validation,\r\n                                      label_validation_final, batch_size, img_sz, n_slices,\r\n                                      last_batch, keep_rate, model_path\r\n                                      )\r\n\r\n\r\nI have already tried tf.set_random_seed( 1 )  but no correction is seen\r\n\r\nDo anyone have any idea about, please?\r\n\r\nthanks so much \r\n\r\nEDITED: \r\n\r\nThe data to be classified are 3d images of 150x150x40 pixels in a biclass problem. I have a total 400 images approaximatly half of each class. I have separated the dataset in train (75%), validation (10%) and test(15%)\r\n\r\n\r\n\r\n \r\n\r\n",
            "link": "https://stackoverflow.com/questions/49889421/tensorflow-validation-prediction-outs-the-same-for-each-image",
            "title": "Tensorflow: validation prediction outs the same for each image",
            "body": "<p>I have the following problem. </p>\n\n<p>I am trying to train a 3d CNN in tensorflow. I have separated the data in three data sets, train, validation and test. </p>\n\n<p>The main problem is that when I test the validation set after 5 epoch of training the output of the model is the nearly the same for the 5 images.\n(this is the output of the last layer without any softmax)</p>\n\n<pre><code>2018-04-17 23:30:35.134318 Prediction: [[0.8185656  2.7571523 ]                     \n[0.8200048  2.7590456 ]\n [0.8185656  2.7571523 ]\n [0.8200048  2.7590458 ]\n [0.7751368  2.7532804 ]\n [0.82061136 2.7588618 ]\n [0.8130686  2.7821052 ]\n [0.83537185 2.7514493 ]\n [0.8200041  2.7590454 ]\n [0.81701267 2.7519925 ]\n [0.8424163  2.8674953 ]\n [0.82000506 2.7590454 ]\n [0.81999433 2.7590487 ]\n [0.81701267 2.7519925 ]\n</code></pre>\n\n<p>However, if i do the same for trainning set I get a conventional prediction.</p>\n\n<p>I have fully check the data sets and both are correct and in the same conditions. </p>\n\n<p>This is my mode used to build the model and do the training:  </p>\n\n<p>class Cnn3DMRI(object):</p>\n\n<pre><code>def weight_variable(self, shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(self, shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\ndef conv3d(self, x, W):\n    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n\ndef maxpool3d(self, x):\n    #                        size of window         movement of window\n    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n\ndef dense_to_one_hot(self, labels_dense, num_classes):\n    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n    num_labels = labels_dense.shape[0]\n    index_offset = np.arange(num_labels) * num_classes\n    labels_one_hot = np.zeros((num_labels, num_classes))\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n    return labels_one_hot\n\n\ndef wrapper_image(self, full_image_set, full_label_set, last_batch=0, batch_size=5):\n    batch_img = full_image_set[last_batch:batch_size+last_batch, :, :, :]\n    batch_label = full_label_set[last_batch:batch_size+last_batch]\n    return batch_img, batch_label, batch_size+last_batch\n\n\ndef convolutional_neural_network(self, x, img_sz, n_slices):\n    weights = {\n        'W_conv1': self.weight_variable([6, 8, 8, 1, 32]),\n        'W_conv2': self.weight_variable([2, 5, 5, 32, 48]),\n        'W_conv3': self.weight_variable([2, 3, 3, 48, 64]),\n        'W_conv4': self.weight_variable([2, 2, 2, 64, 64]),\n        'W_fc': self.weight_variable([int(\n            math.ceil(n_slices / 8) * (math.ceil(img_sz / 8) * math.ceil(img_sz / 8) *\n                                        64)),\n                                      2048]),\n        'W_fc2': self.weight_variable([2048, 1024]),\n        'out': self.weight_variable([1024, 2])\n    }\n\n    biases = {\n        'b_conv1': self.bias_variable([32]),\n        'b_conv2': self.bias_variable([48]),\n        'b_conv3': self.bias_variable([64]),\n        'b_conv4': self.bias_variable([64]),\n        'b_fc': self.bias_variable([2048]),\n        'b_fc2': self.bias_variable([1024]),\n        'out': self.bias_variable([2])\n    }\n\n    self.x_im = tf.reshape(x, shape=[-1, n_slices, img_sz, img_sz, 1])\n\n    conv1 = tf.tanh(self.conv3d(self.x_im, weights['W_conv1']) + biases['b_conv1'])\n    conv1 =self.maxpool3d(conv1)\n\n    conv2 = tf.tanh(self.conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n    conv2 = self.maxpool3d(conv2)\n\n    conv3 = tf.tanh(self.conv3d(conv2, weights['W_conv3']) + biases['b_conv3'])\n    conv3 = self.maxpool3d(conv3)\n    conv4 = tf.tanh(self.conv3d(conv3, weights['W_conv4']) + biases['b_conv4'])\n\n    fc = tf.reshape(conv4, [-1,int(math.ceil(n_slices/8)*math.ceil(img_sz/8)*math.ceil(\n        img_sz/8))*64])\n    fc = tf.tanh(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n    fc = tf.tanh(tf.matmul(fc, weights['W_fc2'])+biases['b_fc2'])\n    fc = tf.nn.dropout(fc, self.keep_prob)\n\n    output = tf.matmul(fc, weights['out'])+biases['out']\n    return output\n\ndef test_validation_set(self, sess, data_validation, label_validation, valid_batch_size=60):\n\n    batch_img, batch_label, last_batch = self.wrapper_image(\n        data_validation, label_validation, self.last_valid_batch, valid_batch_size\n    )\n\n\n    batch_label = self.dense_to_one_hot(\n        np.array(batch_label, dtype=np.int),2\n        ).astype(np.float32)\n\n\n    if last_batch+valid_batch_size &lt; len(label_validation):\n        self.last_valid_batch = last_batch\n    else:\n        self.last_valid_batch = 0\n\n    pred, c, validation_accuracy = sess.run(\n        [self.prediction, self.cost, self.accuracy], feed_dict={\n            self.x: batch_img, self.y_: batch_label, self.keep_prob: 1.0\n        }\n    )\n\n\n    self.log(\"Prediction: \"+str(pred))\n    self.log(\"Label: \"+str(batch_label))\n\n    self.log(\"Validation accuracy: \"+str(validation_accuracy))\n    self.log(\"Validation cost: \"+str(c))\n    return validation_accuracy, c\n\n\ndef train_neural_network(self, data_img, labels,  data_validation, label_validation,\n                         batch_size, img_sz, n_slices, last_batch,\n                         keep_rate, model_path):\n\n    self.prediction = self.convolutional_neural_network(self.x, img_sz, n_slices)\n    self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y_,\n                                                                  logits=self.prediction))\n    optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n    correct_prediction = tf.equal(tf.argmax(self.prediction, 1), tf.argmax(self.y_, 1))\n    self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    hm_epochs = 1000\n    saver = tf.train.Saver(tf.trainable_variables())\n    epoch_loss = 0\n    epoch_loss_mean = []\n    n_epoch = 0\n    learning_rate = 1e-4\n    self.last_valid_batch = 0\n    min_valid_cost = 0\n    all_valid_cost = []\n    model_path_train = 'model_train/my_model.ckpt'\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        if model_path:\n            pass\n            #saver.restore(sess, model_path_train)\n        while n_epoch &lt; hm_epochs:\n            if len(data_img)&gt;last_batch+batch_size:\n                with tf.device('/cpu:0'):\n                    #batch_img, batch_label, last_batch = self.get_image(\n                    #    data_img, labels, last_batch, batch_size, img_sz, n_slices\n                    #)\n                    batch_img, batch_label, last_batch = self.wrapper_image(data_img, labels, last_batch, batch_size)\n\n                print \"Batch label images: \"+str(batch_label)\n                batch_label = self.dense_to_one_hot(np.array(batch_label, dtype=np.int),\n                                                    2).astype(np.float32)\n            else:\n                with tf.device('/cpu:0'):\n                    restbatch = last_batch + batch_size - len(data_img)\n\n                    batch_img = np.concatenate((\n                        self.wrapper_image(data_img, labels, last_batch, len(data_img) -\n                                           last_batch)[0],\n                        self.wrapper_image(data_img, labels, last_batch, len(data_img) -\n                                           last_batch)[0]\n                    ))\n\n                    batch_label = np.concatenate((\n                        self.wrapper_image(data_img, labels, last_batch, len(data_img) -\n                                           last_batch)[1],\n                        self.wrapper_image(data_img, labels, last_batch, len(data_img) -\n                                           last_batch)[1]\n                    ))\n\n                batch_label = self.dense_to_one_hot(np.array(batch_label, dtype=np.int),\n                                                    2).astype(\n                np.float32)\n                last_batch = restbatch\n\n                ####### at the end of EACH EPOCH ###\n                epoch_loss_mean.append(epoch_loss)\n                print \"epoch loss mean: \"+str(epoch_loss_mean)\n                epoch_loss = 0\n                n_epoch += 1\n                print \"n_epoch: \"+str(n_epoch)\n                if model_path:\n                    saver.save(sess, model_path_train)\n\n                if not n_epoch % 5:\n                    valid_accuracy, valid_cost = self.test_validation_set(sess,data_validation,\n                                                           label_validation, 60)\n                    if valid_cost &lt; min_valid_cost - 2:\n                        min_valid_cost = valid_cost\n                        if model_path:\n                            saver.save(sess, model_path)\n                    all_valid_cost.append(valid_cost)\n                    print all_valid_cost\n\n                if self.last_valid_batch == 0:\n                    self.shufle_data(data_validation, label_validation)\n\n                train_accuracy = self.accuracy.eval(\n                    feed_dict={self.x: batch_img, self.y_: batch_label, self.keep_prob: 1.0})\n                print \"trainning accuracy: \" + str(train_accuracy)\n\n                self.shufle_data(data_img, labels)\n\n            _, c, pred = sess.run(\n                [optimizer, self.cost,], feed_dict={\n                    self.x: batch_img, self.y_: batch_label, self.keep_prob: keep_rate,\n                    self.learning_rate: learning_rate\n                }\n            )\n\n            print 'epoch_loss: '+str(c)\n\n\n\ndef main(self, data_dir, labels_dir, img_sz, n_slices, batch_size=5, last_batch=0, train=False,\n         model_path=None, keep_rate=0.5):\n    \"\"\"\n\n    Args:\n        data_dir(list): directories of the image to be tested\n        labels_dir: (str): directory of the csv file where the image are labeled, the index\n        colum is the number 2 and the labels header is 'Diag'.\n        img_sz: the spatial image size the be transformed to. that is the sizes with which\n        the image will be trainned. width and hight must be the same\n        n_slices: the number of slices for the image to be trained\n        last_batch: the batch at which you want to start the trainning\n        train: boolean to set trainning: 0 or testing :1\n        model_path: the path where the model is saved, if there is no previous model you can\n        set a path here to start a new one.\n        keep_rate: the keep_probability of firing a node by means of dropout\n\n    Returns:\n\n    \"\"\"\n\n\n    self.train = train\n    data_path_trainning, label_trainning, data_path_validation, label_validation, \\\n    data_testing, label_testing = self.load_dataset(data_dir, labels_dir,)\n\n    data_trainning, label_trainning_final = self.load_image(data_path_trainning,\n                                                            label_trainning, img_sz, n_slices\n                                                            )\n\n    data_validation, label_validation_final = self.load_image(\n        data_path_validation, label_validation, img_sz, n_slices\n    )\n\n\n    self.x = tf.placeholder(tf.float32, shape=[None, n_slices, img_sz, img_sz]) #batch_size,\n    # image_Size\n    self.y_ = tf.placeholder(tf.float32, shape=[None, 3]) #batch_size, label_size\n    self.learning_rate = tf.placeholder(tf.float32)\n    self.keep_prob = tf.placeholder(tf.float32)\n    if train:\n        self.train_neural_network(data_trainning, label_trainning_final, data_validation,\n                                  label_validation_final, batch_size, img_sz, n_slices,\n                                  last_batch, keep_rate, model_path\n                                  )\n</code></pre>\n\n<p>I have already tried tf.set_random_seed( 1 )  but no correction is seen</p>\n\n<p>Do anyone have any idea about, please?</p>\n\n<p>thanks so much </p>\n\n<p>EDITED: </p>\n\n<p>The data to be classified are 3d images of 150x150x40 pixels in a biclass problem. I have a total 400 images approaximatly half of each class. I have separated the dataset in train (75%), validation (10%) and test(15%)</p>\n"
        },
        {
            "tags": [
                "emacs",
                "verilog"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9529880,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Roarer",
                "link": "https://stackoverflow.com/users/9529880/roarer"
            },
            "is_answered": false,
            "view_count": 20,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165708,
            "creation_date": 1524153885,
            "last_edit_date": 1524165708,
            "question_id": 49925558,
            "body_markdown": "I am usinh emacs verilog-mode to build some verilog source code. However I observe that when the code becomes large(like in a case statement), I find it difficult to understand which begin is paired with which end block. \r\n\r\nVerilog mode has an emacs function that adds a comments to every end block showing which begin it is paired with. However, this does show for every begin and end block.\r\n\r\nI was wondering what are the options when navigating verilog in emacs? Is there any function which will do code-folding given the delimiter used in the language(I should be able to specify begin,end are me delimiters instead of {} in C).\r\n\r\nCould someone help me out?\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49925558/navigating-verilog-begin-and-end-blocks-using-emacs-to-show-structure",
            "title": "Navigating verilog begin and end blocks using emacs to show structure",
            "body": "<p>I am usinh emacs verilog-mode to build some verilog source code. However I observe that when the code becomes large(like in a case statement), I find it difficult to understand which begin is paired with which end block. </p>\n\n<p>Verilog mode has an emacs function that adds a comments to every end block showing which begin it is paired with. However, this does show for every begin and end block.</p>\n\n<p>I was wondering what are the options when navigating verilog in emacs? Is there any function which will do code-folding given the delimiter used in the language(I should be able to specify begin,end are me delimiters instead of {} in C).</p>\n\n<p>Could someone help me out?</p>\n"
        },
        {
            "tags": [
                "haskell"
            ],
            "owner": {
                "reputation": 517,
                "user_id": 5200466,
                "user_type": "registered",
                "accept_rate": 81,
                "profile_image": "https://www.gravatar.com/avatar/abb1362cec6e1f0a2416a6d98a93cd6c?s=128&d=identicon&r=PG&f=1",
                "display_name": "matthias",
                "link": "https://stackoverflow.com/users/5200466/matthias"
            },
            "is_answered": true,
            "view_count": 90,
            "answer_count": 1,
            "score": 2,
            "last_activity_date": 1524165706,
            "creation_date": 1523410582,
            "question_id": 49765136,
            "body_markdown": "I am going through some old courses online and came across this task:\r\n\r\n    data Tree a = Leaf \r\n                | Branch a (Tree a) (Tree a) \r\n                deriving (Show, Eq)\r\n    \r\n    fold :: (a -&gt; b -&gt; b -&gt; b) -&gt; b -&gt; Tree a -&gt; b\r\n    fold _ acc Leaf           = acc\r\n    fold f acc (Branch v l r) = f v (fold f acc l) (fold f acc r)\r\n    \r\n    foldRT :: (a -&gt; b -&gt; b) -&gt; b -&gt; Tree a -&gt; b\r\n    foldRT _ acc Leaf = acc\r\n    foldRT f acc (Branch v l r) = foldRT f (f v (foldRT f acc r)) l\r\n\r\nThe task is to rewrite `foldRT` in terms of `fold`. I have been stuck on it for ages and can&#39;t wrap my head around it.\r\n\r\nA walk through would be greatly appreciated.\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49765136/haskell-folding-over-trees",
            "title": "Haskell: Folding over trees",
            "body": "<p>I am going through some old courses online and came across this task:</p>\n\n<pre><code>data Tree a = Leaf \n            | Branch a (Tree a) (Tree a) \n            deriving (Show, Eq)\n\nfold :: (a -&gt; b -&gt; b -&gt; b) -&gt; b -&gt; Tree a -&gt; b\nfold _ acc Leaf           = acc\nfold f acc (Branch v l r) = f v (fold f acc l) (fold f acc r)\n\nfoldRT :: (a -&gt; b -&gt; b) -&gt; b -&gt; Tree a -&gt; b\nfoldRT _ acc Leaf = acc\nfoldRT f acc (Branch v l r) = foldRT f (f v (foldRT f acc r)) l\n</code></pre>\n\n<p>The task is to rewrite <code>foldRT</code> in terms of <code>fold</code>. I have been stuck on it for ages and can't wrap my head around it.</p>\n\n<p>A walk through would be greatly appreciated.</p>\n"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 184
}