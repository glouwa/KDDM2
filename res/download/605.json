{
    "items": [
        {
            "tags": [
                "android",
                "opengl-es-2.0",
                "gesture"
            ],
            "owner": {
                "reputation": 252,
                "user_id": 2211304,
                "user_type": "registered",
                "accept_rate": 82,
                "profile_image": "https://i.stack.imgur.com/FWRiD.jpg?s=128&g=1",
                "display_name": "Riddhi Shah",
                "link": "https://stackoverflow.com/users/2211304/riddhi-shah"
            },
            "is_answered": false,
            "view_count": 27,
            "answer_count": 0,
            "score": 2,
            "last_activity_date": 1524204143,
            "creation_date": 1524202909,
            "last_edit_date": 1524204143,
            "question_id": 49934749,
            "body_markdown": "I am new to OpenGL and ARCore and I am using [GoogleARCore Sample][1] as a base to create my application. I am using OpenGL-ES-2.0 version. I able to do Pinch zoom (2 fingers) using `android.view.ScaleGestureDetector.SimpleOnScaleGestureListener`. By using this library class of Rotation [Rotation Gesture][2] I am able to get my rotation degree and it worked well with my 3D Object. \r\n\r\nWhile rotating my 3D object, my object gets scaled too. I want to stop my scaling while the user is doing the rotation. How can I achieve this? Or how can I pass my both scaling and rotation in a different method to update their respective matrix? I do not want to use any 3D party library for this.\r\n\r\nPlease help me with this. Below is my code and suggest me where I am doing anything wrong. \r\n\r\n\r\n  [1]: https://github.com/google-ar/arcore-android-sdk\r\n  [2]: https://github.com/Almeros/android-gesture-detectors\r\n\r\n**ScaleGesture**\r\n\r\n    private class CustomScaleGesture extends ScaleGestureDetector.SimpleOnScaleGestureListener {\r\n    \t\t@Override\r\n    \t\tpublic boolean onScale(ScaleGestureDetector detector) {\r\n    \t\t\tDebugHelper.log(&quot;detector.getScaleFactor(): &quot; + detector.getScaleFactor() + &quot; scaleFactor = &quot; + scaleFactor);\r\n    \t\t\tscaleFactor *= detector.getScaleFactor();\r\n    \t\t\tDebugHelper.log(&quot;final scaleFactor: &quot; + scaleFactor);\r\n    \t\t\treturn true;\r\n    \t\t}\r\n    \t}\r\n\r\n**RotationGesture**\r\n\r\n    private class RotateListener extends RotateGestureDetector.SimpleOnRotateGestureListener {\r\n    \t\t@Override\r\n    \t\tpublic boolean onRotate(RotateGestureDetector detector) {\r\n    \t\t\tDebugHelper.log(&quot;RotateListener called..&quot;);\r\n    \t\t\tmRotationDegrees -= detector.getRotationDegreesDelta();\r\n    \t\t\tDebugHelper.log(&quot;RotateListener: &quot; + mRotationDegrees);\r\n    \t\t\treturn true;\r\n    \t\t}\r\n    \t}\r\n\r\n**MainActivity**\r\n\r\n    public class MyARActivity extends BaseActivity&lt;MyActivityArBinding&gt; implements GLSurfaceView.Renderer {\r\n    \t\r\n    \r\n    \t//AR Variables\r\n    \tprivate int mWidth;\r\n    \tprivate int mHeight;\r\n    \tprivate boolean capturePicture = false;\r\n    \tprivate boolean installRequested;\r\n    \tprivate boolean moving;\r\n    \tfloat[] projmtx = new float[16];\r\n    \tfloat[] viewmtx = new float[16];\r\n    \tprivate Session session;\r\n    \r\n    \tprivate Snackbar messageSnackbar;\r\n    \tprivate DisplayRotationHelper displayRotationHelper;\r\n    \tprivate final BackgroundRenderer backgroundRenderer = new BackgroundRenderer();\r\n    \tprivate ObjectRenderer virtualObject;\r\n    \tprivate ObjectRenderer virtualObjectShadow;\r\n    \tprivate final PlaneRenderer planeRenderer = new PlaneRenderer();\r\n    \tprivate PointCloudRenderer pointCloud = new PointCloudRenderer();\r\n    \r\n    \t// Temporary matrix allocated here to reduce number of allocations for each frame.\r\n    \tprivate float[] anchorMatrix = new float[16];\r\n    \t// Tap handling and UI.\r\n    \tprivate ArrayBlockingQueue&lt;MotionEvent&gt; queuedSingleTaps = new ArrayBlockingQueue&lt;&gt;(16);\r\n    \tprivate ArrayList&lt;Anchor&gt; anchors = new ArrayList&lt;&gt;();\r\n    \r\n    \t//load and manipulate obj\r\n    \tprivate SQLiteHelper sqlHelper;\r\n    \tprivate boolean isObjectChanged = false;\r\n    \tprivate String objectPath;\r\n    \tprivate List&lt;CharacterModel&gt; characterModelList = new ArrayList&lt;&gt;();\r\n    \tprivate boolean isFirstTimeLoad = true;\r\n    \t//Gestures\r\n    \tprivate float mRotationDegrees = 0.f;\r\n    \tprivate RotateGestureDetector mRotateDetector;\r\n    \tprivate float scaleFactor = 1.0f;\r\n    \tprivate ScaleGestureDetector scaleDetector;\r\n    \tprivate GestureDetector gestureDetector;\r\n    \r\n    \t@Override\r\n    \tprotected void onCreate(Bundle savedInstanceState) {\r\n    \t\tsuper.onCreate(savedInstanceState);\r\n    \t\tsetHeaderVisible(false);\r\n    \t\tdoDefaults();\r\n    \t}\r\n    \r\n    \tprivate void doDefaults() {\r\n    \t\tbinding.setPresenter(this);\r\n    \t\tsqlHelper = SQLiteHelper.getInstance(this);\r\n    \t\tload3DCharacters();\r\n    \t\tinitAR();\r\n    \t}\r\n    \r\n    \t@SuppressLint(&quot;ClickableViewAccessibility&quot;)\r\n    \tprivate void initAR() {\r\n    \t\tdisplayRotationHelper = new DisplayRotationHelper(this);\r\n    \t\tscaleDetector = new ScaleGestureDetector(this, new CustomScaleGesture());\r\n    \t\tmRotateDetector = new RotateGestureDetector(getApplicationContext(), new RotateListener());\r\n    \r\n    \t\t// Set up tap listener.\r\n    \t\tgestureDetector = new GestureDetector(this, new GestureDetector.SimpleOnGestureListener() {\r\n    \t\t\t@Override\r\n    \t\t\tpublic boolean onSingleTapUp(MotionEvent e) {\r\n    \t\t\t\tif (anchors.size() &lt;= 0) {\r\n    \t\t\t\t\tonSingleTap(e);\r\n    \t\t\t\t}\r\n    \t\t\t\treturn true;\r\n    \t\t\t}\r\n    \r\n    \t\t\t@Override\r\n    \t\t\tpublic boolean onDown(MotionEvent e) {\r\n    \t\t\t\treturn true;\r\n    \t\t\t}\r\n    \t\t});\r\n    \r\n    \t\tbinding.surfaceView.setOnTouchListener(new View.OnTouchListener() {\r\n    \t\t\t@Override\r\n    \t\t\tpublic boolean onTouch(View v, MotionEvent event) {\r\n    \t\t\t\tDebugHelper.log(&quot;binding.surfaceView.setOnTouchListener called..&quot;);\r\n    \t\t\t\tmRotateDetector.onTouchEvent(event);\r\n    \t\t\t\tscaleDetector.onTouchEvent(event);\r\n    \t\t\t\tswitch (event.getAction()) {\r\n    \t\t\t\t\tcase MotionEvent.ACTION_DOWN:\r\n    \t\t\t\t\t\tmoving = true;\r\n    \t\t\t\t\t\tDebugHelper.log(&quot;ACTION_DOWN&quot;);\r\n    \t\t\t\t\t\tbreak;\r\n    \r\n    \t\t\t\t\tcase MotionEvent.ACTION_UP:\r\n    \t\t\t\t\t\tDebugHelper.log(&quot;ACTION_UP&quot;);\r\n    \t\t\t\t\t\tmoving = false;\r\n    \t\t\t\t\t\tbreak;\r\n    \t\t\t\t\tcase MotionEvent.ACTION_MOVE:\r\n    \t\t\t\t\t\tDebugHelper.log(&quot;ACTION_MOVE&quot;);\r\n    \t\t\t\t\t\tif (anchors.size() &gt; 0) {\r\n    \t\t\t\t\t\t\tonSecondTouch(event);\r\n    \t\t\t\t\t\t}\r\n    \t\t\t\t\t\tbreak;\r\n    \t\t\t\t}\r\n    \t\t\t\treturn gestureDetector.onTouchEvent(event);\r\n    \r\n    \t\t\t}\r\n    \t\t});\r\n    \r\n    \t\t// Set up renderer.\r\n    \t\tbinding.surfaceView.setPreserveEGLContextOnPause(true);\r\n    \t\tbinding.surfaceView.setEGLContextClientVersion(2);\r\n    \t\tbinding.surfaceView.setEGLConfigChooser(8, 8, 8, 8, 16, 0); // Alpha used for plane blending.\r\n    \t\tbinding.surfaceView.setRenderer(this);\r\n    \t\tbinding.surfaceView.setRenderMode(GLSurfaceView.RENDERMODE_CONTINUOUSLY);\r\n    \t\tinstallRequested = false;\r\n    \t}\r\n    \tprivate void onSecondTouch(MotionEvent e) {\r\n    \t\tLog.e(&quot;Second Touch&quot;, &quot;Executed&quot;);\r\n    \t\tif (e.getPointerCount() &gt; 1) {\r\n    \t\t\tscaleDetector.onTouchEvent(e);\r\n    \t\t} else {\r\n    \t\t\tqueuedSingleTaps.offer(e);\r\n    \t\t}\r\n    \t}\r\n    private void onSingleTap(MotionEvent e) {\r\n    \t\t// Queue tap if there is space. Tap is lost if queue is full.\r\n    \t\tDebugHelper.log(&quot;onSingleTap()&quot;);\r\n    \t\tqueuedSingleTaps.offer(e);\r\n    \t}\r\n    \r\n    \tprivate void load3DCharacters() {\r\n    \t\tCharacterModel model = new CharacterModel();\r\n    \t\tmodel.setName(&quot;Cat&quot;);\r\n    \t\tmodel.setObjectPath(&quot;cat/cat.obj&quot;);\r\n    \t\tmodel.setScaleFactor(0.25f);\r\n    \t\tmodel.setResourceId(R.drawable.cat);\r\n    \t\tcharacterModelList.add(model);\r\n    \r\n    \t\tmodel = new CharacterModel();\r\n    \t\tmodel.setName(&quot;Old Man&quot;);\r\n    \t\tmodel.setObjectPath(&quot;man/muro.obj&quot;);\r\n    \t\tmodel.setScaleFactor(0.0085f);\r\n    \t\tmodel.setResourceId(R.drawable.old_man);\r\n    \t\tcharacterModelList.add(model);\r\n    \r\n    \r\n    \t\tmodel = new CharacterModel();\r\n    \t\tmodel.setName(&quot;Bloodwing&quot;);\r\n    \t\tmodel.setObjectPath(&quot;bloodwing/bloodwing.obj&quot;);\r\n    \t\tmodel.setScaleFactor(0.0009f);\r\n    \t\tmodel.setResourceId(R.drawable.bat);\r\n    \t\tcharacterModelList.add(model);\r\n    \t}\r\n    \r\n    \tprivate void loadObject(CharacterModel model) {\r\n    \t\ttry {\r\n    \t\t\tthis.objectPath = model.getObjectPath();\r\n    \t\t\tthis.scaleFactor = model.getScaleFactor();\r\n    \t\t\tif (virtualObject == null) {\r\n    \t\t\t\tvirtualObject = new ObjectRenderer(objectPath);\r\n    \t\t\t\tvirtualObject.createOnGlThread(this);\r\n    \t\t\t\tvirtualObject.setMaterialProperties(0.0f, 1.0f, 1.0f, 6.0f);\r\n    \t\t\t} else {\r\n    \t\t\t\t// Clear screen to notify driver it should not load any pixels from previous frame.\r\n    \t\t\t\tGLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT);\r\n    \t\t\t\tisObjectChanged = true;\r\n    \t\t\t\tvirtualObject.updateObjectPath(model.getObjectPath());\r\n    \t\t\t}\r\n    \t\t} catch (Exception ex) {\r\n    \t\t\tex.printStackTrace();\r\n    \t\t}\r\n    \t}\r\n \r\n\r\n    @Override\r\n    \t    public void onDrawFrame(GL10 gl) {\r\n    \t\tif (isObjectChanged) {\r\n    \t\t\tisObjectChanged = false;\r\n    \t\t\ttry {\r\n    \t\t\t\tvirtualObject.createOnGlThread(this);\r\n    \t\t\t\tvirtualObject.setMaterialProperties(0.0f, 2.0f, 0.5f, 6.0f);\r\n    \t\t\t} catch (IOException e) {\r\n    \t\t\t\te.printStackTrace();\r\n    \t\t\t}\r\n    \t\t\treturn;\r\n    \t\t}\r\n    \r\n    \t\t// Clear screen to notify driver it should not load any pixels from previous frame.\r\n    \t\tGLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT);\r\n    \r\n    \t\tif (session == null) {\r\n    \t\t\treturn;\r\n    \t\t}\r\n    \t\t// Notify ARCore session that the view size changed so that the perspective matrix and\r\n    \t\t// the video background can be properly adjusted.\r\n    \t\tdisplayRotationHelper.updateSessionIfNeeded(session);\r\n    \r\n    \t\ttry {\r\n    \t\t\tsession.setCameraTextureName(backgroundRenderer.getTextureId());\r\n    \r\n    \t\t\t// Obtain the current frame from ARSession. When the configuration is set to\r\n    \t\t\t// UpdateMode.BLOCKING (it is by default), this will throttle the rendering to the\r\n    \t\t\t// camera framerate.\r\n    \t\t\tFrame frame = session.update();\r\n    \t\t\tCamera camera = frame.getCamera();\r\n    \r\n    \t\t\t// Handle taps. Handling only one tap per frame, as taps are usually low frequency\r\n    \t\t\t// compared to frame rate.\r\n    \t\t\tMotionEvent tap = queuedSingleTaps.poll();\r\n    \t\t\tif (tap != null &amp;&amp; camera.getTrackingState() == TrackingState.TRACKING) {\r\n    \t\t\t\tfor (HitResult hit : frame.hitTest(tap)) {\r\n    \t\t\t\t\t// Check if any plane was hit, and if it was hit inside the plane polygon\r\n    \t\t\t\t\tTrackable trackable = hit.getTrackable();\r\n    \t\t\t\t\t// Creates an anchor if a plane or an oriented point was hit.\r\n    \t\t\t\t\tif ((trackable instanceof Plane &amp;&amp; ((Plane) trackable).isPoseInPolygon(hit.getHitPose())) || (trackable instanceof Point &amp;&amp; ((Point) trackable).getOrientationMode() == Point.OrientationMode.ESTIMATED_SURFACE_NORMAL)) {\r\n    \t\t\t\t\t\t// Hits are sorted by depth. Consider only closest hit on a plane or oriented point.\r\n    \t\t\t\t\t\t// Cap the number of objects created. This avoids overloading both the\r\n    \t\t\t\t\t\t// rendering system and ARCore.\r\n    \t\t\t\t\t\t//if (!isUpdate) {\r\n    \t\t\t\t\t\tDebugHelper.log(&quot;Anchor size = &quot; + anchors.size());\r\n    \t\t\t\t\t\tif (anchors.size() &gt;= 1) {\r\n    \t\t\t\t\t\t\tanchors.get(0).detach();\r\n    \t\t\t\t\t\t\tanchors.remove(0);\r\n    \t\t\t\t\t\t}\r\n    \t\t\t\t\t\t// Adding an Anchor tells ARCore that it should track this position in\r\n    \t\t\t\t\t\t// space. This anchor is created on the Plane to place the 3D model\r\n    \t\t\t\t\t\t// in the correct position relative both to the world and to the plane.\r\n    \t\t\t\t\t\tif (anchors.size() &gt; 0) {\r\n    \t\t\t\t\t\t\tDebugHelper.log(&quot;anchor list has data&quot;);\r\n    \t\t\t\t\t\t\tfor (Anchor anchor : anchors) {\r\n    \t\t\t\t\t\t\t\tanchor.detach();\r\n    \t\t\t\t\t\t\t\tanchors.remove(anchor);\r\n    \t\t\t\t\t\t\t}\r\n    \t\t\t\t\t\t}\r\n    \t\t\t\t\t\tAnchor anchor = hit.createAnchor();\r\n    \t\t\t\t\t\tif (anchor != null)\r\n    \t\t\t\t\t\t\tanchors.add(anchor);\r\n    \t\t\t\t\t\telse\r\n    \t\t\t\t\t\t\tDebugHelper.log(&quot;anchor is null&quot;);\r\n    \t\t\t\t\t\t//}\r\n    \t\t\t\t\t\tbreak;\r\n    \t\t\t\t\t}\r\n    \t\t\t\t}\r\n    \t\t\t}\r\n    \r\n    \t\t\t// Draw background.\r\n    \t\t\tbackgroundRenderer.draw(frame);\r\n    \r\n    \t\t\t// If not tracking, don&#39;t draw 3d objects.\r\n    \t\t\tif (camera.getTrackingState() == TrackingState.PAUSED) {\r\n    \t\t\t\treturn;\r\n    \t\t\t}\r\n    \r\n    \t\t\t// Get projection matrix.\r\n    \t\t\tcamera.getProjectionMatrix(projmtx, 0, 0.1f, 100.0f);\r\n    \r\n    \t\t\t// Get camera matrix and draw.\r\n    \t\t\tcamera.getViewMatrix(viewmtx, 0);\r\n    \r\n    \t\t\t// Compute lighting from average intensity of the image.\r\n    \t\t\tfinal float lightIntensity = frame.getLightEstimate().getPixelIntensity();\r\n    \r\n    \t\t\t// Visualize tracked points.\r\n    \t\t\tPointCloud pointCloud = frame.acquirePointCloud();\r\n    \t\t\tthis.pointCloud.update(pointCloud);\r\n    \t\t\tif (!capturePicture)\r\n    \t\t\t\tthis.pointCloud.draw(viewmtx, projmtx);\r\n    \r\n    \t\t\t// Application is responsible for releasing the point cloud resources after\r\n    \t\t\t// using it.\r\n    \t\t\tpointCloud.release();\r\n    \r\n    \t\t\t// Check if we detected at least one plane. If so, hide the loading message.\r\n    \t\t\tif (messageSnackbar != null) {\r\n    \t\t\t\t{\r\n    \t\t\t\t\tfor (Plane plane : session.getAllTrackables(Plane.class)) {\r\n    \t\t\t\t\t\tif (plane.getType() == Plane.Type.HORIZONTAL_UPWARD_FACING\r\n    \t\t\t\t\t\t\t\t&amp;&amp; plane.getTrackingState() == TrackingState.TRACKING) {\r\n    \t\t\t\t\t\t\thideLoadingMessage();\r\n    \t\t\t\t\t\t\tbreak;\r\n    \t\t\t\t\t\t}\r\n    \t\t\t\t\t}\r\n    \t\t\t\t}\r\n    \t\t\t\tfor (Plane plane : session.getAllTrackables(Plane.class)) {\r\n    \t\t\t\t\tif (plane.getType() == Plane.Type.HORIZONTAL_UPWARD_FACING &amp;&amp; plane.getTrackingState() == TrackingState.TRACKING) {\r\n    \t\t\t\t\t\thideLoadingMessage();\r\n    \t\t\t\t\t\tbreak;\r\n    \t\t\t\t\t}\r\n    \t\t\t\t}\r\n    \t\t\t}\r\n    \t\t\t// Visualize planes.\r\n    \t\t\tif (!capturePicture)\r\n    \t\t\t\tplaneRenderer.drawPlanes(session.getAllTrackables(Plane.class), camera.getDisplayOrientedPose(), projmtx);\r\n    \r\n    \t\t\t// Visualize anchors created by touch.\r\n    \t\t\tfor (Anchor anchor : anchors) {\r\n    \t\t\t\tif (anchor.getTrackingState() != TrackingState.TRACKING) {\r\n    \t\t\t\t\tcontinue;\r\n    \t\t\t\t}\r\n    \t\t\t\t// Get the current pose of an Anchor in world space. The Anchor pose is updated\r\n    \t\t\t\t// during calls to session.update() as ARCore refines its estimate of the world.\r\n    \t\t\t\tanchor.getPose().toMatrix(anchorMatrix, 0);\r\n    \r\n    \t\t\t\t// Update and draw the model and its shadow.\r\n    \t\t\t\tif (virtualObject != null) {\r\n    //passing my scaleFector and rotationDegree to update my matrix.\r\n    \t\t\t\t\tvirtualObject.updateModelMatrix(anchorMatrix, scaleFactor, mRotationDegrees);\r\n    \t\t\t\t\tif (viewmtx != null &amp;&amp; projmtx != null) {\r\n    \t\t\t\t\t\tvirtualObject.draw(viewmtx, projmtx, lightIntensity);\r\n    \t\t\t\t\t}\r\n    \t\t\t\t}\r\n    \r\n    \t\t\t}\r\n    \r\n    \t\t\tif (capturePicture) {\r\n    \t\t\t\tcapturePicture = false;\r\n    \t\t\t\tonSavePicture();\r\n    \t\t\t}\r\n    \r\n    \t\t} catch (Throwable t) {\r\n    \t\t\tLog.e(TAG, &quot;Exception on the OpenGL thread&quot;, t);\r\n    \t\t}\r\n    \t}\r\n\r\n**ObjectRenderer**\r\n\r\n    public void updateModelMatrix(float[] modelMatrix, float scaleFactor, float rotationFactor) {\r\n    \t\tfloat[] scaleMatrix = new float[16];\r\n    \t\tMatrix.setIdentityM(scaleMatrix, 0);\r\n    \t\tscaleMatrix[0] = scaleFactor;\r\n    \t\tscaleMatrix[5] = scaleFactor;\r\n    \t\tscaleMatrix[10] = scaleFactor;\r\n    \r\n    \t\tMatrix.rotateM(modelMatrix, 0, rotationFactor, 0, 1, 0);\r\n    //\t\tMatrix.rotateM(modelMatrix, 0, scaleFactor, 0, 1, 0);\r\n    //\t\tMatrix.rotateM(modelMatrix, 0, scaleFactor, 0, 0, 1);\r\n    \r\n    \t\tMatrix.multiplyMM(mModelMatrix, 0, modelMatrix, 0, scaleMatrix, 0);\r\n    \t}",
            "link": "https://stackoverflow.com/questions/49934749/3d-object-scaled-while-rotating-y-axis",
            "title": "3D object Scaled while rotating y axis",
            "body": "<p>I am new to OpenGL and ARCore and I am using <a href=\"https://github.com/google-ar/arcore-android-sdk\" rel=\"nofollow noreferrer\">GoogleARCore Sample</a> as a base to create my application. I am using OpenGL-ES-2.0 version. I able to do Pinch zoom (2 fingers) using <code>android.view.ScaleGestureDetector.SimpleOnScaleGestureListener</code>. By using this library class of Rotation <a href=\"https://github.com/Almeros/android-gesture-detectors\" rel=\"nofollow noreferrer\">Rotation Gesture</a> I am able to get my rotation degree and it worked well with my 3D Object. </p>\n\n<p>While rotating my 3D object, my object gets scaled too. I want to stop my scaling while the user is doing the rotation. How can I achieve this? Or how can I pass my both scaling and rotation in a different method to update their respective matrix? I do not want to use any 3D party library for this.</p>\n\n<p>Please help me with this. Below is my code and suggest me where I am doing anything wrong. </p>\n\n<p><strong>ScaleGesture</strong></p>\n\n<pre><code>private class CustomScaleGesture extends ScaleGestureDetector.SimpleOnScaleGestureListener {\n        @Override\n        public boolean onScale(ScaleGestureDetector detector) {\n            DebugHelper.log(\"detector.getScaleFactor(): \" + detector.getScaleFactor() + \" scaleFactor = \" + scaleFactor);\n            scaleFactor *= detector.getScaleFactor();\n            DebugHelper.log(\"final scaleFactor: \" + scaleFactor);\n            return true;\n        }\n    }\n</code></pre>\n\n<p><strong>RotationGesture</strong></p>\n\n<pre><code>private class RotateListener extends RotateGestureDetector.SimpleOnRotateGestureListener {\n        @Override\n        public boolean onRotate(RotateGestureDetector detector) {\n            DebugHelper.log(\"RotateListener called..\");\n            mRotationDegrees -= detector.getRotationDegreesDelta();\n            DebugHelper.log(\"RotateListener: \" + mRotationDegrees);\n            return true;\n        }\n    }\n</code></pre>\n\n<p><strong>MainActivity</strong></p>\n\n<pre><code>public class MyARActivity extends BaseActivity&lt;MyActivityArBinding&gt; implements GLSurfaceView.Renderer {\n\n\n    //AR Variables\n    private int mWidth;\n    private int mHeight;\n    private boolean capturePicture = false;\n    private boolean installRequested;\n    private boolean moving;\n    float[] projmtx = new float[16];\n    float[] viewmtx = new float[16];\n    private Session session;\n\n    private Snackbar messageSnackbar;\n    private DisplayRotationHelper displayRotationHelper;\n    private final BackgroundRenderer backgroundRenderer = new BackgroundRenderer();\n    private ObjectRenderer virtualObject;\n    private ObjectRenderer virtualObjectShadow;\n    private final PlaneRenderer planeRenderer = new PlaneRenderer();\n    private PointCloudRenderer pointCloud = new PointCloudRenderer();\n\n    // Temporary matrix allocated here to reduce number of allocations for each frame.\n    private float[] anchorMatrix = new float[16];\n    // Tap handling and UI.\n    private ArrayBlockingQueue&lt;MotionEvent&gt; queuedSingleTaps = new ArrayBlockingQueue&lt;&gt;(16);\n    private ArrayList&lt;Anchor&gt; anchors = new ArrayList&lt;&gt;();\n\n    //load and manipulate obj\n    private SQLiteHelper sqlHelper;\n    private boolean isObjectChanged = false;\n    private String objectPath;\n    private List&lt;CharacterModel&gt; characterModelList = new ArrayList&lt;&gt;();\n    private boolean isFirstTimeLoad = true;\n    //Gestures\n    private float mRotationDegrees = 0.f;\n    private RotateGestureDetector mRotateDetector;\n    private float scaleFactor = 1.0f;\n    private ScaleGestureDetector scaleDetector;\n    private GestureDetector gestureDetector;\n\n    @Override\n    protected void onCreate(Bundle savedInstanceState) {\n        super.onCreate(savedInstanceState);\n        setHeaderVisible(false);\n        doDefaults();\n    }\n\n    private void doDefaults() {\n        binding.setPresenter(this);\n        sqlHelper = SQLiteHelper.getInstance(this);\n        load3DCharacters();\n        initAR();\n    }\n\n    @SuppressLint(\"ClickableViewAccessibility\")\n    private void initAR() {\n        displayRotationHelper = new DisplayRotationHelper(this);\n        scaleDetector = new ScaleGestureDetector(this, new CustomScaleGesture());\n        mRotateDetector = new RotateGestureDetector(getApplicationContext(), new RotateListener());\n\n        // Set up tap listener.\n        gestureDetector = new GestureDetector(this, new GestureDetector.SimpleOnGestureListener() {\n            @Override\n            public boolean onSingleTapUp(MotionEvent e) {\n                if (anchors.size() &lt;= 0) {\n                    onSingleTap(e);\n                }\n                return true;\n            }\n\n            @Override\n            public boolean onDown(MotionEvent e) {\n                return true;\n            }\n        });\n\n        binding.surfaceView.setOnTouchListener(new View.OnTouchListener() {\n            @Override\n            public boolean onTouch(View v, MotionEvent event) {\n                DebugHelper.log(\"binding.surfaceView.setOnTouchListener called..\");\n                mRotateDetector.onTouchEvent(event);\n                scaleDetector.onTouchEvent(event);\n                switch (event.getAction()) {\n                    case MotionEvent.ACTION_DOWN:\n                        moving = true;\n                        DebugHelper.log(\"ACTION_DOWN\");\n                        break;\n\n                    case MotionEvent.ACTION_UP:\n                        DebugHelper.log(\"ACTION_UP\");\n                        moving = false;\n                        break;\n                    case MotionEvent.ACTION_MOVE:\n                        DebugHelper.log(\"ACTION_MOVE\");\n                        if (anchors.size() &gt; 0) {\n                            onSecondTouch(event);\n                        }\n                        break;\n                }\n                return gestureDetector.onTouchEvent(event);\n\n            }\n        });\n\n        // Set up renderer.\n        binding.surfaceView.setPreserveEGLContextOnPause(true);\n        binding.surfaceView.setEGLContextClientVersion(2);\n        binding.surfaceView.setEGLConfigChooser(8, 8, 8, 8, 16, 0); // Alpha used for plane blending.\n        binding.surfaceView.setRenderer(this);\n        binding.surfaceView.setRenderMode(GLSurfaceView.RENDERMODE_CONTINUOUSLY);\n        installRequested = false;\n    }\n    private void onSecondTouch(MotionEvent e) {\n        Log.e(\"Second Touch\", \"Executed\");\n        if (e.getPointerCount() &gt; 1) {\n            scaleDetector.onTouchEvent(e);\n        } else {\n            queuedSingleTaps.offer(e);\n        }\n    }\nprivate void onSingleTap(MotionEvent e) {\n        // Queue tap if there is space. Tap is lost if queue is full.\n        DebugHelper.log(\"onSingleTap()\");\n        queuedSingleTaps.offer(e);\n    }\n\n    private void load3DCharacters() {\n        CharacterModel model = new CharacterModel();\n        model.setName(\"Cat\");\n        model.setObjectPath(\"cat/cat.obj\");\n        model.setScaleFactor(0.25f);\n        model.setResourceId(R.drawable.cat);\n        characterModelList.add(model);\n\n        model = new CharacterModel();\n        model.setName(\"Old Man\");\n        model.setObjectPath(\"man/muro.obj\");\n        model.setScaleFactor(0.0085f);\n        model.setResourceId(R.drawable.old_man);\n        characterModelList.add(model);\n\n\n        model = new CharacterModel();\n        model.setName(\"Bloodwing\");\n        model.setObjectPath(\"bloodwing/bloodwing.obj\");\n        model.setScaleFactor(0.0009f);\n        model.setResourceId(R.drawable.bat);\n        characterModelList.add(model);\n    }\n\n    private void loadObject(CharacterModel model) {\n        try {\n            this.objectPath = model.getObjectPath();\n            this.scaleFactor = model.getScaleFactor();\n            if (virtualObject == null) {\n                virtualObject = new ObjectRenderer(objectPath);\n                virtualObject.createOnGlThread(this);\n                virtualObject.setMaterialProperties(0.0f, 1.0f, 1.0f, 6.0f);\n            } else {\n                // Clear screen to notify driver it should not load any pixels from previous frame.\n                GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT);\n                isObjectChanged = true;\n                virtualObject.updateObjectPath(model.getObjectPath());\n            }\n        } catch (Exception ex) {\n            ex.printStackTrace();\n        }\n    }\n\n\n@Override\n        public void onDrawFrame(GL10 gl) {\n        if (isObjectChanged) {\n            isObjectChanged = false;\n            try {\n                virtualObject.createOnGlThread(this);\n                virtualObject.setMaterialProperties(0.0f, 2.0f, 0.5f, 6.0f);\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n            return;\n        }\n\n        // Clear screen to notify driver it should not load any pixels from previous frame.\n        GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT | GLES20.GL_DEPTH_BUFFER_BIT);\n\n        if (session == null) {\n            return;\n        }\n        // Notify ARCore session that the view size changed so that the perspective matrix and\n        // the video background can be properly adjusted.\n        displayRotationHelper.updateSessionIfNeeded(session);\n\n        try {\n            session.setCameraTextureName(backgroundRenderer.getTextureId());\n\n            // Obtain the current frame from ARSession. When the configuration is set to\n            // UpdateMode.BLOCKING (it is by default), this will throttle the rendering to the\n            // camera framerate.\n            Frame frame = session.update();\n            Camera camera = frame.getCamera();\n\n            // Handle taps. Handling only one tap per frame, as taps are usually low frequency\n            // compared to frame rate.\n            MotionEvent tap = queuedSingleTaps.poll();\n            if (tap != null &amp;&amp; camera.getTrackingState() == TrackingState.TRACKING) {\n                for (HitResult hit : frame.hitTest(tap)) {\n                    // Check if any plane was hit, and if it was hit inside the plane polygon\n                    Trackable trackable = hit.getTrackable();\n                    // Creates an anchor if a plane or an oriented point was hit.\n                    if ((trackable instanceof Plane &amp;&amp; ((Plane) trackable).isPoseInPolygon(hit.getHitPose())) || (trackable instanceof Point &amp;&amp; ((Point) trackable).getOrientationMode() == Point.OrientationMode.ESTIMATED_SURFACE_NORMAL)) {\n                        // Hits are sorted by depth. Consider only closest hit on a plane or oriented point.\n                        // Cap the number of objects created. This avoids overloading both the\n                        // rendering system and ARCore.\n                        //if (!isUpdate) {\n                        DebugHelper.log(\"Anchor size = \" + anchors.size());\n                        if (anchors.size() &gt;= 1) {\n                            anchors.get(0).detach();\n                            anchors.remove(0);\n                        }\n                        // Adding an Anchor tells ARCore that it should track this position in\n                        // space. This anchor is created on the Plane to place the 3D model\n                        // in the correct position relative both to the world and to the plane.\n                        if (anchors.size() &gt; 0) {\n                            DebugHelper.log(\"anchor list has data\");\n                            for (Anchor anchor : anchors) {\n                                anchor.detach();\n                                anchors.remove(anchor);\n                            }\n                        }\n                        Anchor anchor = hit.createAnchor();\n                        if (anchor != null)\n                            anchors.add(anchor);\n                        else\n                            DebugHelper.log(\"anchor is null\");\n                        //}\n                        break;\n                    }\n                }\n            }\n\n            // Draw background.\n            backgroundRenderer.draw(frame);\n\n            // If not tracking, don't draw 3d objects.\n            if (camera.getTrackingState() == TrackingState.PAUSED) {\n                return;\n            }\n\n            // Get projection matrix.\n            camera.getProjectionMatrix(projmtx, 0, 0.1f, 100.0f);\n\n            // Get camera matrix and draw.\n            camera.getViewMatrix(viewmtx, 0);\n\n            // Compute lighting from average intensity of the image.\n            final float lightIntensity = frame.getLightEstimate().getPixelIntensity();\n\n            // Visualize tracked points.\n            PointCloud pointCloud = frame.acquirePointCloud();\n            this.pointCloud.update(pointCloud);\n            if (!capturePicture)\n                this.pointCloud.draw(viewmtx, projmtx);\n\n            // Application is responsible for releasing the point cloud resources after\n            // using it.\n            pointCloud.release();\n\n            // Check if we detected at least one plane. If so, hide the loading message.\n            if (messageSnackbar != null) {\n                {\n                    for (Plane plane : session.getAllTrackables(Plane.class)) {\n                        if (plane.getType() == Plane.Type.HORIZONTAL_UPWARD_FACING\n                                &amp;&amp; plane.getTrackingState() == TrackingState.TRACKING) {\n                            hideLoadingMessage();\n                            break;\n                        }\n                    }\n                }\n                for (Plane plane : session.getAllTrackables(Plane.class)) {\n                    if (plane.getType() == Plane.Type.HORIZONTAL_UPWARD_FACING &amp;&amp; plane.getTrackingState() == TrackingState.TRACKING) {\n                        hideLoadingMessage();\n                        break;\n                    }\n                }\n            }\n            // Visualize planes.\n            if (!capturePicture)\n                planeRenderer.drawPlanes(session.getAllTrackables(Plane.class), camera.getDisplayOrientedPose(), projmtx);\n\n            // Visualize anchors created by touch.\n            for (Anchor anchor : anchors) {\n                if (anchor.getTrackingState() != TrackingState.TRACKING) {\n                    continue;\n                }\n                // Get the current pose of an Anchor in world space. The Anchor pose is updated\n                // during calls to session.update() as ARCore refines its estimate of the world.\n                anchor.getPose().toMatrix(anchorMatrix, 0);\n\n                // Update and draw the model and its shadow.\n                if (virtualObject != null) {\n//passing my scaleFector and rotationDegree to update my matrix.\n                    virtualObject.updateModelMatrix(anchorMatrix, scaleFactor, mRotationDegrees);\n                    if (viewmtx != null &amp;&amp; projmtx != null) {\n                        virtualObject.draw(viewmtx, projmtx, lightIntensity);\n                    }\n                }\n\n            }\n\n            if (capturePicture) {\n                capturePicture = false;\n                onSavePicture();\n            }\n\n        } catch (Throwable t) {\n            Log.e(TAG, \"Exception on the OpenGL thread\", t);\n        }\n    }\n</code></pre>\n\n<p><strong>ObjectRenderer</strong></p>\n\n<pre><code>public void updateModelMatrix(float[] modelMatrix, float scaleFactor, float rotationFactor) {\n        float[] scaleMatrix = new float[16];\n        Matrix.setIdentityM(scaleMatrix, 0);\n        scaleMatrix[0] = scaleFactor;\n        scaleMatrix[5] = scaleFactor;\n        scaleMatrix[10] = scaleFactor;\n\n        Matrix.rotateM(modelMatrix, 0, rotationFactor, 0, 1, 0);\n//      Matrix.rotateM(modelMatrix, 0, scaleFactor, 0, 1, 0);\n//      Matrix.rotateM(modelMatrix, 0, scaleFactor, 0, 0, 1);\n\n        Matrix.multiplyMM(mModelMatrix, 0, modelMatrix, 0, scaleMatrix, 0);\n    }\n</code></pre>\n"
        },
        {
            "tags": [
                "python",
                "python-c-api"
            ],
            "owner": {
                "reputation": 86,
                "user_id": 7838619,
                "user_type": "registered",
                "accept_rate": 0,
                "profile_image": "https://www.gravatar.com/avatar/4ad17a611568edbe8ce53033c6030d59?s=128&d=identicon&r=PG&f=1",
                "display_name": "user62039",
                "link": "https://stackoverflow.com/users/7838619/user62039"
            },
            "is_answered": true,
            "view_count": 23,
            "accepted_answer_id": 49934587,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524204138,
            "creation_date": 1524200512,
            "last_edit_date": 1524201953,
            "question_id": 49934314,
            "body_markdown": "How to get installed python package folder path in Python C API?\r\n\r\nSuppose I want to open a file `data.txt` from the Python C-API `module.pyd` that resides as follows:\r\n\r\n    package\r\n       |--module.pyd\r\n       |--data\r\n       |    |-data.txt\r\n\r\n\r\nHow do I get the path name of `data.txt`?\r\n\r\n\r\n---",
            "link": "https://stackoverflow.com/questions/49934314/how-to-get-installed-python-package-folder-path",
            "title": "How to get installed python package folder path?",
            "body": "<p>How to get installed python package folder path in Python C API?</p>\n\n<p>Suppose I want to open a file <code>data.txt</code> from the Python C-API <code>module.pyd</code> that resides as follows:</p>\n\n<pre><code>package\n   |--module.pyd\n   |--data\n   |    |-data.txt\n</code></pre>\n\n<p>How do I get the path name of <code>data.txt</code>?</p>\n\n<hr>\n"
        },
        {
            "tags": [
                "javascript",
                "html-table",
                "datatables",
                "protractor",
                "cucumber"
            ],
            "owner": {
                "reputation": 16,
                "user_id": 2812819,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/c446b1ec715373761bb17eb2c705a54d?s=128&d=identicon&r=PG&f=1",
                "display_name": "user2812819",
                "link": "https://stackoverflow.com/users/2812819/user2812819"
            },
            "is_answered": false,
            "view_count": 13,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524204133,
            "creation_date": 1524204133,
            "question_id": 49934993,
            "body_markdown": "For security reasons, I cant post the DOM but I have table in the UI similar to the picture posted below. For now, I am just trying to validate the value in the cell 1(under header 1) with the values in the cucumber datatable\r\n\r\nHere is the cucumber step:\r\n\r\nThen for &quot;School Name - Test123&quot; I should see the following data in &quot;Header 1&quot; column\r\n      \r\n      | Name   | STDID     | Dept # |\r\n      | John  | 316069844 | 1761   |  \r\n\r\nAnd here is the sample of the UI table I have\r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\nCould someone share some ideas as to how I can get this done?I referred to the : https://stackoverflow.com/questions/29501976/protractor-read-table-contents?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa\r\n\r\nbut I didn&#39;t get me far, I can print the cell value in this entirety but clearly there are many things here to validate even inside cell #1. Any pointers would be helpful. Thanks\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/S7Sul.jpg",
            "link": "https://stackoverflow.com/questions/49934993/protractor-cucumber-validating-html-table-content-with-cucumber-data-table-jav",
            "title": "Protractor-Cucumber: Validating HTML table content with cucumber data table (javascript)",
            "body": "<p>For security reasons, I cant post the DOM but I have table in the UI similar to the picture posted below. For now, I am just trying to validate the value in the cell 1(under header 1) with the values in the cucumber datatable</p>\n\n<p>Here is the cucumber step:</p>\n\n<p>Then for \"School Name - Test123\" I should see the following data in \"Header 1\" column</p>\n\n<pre><code>  | Name   | STDID     | Dept # |\n  | John  | 316069844 | 1761   |  \n</code></pre>\n\n<p>And here is the sample of the UI table I have</p>\n\n<p><a href=\"https://i.stack.imgur.com/S7Sul.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/S7Sul.jpg\" alt=\"enter image description here\"></a></p>\n\n<p>Could someone share some ideas as to how I can get this done?I referred to the : <a href=\"https://stackoverflow.com/questions/29501976/protractor-read-table-contents?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa\">Protractor : Read Table contents</a></p>\n\n<p>but I didn't get me far, I can print the cell value in this entirety but clearly there are many things here to validate even inside cell #1. Any pointers would be helpful. Thanks</p>\n"
        },
        {
            "tags": [
                "nginx",
                "docker",
                "reverse-proxy",
                "docker-networking"
            ],
            "owner": {
                "reputation": 7729,
                "user_id": 78000,
                "user_type": "registered",
                "accept_rate": 65,
                "profile_image": "https://www.gravatar.com/avatar/e14e616a0f9734fc8f0a2ce02d30f735?s=128&d=identicon&r=PG",
                "display_name": "Phil",
                "link": "https://stackoverflow.com/users/78000/phil"
            },
            "is_answered": true,
            "view_count": 280307,
            "accepted_answer_id": 24326540,
            "answer_count": 13,
            "score": 549,
            "last_activity_date": 1524204127,
            "creation_date": 1403236456,
            "last_edit_date": 1488558727,
            "question_id": 24319662,
            "body_markdown": "So I have a Nginx running inside a docker container, I have a mysql running on localhost, I want to connect to the MySql from within my Nginx. The MySql is running on localhost and not exposing a port to the outside world, so its bound on localhost, not bound on the ip address of the machine.\r\n\r\n\r\nIs there any way to connect to this MySql or any other program on localhost from within this docker container?",
            "link": "https://stackoverflow.com/questions/24319662/from-inside-of-a-docker-container-how-do-i-connect-to-the-localhost-of-the-mach",
            "title": "From inside of a Docker container, how do I connect to the localhost of the machine?",
            "body": "<p>So I have a Nginx running inside a docker container, I have a mysql running on localhost, I want to connect to the MySql from within my Nginx. The MySql is running on localhost and not exposing a port to the outside world, so its bound on localhost, not bound on the ip address of the machine.</p>\n\n<p>Is there any way to connect to this MySql or any other program on localhost from within this docker container?</p>\n"
        },
        {
            "tags": [
                "java",
                "html",
                "spring",
                "spring-boot",
                "thymeleaf"
            ],
            "owner": {
                "reputation": 48,
                "user_id": 6138508,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/f69ca23781018d71504bf90156c7a5cc?s=128&d=identicon&r=PG&f=1",
                "display_name": "FunkyMan",
                "link": "https://stackoverflow.com/users/6138508/funkyman"
            },
            "is_answered": false,
            "view_count": 12,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524204112,
            "creation_date": 1524151293,
            "last_edit_date": 1524204112,
            "question_id": 49924713,
            "body_markdown": "how can i display a svg graphics using thymeleaf in a html fragment?\r\n\r\nfollowing snippets are not working:\r\n\r\n    &lt;img th:src=&quot;@{vector.svg}&quot;&gt;\r\n\r\n    &lt;svg width=&quot;300px&quot; height=&quot;300px&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; th:src=&quot;@{vector.svg}&gt;\r\n\r\nthe location of the svg graphics are &quot;static/images/vector.svg&quot;\r\n\r\nalso tried th:data\r\n\r\nI&#39;m using thymeleaf 3 with Spring boot 4 and flying saucer.",
            "link": "https://stackoverflow.com/questions/49924713/can-not-display-a-svg-graphic-with-thymeleaf",
            "title": "Can not display a SVG Graphic with Thymeleaf",
            "body": "<p>how can i display a svg graphics using thymeleaf in a html fragment?</p>\n\n<p>following snippets are not working:</p>\n\n<pre><code>&lt;img th:src=\"@{vector.svg}\"&gt;\n\n&lt;svg width=\"300px\" height=\"300px\" xmlns=\"http://www.w3.org/2000/svg\" th:src=\"@{vector.svg}&gt;\n</code></pre>\n\n<p>the location of the svg graphics are \"static/images/vector.svg\"</p>\n\n<p>also tried th:data</p>\n\n<p>I'm using thymeleaf 3 with Spring boot 4 and flying saucer.</p>\n"
        },
        {
            "tags": [
                "optimization",
                "mathematical-optimization",
                "modeling",
                "path-finding"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9670253,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-MeTTX93UiB8/AAAAAAAAAAI/AAAAAAAAAHU/U4AeYQ_2H9Q/photo.jpg?sz=128",
                "display_name": "venkatesh suswaram",
                "link": "https://stackoverflow.com/users/9670253/venkatesh-suswaram"
            },
            "is_answered": false,
            "view_count": 9,
            "answer_count": 0,
            "score": -1,
            "last_activity_date": 1524204108,
            "creation_date": 1524146620,
            "last_edit_date": 1524204108,
            "question_id": 49923116,
            "body_markdown": "I have a list of hold orders at GEO &amp; Product level ( usually 1 order will have multiple products for one specific Geo ). I want to fill the gap w.r.t Target values across GEO &amp; Product.\r\n\r\nI have tried to fill in one dimensional. i.e for one GEO &amp; one product. But we need to implement it in two dimensional way.\r\n\r\nCan some one help in optimizing the process of order release that will clear the gap and also will not skew other products. i.e to get the optimal path across product &amp; Geo such that I will meet my Target with minimal variance.\r\n\r\nThank you.",
            "link": "https://stackoverflow.com/questions/49923116/i-want-to-create-a-optimization-model-which-lists-me-set-of-orders-that-fill-the",
            "title": "I want to create a optimization model which lists me set of orders that fill the gap w.r.t target values",
            "body": "<p>I have a list of hold orders at GEO &amp; Product level ( usually 1 order will have multiple products for one specific Geo ). I want to fill the gap w.r.t Target values across GEO &amp; Product.</p>\n\n<p>I have tried to fill in one dimensional. i.e for one GEO &amp; one product. But we need to implement it in two dimensional way.</p>\n\n<p>Can some one help in optimizing the process of order release that will clear the gap and also will not skew other products. i.e to get the optimal path across product &amp; Geo such that I will meet my Target with minimal variance.</p>\n\n<p>Thank you.</p>\n"
        },
        {
            "tags": [
                "ruby",
                "rubygems"
            ],
            "owner": {
                "reputation": 528,
                "user_id": 776723,
                "user_type": "registered",
                "accept_rate": 65,
                "profile_image": "https://www.gravatar.com/avatar/0ce47adef9e11712c1625b52c7ebd3f8?s=128&d=identicon&r=PG",
                "display_name": "ShadSterling",
                "link": "https://stackoverflow.com/users/776723/shadsterling"
            },
            "is_answered": false,
            "view_count": 19,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524204100,
            "creation_date": 1524197350,
            "last_edit_date": 1524204100,
            "question_id": 49933847,
            "body_markdown": "I&#39;m familiar with the node/npm way, and trying to get set up using ruby/gem/bundler as well.\r\n\r\nThe output from `gem env` includes these lines:\r\n\r\n      - RUBYGEMS VERSION: 2.7.6\r\n      - RUBY VERSION: 2.5.1 (2018-03-29 patchlevel 57) [x86_64-darwin17]\r\n      - INSTALLATION DIRECTORY: /opt/local/lib/ruby2.5/gems/2.5.0\r\n      - USER INSTALLATION DIRECTORY: /Users/ssterling3/.gem/ruby/2.5.0\r\n\r\n(I don&#39;t get why gems for ruby 2.5.1 would be installed in dir named 2.5.0, but that&#39;s not what this question is about.)\r\n\r\n**I don&#39;t want `gem` to ever touch anything outside of `$HOME`, and I want to do so in a way that I&#39;ll never have to edit even when I upgrade ruby or move the content of `$HOME` to a different computer where I have a different username.**\r\n\r\n(Sure, I&#39;ll have to reinstall all the gems or something, that&#39;s also not what this question is about.)\r\n\r\n**I think the right way to do it is to override the default `INSTALLATION DIRECTORY` and set it to always match the default `USER INSTALLATION DIRECTORY`.**\r\n\r\n**How can I do that?**\r\n\r\nI know I can override the `INSTALLATION DIRECTORY` by setting `$GEM_HOME`, but I don&#39;t know how to get gem to output the `USER INSTALLATION DIRECTORY` in a way I won&#39;t have to parse before setting `$GEM_HOME`.  I can get the `INSTALLATION DIRECTORY` from `gem env gemdir`, but `gem env --user-install gemdir` says `Invalid option`.\r\n\r\n(Why one value has three dissimilar names and a closely related value only has the least usable analogous name are both also not what this question is about.)\r\n\r\nI know I can configure some things in `$HOME/.gemrc`, but the documentation and examples I found didn&#39;t make it clear to me how to manipulate the `INSTALLATION DIRECTORY`.  It sounded like I might be able to do it by adding the line `gem: --user-install`, but maybe it has to be at least three lines for `install`, `uninstall`, and `update`, but adding the line with `gem:` doesn&#39;t change the output of `gem env` so maybe none of those will really do what I want.",
            "link": "https://stackoverflow.com/questions/49933847/configure-gem-installation-directory-to-match-user-installation-directory",
            "title": "Configure gem installation directory to match user installation directory",
            "body": "<p>I'm familiar with the node/npm way, and trying to get set up using ruby/gem/bundler as well.</p>\n\n<p>The output from <code>gem env</code> includes these lines:</p>\n\n<pre><code>  - RUBYGEMS VERSION: 2.7.6\n  - RUBY VERSION: 2.5.1 (2018-03-29 patchlevel 57) [x86_64-darwin17]\n  - INSTALLATION DIRECTORY: /opt/local/lib/ruby2.5/gems/2.5.0\n  - USER INSTALLATION DIRECTORY: /Users/ssterling3/.gem/ruby/2.5.0\n</code></pre>\n\n<p>(I don't get why gems for ruby 2.5.1 would be installed in dir named 2.5.0, but that's not what this question is about.)</p>\n\n<p><strong>I don't want <code>gem</code> to ever touch anything outside of <code>$HOME</code>, and I want to do so in a way that I'll never have to edit even when I upgrade ruby or move the content of <code>$HOME</code> to a different computer where I have a different username.</strong></p>\n\n<p>(Sure, I'll have to reinstall all the gems or something, that's also not what this question is about.)</p>\n\n<p><strong>I think the right way to do it is to override the default <code>INSTALLATION DIRECTORY</code> and set it to always match the default <code>USER INSTALLATION DIRECTORY</code>.</strong></p>\n\n<p><strong>How can I do that?</strong></p>\n\n<p>I know I can override the <code>INSTALLATION DIRECTORY</code> by setting <code>$GEM_HOME</code>, but I don't know how to get gem to output the <code>USER INSTALLATION DIRECTORY</code> in a way I won't have to parse before setting <code>$GEM_HOME</code>.  I can get the <code>INSTALLATION DIRECTORY</code> from <code>gem env gemdir</code>, but <code>gem env --user-install gemdir</code> says <code>Invalid option</code>.</p>\n\n<p>(Why one value has three dissimilar names and a closely related value only has the least usable analogous name are both also not what this question is about.)</p>\n\n<p>I know I can configure some things in <code>$HOME/.gemrc</code>, but the documentation and examples I found didn't make it clear to me how to manipulate the <code>INSTALLATION DIRECTORY</code>.  It sounded like I might be able to do it by adding the line <code>gem: --user-install</code>, but maybe it has to be at least three lines for <code>install</code>, <code>uninstall</code>, and <code>update</code>, but adding the line with <code>gem:</code> doesn't change the output of <code>gem env</code> so maybe none of those will really do what I want.</p>\n"
        },
        {
            "tags": [
                "python"
            ],
            "owner": {
                "reputation": 3103,
                "user_id": 1103966,
                "user_type": "registered",
                "accept_rate": 76,
                "profile_image": "https://www.gravatar.com/avatar/0fb92143734ac26c56fca34c669cd99a?s=128&d=identicon&r=PG",
                "display_name": "Dr.Knowitall",
                "link": "https://stackoverflow.com/users/1103966/dr-knowitall"
            },
            "is_answered": true,
            "view_count": 30,
            "closed_date": 1524211925,
            "accepted_answer_id": 49934989,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1524204097,
            "creation_date": 1524202135,
            "question_id": 49934598,
            "body_markdown": "Currently when I write to a temporary:\r\n\r\n    import tempfile\r\n    a = tempfile.TemporaryFile()\r\n    \r\n    a.write(...)\r\n    \r\n    # The only way I know to get the size\r\n    a.seek(0)\r\n    len(a.read())\r\n\r\nIs there a better way?\r\n",
            "link": "https://stackoverflow.com/questions/49934598/how-can-i-get-the-size-of-a-temporaryfile-in-python",
            "closed_reason": "duplicate",
            "title": "How can I get the size of a TemporaryFile in python?",
            "body": "<p>Currently when I write to a temporary:</p>\n\n<pre><code>import tempfile\na = tempfile.TemporaryFile()\n\na.write(...)\n\n# The only way I know to get the size\na.seek(0)\nlen(a.read())\n</code></pre>\n\n<p>Is there a better way?</p>\n"
        },
        {
            "tags": [
                "php"
            ],
            "owner": {
                "user_type": "does_not_exist",
                "display_name": "John"
            },
            "is_answered": true,
            "view_count": 40700,
            "accepted_answer_id": 1761302,
            "answer_count": 9,
            "score": 16,
            "last_activity_date": 1524204092,
            "creation_date": 1258611626,
            "last_edit_date": 1368318553,
            "question_id": 1761252,
            "body_markdown": "I have one directory called images/tips.\r\n\r\nNow in that directory I have many images which can change.\r\n\r\nI want the PHP script to read the directory, to find the images, and out of those images found to pick a random image.\r\n\r\nAny idea on how to do this?",
            "link": "https://stackoverflow.com/questions/1761252/how-to-get-random-image-from-directory-using-php",
            "title": "How to get random image from directory using PHP",
            "body": "<p>I have one directory called images/tips.</p>\n\n<p>Now in that directory I have many images which can change.</p>\n\n<p>I want the PHP script to read the directory, to find the images, and out of those images found to pick a random image.</p>\n\n<p>Any idea on how to do this?</p>\n"
        },
        {
            "tags": [
                "emacs",
                "tabs"
            ],
            "owner": {
                "reputation": 19286,
                "user_id": 122536,
                "user_type": "registered",
                "accept_rate": 80,
                "profile_image": "https://www.gravatar.com/avatar/6fd51ed284bddf7eeab9de416359021e?s=128&d=identicon&r=PG",
                "display_name": "alexchenco",
                "link": "https://stackoverflow.com/users/122536/alexchenco"
            },
            "is_answered": true,
            "view_count": 515,
            "accepted_answer_id": 2035513,
            "answer_count": 2,
            "score": 1,
            "last_activity_date": 1524204084,
            "creation_date": 1263080034,
            "last_edit_date": 1263112156,
            "question_id": 2035383,
            "body_markdown": "I&#39;m used to have 4 spaces of Tab width. YASnippets uses 2 spaces in its snippets for instance:\r\n\r\n    &lt;div id=&quot;$1&quot;&gt;\r\n      $0\r\n    &lt;/div&gt;\r\n\r\nI thought this would turn it into 4 spaces:\r\n\r\n    &lt;div id=&quot;$1&quot;&gt;\r\n       $0\r\n    &lt;/div&gt;\r\n\r\nbut no luck...\r\n\r\nSo I also tried:\r\n\r\n    (setq-default tab-width 4) \r\n    (setq-default indent-tabs-mode t)\r\n    (setq tab-stop-list &#39;(4 8 12 16))\r\n\r\nbut no luck again\r\n\r\nIs there another setting that helps in this kind of situation?",
            "link": "https://stackoverflow.com/questions/2035383/i-need-help-with-yasnippet-and-tab-width",
            "title": "I need help with YASnippet and tab width",
            "body": "<p>I'm used to have 4 spaces of Tab width. YASnippets uses 2 spaces in its snippets for instance:</p>\n\n<pre><code>&lt;div id=\"$1\"&gt;\n  $0\n&lt;/div&gt;\n</code></pre>\n\n<p>I thought this would turn it into 4 spaces:</p>\n\n<pre><code>&lt;div id=\"$1\"&gt;\n   $0\n&lt;/div&gt;\n</code></pre>\n\n<p>but no luck...</p>\n\n<p>So I also tried:</p>\n\n<pre><code>(setq-default tab-width 4) \n(setq-default indent-tabs-mode t)\n(setq tab-stop-list '(4 8 12 16))\n</code></pre>\n\n<p>but no luck again</p>\n\n<p>Is there another setting that helps in this kind of situation?</p>\n"
        },
        {
            "tags": [
                "ios",
                "formatting",
                "nsnumber",
                "data-conversion",
                "human-readable"
            ],
            "owner": {
                "reputation": 5038,
                "user_id": 1339303,
                "user_type": "registered",
                "accept_rate": 65,
                "profile_image": "https://graph.facebook.com/100002566602308/picture?type=large",
                "display_name": "Kyle Begeman",
                "link": "https://stackoverflow.com/users/1339303/kyle-begeman"
            },
            "is_answered": true,
            "view_count": 16985,
            "accepted_answer_id": 18295494,
            "answer_count": 19,
            "score": 44,
            "last_activity_date": 1524204081,
            "creation_date": 1376635028,
            "last_edit_date": 1456916352,
            "question_id": 18267211,
            "body_markdown": "How can I convert all numbers that are more than 3 digits down to a 4 digit or less number?\r\n\r\nThis is exactly what I mean:\r\n\r\n    10345 = 10.3k\r\n    10012 = 10k\r\n    123546 = 123.5k\r\n    4384324 = 4.3m\r\n\r\nRounding is not entirely important, but an added plus. \r\n\r\nI have looked into NSNumberFormatter but have not found the proper solution, and I have yet to find a proper solution here on SO. Any help is greatly appreciated, thanks! ",
            "link": "https://stackoverflow.com/questions/18267211/ios-convert-large-numbers-to-smaller-format",
            "title": "iOS convert large numbers to smaller format",
            "body": "<p>How can I convert all numbers that are more than 3 digits down to a 4 digit or less number?</p>\n\n<p>This is exactly what I mean:</p>\n\n<pre><code>10345 = 10.3k\n10012 = 10k\n123546 = 123.5k\n4384324 = 4.3m\n</code></pre>\n\n<p>Rounding is not entirely important, but an added plus. </p>\n\n<p>I have looked into NSNumberFormatter but have not found the proper solution, and I have yet to find a proper solution here on SO. Any help is greatly appreciated, thanks! </p>\n"
        },
        {
            "tags": [
                "sql",
                "ms-access"
            ],
            "owner": {
                "reputation": 11,
                "user_id": 8843367,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/ae5d630e09f55f7a82c216e94869cdfb?s=128&d=identicon&r=PG&f=1",
                "display_name": "Tucker Black",
                "link": "https://stackoverflow.com/users/8843367/tucker-black"
            },
            "is_answered": false,
            "view_count": 38,
            "answer_count": 2,
            "score": 2,
            "last_activity_date": 1524204074,
            "creation_date": 1524187642,
            "last_edit_date": 1524195560,
            "question_id": 49932520,
            "body_markdown": "I will try to simplify the situation as best as I can...\r\nI work with a team of field service technicians.  We share a lot of our tools and equipment between us because SOMEONE doesnt want to spend money on us.  I am using MS Access to develope a way to track who has what tool or specific piece of equipment out of a pool of about 2000+ items.  I have got the process figured out down to one last step.  It gos like this:\r\n\r\n1. Tech opens a form that shows current location/ownership of all 2000+ items, which is pulled off a SharePoint List and inserted into\r\n    a local table. \r\n2. Tech makes changes to local table.\r\n3. When Tech is done, the Sharepoint List gets updated FROM the local table (This is where I am stuck).\r\n\r\nI have followed every tutorial, walk through, and work around that I can understand.  But every time I run the Query, Access asks me for the &quot;Parameter Value&quot; of each field I am trying to update.  Mind you, everything I have found shows an example of how to update one field in a table.  I am trying to update 5 fields per row.  When I let Access build the SQL for this it looks like:\r\n\r\n    UPDATE Table1 INNER JOIN Table2 \r\n    ON Table1.[Asset ID] = Table2.[Asset ID] \r\n    SET Table1.Department = Table2.[Department], Table1.[Cal Status] = Table2. \r\n    [Cal Status], Table1.[Return Date] = Table2.[Return Date], Table1.Comments = \r\n    Table2.[Comments], Table1.[Cal Due] = Table2.[Cal Due], Table1.Active = \r\n    Table2.[Active];\r\n\r\nThe fields are not misspelled, I already checked and double checked that.\r\n\r\nI have seen some comments about how Access has problems with UPDATE. But I am self taught with everything I do and I cant switch to something else until I understand this.  I just started with Access and SQL at the begining of this week, so please be patient with me.\r\n\r\n**EDIT**\r\n\r\n    UPDATE Assets\r\n    SET Assets.Department = AssetsSharePoint.[Department],\r\n    Assets.[Cal Status]   = AssetsSharePoint.[Cal Status],\r\n    Assets.[Return Date]  = AssetsSharePoint.[Return Date],\r\n    Assets.Comments       = AssetsSharePoint.[Comments],\r\n    Assets.[Cal Due]      = AssetsSharePoint.[Cal Due],\r\n    Assets.Active         = AssetsSharePoint.[Active]\r\n    FROM Assets\r\n    INNER JOIN AssetsSharePoint ON Assets.[Asset ID] = AssetsSharePoint.[Asset \r\n    ID];\r\n\r\nThis gives me a &quot;Syntax Error.  Missing Operator&quot;  Then Highlights `FROM` \r\n\r\n**EDIT 2**\r\n\r\nIf I cut it down to 1 field, leave out the `FROM`, and include `WHERE` it works. I dont want to make 5 seperate queries for this.  But I guess I am going to have to.... \r\n",
            "link": "https://stackoverflow.com/questions/49932520/ms-access-update-query-keeps-asking-for-parameter-value",
            "title": "MS Access Update Query Keeps Asking for &quot;Parameter Value&quot;",
            "body": "<p>I will try to simplify the situation as best as I can...\nI work with a team of field service technicians.  We share a lot of our tools and equipment between us because SOMEONE doesnt want to spend money on us.  I am using MS Access to develope a way to track who has what tool or specific piece of equipment out of a pool of about 2000+ items.  I have got the process figured out down to one last step.  It gos like this:</p>\n\n<ol>\n<li>Tech opens a form that shows current location/ownership of all 2000+ items, which is pulled off a SharePoint List and inserted into\na local table. </li>\n<li>Tech makes changes to local table.</li>\n<li>When Tech is done, the Sharepoint List gets updated FROM the local table (This is where I am stuck).</li>\n</ol>\n\n<p>I have followed every tutorial, walk through, and work around that I can understand.  But every time I run the Query, Access asks me for the \"Parameter Value\" of each field I am trying to update.  Mind you, everything I have found shows an example of how to update one field in a table.  I am trying to update 5 fields per row.  When I let Access build the SQL for this it looks like:</p>\n\n<pre><code>UPDATE Table1 INNER JOIN Table2 \nON Table1.[Asset ID] = Table2.[Asset ID] \nSET Table1.Department = Table2.[Department], Table1.[Cal Status] = Table2. \n[Cal Status], Table1.[Return Date] = Table2.[Return Date], Table1.Comments = \nTable2.[Comments], Table1.[Cal Due] = Table2.[Cal Due], Table1.Active = \nTable2.[Active];\n</code></pre>\n\n<p>The fields are not misspelled, I already checked and double checked that.</p>\n\n<p>I have seen some comments about how Access has problems with UPDATE. But I am self taught with everything I do and I cant switch to something else until I understand this.  I just started with Access and SQL at the begining of this week, so please be patient with me.</p>\n\n<p><strong>EDIT</strong></p>\n\n<pre><code>UPDATE Assets\nSET Assets.Department = AssetsSharePoint.[Department],\nAssets.[Cal Status]   = AssetsSharePoint.[Cal Status],\nAssets.[Return Date]  = AssetsSharePoint.[Return Date],\nAssets.Comments       = AssetsSharePoint.[Comments],\nAssets.[Cal Due]      = AssetsSharePoint.[Cal Due],\nAssets.Active         = AssetsSharePoint.[Active]\nFROM Assets\nINNER JOIN AssetsSharePoint ON Assets.[Asset ID] = AssetsSharePoint.[Asset \nID];\n</code></pre>\n\n<p>This gives me a \"Syntax Error.  Missing Operator\"  Then Highlights <code>FROM</code> </p>\n\n<p><strong>EDIT 2</strong></p>\n\n<p>If I cut it down to 1 field, leave out the <code>FROM</code>, and include <code>WHERE</code> it works. I dont want to make 5 seperate queries for this.  But I guess I am going to have to.... </p>\n"
        },
        {
            "tags": [
                "javascript",
                "d3.js"
            ],
            "owner": {
                "reputation": 122,
                "user_id": 8198606,
                "user_type": "registered",
                "accept_rate": 24,
                "profile_image": "https://www.gravatar.com/avatar/6c6e30dba2e959d49af1312ce26a69a5?s=128&d=identicon&r=PG&f=1",
                "display_name": "PurplePanda",
                "link": "https://stackoverflow.com/users/8198606/purplepanda"
            },
            "is_answered": false,
            "view_count": 24,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524204072,
            "creation_date": 1524185259,
            "last_edit_date": 1524204072,
            "question_id": 49932248,
            "body_markdown": "I have a D3 force layout that updates the number of nodes several times per second and that is called by restartD3(). I currently have a circle appended to each node and that works great. However, I now need to have 2 circles per node, but the key here is that they need to be on unique layers by type not by node, so I need to put them in groups. Here is the grouping layering that I am talking about: [link][1]\r\n\r\n\r\n  [1]: https://stackoverflow.com/questions/47492323/how-to-layer-d3-force-simulation-nodes-based-on-element-and-not-node-order\r\n\r\nI want this.circleNode to become an outer group for 2 other groups inside so that I only have to manipulate x and y position for the outer group and the 2 inner groups move as well. Here is my current code with just 1 outer group for the nodes but no groups nested inside yet:\r\n\r\n    // Create force simulation\r\n    this.force = d3.forceSimulation(this.users)\r\n    .alphaDecay(0)\r\n    .velocityDecay(0)\r\n    .on(&#39;tick&#39;, this.tickActions);\r\n\r\n\r\n    // Create circle nodes\r\n    this.circleNode = this.d3Graph.selectAll(null)\r\n    .enter()\r\n    .append(&quot;g&quot;)\r\n\r\n\r\n    // Call our restartD3 function\r\n    this.restartD3();\r\n\r\n    // My restartD3 function\r\n    restartD3() {\r\n\r\n    // Circles\r\n    this.circleNode = this.circleNode.data(this.users, function(d) {\r\n      return d.id;\r\n    });\r\n\r\n    this.circleNode.exit().remove();\r\n\r\n    this.circleNode = this.circleNode\r\n    .enter()\r\n    .append(&quot;circle&quot;)\r\n    .attr(&quot;class&quot;, &quot;usercircles&quot;)\r\n    .attr(&quot;r&quot;, this.userRadius)\r\n    .attr(&quot;fill&quot;, d =&gt; &quot;#00aced&quot;)\r\n    .merge(this.circleNode)\r\n\r\n    this.force.nodes(this.users);\r\n    }\r\n\r\nI haven&#39;t been able to implement this, and my attempts have been far off with nothing rendering. Any guidance on nesting groups in a node that works with updating a lot would be much appreciated.",
            "link": "https://stackoverflow.com/questions/49932248/how-to-add-and-remove-nodes-with-nested-groups-inside-a-d3-force-layout",
            "title": "How to add and remove nodes with nested groups inside a D3 force layout?",
            "body": "<p>I have a D3 force layout that updates the number of nodes several times per second and that is called by restartD3(). I currently have a circle appended to each node and that works great. However, I now need to have 2 circles per node, but the key here is that they need to be on unique layers by type not by node, so I need to put them in groups. Here is the grouping layering that I am talking about: <a href=\"https://stackoverflow.com/questions/47492323/how-to-layer-d3-force-simulation-nodes-based-on-element-and-not-node-order\">link</a></p>\n\n<p>I want this.circleNode to become an outer group for 2 other groups inside so that I only have to manipulate x and y position for the outer group and the 2 inner groups move as well. Here is my current code with just 1 outer group for the nodes but no groups nested inside yet:</p>\n\n<pre><code>// Create force simulation\nthis.force = d3.forceSimulation(this.users)\n.alphaDecay(0)\n.velocityDecay(0)\n.on('tick', this.tickActions);\n\n\n// Create circle nodes\nthis.circleNode = this.d3Graph.selectAll(null)\n.enter()\n.append(\"g\")\n\n\n// Call our restartD3 function\nthis.restartD3();\n\n// My restartD3 function\nrestartD3() {\n\n// Circles\nthis.circleNode = this.circleNode.data(this.users, function(d) {\n  return d.id;\n});\n\nthis.circleNode.exit().remove();\n\nthis.circleNode = this.circleNode\n.enter()\n.append(\"circle\")\n.attr(\"class\", \"usercircles\")\n.attr(\"r\", this.userRadius)\n.attr(\"fill\", d =&gt; \"#00aced\")\n.merge(this.circleNode)\n\nthis.force.nodes(this.users);\n}\n</code></pre>\n\n<p>I haven't been able to implement this, and my attempts have been far off with nothing rendering. Any guidance on nesting groups in a node that works with updating a lot would be much appreciated.</p>\n"
        },
        {
            "tags": [
                "python",
                "sql",
                "django"
            ],
            "owner": {
                "reputation": 613,
                "user_id": 4942153,
                "user_type": "registered",
                "accept_rate": 100,
                "profile_image": "https://i.stack.imgur.com/qrvnt.png?s=128&g=1",
                "display_name": "Abdelilah El Aissaoui",
                "link": "https://stackoverflow.com/users/4942153/abdelilah-el-aissaoui"
            },
            "is_answered": false,
            "view_count": 29,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524204061,
            "creation_date": 1524173423,
            "last_edit_date": 1524204061,
            "question_id": 49930524,
            "body_markdown": "First of all, I have got 2 models. \r\n\r\nThe first one is a **Customer** with some properties:\r\n\r\n    class Customer(models.Model):\r\n        name = models.CharField(max_length=250)\r\n        last_name = models.CharField(max_length=250)\r\n        email = models.EmailField(null=True)\r\n\r\nThe second one is a **Payment**:\r\n\r\n    class Payment(models.Model):\r\n        customer = models.ForeignKey(&#39;Customer&#39;, related_name=&#39;payments&#39;, on_delete=models.CASCADE)\r\n        month = models.DateField()\r\n        paid = models.BooleanField(default=False)\r\n\r\nI want to know if a Customer has paid in filtering by month. Month dates are stored using the 1st day (01/MM/YYYY).\r\n\r\nHowever a Customer might not have a payment created for the month that I&#39;m filtering but I still want to list this customer and using a default value for *paid* (the default value is false in this case).\r\n\r\nThis is my queryset:\r\n\r\n    values = [&#39;id&#39;, &#39;paid&#39;, &#39;payment_id&#39;]\r\n    qs = Customer.objects.filter(Q(payments__isnull=True) | Q(payments__month = date_filter)).annotate(paid=Coalesce(&#39;payments__paid&#39;, False), payment_id=F(&#39;payments__id&#39;)).values(*values)\r\n\r\n\r\n\r\nI get this SQL Query using `print(queryset.query)`:\r\n\r\n    SELECT &quot;restapi_customer&quot;.&quot;id&quot;, COALESCE(&quot;restapi_payment&quot;.&quot;paid&quot;, False) AS &quot;paid&quot;, &quot;restapi_payment&quot;.&quot;id&quot; AS &quot;payment_id&quot; \r\n    FROM &quot;restapi_customer&quot; \r\n    LEFT JOIN &quot;restapi_payment&quot; ON (&quot;restapi_customer&quot;.&quot;id&quot; = &quot;restapi_payment&quot;.&quot;customer_id&quot;) \r\n    WHERE (&quot;restapi_payment&quot;.&quot;id&quot; IS NULL OR &quot;restapi_payment&quot;.&quot;month&quot; = 2018-04-01)\r\n\r\nHowever this will not return every customer, it will  only return the customers without any payment or with payments done in the filtered month. If a customer has only payments in different dates, it won&#39;t appear.\r\n\r\nSo how should be my queryset to achieve the desired result? I want to add the date filter to my left join condition in my queryset to get the following SQL query to make every customer appear:\r\n\r\n    SELECT &quot;restapi_customer&quot;.&quot;id&quot;, COALESCE(&quot;restapi_payment&quot;.&quot;paid&quot;, False) AS &quot;paid&quot;, &quot;restapi_payment&quot;.&quot;id&quot; AS &quot;payment_id&quot; \r\n    FROM &quot;restapi_customer&quot; \r\n    LEFT JOIN &quot;restapi_payment&quot; ON (&quot;restapi_customer&quot;.&quot;id&quot; = &quot;restapi_payment&quot;.&quot;customer_id&quot; AND  &quot;restapi_payment&quot;.&quot;month&quot; = 2018-04-01)\r\n    WHERE (&quot;restapi_payment&quot;.&quot;id&quot; IS NULL)",
            "link": "https://stackoverflow.com/questions/49930524/adding-conditions-to-left-join-using-django-queryset",
            "title": "Adding conditions to left join using Django queryset",
            "body": "<p>First of all, I have got 2 models. </p>\n\n<p>The first one is a <strong>Customer</strong> with some properties:</p>\n\n<pre><code>class Customer(models.Model):\n    name = models.CharField(max_length=250)\n    last_name = models.CharField(max_length=250)\n    email = models.EmailField(null=True)\n</code></pre>\n\n<p>The second one is a <strong>Payment</strong>:</p>\n\n<pre><code>class Payment(models.Model):\n    customer = models.ForeignKey('Customer', related_name='payments', on_delete=models.CASCADE)\n    month = models.DateField()\n    paid = models.BooleanField(default=False)\n</code></pre>\n\n<p>I want to know if a Customer has paid in filtering by month. Month dates are stored using the 1st day (01/MM/YYYY).</p>\n\n<p>However a Customer might not have a payment created for the month that I'm filtering but I still want to list this customer and using a default value for <em>paid</em> (the default value is false in this case).</p>\n\n<p>This is my queryset:</p>\n\n<pre><code>values = ['id', 'paid', 'payment_id']\nqs = Customer.objects.filter(Q(payments__isnull=True) | Q(payments__month = date_filter)).annotate(paid=Coalesce('payments__paid', False), payment_id=F('payments__id')).values(*values)\n</code></pre>\n\n<p>I get this SQL Query using <code>print(queryset.query)</code>:</p>\n\n<pre><code>SELECT \"restapi_customer\".\"id\", COALESCE(\"restapi_payment\".\"paid\", False) AS \"paid\", \"restapi_payment\".\"id\" AS \"payment_id\" \nFROM \"restapi_customer\" \nLEFT JOIN \"restapi_payment\" ON (\"restapi_customer\".\"id\" = \"restapi_payment\".\"customer_id\") \nWHERE (\"restapi_payment\".\"id\" IS NULL OR \"restapi_payment\".\"month\" = 2018-04-01)\n</code></pre>\n\n<p>However this will not return every customer, it will  only return the customers without any payment or with payments done in the filtered month. If a customer has only payments in different dates, it won't appear.</p>\n\n<p>So how should be my queryset to achieve the desired result? I want to add the date filter to my left join condition in my queryset to get the following SQL query to make every customer appear:</p>\n\n<pre><code>SELECT \"restapi_customer\".\"id\", COALESCE(\"restapi_payment\".\"paid\", False) AS \"paid\", \"restapi_payment\".\"id\" AS \"payment_id\" \nFROM \"restapi_customer\" \nLEFT JOIN \"restapi_payment\" ON (\"restapi_customer\".\"id\" = \"restapi_payment\".\"customer_id\" AND  \"restapi_payment\".\"month\" = 2018-04-01)\nWHERE (\"restapi_payment\".\"id\" IS NULL)\n</code></pre>\n"
        },
        {
            "tags": [
                "javascript",
                "reactjs"
            ],
            "owner": {
                "reputation": 39,
                "user_id": 8023463,
                "user_type": "registered",
                "accept_rate": 33,
                "profile_image": "https://i.stack.imgur.com/wYe5W.jpg?s=128&g=1",
                "display_name": "jimc3",
                "link": "https://stackoverflow.com/users/8023463/jimc3"
            },
            "is_answered": true,
            "view_count": 16,
            "accepted_answer_id": 49934978,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524204032,
            "creation_date": 1524203591,
            "question_id": 49934888,
            "body_markdown": "I just started my journey into the world of React and I love it so far. I finally started to get a grasp of the basics and tried my hand in creating a simple program.\r\nThis program simply takes what you are typing in a text box and displays it live in a header tag. I can&#39;t seem to figure out why this isn&#39;t working. I get the text to appear in the console, but can&#39;t figure out why it isn&#39;t displaying in my &lt;h2&gt; tag. Thank you in advance for the help. Any tips are greatly appreciated.\r\n\r\n\r\n    class Header extends Component{\r\n        render(){\r\n            return(\r\n                &lt;div className = &quot;header&quot;&gt;\r\n                    &lt;h1&gt;Enter Your Name&lt;/h1&gt;\r\n                &lt;/div&gt;\r\n            )\r\n        }\r\n    }\r\n\r\n    class Input extends Component{\r\n        render(){\r\n            return(\r\n                &lt;div className = &quot;input_container&quot;&gt;\r\n                    &lt;input onChange = {this.props.onChange} className = &quot;input_field&quot; type = &quot;text&quot; placeholder = &quot;Name...&quot;&gt;&lt;/input&gt;\r\n                &lt;/div&gt;\r\n            )\r\n        }\r\n    }\r\n\r\n    class App extends Component {\r\n        state = {\r\n            inputValue : &quot;&quot;\r\n        }\r\n    \r\n        onChange = (e) =&gt; {\r\n            console.log(e.target.value)\r\n            this.setState = ({inputValue: e.target.value});\r\n        }\r\n    \r\n        render(){\r\n            return(\r\n                &lt;div&gt;\r\n                &lt;Columns /&gt;\r\n                &lt;Input\r\n                    onChange = {this.onChange}/&gt;\r\n                &lt;h2&gt;{this.state.inputValue}&lt;/h2&gt;\r\n            &lt;/div&gt;\r\n            )\r\n        }\r\n    }",
            "link": "https://stackoverflow.com/questions/49934888/show-text-in-a-header-tag-as-it-is-being-typed-in-an-input-tag",
            "title": "Show text in a header tag as it is being typed in an input tag",
            "body": "<p>I just started my journey into the world of React and I love it so far. I finally started to get a grasp of the basics and tried my hand in creating a simple program.\nThis program simply takes what you are typing in a text box and displays it live in a header tag. I can't seem to figure out why this isn't working. I get the text to appear in the console, but can't figure out why it isn't displaying in my  tag. Thank you in advance for the help. Any tips are greatly appreciated.</p>\n\n<pre><code>class Header extends Component{\n    render(){\n        return(\n            &lt;div className = \"header\"&gt;\n                &lt;h1&gt;Enter Your Name&lt;/h1&gt;\n            &lt;/div&gt;\n        )\n    }\n}\n\nclass Input extends Component{\n    render(){\n        return(\n            &lt;div className = \"input_container\"&gt;\n                &lt;input onChange = {this.props.onChange} className = \"input_field\" type = \"text\" placeholder = \"Name...\"&gt;&lt;/input&gt;\n            &lt;/div&gt;\n        )\n    }\n}\n\nclass App extends Component {\n    state = {\n        inputValue : \"\"\n    }\n\n    onChange = (e) =&gt; {\n        console.log(e.target.value)\n        this.setState = ({inputValue: e.target.value});\n    }\n\n    render(){\n        return(\n            &lt;div&gt;\n            &lt;Columns /&gt;\n            &lt;Input\n                onChange = {this.onChange}/&gt;\n            &lt;h2&gt;{this.state.inputValue}&lt;/h2&gt;\n        &lt;/div&gt;\n        )\n    }\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "c",
                "visual-studio-2013",
                "linked-list"
            ],
            "owner": {
                "reputation": 24,
                "user_id": 9672569,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/b440723321ca533309e3e1ca3b5ffcff?s=128&d=identicon&r=PG&f=1",
                "display_name": "KKK",
                "link": "https://stackoverflow.com/users/9672569/kkk"
            },
            "is_answered": false,
            "view_count": 34,
            "answer_count": 0,
            "score": 3,
            "last_activity_date": 1524204027,
            "creation_date": 1524190048,
            "last_edit_date": 1524204027,
            "question_id": 49932828,
            "body_markdown": "In the following code (that inserts only process names that still not are in list), the trouble is that I&#39;m not able to print all items while the next node is different of `NULL`. I&#39;m catching the exception that says **STATUS_ACCESS_VIOLATION (0xC0000005)**. This trouble is present on two commented lines below.\r\n\r\nHow to fix this?\r\n\r\n    #include &quot;stdafx.h&quot;\r\n    #include &lt;conio.h&gt;\r\n    #include &lt;windows.h&gt;\r\n    #include &lt;Winternl.h&gt;\r\n    \r\n    #pragma comment(lib,&quot;ntdll.lib&quot;)\r\n    \r\n    typedef struct _SYSTEM_PROCESS_INFO\r\n    {\r\n    \tULONG                   NextEntryOffset;\r\n    \tULONG                   NumberOfThreads;\r\n    \tLARGE_INTEGER           Reserved[3];\r\n    \tLARGE_INTEGER           CreateTime;\r\n    \tLARGE_INTEGER           UserTime;\r\n    \tLARGE_INTEGER           KernelTime;\r\n    \tUNICODE_STRING          ImageName;\r\n    \tULONG                   BasePriority;\r\n    \tHANDLE                  ProcessId;\r\n    \tHANDLE                  InheritedFromProcessId;\r\n    }SYSTEM_PROCESS_INFO, *PSYSTEM_PROCESS_INFO;\r\n    \r\n    #pragma region LinkedList\r\n    \r\n    struct test_struct\r\n    {\r\n    \tUNICODE_STRING val;\r\n    \tstruct test_struct *next;\r\n    };\r\n    \r\n    struct test_struct *head = NULL;\r\n    struct test_struct *curr = NULL;\r\n    \r\n    struct test_struct* create_list(UNICODE_STRING val)\r\n    {\r\n    \tprintf(&quot;\\n creating list with headnode as [%wZ]\\n&quot;, &amp;val);\r\n    \tstruct test_struct *ptr = (struct test_struct*)malloc(sizeof(struct test_struct));\r\n    \tif (NULL == ptr)\r\n    \t{\r\n    \t\tprintf(&quot;\\n Node creation failed \\n&quot;);\r\n    \t\treturn NULL;\r\n    \t}\r\n    \tptr-&gt;val = val;\r\n    \tptr-&gt;next = NULL;\r\n    \r\n    \thead = curr = ptr;\r\n    \treturn ptr;\r\n    }\r\n    \r\n    struct test_struct* add_to_list(UNICODE_STRING val, BOOLEAN add_to_end)\r\n    {\r\n    \tif (NULL == head)\r\n    \t{\r\n    \t\treturn (create_list(val));\r\n    \t}\r\n    \r\n    \tif (add_to_end)\r\n    \t\tprintf(&quot;\\n Adding node to end of list with value [%wZ]\\n&quot;, &amp;val);\r\n    \telse\r\n    \t\tprintf(&quot;\\n Adding node to beginning of list with value [%wZ]\\n&quot;, &amp;val);\r\n    \r\n    \tstruct test_struct *ptr = (struct test_struct*)malloc(sizeof(struct test_struct));\r\n    \tif (NULL == ptr)\r\n    \t{\r\n    \t\tprintf(&quot;\\n Node creation failed \\n&quot;);\r\n    \t\treturn NULL;\r\n    \t}\r\n    \tptr-&gt;val = val;\r\n    \tptr-&gt;next = NULL;\r\n    \r\n    \tif (add_to_end)\r\n    \t{\r\n    \t\tcurr-&gt;next = ptr;\r\n    \t\tcurr = ptr;\r\n    \t}\r\n    \telse\r\n    \t{\r\n    \t\tptr-&gt;next = head;\r\n    \t\thead = ptr;\r\n    \t}\r\n    \treturn ptr;\r\n    }\r\n    \r\n    struct test_struct* search_in_list(UNICODE_STRING val, struct test_struct **prev)\r\n    {\r\n    \tBOOLEAN(WINAPI * RtlEqualUnicodeString)(IN PCUNICODE_STRING String1, IN PCUNICODE_STRING String2, IN BOOLEAN CaseInSensitive);\r\n    \tHMODULE ntDll = GetModuleHandleA(&quot;ntdll&quot;);\r\n    \tRtlEqualUnicodeString = (BOOLEAN (WINAPI *)(IN PCUNICODE_STRING String1, IN PCUNICODE_STRING String2, IN BOOLEAN CaseInSensitive))GetProcAddress(ntDll, &quot;RtlEqualUnicodeString&quot;);\r\n    \t\r\n    \tstruct test_struct *ptr = head;\r\n    \tstruct test_struct *tmp = NULL;\r\n    \tBOOLEAN found = FALSE;\r\n    \r\n    \tprintf(&quot;\\n Searching the list for value [%wZ] \\n&quot;, &amp;val);\r\n    \r\n    \twhile (ptr != NULL)\r\n    \t{\r\n    \t\tif (RtlEqualUnicodeString(&amp;ptr-&gt;val, &amp;val, TRUE))\r\n    \t\t{\r\n    \t\t\tfound = TRUE;\r\n    \t\t\tbreak;\r\n    \t\t}\r\n    \t\telse\r\n    \t\t{\r\n    \t\t\ttmp = ptr;\r\n    \t\t\tptr = ptr-&gt;next;\r\n    \t\t}\r\n    \t}\r\n    \r\n    \tif (TRUE == found)\r\n    \t{\r\n    \t\tif (prev)\r\n    \t\t\t*prev = tmp;\r\n    \t\treturn ptr;\r\n    \t}\r\n    \telse\r\n    \t{\r\n    \t\treturn NULL;\r\n    \t}\r\n    }\r\n    \r\n    void dispose(struct test_struct *head)\r\n    {\r\n    \tstruct test_struct *cursor, *tmp;\r\n    \r\n    \tif (head != NULL)\r\n    \t{\r\n    \t\tcursor = head;\r\n    \r\n    \t\twhile (cursor != NULL)\r\n    \t\t{\r\n    \t\t\ttmp = cursor-&gt;next;\r\n    \t\t\t//printf(&quot;Releasing: %wZ \\n&quot;, &amp;cursor-&gt;val);\r\n    \t\t\tfree(cursor);\r\n    \t\t\tcursor = tmp;\r\n    \t\t}\r\n    \t}\r\n    }\r\n    \r\n    int filterException(int code, PEXCEPTION_POINTERS ex) {\r\n    \tprintf(&quot;Exception: %#X\\n&quot;, code);\r\n    \treturn EXCEPTION_EXECUTE_HANDLER;\r\n    }\r\n    \r\n    void print_list(void)\r\n    {\r\n    \tstruct test_struct *ptr = head;\r\n    \r\n    \tprintf(&quot;\\n -------Printing list Start------- \\n&quot;);\r\n    \twhile (ptr != NULL)\r\n    \t{\r\n    \t\t__try\r\n    \t\t{\r\n    \t\t\t//printf(&quot;\\n [%wZ] \\n&quot;, &amp;ptr-&gt;val);\r\n    \t\t\tptr = ptr-&gt;next;\r\n    \t\t}\r\n    \t\t__except (filterException(GetExceptionCode(), GetExceptionInformation())) \r\n    \t\t{\r\n    \t\t\tprintf(&quot;&quot;);\r\n    \t\t}\r\n    \t}\r\n    \tprintf(&quot;\\n -------Printing list End------- \\n&quot;);\r\n    \r\n    \treturn;\r\n    }\r\n    \r\n    #pragma endregion LinkedList\r\n    \r\n    int _tmain(int argc, _TCHAR* argv[])\r\n    {\r\n    \r\n    \tNTSTATUS status;\r\n    \tPVOID buffer;\r\n    \tPSYSTEM_PROCESS_INFO spi;\r\n    \r\n    \tstruct test_struct *ptr = NULL;\r\n    \r\n    \tbuffer = VirtualAlloc(NULL, 1024 * 1024, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE);\r\n    \r\n    \tif (!buffer)\r\n    \t{\r\n    \t\tprintf(&quot;\\nError: Unable to allocate memory for process list (%d)\\n&quot;, GetLastError());\r\n    \t\treturn -1;\r\n    \t}\r\n    \r\n    \tprintf(&quot;\\nProcess list allocated at address %#X\\n&quot;, buffer);\r\n    \tspi = (PSYSTEM_PROCESS_INFO)buffer;\r\n    \r\n    \tif (!NT_SUCCESS(status = NtQuerySystemInformation(SystemProcessInformation, spi, 1024 * 1024, NULL)))\r\n    \t{\r\n    \t\tprintf(&quot;\\nError: Unable to query process list (%#X)\\n&quot;, status);\r\n    \r\n    \t\tVirtualFree(buffer, 0, MEM_RELEASE);\r\n    \t\treturn -1;\r\n    \t}\r\n    \r\n    \twhile (spi-&gt;NextEntryOffset)\r\n    \t{\r\n    \t\tprintf(&quot;\\nProcess name: %wZ | Process ID: %d\\n&quot;, &amp;spi-&gt;ImageName, spi-&gt;ProcessId);\r\n    \r\n    \t\tptr = search_in_list(spi-&gt;ImageName, NULL);\r\n    \r\n    \t\tif (NULL == ptr)\r\n    \t\t{\r\n    \t\t\tadd_to_list(spi-&gt;ImageName, TRUE);\r\n    \t\t}\r\n    \t\telse\r\n    \t\t{\r\n    \t\t\tprintf(&quot;process already in list \\n&quot;);\r\n    \t\t}\r\n    \r\n    \t\tspi = (PSYSTEM_PROCESS_INFO)((LPBYTE)spi + spi-&gt;NextEntryOffset);\r\n    \t}\r\n    \tVirtualFree(buffer, 0, MEM_RELEASE);\r\n    \r\n    \tprint_list();\r\n    \tdispose(head);\r\n    \r\n    \t_getch();\r\n    \treturn 0;\r\n    }",
            "link": "https://stackoverflow.com/questions/49932828/linked-list-printf-access-violation-while-next-node-null",
            "title": "Linked List: printf() Access Violation while next node != NULL?",
            "body": "<p>In the following code (that inserts only process names that still not are in list), the trouble is that I'm not able to print all items while the next node is different of <code>NULL</code>. I'm catching the exception that says <strong>STATUS_ACCESS_VIOLATION (0xC0000005)</strong>. This trouble is present on two commented lines below.</p>\n\n<p>How to fix this?</p>\n\n<pre><code>#include \"stdafx.h\"\n#include &lt;conio.h&gt;\n#include &lt;windows.h&gt;\n#include &lt;Winternl.h&gt;\n\n#pragma comment(lib,\"ntdll.lib\")\n\ntypedef struct _SYSTEM_PROCESS_INFO\n{\n    ULONG                   NextEntryOffset;\n    ULONG                   NumberOfThreads;\n    LARGE_INTEGER           Reserved[3];\n    LARGE_INTEGER           CreateTime;\n    LARGE_INTEGER           UserTime;\n    LARGE_INTEGER           KernelTime;\n    UNICODE_STRING          ImageName;\n    ULONG                   BasePriority;\n    HANDLE                  ProcessId;\n    HANDLE                  InheritedFromProcessId;\n}SYSTEM_PROCESS_INFO, *PSYSTEM_PROCESS_INFO;\n\n#pragma region LinkedList\n\nstruct test_struct\n{\n    UNICODE_STRING val;\n    struct test_struct *next;\n};\n\nstruct test_struct *head = NULL;\nstruct test_struct *curr = NULL;\n\nstruct test_struct* create_list(UNICODE_STRING val)\n{\n    printf(\"\\n creating list with headnode as [%wZ]\\n\", &amp;val);\n    struct test_struct *ptr = (struct test_struct*)malloc(sizeof(struct test_struct));\n    if (NULL == ptr)\n    {\n        printf(\"\\n Node creation failed \\n\");\n        return NULL;\n    }\n    ptr-&gt;val = val;\n    ptr-&gt;next = NULL;\n\n    head = curr = ptr;\n    return ptr;\n}\n\nstruct test_struct* add_to_list(UNICODE_STRING val, BOOLEAN add_to_end)\n{\n    if (NULL == head)\n    {\n        return (create_list(val));\n    }\n\n    if (add_to_end)\n        printf(\"\\n Adding node to end of list with value [%wZ]\\n\", &amp;val);\n    else\n        printf(\"\\n Adding node to beginning of list with value [%wZ]\\n\", &amp;val);\n\n    struct test_struct *ptr = (struct test_struct*)malloc(sizeof(struct test_struct));\n    if (NULL == ptr)\n    {\n        printf(\"\\n Node creation failed \\n\");\n        return NULL;\n    }\n    ptr-&gt;val = val;\n    ptr-&gt;next = NULL;\n\n    if (add_to_end)\n    {\n        curr-&gt;next = ptr;\n        curr = ptr;\n    }\n    else\n    {\n        ptr-&gt;next = head;\n        head = ptr;\n    }\n    return ptr;\n}\n\nstruct test_struct* search_in_list(UNICODE_STRING val, struct test_struct **prev)\n{\n    BOOLEAN(WINAPI * RtlEqualUnicodeString)(IN PCUNICODE_STRING String1, IN PCUNICODE_STRING String2, IN BOOLEAN CaseInSensitive);\n    HMODULE ntDll = GetModuleHandleA(\"ntdll\");\n    RtlEqualUnicodeString = (BOOLEAN (WINAPI *)(IN PCUNICODE_STRING String1, IN PCUNICODE_STRING String2, IN BOOLEAN CaseInSensitive))GetProcAddress(ntDll, \"RtlEqualUnicodeString\");\n\n    struct test_struct *ptr = head;\n    struct test_struct *tmp = NULL;\n    BOOLEAN found = FALSE;\n\n    printf(\"\\n Searching the list for value [%wZ] \\n\", &amp;val);\n\n    while (ptr != NULL)\n    {\n        if (RtlEqualUnicodeString(&amp;ptr-&gt;val, &amp;val, TRUE))\n        {\n            found = TRUE;\n            break;\n        }\n        else\n        {\n            tmp = ptr;\n            ptr = ptr-&gt;next;\n        }\n    }\n\n    if (TRUE == found)\n    {\n        if (prev)\n            *prev = tmp;\n        return ptr;\n    }\n    else\n    {\n        return NULL;\n    }\n}\n\nvoid dispose(struct test_struct *head)\n{\n    struct test_struct *cursor, *tmp;\n\n    if (head != NULL)\n    {\n        cursor = head;\n\n        while (cursor != NULL)\n        {\n            tmp = cursor-&gt;next;\n            //printf(\"Releasing: %wZ \\n\", &amp;cursor-&gt;val);\n            free(cursor);\n            cursor = tmp;\n        }\n    }\n}\n\nint filterException(int code, PEXCEPTION_POINTERS ex) {\n    printf(\"Exception: %#X\\n\", code);\n    return EXCEPTION_EXECUTE_HANDLER;\n}\n\nvoid print_list(void)\n{\n    struct test_struct *ptr = head;\n\n    printf(\"\\n -------Printing list Start------- \\n\");\n    while (ptr != NULL)\n    {\n        __try\n        {\n            //printf(\"\\n [%wZ] \\n\", &amp;ptr-&gt;val);\n            ptr = ptr-&gt;next;\n        }\n        __except (filterException(GetExceptionCode(), GetExceptionInformation())) \n        {\n            printf(\"\");\n        }\n    }\n    printf(\"\\n -------Printing list End------- \\n\");\n\n    return;\n}\n\n#pragma endregion LinkedList\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n\n    NTSTATUS status;\n    PVOID buffer;\n    PSYSTEM_PROCESS_INFO spi;\n\n    struct test_struct *ptr = NULL;\n\n    buffer = VirtualAlloc(NULL, 1024 * 1024, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE);\n\n    if (!buffer)\n    {\n        printf(\"\\nError: Unable to allocate memory for process list (%d)\\n\", GetLastError());\n        return -1;\n    }\n\n    printf(\"\\nProcess list allocated at address %#X\\n\", buffer);\n    spi = (PSYSTEM_PROCESS_INFO)buffer;\n\n    if (!NT_SUCCESS(status = NtQuerySystemInformation(SystemProcessInformation, spi, 1024 * 1024, NULL)))\n    {\n        printf(\"\\nError: Unable to query process list (%#X)\\n\", status);\n\n        VirtualFree(buffer, 0, MEM_RELEASE);\n        return -1;\n    }\n\n    while (spi-&gt;NextEntryOffset)\n    {\n        printf(\"\\nProcess name: %wZ | Process ID: %d\\n\", &amp;spi-&gt;ImageName, spi-&gt;ProcessId);\n\n        ptr = search_in_list(spi-&gt;ImageName, NULL);\n\n        if (NULL == ptr)\n        {\n            add_to_list(spi-&gt;ImageName, TRUE);\n        }\n        else\n        {\n            printf(\"process already in list \\n\");\n        }\n\n        spi = (PSYSTEM_PROCESS_INFO)((LPBYTE)spi + spi-&gt;NextEntryOffset);\n    }\n    VirtualFree(buffer, 0, MEM_RELEASE);\n\n    print_list();\n    dispose(head);\n\n    _getch();\n    return 0;\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "python",
                "django",
                "django-rest-framework",
                "django-rest-swagger"
            ],
            "owner": {
                "reputation": 85,
                "user_id": 6289691,
                "user_type": "registered",
                "accept_rate": 50,
                "profile_image": "https://www.gravatar.com/avatar/3b8c87596ee2e75ecceff56501d10660?s=128&d=identicon&r=PG&f=1",
                "display_name": "Naella",
                "link": "https://stackoverflow.com/users/6289691/naella"
            },
            "is_answered": true,
            "view_count": 729,
            "accepted_answer_id": 45326499,
            "answer_count": 4,
            "score": 2,
            "last_activity_date": 1524204021,
            "creation_date": 1500968605,
            "last_edit_date": 1524204021,
            "question_id": 45296939,
            "body_markdown": "I&#39;m working with Django rest framework API, I am trying to make a filter by first_name or by last_name or by both of them.\r\nThis is my **ContactViewSet.py** :\r\n\r\n    class ContactViewSet(viewsets.ModelViewSet):\r\n        queryset = Contact.objects.all()\r\n        serializer_class = ContactSerializer\r\n        filter_backends = (DjangoFilterBackend, )\r\n        filter_fields = (&#39;first_name&#39;, &#39;last_name&#39;)\r\n        lookup_field = &#39;idContact&#39;\r\n\r\n\r\n\r\nMy DRF&#39;s settings : \r\n\r\n    REST_FRAMEWORK = {\r\n        &#39;DEFAULT_FILTER_BACKENDS&#39;: (&#39;django_filters.rest_framework.DjangoFilterBackend&#39;,),\r\n    }\r\n\r\n\r\nMy actuel request url looks like : \r\n\r\n\r\n    http://localhost:8000/api/v1/contacts/?first_name=Clair&amp;last_name=Test\r\n\r\n\r\nBut I&#39;m looking for something like this : \r\n\r\n\r\n    http://localhost:8000/api/v1/contacts/?first_name=Cl**&amp;last_name=Tes**\r\n\r\n\r\nAny help would be appreciated ..",
            "link": "https://stackoverflow.com/questions/45296939/django-filter-backend",
            "title": "Django Filter Backend",
            "body": "<p>I'm working with Django rest framework API, I am trying to make a filter by first_name or by last_name or by both of them.\nThis is my <strong>ContactViewSet.py</strong> :</p>\n\n<pre><code>class ContactViewSet(viewsets.ModelViewSet):\n    queryset = Contact.objects.all()\n    serializer_class = ContactSerializer\n    filter_backends = (DjangoFilterBackend, )\n    filter_fields = ('first_name', 'last_name')\n    lookup_field = 'idContact'\n</code></pre>\n\n<p>My DRF's settings : </p>\n\n<pre><code>REST_FRAMEWORK = {\n    'DEFAULT_FILTER_BACKENDS': ('django_filters.rest_framework.DjangoFilterBackend',),\n}\n</code></pre>\n\n<p>My actuel request url looks like : </p>\n\n<pre><code>http://localhost:8000/api/v1/contacts/?first_name=Clair&amp;last_name=Test\n</code></pre>\n\n<p>But I'm looking for something like this : </p>\n\n<pre><code>http://localhost:8000/api/v1/contacts/?first_name=Cl**&amp;last_name=Tes**\n</code></pre>\n\n<p>Any help would be appreciated ..</p>\n"
        },
        {
            "tags": [
                "cppcms"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 6288639,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/171df9d7194a861574a29e201a35c255?s=128&d=identicon&r=PG&f=1",
                "display_name": "Vandana Chadha",
                "link": "https://stackoverflow.com/users/6288639/vandana-chadha"
            },
            "is_answered": false,
            "view_count": 9,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524204012,
            "creation_date": 1524146012,
            "last_edit_date": 1524204012,
            "question_id": 49922887,
            "body_markdown": "I am using cppcms ver 1.2, and want to include external css and js files as follows:\r\nmedia/css/bootstrap.min.css\r\nBut I get a 404 error for them, even though the files exist in the media folder in my root folder of the app.\r\n\r\nI tried copying the media folder manually to the  CMakeFiles folder. But that didnt work also.\r\n\r\nStill keep getting a 404 error for localhost:8080/media/style.css or any of the other css or js files. \r\n\r\nWhat is the document root of the cppcms, and if it is the root folder where the code is, then why isnt it able to read them?\r\n\r\nMy code is modelled on the examples/message_board sample.\r\n",
            "link": "https://stackoverflow.com/questions/49922887/cppcms-404-error-for-css-and-js-files",
            "title": "cppcms: 404 error for css and js files",
            "body": "<p>I am using cppcms ver 1.2, and want to include external css and js files as follows:\nmedia/css/bootstrap.min.css\nBut I get a 404 error for them, even though the files exist in the media folder in my root folder of the app.</p>\n\n<p>I tried copying the media folder manually to the  CMakeFiles folder. But that didnt work also.</p>\n\n<p>Still keep getting a 404 error for localhost:8080/media/style.css or any of the other css or js files. </p>\n\n<p>What is the document root of the cppcms, and if it is the root folder where the code is, then why isnt it able to read them?</p>\n\n<p>My code is modelled on the examples/message_board sample.</p>\n"
        },
        {
            "tags": [
                "python",
                "big-o"
            ],
            "owner": {
                "reputation": 409,
                "user_id": 6930377,
                "user_type": "registered",
                "accept_rate": 48,
                "profile_image": "https://www.gravatar.com/avatar/72345ae8dcbde9beac98f975d909e84a?s=128&d=identicon&r=PG&f=1",
                "display_name": "Dilli",
                "link": "https://stackoverflow.com/users/6930377/dilli"
            },
            "is_answered": false,
            "view_count": 31,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524204010,
            "creation_date": 1524201365,
            "question_id": 49934465,
            "body_markdown": "Suppose we could access yesterday&#39;s stock prices as a list, where:\r\n\r\nThe indices are the time in minutes past trade opening time, which was 9:30am local time.\r\nThe values are the price in dollars of Apple stock at that time.\r\nSo if the stock cost $500 at 10:30am, stock_prices_yesterday[60] = 500.\r\n\r\nWrite an efficient function that takes stock_prices_yesterday and returns the best profit I could have made from 1 purchase and 1 sale of 1 Apple stock yesterday.\r\n\r\n\r\n\r\nThe solution I came up with:\r\n\r\n    def get_best_stock_price(list):\r\n        first_minimum_value = min(list)\r\n        index_of_the_minimum_value = list.index(first_lowest_value)\r\n        new_list_excluding_all_the_unwanted_items = list[new_list_index:]\r\n        max_new = max(new_list)\r\n        return max_new - first_minimum_value\r\n\r\nThe solution they offered:\r\n\r\n    def get_max_profit(stock_prices_yesterday):\r\n      if len(stock_prices_yesterday) &lt; 2:\r\n          raise ValueError(&#39;Getting a profit requires at least 2 prices&#39;)\r\n      min_price  = stock_prices_yesterday[0]\r\n      max_profit = stock_prices_yesterday[1] - stock_prices_yesterday[0]\r\n      for current_time in xrange(1, len(stock_prices_yesterday)):\r\n          current_price = stock_prices_yesterday[current_time]\r\n          potential_profit = current_price - min_price\r\n          max_profit = max(max_profit, potential_profit)\r\n          min_price  = min(min_price, current_price)\r\n    \r\n      return max_profit\r\n\r\nIs my answer suffice in terms of what they offer? if not how can I improve it. And what is my function lacking?\r\n\r\nThe function they offer includes O(n) time and O(1)O(1) space in the language of Big O notation. ",
            "link": "https://stackoverflow.com/questions/49934465/which-function-is-faster-in-terms-of-time-complexity-space-python",
            "title": "Which function is faster in terms of time complexity/space python",
            "body": "<p>Suppose we could access yesterday's stock prices as a list, where:</p>\n\n<p>The indices are the time in minutes past trade opening time, which was 9:30am local time.\nThe values are the price in dollars of Apple stock at that time.\nSo if the stock cost $500 at 10:30am, stock_prices_yesterday[60] = 500.</p>\n\n<p>Write an efficient function that takes stock_prices_yesterday and returns the best profit I could have made from 1 purchase and 1 sale of 1 Apple stock yesterday.</p>\n\n<p>The solution I came up with:</p>\n\n<pre><code>def get_best_stock_price(list):\n    first_minimum_value = min(list)\n    index_of_the_minimum_value = list.index(first_lowest_value)\n    new_list_excluding_all_the_unwanted_items = list[new_list_index:]\n    max_new = max(new_list)\n    return max_new - first_minimum_value\n</code></pre>\n\n<p>The solution they offered:</p>\n\n<pre><code>def get_max_profit(stock_prices_yesterday):\n  if len(stock_prices_yesterday) &lt; 2:\n      raise ValueError('Getting a profit requires at least 2 prices')\n  min_price  = stock_prices_yesterday[0]\n  max_profit = stock_prices_yesterday[1] - stock_prices_yesterday[0]\n  for current_time in xrange(1, len(stock_prices_yesterday)):\n      current_price = stock_prices_yesterday[current_time]\n      potential_profit = current_price - min_price\n      max_profit = max(max_profit, potential_profit)\n      min_price  = min(min_price, current_price)\n\n  return max_profit\n</code></pre>\n\n<p>Is my answer suffice in terms of what they offer? if not how can I improve it. And what is my function lacking?</p>\n\n<p>The function they offer includes O(n) time and O(1)O(1) space in the language of Big O notation. </p>\n"
        },
        {
            "tags": [
                "tensorflow",
                "tensorflow-estimator"
            ],
            "owner": {
                "reputation": 86,
                "user_id": 8023137,
                "user_type": "registered",
                "accept_rate": 85,
                "profile_image": "https://i.stack.imgur.com/NRwxo.jpg?s=128&g=1",
                "display_name": "Rocket Pingu",
                "link": "https://stackoverflow.com/users/8023137/rocket-pingu"
            },
            "is_answered": false,
            "view_count": 43,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524203997,
            "creation_date": 1524102987,
            "last_edit_date": 1524203048,
            "question_id": 49911525,
            "body_markdown": "I can train and evalaute a Tensorflow Estimator model without any problems. When I do prediction, this error arises:\r\n\r\n    InvalidArgumentError (see above for traceback): output_shape has incorrect number of elements: 68 should be: 2\r\n    \t [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\r\n\r\nAll of the model functions use the same architecture:\r\n\r\n    def _train_model_fn(features, labels, mode, params):\r\n        features = _network_fn(features, mode, params)\r\n    \r\n        outputs = _get_output(features, params[&quot;output_layer&quot;],\r\n                              params[&quot;num_classes&quot;])\r\n        predictions = {\r\n            &quot;outputs&quot;: outputs\r\n        }\r\n    \r\n        ... # loss initialization and whatnot\r\n\r\n    def _eval_model_fn(features, labels, mode, params):\r\n        features = _network_fn(features, mode, params)\r\n        outputs = _get_output(features, params[&quot;output_layer&quot;], params[&quot;num_classes&quot;])\r\n        predictions = {\r\n            &quot;outputs&quot;: outputs\r\n        }\r\n    \r\n        ... # loss initialization and whatnot\r\n\r\n\r\n    def _predict_model_fn(features, mode, params):\r\n        features = _network_fn(features, mode, params)\r\n        outputs = _get_output(features, params[&quot;output_layer&quot;], params[&quot;num_classes&quot;])\r\n        predictions = {\r\n            &quot;outputs&quot;: outputs\r\n        }\r\n    \r\n        ...\r\n\r\nHere&#39;s the predict code:\r\n\r\n    def predict(params, features, checkpoint_dir):\r\n        estimator = tf.estimator.Estimator(model_fn=_predict_model_fn,\r\n                                           params=params,\r\n                                           model_dir=checkpoint_dir)\r\n        predictions = estimator.predict(input_fn=_input_fn(features))\r\n        for i, p in enumerate(predictions):\r\n            print(i, p)\r\n\r\nI also checked the shapes given every time the input passes a layer when training, and the same thing for predicting. They give the same shapes:\r\n\r\nTraining:\r\n\r\n    conv2d [1, 358, 358, 16]\r\n    max_pool2d [1, 179, 179, 16]\r\n    collapse_to_rnn_dims [1, 179, 2864]\r\n    birnn [1, 179, 64]\r\n\r\nPrediction:\r\n\r\n    conv2d [1, 358, 358, 16]\r\n    max_pool2d [1, 179, 179, 16]\r\n    collapse_to_rnn_dims [1, 179, 2864]\r\n    birnn [1, 179, 64]\r\n\r\nHere are the `SparseTensor`s I passed to `sparse_to_dense`:\r\n\r\nTraining:\r\n\r\n    SparseTensor(indices=Tensor(&quot;CTCBeamSearchDecoder:0&quot;, shape=(?, 2), dtype=int64), values=Tensor(&quot;CTCBeamSearchDecoder:1&quot;, shape=(?,), dtype=int64), dense_shape=Tensor(&quot;CTCBeamSearchDecoder:2&quot;, shape=(2,), dtype=int64))\r\n\r\nEvaluation:\r\n\r\n    SparseTensor(indices=Tensor(&quot;CTCBeamSearchDecoder:0&quot;, shape=(?, 2), dtype=int64), values=Tensor(&quot;CTCBeamSearchDecoder:1&quot;, shape=(?,), dtype=int64), dense_shape=Tensor(&quot;CTCBeamSearchDecoder:2&quot;, shape=(2,), dtype=int64))\r\n\r\nPrediction:\r\n\r\n    SparseTensor(indices=Tensor(&quot;CTCBeamSearchDecoder:0&quot;, shape=(?, 2), dtype=int64), values=Tensor(&quot;CTCBeamSearchDecoder:1&quot;, shape=(?,), dtype=int64), dense_shape=Tensor(&quot;CTCBeamSearchDecoder:2&quot;, shape=(2,), dtype=int64))\r\n\r\n\r\nWhich are all pretty much the same.\r\n\r\nAny reason why this is happening? Shouldn&#39;t the `_predict_model_fn` work given that it follows the same architecture as that of the other `model_fn`s?\r\n\r\nHere&#39;s the full stacktrace:\r\n\r\n    INFO:tensorflow:Using default config.\r\n    INFO:tensorflow:Using config: {&#39;_log_step_count_steps&#39;: 100, &#39;_keep_checkpoint_max&#39;: 5, &#39;_task_type&#39;: &#39;worker&#39;, &#39;_is_chief&#39;: True, &#39;_service&#39;: None, &#39;_save_summary_steps&#39;: 100, &#39;_model_dir&#39;: &#39;checkpoint\\\\model-20180419-150303&#39;, &#39;_task_id&#39;: 0, &#39;_evaluation_master&#39;: &#39;&#39;, &#39;_tf_random_seed&#39;: None, &#39;_cluster_spec&#39;: &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x00000091F58B3080&gt;, &#39;_num_ps_replicas&#39;: 0, &#39;_master&#39;: &#39;&#39;, &#39;_save_checkpoints_secs&#39;: 600, &#39;_session_config&#39;: None, &#39;_save_checkpoints_steps&#39;: None, &#39;_keep_checkpoint_every_n_hours&#39;: 10000, &#39;_global_id_in_cluster&#39;: 0, &#39;_num_worker_replicas&#39;: 1}\r\n    INFO:tensorflow:Calling model_fn.\r\n    INFO:tensorflow:Done calling model_fn.\r\n    INFO:tensorflow:Graph was finalized.\r\n    INFO:tensorflow:Restoring parameters from checkpoint\\model-20180419-150303\\model.ckpt-1\r\n    INFO:tensorflow:Running local_init_op.\r\n    INFO:tensorflow:Done running local_init_op.\r\n    Process Process-2:\r\n    Traceback (most recent call last):\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py&quot;, line 1361, in _do_call\r\n        return fn(*args)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py&quot;, line 1340, in _run_fn\r\n        target_list, status, run_metadata)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py&quot;, line 516, in __exit__\r\n        c_api.TF_GetCode(self.status.status))\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: output_shape has incorrect number of elements: 68 should be: 2\r\n    \t [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\r\n    \r\n    During handling of the above exception, another exception occurred:\r\n    \r\n    Traceback (most recent call last):\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\process.py&quot;, line 249, in _bootstrap\r\n        self.run()\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\process.py&quot;, line 93, in run\r\n        self._target(*self._args, **self._kwargs)\r\n      File &quot;C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\train_ocr.py&quot;, line 42, in evaluate_model\r\n        evaluate(architecture_params, images, labels, checkpoint_dir)\r\n      File &quot;C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py&quot;, line 82, in evaluate\r\n        predict(params, features, checkpoint_dir)\r\n      File &quot;C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py&quot;, line 90, in predict\r\n        for i, p in enumerate(predictions):\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py&quot;, line 492, in predict\r\n        preds_evaluated = mon_sess.run(predictions)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py&quot;, line 546, in run\r\n        run_metadata=run_metadata)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py&quot;, line 1022, in run\r\n        run_metadata=run_metadata)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py&quot;, line 1113, in run\r\n        raise six.reraise(*original_exc_info)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\six.py&quot;, line 693, in reraise\r\n        raise value\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py&quot;, line 1098, in run\r\n        return self._sess.run(*args, **kwargs)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py&quot;, line 1170, in run\r\n        run_metadata=run_metadata)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py&quot;, line 950, in run\r\n        return self._sess.run(*args, **kwargs)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py&quot;, line 905, in run\r\n        run_metadata_ptr)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py&quot;, line 1137, in _run\r\n        feed_dict_tensor, options, run_metadata)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py&quot;, line 1355, in _do_run\r\n        options, run_metadata)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py&quot;, line 1374, in _do_call\r\n        raise type(e)(node_def, op, message)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: output_shape has incorrect number of elements: 68 should be: 2\r\n    \t [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\r\n    \r\n    Caused by op &#39;output&#39;, defined at:\r\n      File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\spawn.py&quot;, line 106, in spawn_main\r\n        exitcode = _main(fd)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\spawn.py&quot;, line 119, in _main\r\n        return self._bootstrap()\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\process.py&quot;, line 249, in _bootstrap\r\n        self.run()\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\process.py&quot;, line 93, in run\r\n        self._target(*self._args, **self._kwargs)\r\n      File &quot;C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\train_ocr.py&quot;, line 42, in evaluate_model\r\n        evaluate(architecture_params, images, labels, checkpoint_dir)\r\n      File &quot;C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py&quot;, line 82, in evaluate\r\n        predict(params, features, checkpoint_dir)\r\n      File &quot;C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py&quot;, line 90, in predict\r\n        for i, p in enumerate(predictions):\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py&quot;, line 479, in predict\r\n        features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py&quot;, line 793, in _call_model_fn\r\n        model_fn_results = self._model_fn(features=features, **kwargs)\r\n      File &quot;C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py&quot;, line 217, in _predict_model_fn\r\n        outputs = _get_output(features, params[&quot;output_layer&quot;], params[&quot;num_classes&quot;])\r\n      File &quot;C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py&quot;, line 134, in _get_output\r\n        return _sparse_to_dense(decoded, name=&quot;output&quot;)\r\n      File &quot;C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py&quot;, line 38, in _sparse_to_dense\r\n        name=name)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py&quot;, line 791, in sparse_to_dense\r\n        name=name)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_sparse_ops.py&quot;, line 2401, in _sparse_to_dense\r\n        name=name)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py&quot;, line 787, in _apply_op_helper\r\n        op_def=op_def)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py&quot;, line 3271, in create_op\r\n        op_def=op_def)\r\n      File &quot;C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py&quot;, line 1650, in __init__\r\n        self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n    \r\n    InvalidArgumentError (see above for traceback): output_shape has incorrect number of elements: 68 should be: 2\r\n    \t [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\r\n\r\n**Update**\r\n\r\nI tried using the same architecture in a different training run, I encountered a different shap error:\r\n\r\n    InvalidArgumentError (see above for traceback): output_shape has incorrect number of elements: 69 should be: 2\r\n    \t [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=&quot;/job:localhost/replica:0/task:0/device:CPU:0&quot;](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\r\n\r\nApparently, the problem seems to lie in the `ctc_beam_search_decoder`. Switching to `ctc_greedy_decoder` doesn&#39;t help either. Why is it doing this?\r\n\r\n**More updates**\r\n\r\nI have uploaded the reproducible example: https://github.com/selcouthlyBlue/ShapeErrorReproduce\r\n",
            "link": "https://stackoverflow.com/questions/49911525/estimator-predict-has-shape-issues",
            "title": "Estimator.predict() has Shape Issues?",
            "body": "<p>I can train and evalaute a Tensorflow Estimator model without any problems. When I do prediction, this error arises:</p>\n\n<pre><code>InvalidArgumentError (see above for traceback): output_shape has incorrect number of elements: 68 should be: 2\n     [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\n</code></pre>\n\n<p>All of the model functions use the same architecture:</p>\n\n<pre><code>def _train_model_fn(features, labels, mode, params):\n    features = _network_fn(features, mode, params)\n\n    outputs = _get_output(features, params[\"output_layer\"],\n                          params[\"num_classes\"])\n    predictions = {\n        \"outputs\": outputs\n    }\n\n    ... # loss initialization and whatnot\n\ndef _eval_model_fn(features, labels, mode, params):\n    features = _network_fn(features, mode, params)\n    outputs = _get_output(features, params[\"output_layer\"], params[\"num_classes\"])\n    predictions = {\n        \"outputs\": outputs\n    }\n\n    ... # loss initialization and whatnot\n\n\ndef _predict_model_fn(features, mode, params):\n    features = _network_fn(features, mode, params)\n    outputs = _get_output(features, params[\"output_layer\"], params[\"num_classes\"])\n    predictions = {\n        \"outputs\": outputs\n    }\n\n    ...\n</code></pre>\n\n<p>Here's the predict code:</p>\n\n<pre><code>def predict(params, features, checkpoint_dir):\n    estimator = tf.estimator.Estimator(model_fn=_predict_model_fn,\n                                       params=params,\n                                       model_dir=checkpoint_dir)\n    predictions = estimator.predict(input_fn=_input_fn(features))\n    for i, p in enumerate(predictions):\n        print(i, p)\n</code></pre>\n\n<p>I also checked the shapes given every time the input passes a layer when training, and the same thing for predicting. They give the same shapes:</p>\n\n<p>Training:</p>\n\n<pre><code>conv2d [1, 358, 358, 16]\nmax_pool2d [1, 179, 179, 16]\ncollapse_to_rnn_dims [1, 179, 2864]\nbirnn [1, 179, 64]\n</code></pre>\n\n<p>Prediction:</p>\n\n<pre><code>conv2d [1, 358, 358, 16]\nmax_pool2d [1, 179, 179, 16]\ncollapse_to_rnn_dims [1, 179, 2864]\nbirnn [1, 179, 64]\n</code></pre>\n\n<p>Here are the <code>SparseTensor</code>s I passed to <code>sparse_to_dense</code>:</p>\n\n<p>Training:</p>\n\n<pre><code>SparseTensor(indices=Tensor(\"CTCBeamSearchDecoder:0\", shape=(?, 2), dtype=int64), values=Tensor(\"CTCBeamSearchDecoder:1\", shape=(?,), dtype=int64), dense_shape=Tensor(\"CTCBeamSearchDecoder:2\", shape=(2,), dtype=int64))\n</code></pre>\n\n<p>Evaluation:</p>\n\n<pre><code>SparseTensor(indices=Tensor(\"CTCBeamSearchDecoder:0\", shape=(?, 2), dtype=int64), values=Tensor(\"CTCBeamSearchDecoder:1\", shape=(?,), dtype=int64), dense_shape=Tensor(\"CTCBeamSearchDecoder:2\", shape=(2,), dtype=int64))\n</code></pre>\n\n<p>Prediction:</p>\n\n<pre><code>SparseTensor(indices=Tensor(\"CTCBeamSearchDecoder:0\", shape=(?, 2), dtype=int64), values=Tensor(\"CTCBeamSearchDecoder:1\", shape=(?,), dtype=int64), dense_shape=Tensor(\"CTCBeamSearchDecoder:2\", shape=(2,), dtype=int64))\n</code></pre>\n\n<p>Which are all pretty much the same.</p>\n\n<p>Any reason why this is happening? Shouldn't the <code>_predict_model_fn</code> work given that it follows the same architecture as that of the other <code>model_fn</code>s?</p>\n\n<p>Here's the full stacktrace:</p>\n\n<pre><code>INFO:tensorflow:Using default config.\nINFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_service': None, '_save_summary_steps': 100, '_model_dir': 'checkpoint\\\\model-20180419-150303', '_task_id': 0, '_evaluation_master': '', '_tf_random_seed': None, '_cluster_spec': &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x00000091F58B3080&gt;, '_num_ps_replicas': 0, '_master': '', '_save_checkpoints_secs': 600, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_num_worker_replicas': 1}\nINFO:tensorflow:Calling model_fn.\nINFO:tensorflow:Done calling model_fn.\nINFO:tensorflow:Graph was finalized.\nINFO:tensorflow:Restoring parameters from checkpoint\\model-20180419-150303\\model.ckpt-1\nINFO:tensorflow:Running local_init_op.\nINFO:tensorflow:Done running local_init_op.\nProcess Process-2:\nTraceback (most recent call last):\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1361, in _do_call\n    return fn(*args)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1340, in _run_fn\n    target_list, status, run_metadata)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 516, in __exit__\n    c_api.TF_GetCode(self.status.status))\ntensorflow.python.framework.errors_impl.InvalidArgumentError: output_shape has incorrect number of elements: 68 should be: 2\n     [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\process.py\", line 249, in _bootstrap\n    self.run()\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\train_ocr.py\", line 42, in evaluate_model\n    evaluate(architecture_params, images, labels, checkpoint_dir)\n  File \"C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py\", line 82, in evaluate\n    predict(params, features, checkpoint_dir)\n  File \"C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py\", line 90, in predict\n    for i, p in enumerate(predictions):\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 492, in predict\n    preds_evaluated = mon_sess.run(predictions)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 546, in run\n    run_metadata=run_metadata)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1022, in run\n    run_metadata=run_metadata)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1113, in run\n    raise six.reraise(*original_exc_info)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\six.py\", line 693, in reraise\n    raise value\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1098, in run\n    return self._sess.run(*args, **kwargs)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1170, in run\n    run_metadata=run_metadata)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 950, in run\n    return self._sess.run(*args, **kwargs)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 905, in run\n    run_metadata_ptr)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1137, in _run\n    feed_dict_tensor, options, run_metadata)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1355, in _do_run\n    options, run_metadata)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1374, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors_impl.InvalidArgumentError: output_shape has incorrect number of elements: 68 should be: 2\n     [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\n\nCaused by op 'output', defined at:\n  File \"&lt;string&gt;\", line 1, in &lt;module&gt;\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\spawn.py\", line 106, in spawn_main\n    exitcode = _main(fd)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\spawn.py\", line 119, in _main\n    return self._bootstrap()\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\process.py\", line 249, in _bootstrap\n    self.run()\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\multiprocessing\\process.py\", line 93, in run\n    self._target(*self._args, **self._kwargs)\n  File \"C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\train_ocr.py\", line 42, in evaluate_model\n    evaluate(architecture_params, images, labels, checkpoint_dir)\n  File \"C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py\", line 82, in evaluate\n    predict(params, features, checkpoint_dir)\n  File \"C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py\", line 90, in predict\n    for i, p in enumerate(predictions):\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 479, in predict\n    features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 793, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py\", line 217, in _predict_model_fn\n    outputs = _get_output(features, params[\"output_layer\"], params[\"num_classes\"])\n  File \"C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py\", line 134, in _get_output\n    return _sparse_to_dense(decoded, name=\"output\")\n  File \"C:\\Users\\asus.11\\Documents\\Optimized_OCR\\trainer\\backend\\tf\\experiment_ops.py\", line 38, in _sparse_to_dense\n    name=name)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\sparse_ops.py\", line 791, in sparse_to_dense\n    name=name)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_sparse_ops.py\", line 2401, in _sparse_to_dense\n    name=name)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\asus.11\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): output_shape has incorrect number of elements: 68 should be: 2\n     [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\n</code></pre>\n\n<p><strong>Update</strong></p>\n\n<p>I tried using the same architecture in a different training run, I encountered a different shap error:</p>\n\n<pre><code>InvalidArgumentError (see above for traceback): output_shape has incorrect number of elements: 69 should be: 2\n     [[Node: output = SparseToDense[T=DT_INT32, Tindices=DT_INT32, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ToInt32, ToInt32_1, ToInt32_2, bidirectional_rnn/bidirectional_rnn/fw/fw/time)]]\n</code></pre>\n\n<p>Apparently, the problem seems to lie in the <code>ctc_beam_search_decoder</code>. Switching to <code>ctc_greedy_decoder</code> doesn't help either. Why is it doing this?</p>\n\n<p><strong>More updates</strong></p>\n\n<p>I have uploaded the reproducible example: <a href=\"https://github.com/selcouthlyBlue/ShapeErrorReproduce\" rel=\"nofollow noreferrer\">https://github.com/selcouthlyBlue/ShapeErrorReproduce</a></p>\n"
        },
        {
            "tags": [
                "algorithm",
                "ionic-framework",
                "tinder"
            ],
            "owner": {
                "reputation": 229,
                "user_id": 3024827,
                "user_type": "registered",
                "accept_rate": 33,
                "profile_image": "https://graph.facebook.com/1275986857/picture?type=large",
                "display_name": "user3024827",
                "link": "https://stackoverflow.com/users/3024827/user3024827"
            },
            "is_answered": false,
            "view_count": 31,
            "closed_date": 1524214624,
            "answer_count": 0,
            "score": -1,
            "last_activity_date": 1524203985,
            "creation_date": 1524203985,
            "question_id": 49934974,
            "body_markdown": "I want to build a tinder style matching system for another topic.\r\n\r\nWhen you swipe left to someone, tider won&#39;t show that person to your again. How does it make sure this happens.\r\n\r\nDoes tinder store every &#39;no&#39; on a user record as an id, and this ID is looked for when a query is made. If it finds the ID it will filter it out.\r\n\r\nThis approach seems unefficient. Is there a better way an yone could theorise?\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49934974/tinder-style-match-system",
            "closed_reason": "too broad",
            "title": "Tinder style match system",
            "body": "<p>I want to build a tinder style matching system for another topic.</p>\n\n<p>When you swipe left to someone, tider won't show that person to your again. How does it make sure this happens.</p>\n\n<p>Does tinder store every 'no' on a user record as an id, and this ID is looked for when a query is made. If it finds the ID it will filter it out.</p>\n\n<p>This approach seems unefficient. Is there a better way an yone could theorise?</p>\n"
        },
        {
            "tags": [
                "c++"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 8230572,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/5ca89642bfb535488509ed5bc867bdde?s=128&d=identicon&r=PG&f=1",
                "display_name": "Divya",
                "link": "https://stackoverflow.com/users/8230572/divya"
            },
            "is_answered": false,
            "view_count": 37,
            "closed_date": 1524203981,
            "answer_count": 0,
            "score": -5,
            "last_activity_date": 1524203970,
            "creation_date": 1524202815,
            "last_edit_date": 1524203970,
            "question_id": 49934735,
            "body_markdown": "I am doing a code review where the dev is trying to search a value in the container..\r\n\r\n    std::vector&lt;int&gt; indexOfNumber;\r\n    int numberToBesearched ;\r\n    \r\n    if(indexOfNumber.end() != std::find(indexOfNumber.begin(), indexOfNumber.end(), numberToBesearched ));\r\n\r\nI think this is rong and should be reversed .\r\nPlease suggest whether this is an expected way of doing this.. Will not be an expensive operation on a huge container moving the iterator too and fro.. ",
            "link": "https://stackoverflow.com/questions/49934735/correct-way-of-writing-a-code-for-searching-a-container",
            "closed_reason": "too broad",
            "title": "Correct way of writing a code for searching a container",
            "body": "<p>I am doing a code review where the dev is trying to search a value in the container..</p>\n\n<pre><code>std::vector&lt;int&gt; indexOfNumber;\nint numberToBesearched ;\n\nif(indexOfNumber.end() != std::find(indexOfNumber.begin(), indexOfNumber.end(), numberToBesearched ));\n</code></pre>\n\n<p>I think this is rong and should be reversed .\nPlease suggest whether this is an expected way of doing this.. Will not be an expensive operation on a huge container moving the iterator too and fro.. </p>\n"
        },
        {
            "tags": [
                "java",
                "scala",
                "apache-spark",
                "streaming"
            ],
            "owner": {
                "reputation": 5,
                "user_id": 5868625,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/62943da80e6fe9e5409d93d0d4371d23?s=128&d=identicon&r=PG&f=1",
                "display_name": "erikejan",
                "link": "https://stackoverflow.com/users/5868625/erikejan"
            },
            "is_answered": false,
            "view_count": 33,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524203961,
            "creation_date": 1522955345,
            "last_edit_date": 1524203961,
            "question_id": 49679768,
            "body_markdown": "I&#39;m new to Apache Spark and currently working on a Structured Streaming pipeline. In the middle of the data processing I need to do a bit of finnicky manipulation that requires that _all_ of the data (so far) is present. The amount of data has been heavily reduced at this point in the pipeline and performing a `.collect()`-like action will not be a bottleneck. The operation I need to perform is basically putting all remaining elements in a HashSet and doing a series of tricky existence checks. After this, I need to &quot;re-enter&quot; the streaming-pipeline to perform various writes to csv-files.\r\n\r\nHowever, attempting to perform `collect()` on a streaming pipeline understandably results in an error message. Below is a barebones (and stupid) example that illustrates my problem:\r\n\r\n    // imports ...\r\n\r\n    val spark = SparkSession.builder\r\n                            .appName(&quot;StructuredNetworkWordCount&quot;)\r\n                            .getOrCreate()\r\n    val lines = spark.readStream\r\n                     .format(&quot;socket&quot;)\r\n                     .option(&quot;host&quot;, &quot;localhost&quot;)\r\n                     .option(&quot;port&quot;, 4444)\r\n                     .load()\r\n\r\n    import spark.implicits._\r\n    \r\n    // Split the lines into words\r\n    val words = lines.as[String].flatMap(_.split(&quot; &quot;))\r\n\r\n    // Won&#39;t work in a streaming context\r\n    val wordList = words.collectAsList()\r\n\r\n    // Perform some operations on the collected() data\r\n    val numWords = wordList.size\r\n    val doubledNum = numWords * 2\r\n    \r\n    // Somehow output doubledNum\r\n    val query = wordCounts.writeStream\r\n                          .outputMode(&quot;complete&quot;)\r\n                          .format(&quot;console&quot;)\r\n                          .start()\r\n\r\n    query.awaitTermination()\r\n\r\nAs I said, this will definitely not work, but illustrates my problem. I need to perform a `collect()`-like action _in the middle of every microbatch_ in order to have simultaneous access to all data that is left. How would I go about doing this? Are accumulators the only way to access all the cumulative data in all partitions in the middle of a streaming pipeline?\r\n\r\nThanks!",
            "link": "https://stackoverflow.com/questions/49679768/applying-collect-to-a-apache-spark-structured-streaming-dataset",
            "title": "Applying collect() to a Apache Spark structured streaming Dataset",
            "body": "<p>I'm new to Apache Spark and currently working on a Structured Streaming pipeline. In the middle of the data processing I need to do a bit of finnicky manipulation that requires that <em>all</em> of the data (so far) is present. The amount of data has been heavily reduced at this point in the pipeline and performing a <code>.collect()</code>-like action will not be a bottleneck. The operation I need to perform is basically putting all remaining elements in a HashSet and doing a series of tricky existence checks. After this, I need to \"re-enter\" the streaming-pipeline to perform various writes to csv-files.</p>\n\n<p>However, attempting to perform <code>collect()</code> on a streaming pipeline understandably results in an error message. Below is a barebones (and stupid) example that illustrates my problem:</p>\n\n<pre><code>// imports ...\n\nval spark = SparkSession.builder\n                        .appName(\"StructuredNetworkWordCount\")\n                        .getOrCreate()\nval lines = spark.readStream\n                 .format(\"socket\")\n                 .option(\"host\", \"localhost\")\n                 .option(\"port\", 4444)\n                 .load()\n\nimport spark.implicits._\n\n// Split the lines into words\nval words = lines.as[String].flatMap(_.split(\" \"))\n\n// Won't work in a streaming context\nval wordList = words.collectAsList()\n\n// Perform some operations on the collected() data\nval numWords = wordList.size\nval doubledNum = numWords * 2\n\n// Somehow output doubledNum\nval query = wordCounts.writeStream\n                      .outputMode(\"complete\")\n                      .format(\"console\")\n                      .start()\n\nquery.awaitTermination()\n</code></pre>\n\n<p>As I said, this will definitely not work, but illustrates my problem. I need to perform a <code>collect()</code>-like action <em>in the middle of every microbatch</em> in order to have simultaneous access to all data that is left. How would I go about doing this? Are accumulators the only way to access all the cumulative data in all partitions in the middle of a streaming pipeline?</p>\n\n<p>Thanks!</p>\n"
        },
        {
            "tags": [
                "hyperledger",
                "hyperledger-explorer"
            ],
            "owner": {
                "reputation": 61,
                "user_id": 6339960,
                "user_type": "registered",
                "profile_image": "https://lh4.googleusercontent.com/-Nrit3el3TBA/AAAAAAAAAAI/AAAAAAAAAB8/Z4ot0NGedq8/photo.jpg?sz=128",
                "display_name": "Christian Lim",
                "link": "https://stackoverflow.com/users/6339960/christian-lim"
            },
            "is_answered": false,
            "view_count": 46,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524203959,
            "creation_date": 1523870751,
            "question_id": 49853848,
            "body_markdown": "I recently installed Hyperledger Explorer. When running Explorer, it returns nothing to the browser and gives the error:\r\n\r\n    postgres://hppoc:password@127.0.0.1:5432/fabricexplorer\r\n    Please open web browser to access ：http://localhost:8080/\r\n    [2018-04-16 08:15:18.542] [ERROR] Query - Error: No identity has been assigned to this client\r\n        at Client._getSigningIdentity (/home/ubuntu/blockchain-explorer/node_modules/fabric-client/lib/Client.js:1206:11)\r\n        at Channel.queryInfo (/home/ubuntu/blockchain-explorer/node_modules/fabric-client/lib/Channel.js:896:36)\r\n        at helper.getOrgAdmin.then (/home/ubuntu/blockchain-explorer/app/query.js:98:18)\r\n        at &lt;anonymous&gt;\r\n\r\nI tried to `console.log` the output of `blockchain-explorer/node_modules/fabric-client/lib/Client.js:1206:11` indeed the `admin` variable is `undefined`\r\n\r\nIt&#39;s pretty weird since I installed Composer before this and it runs perfectly fine. All the`crypto-config` uses the default settings provided by the Composer example.\r\n\r\nVersions (pretty much latest stable version):\r\n\r\n* OS: Ubuntu 16.04 LTS\r\n* Docker: 18.03.0-ce\r\n* Node: v8.11.1\r\n* Hyperledger Fabric: 1.1.0 \r\n* Hyperledger Composer: 0.19\r\n\r\nExplorer `config.json` pretty much default, no TLS:\r\n\r\n    {\r\n        &quot;network-config&quot;: {\r\n                &quot;org1&quot;: {\r\n                        &quot;name&quot;: &quot;hlfv1&quot;,\r\n                        &quot;mspid&quot;: &quot;Org1MSP&quot;,\r\n                        &quot;peer1&quot;: {\r\n                                &quot;requests&quot;: &quot;grpc://127.0.0.1:7051&quot;,\r\n                                &quot;events&quot;: &quot;grpc://127.0.0.1:7053&quot;,\r\n                                &quot;server-hostname&quot;: &quot;peer0.org1.example.com&quot;\r\n                        },\r\n                        &quot;admin&quot;: {\r\n                                &quot;key&quot;: &quot;/home/ubuntu/fabric-tools/fabric-scripts/hlfv11/composer/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore&quot;,\r\n                                &quot;cert&quot;: &quot;/home/ubuntu/fabric-tools/fabric-scripts/hlfv11/composer/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts&quot;\r\n                        }\r\n                }\r\n        },\r\n        &quot;host&quot;: &quot;localhost&quot;,\r\n        &quot;port&quot;: &quot;8080&quot;,\r\n        &quot;channel&quot;: &quot;composerchannel&quot;,\r\n        &quot;keyValueStore&quot;: &quot;/tmp/fabric-client-kvs&quot;,\r\n        &quot;eventWaitTime&quot;: &quot;30000&quot;,\r\n        &quot;pg&quot;: {\r\n                &quot;host&quot;: &quot;127.0.0.1&quot;,\r\n                &quot;port&quot;: &quot;5432&quot;,\r\n                &quot;database&quot;: &quot;fabricexplorer&quot;,\r\n                &quot;username&quot;: &quot;hppoc&quot;,\r\n                &quot;passwd&quot;: &quot;password&quot;\r\n        },\r\n        &quot;license&quot;: &quot;Apache-2.0&quot;\r\n    }\r\n\r\nAnything I missed / hints? Thanks beforehand.",
            "link": "https://stackoverflow.com/questions/49853848/hyperledger-explorer-is-empty-with-query-error-no-identity-has-been-assigned",
            "title": "Hyperledger Explorer is empty with Query - Error: No identity has been assigned to this client",
            "body": "<p>I recently installed Hyperledger Explorer. When running Explorer, it returns nothing to the browser and gives the error:</p>\n\n<pre><code>postgres://hppoc:password@127.0.0.1:5432/fabricexplorer\nPlease open web browser to access ：http://localhost:8080/\n[2018-04-16 08:15:18.542] [ERROR] Query - Error: No identity has been assigned to this client\n    at Client._getSigningIdentity (/home/ubuntu/blockchain-explorer/node_modules/fabric-client/lib/Client.js:1206:11)\n    at Channel.queryInfo (/home/ubuntu/blockchain-explorer/node_modules/fabric-client/lib/Channel.js:896:36)\n    at helper.getOrgAdmin.then (/home/ubuntu/blockchain-explorer/app/query.js:98:18)\n    at &lt;anonymous&gt;\n</code></pre>\n\n<p>I tried to <code>console.log</code> the output of <code>blockchain-explorer/node_modules/fabric-client/lib/Client.js:1206:11</code> indeed the <code>admin</code> variable is <code>undefined</code></p>\n\n<p>It's pretty weird since I installed Composer before this and it runs perfectly fine. All the<code>crypto-config</code> uses the default settings provided by the Composer example.</p>\n\n<p>Versions (pretty much latest stable version):</p>\n\n<ul>\n<li>OS: Ubuntu 16.04 LTS</li>\n<li>Docker: 18.03.0-ce</li>\n<li>Node: v8.11.1</li>\n<li>Hyperledger Fabric: 1.1.0 </li>\n<li>Hyperledger Composer: 0.19</li>\n</ul>\n\n<p>Explorer <code>config.json</code> pretty much default, no TLS:</p>\n\n<pre><code>{\n    \"network-config\": {\n            \"org1\": {\n                    \"name\": \"hlfv1\",\n                    \"mspid\": \"Org1MSP\",\n                    \"peer1\": {\n                            \"requests\": \"grpc://127.0.0.1:7051\",\n                            \"events\": \"grpc://127.0.0.1:7053\",\n                            \"server-hostname\": \"peer0.org1.example.com\"\n                    },\n                    \"admin\": {\n                            \"key\": \"/home/ubuntu/fabric-tools/fabric-scripts/hlfv11/composer/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/keystore\",\n                            \"cert\": \"/home/ubuntu/fabric-tools/fabric-scripts/hlfv11/composer/crypto-config/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp/signcerts\"\n                    }\n            }\n    },\n    \"host\": \"localhost\",\n    \"port\": \"8080\",\n    \"channel\": \"composerchannel\",\n    \"keyValueStore\": \"/tmp/fabric-client-kvs\",\n    \"eventWaitTime\": \"30000\",\n    \"pg\": {\n            \"host\": \"127.0.0.1\",\n            \"port\": \"5432\",\n            \"database\": \"fabricexplorer\",\n            \"username\": \"hppoc\",\n            \"passwd\": \"password\"\n    },\n    \"license\": \"Apache-2.0\"\n}\n</code></pre>\n\n<p>Anything I missed / hints? Thanks beforehand.</p>\n"
        },
        {
            "tags": [
                "ubuntu-14.04",
                "ubuntu-16.04",
                "ubuntu-server"
            ],
            "owner": {
                "reputation": 135,
                "user_id": 4809070,
                "user_type": "registered",
                "accept_rate": 87,
                "profile_image": "https://www.gravatar.com/avatar/de25dab19b78af326cc9a7734ff89ee1?s=128&d=identicon&r=PG&f=1",
                "display_name": "Athi",
                "link": "https://stackoverflow.com/users/4809070/athi"
            },
            "is_answered": false,
            "view_count": 7,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524203951,
            "creation_date": 1524203951,
            "question_id": 49934966,
            "body_markdown": "I use UBUNTU server version 17.4. Using VMware I accessed the server. I configured the Network interface.\r\nhttp://10.1.3.163:8080/ is not reached in client side.\r\nUsing SQLyog, I cant access the MYSQL. I checked Port 8080 &amp; 3306 is active connections in the server and I also checked the TELNET and it shows error like\r\n\r\n    telnet: unable to connect the remote host: invalid argument\r\n\r\nI granted privileges for all users in mysql\r\n\r\nI think issues to execute map address from server or map address from client.\r\n\r\nPlease help me to solve the issue.",
            "link": "https://stackoverflow.com/questions/49934966/cant-accessible-from-ubuntu-server-to-client",
            "title": "Cant accessible from Ubuntu Server to Client",
            "body": "<p>I use UBUNTU server version 17.4. Using VMware I accessed the server. I configured the Network interface.\n<a href=\"http://10.1.3.163:8080/\" rel=\"nofollow noreferrer\">http://10.1.3.163:8080/</a> is not reached in client side.\nUsing SQLyog, I cant access the MYSQL. I checked Port 8080 &amp; 3306 is active connections in the server and I also checked the TELNET and it shows error like</p>\n\n<pre><code>telnet: unable to connect the remote host: invalid argument\n</code></pre>\n\n<p>I granted privileges for all users in mysql</p>\n\n<p>I think issues to execute map address from server or map address from client.</p>\n\n<p>Please help me to solve the issue.</p>\n"
        },
        {
            "tags": [
                "node.js",
                "bigdata"
            ],
            "owner": {
                "reputation": 17,
                "user_id": 9539529,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/4b9ab21918e08e353280053a7404fbdf?s=128&d=identicon&r=PG&f=1",
                "display_name": "Ajay Poriya",
                "link": "https://stackoverflow.com/users/9539529/ajay-poriya"
            },
            "is_answered": false,
            "view_count": 13,
            "closed_date": 1524206051,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524203949,
            "creation_date": 1524203949,
            "question_id": 49934964,
            "body_markdown": "I wanted to learn big data I have quite good knowledge of Nodejs. Is there any possible way to learn big data with nodejs ? In java we have options like Hadoop and Scala.",
            "link": "https://stackoverflow.com/questions/49934964/is-there-any-possible-way-to-configure-node-with-bigdata",
            "closed_reason": "off-topic",
            "title": "Is there any possible way to configure Node with BIGData?",
            "body": "<p>I wanted to learn big data I have quite good knowledge of Nodejs. Is there any possible way to learn big data with nodejs ? In java we have options like Hadoop and Scala.</p>\n"
        },
        {
            "tags": [
                "amazon-s3",
                "unicode",
                "aws-sdk"
            ],
            "owner": {
                "reputation": 529,
                "user_id": 1882090,
                "user_type": "registered",
                "accept_rate": 60,
                "profile_image": "https://i.stack.imgur.com/ygKG0.jpg?s=128&g=1",
                "display_name": "fjanisze",
                "link": "https://stackoverflow.com/users/1882090/fjanisze"
            },
            "is_answered": false,
            "view_count": 37,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524203941,
            "creation_date": 1523638369,
            "last_edit_date": 1524203941,
            "question_id": 49821811,
            "body_markdown": "How to decode unicode object names from S3 using the Windows C++ AWS SDK?\r\n\r\nI&#39;m facing the weird issue of getting wrongly decoded object names when listing buckets with files having unicode names. What I do is that I run &#39;mbstowcs_s&#39; or &#39;MultiByteToWideChar&#39; (Attempted both) to decode the object names that I get from S3.\r\n\r\nAs I understand, the object names coming from S3 are in multibyte format so I convert it to wide chars string using these converting functions, this seems to not work and I always get some trash names while listing unicode files, but names which use standard symbols from the ASCII table are properly decoded.\r\n\r\nFor example, having the file &#39;ธงไชย แม็คอินไตย์.txt&#39; on my bucket, if I attempt to list it from S3 using ListObjectV2Request and I attempt to convert its name to wide chars using mbstowcs_s I always get some noise instead of a valid name. The same method works perfectly with ASCII name.\r\n\r\nAny suggestion?\r\n\r\n**EDIT 1:**\r\n\r\nHere are a bit more details on how I&#39;m attempting to decode the names (cutting off all the not relevant parts in order to focus on the decoding steps)\r\n\r\n1) First I get the list of objects from S3:\r\n    \r\n    pListObjectsOutcome = new Aws::S3::Model::ListObjectsV2Outcome(pS3Client-&gt;ListObjectsV2(*pObjectsRequest));\r\n    pObjectList = new (std::nothrow) Aws::Vector&lt;Aws::S3::Model::Object&gt;(pListObjectsOutcome-&gt;GetResult().GetContents());\r\n\r\n2) Iterate over the list and extract the names:\r\n\r\n    Aws::Vector&lt;Aws::S3::Model::Object&gt;::iterator it = pObjectList-&gt;begin();\r\n    //loop for each name\r\n    Aws::String name = it-&gt;GetKey();\r\n\r\n3) Now `name` contains one of the filenames, attempt to decode it:\r\n\r\n    PWCHAR* objectName = nullptr;\r\n    //Properly initialize objectName and szObjNameLen, then:\r\n    mbstowcs_s(&amp;szCount, objectName, szObjNameLen, name.c_str(), name.length());\r\n    //OR:\r\n    MultiByteToWideChar(CP_ACP, MB_PRECOMPOSED, name.c_str(), name.length(), objectName, szObjNameLen); //Using CP_UTF8 does not work as well\r\n\r\n\r\n4) Later on, try to create a file on disk:\r\n\r\n    //Prepare the PATH for objectName and create the file...\r\n    hFile = CreateFile(objectName, GENERIC_WRITE | GENERIC_READ, 0,\r\n         NULL, OPEN_ALWAYS, FILE_ATTRIBUTE_NORMAL, NULL);\r\n\r\nUsing this procedure I&#39;m able to create ASCII filenames but not unicode filenames.",
            "link": "https://stackoverflow.com/questions/49821811/how-to-decode-unicode-s3-object-names",
            "title": "How to decode unicode S3 object names?",
            "body": "<p>How to decode unicode object names from S3 using the Windows C++ AWS SDK?</p>\n\n<p>I'm facing the weird issue of getting wrongly decoded object names when listing buckets with files having unicode names. What I do is that I run 'mbstowcs_s' or 'MultiByteToWideChar' (Attempted both) to decode the object names that I get from S3.</p>\n\n<p>As I understand, the object names coming from S3 are in multibyte format so I convert it to wide chars string using these converting functions, this seems to not work and I always get some trash names while listing unicode files, but names which use standard symbols from the ASCII table are properly decoded.</p>\n\n<p>For example, having the file 'ธงไชย แม็คอินไตย์.txt' on my bucket, if I attempt to list it from S3 using ListObjectV2Request and I attempt to convert its name to wide chars using mbstowcs_s I always get some noise instead of a valid name. The same method works perfectly with ASCII name.</p>\n\n<p>Any suggestion?</p>\n\n<p><strong>EDIT 1:</strong></p>\n\n<p>Here are a bit more details on how I'm attempting to decode the names (cutting off all the not relevant parts in order to focus on the decoding steps)</p>\n\n<p>1) First I get the list of objects from S3:</p>\n\n<pre><code>pListObjectsOutcome = new Aws::S3::Model::ListObjectsV2Outcome(pS3Client-&gt;ListObjectsV2(*pObjectsRequest));\npObjectList = new (std::nothrow) Aws::Vector&lt;Aws::S3::Model::Object&gt;(pListObjectsOutcome-&gt;GetResult().GetContents());\n</code></pre>\n\n<p>2) Iterate over the list and extract the names:</p>\n\n<pre><code>Aws::Vector&lt;Aws::S3::Model::Object&gt;::iterator it = pObjectList-&gt;begin();\n//loop for each name\nAws::String name = it-&gt;GetKey();\n</code></pre>\n\n<p>3) Now <code>name</code> contains one of the filenames, attempt to decode it:</p>\n\n<pre><code>PWCHAR* objectName = nullptr;\n//Properly initialize objectName and szObjNameLen, then:\nmbstowcs_s(&amp;szCount, objectName, szObjNameLen, name.c_str(), name.length());\n//OR:\nMultiByteToWideChar(CP_ACP, MB_PRECOMPOSED, name.c_str(), name.length(), objectName, szObjNameLen); //Using CP_UTF8 does not work as well\n</code></pre>\n\n<p>4) Later on, try to create a file on disk:</p>\n\n<pre><code>//Prepare the PATH for objectName and create the file...\nhFile = CreateFile(objectName, GENERIC_WRITE | GENERIC_READ, 0,\n     NULL, OPEN_ALWAYS, FILE_ATTRIBUTE_NORMAL, NULL);\n</code></pre>\n\n<p>Using this procedure I'm able to create ASCII filenames but not unicode filenames.</p>\n"
        },
        {
            "tags": [
                "google-cloud-dataflow",
                "apache-beam",
                "google-natural-language"
            ],
            "owner": {
                "reputation": 48,
                "user_id": 1162583,
                "user_type": "registered",
                "accept_rate": 38,
                "profile_image": "https://www.gravatar.com/avatar/e2a9731f760b90e7a60d85c9fbc724a6?s=128&d=identicon&r=PG",
                "display_name": "John Watson",
                "link": "https://stackoverflow.com/users/1162583/john-watson"
            },
            "is_answered": false,
            "view_count": 10,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524203941,
            "creation_date": 1524203941,
            "question_id": 49934963,
            "body_markdown": "I have a dataflow pipepline to use google cloud natural language API for sentimental analysis. So, i include jar for cloud language &amp; dataflow runner as below:\r\n\r\n    &lt;dependency&gt;\r\n      &lt;groupId&gt;com.google.cloud&lt;/groupId&gt;\r\n      &lt;artifactId&gt;google-cloud-language&lt;/artifactId&gt;\r\n      &lt;version&gt;1.25.0&lt;/version&gt;\r\n    &lt;/dependency&gt;\r\n\r\n\t&lt;dependency&gt;\r\n\t\t&lt;groupId&gt;org.apache.beam&lt;/groupId&gt;\r\n\t\t&lt;artifactId&gt;beam-runners-google-cloud-dataflow-java&lt;/artifactId&gt;\r\n\t\t&lt;version&gt;2.4.0&lt;/version&gt;\r\n\t&lt;/dependency&gt;\r\n\r\nBut the problem is, there are crashes on the dependencies\r\n\r\ncloud language is using io.grpc 1.10.1 while beam sdk is using 1.2.0. Is there any way to sort it out? Thanks.\r\n\r\n\r\n\r\ncom.google.cloud:google-cloud-language:jar:1.25.0 -&gt; io.grpc:grpc-stub:jar:1.10.1 -&gt; io.grpc:grpc-core:jar:1.10.1\r\n\r\norg.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-core:jar:1.2.0, \r\n\r\nDetails logs:\r\n\r\n\r\n    [ERROR] Failed to execute goal on project apache-beam-loader: Could not resolve dependencies for project com.sample.cloud:apache-beam-loader:jar:0.0.1-SNAPSHOT: Failed to collect dependencies for com.sample.cloud:apache-beam-loader:jar:0.0.1-SNAPSHOT: Could not resolve version conflict among [org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-core:jar:1.2.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-netty:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:[1.2.0,1.2.0], org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-all:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:[1.2.0,1.2.0], org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-all:jar:1.2.0 -&gt; io.grpc:grpc-okhttp:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:[1.2.0,1.2.0], org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-all:jar:1.2.0 -&gt; io.grpc:grpc-protobuf-lite:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:1.2.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-all:jar:1.2.0 -&gt; io.grpc:grpc-protobuf-nano:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:1.2.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; com.google.cloud.bigtable:bigtable-protos:jar:1.0.0-pre3 -&gt; io.grpc:grpc-core:jar:1.5.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0 -&gt; io.grpc:grpc-core:jar:1.7.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0 -&gt; io.opencensus:opencensus-contrib-grpc-util:jar:0.7.0 -&gt; io.grpc:grpc-core:jar:1.6.1, com.google.cloud:google-cloud-language:jar:1.25.0 -&gt; com.google.cloud:google-cloud-core-grpc:jar:1.25.0 -&gt; io.grpc:grpc-protobuf:jar:1.10.1 -&gt; io.grpc:grpc-core:jar:1.10.1, com.google.cloud:google-cloud-language:jar:1.25.0 -&gt; io.grpc:grpc-netty-shaded:jar:1.10.1 -&gt; io.grpc:grpc-core:jar:[1.10.1,1.10.1], com.google.cloud:google-cloud-language:jar:1.25.0 -&gt; io.grpc:grpc-stub:jar:1.10.1 -&gt; io.grpc:grpc-core:jar:1.10.1, com.google.cloud:google-cloud-language:jar:1.25.0 -&gt; io.grpc:grpc-auth:jar:1.10.1 -&gt; io.grpc:grpc-core:jar:[1.10.1,1.10.1]] -&gt; [Help 1]\r\n\r\n\r\n ",
            "link": "https://stackoverflow.com/questions/49934963/unable-to-use-dataflow-with-google-cloud-nature-language-api",
            "title": "Unable to use dataflow with google cloud nature language API",
            "body": "<p>I have a dataflow pipepline to use google cloud natural language API for sentimental analysis. So, i include jar for cloud language &amp; dataflow runner as below:</p>\n\n<pre><code>&lt;dependency&gt;\n  &lt;groupId&gt;com.google.cloud&lt;/groupId&gt;\n  &lt;artifactId&gt;google-cloud-language&lt;/artifactId&gt;\n  &lt;version&gt;1.25.0&lt;/version&gt;\n&lt;/dependency&gt;\n\n&lt;dependency&gt;\n    &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;\n    &lt;artifactId&gt;beam-runners-google-cloud-dataflow-java&lt;/artifactId&gt;\n    &lt;version&gt;2.4.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>\n\n<p>But the problem is, there are crashes on the dependencies</p>\n\n<p>cloud language is using io.grpc 1.10.1 while beam sdk is using 1.2.0. Is there any way to sort it out? Thanks.</p>\n\n<p>com.google.cloud:google-cloud-language:jar:1.25.0 -> io.grpc:grpc-stub:jar:1.10.1 -> io.grpc:grpc-core:jar:1.10.1</p>\n\n<p>org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -> io.grpc:grpc-core:jar:1.2.0, </p>\n\n<p>Details logs:</p>\n\n<pre><code>[ERROR] Failed to execute goal on project apache-beam-loader: Could not resolve dependencies for project com.sample.cloud:apache-beam-loader:jar:0.0.1-SNAPSHOT: Failed to collect dependencies for com.sample.cloud:apache-beam-loader:jar:0.0.1-SNAPSHOT: Could not resolve version conflict among [org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-core:jar:1.2.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-netty:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:[1.2.0,1.2.0], org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-all:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:[1.2.0,1.2.0], org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-all:jar:1.2.0 -&gt; io.grpc:grpc-okhttp:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:[1.2.0,1.2.0], org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-all:jar:1.2.0 -&gt; io.grpc:grpc-protobuf-lite:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:1.2.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; io.grpc:grpc-all:jar:1.2.0 -&gt; io.grpc:grpc-protobuf-nano:jar:1.2.0 -&gt; io.grpc:grpc-core:jar:1.2.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; com.google.cloud.bigtable:bigtable-protos:jar:1.0.0-pre3 -&gt; io.grpc:grpc-core:jar:1.5.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0 -&gt; io.grpc:grpc-core:jar:1.7.0, org.apache.beam:beam-runners-google-cloud-dataflow-java:jar:2.4.0 -&gt; org.apache.beam:beam-sdks-java-io-google-cloud-platform:jar:2.4.0 -&gt; com.google.cloud.bigtable:bigtable-client-core:jar:1.0.0 -&gt; io.opencensus:opencensus-contrib-grpc-util:jar:0.7.0 -&gt; io.grpc:grpc-core:jar:1.6.1, com.google.cloud:google-cloud-language:jar:1.25.0 -&gt; com.google.cloud:google-cloud-core-grpc:jar:1.25.0 -&gt; io.grpc:grpc-protobuf:jar:1.10.1 -&gt; io.grpc:grpc-core:jar:1.10.1, com.google.cloud:google-cloud-language:jar:1.25.0 -&gt; io.grpc:grpc-netty-shaded:jar:1.10.1 -&gt; io.grpc:grpc-core:jar:[1.10.1,1.10.1], com.google.cloud:google-cloud-language:jar:1.25.0 -&gt; io.grpc:grpc-stub:jar:1.10.1 -&gt; io.grpc:grpc-core:jar:1.10.1, com.google.cloud:google-cloud-language:jar:1.25.0 -&gt; io.grpc:grpc-auth:jar:1.10.1 -&gt; io.grpc:grpc-core:jar:[1.10.1,1.10.1]] -&gt; [Help 1]\n</code></pre>\n"
        },
        {
            "tags": [
                "c#",
                "asp.net",
                ".net",
                "model-view-controller"
            ],
            "owner": {
                "reputation": 65,
                "user_id": 2769810,
                "user_type": "registered",
                "accept_rate": 60,
                "profile_image": "https://www.gravatar.com/avatar/4b25b6612f71146dfca0a0c0c7e9044f?s=128&d=identicon&r=PG&f=1",
                "display_name": "user2769810",
                "link": "https://stackoverflow.com/users/2769810/user2769810"
            },
            "is_answered": false,
            "view_count": 29,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524203932,
            "creation_date": 1524203932,
            "question_id": 49934960,
            "body_markdown": "I am on a C# .NET MVC project, and have a form that can dynamically add/remove n number of complex objects in a list. This complex object, for example represents a Person. This person has FirstName and Address properties. \r\n\r\nWhen the user loads the page, all the People in the system are displayed in a list. When the user presses the &#39;add&#39; button, two new text boxes show up for the Person&#39;s FirstName and Address properties. When the user presses the submit button, it will make a POST request to the server. \r\n\r\nI know that you can write regular html in the View, and can use Javascript to add the new DOM elements for the FirstName and Address properties. \r\n\r\nAnd with regards to when the user submits, I can use javascript to scrape all the data in the screen, and send a POST request to the server. Theoretically, another method is instead of using javascript, just make the button submit the form to the POST action of the controller; if I give my DOM elements the proper name attribute, the Action should recognize the data.\r\n\r\nHowever, is there a MVC way of doing this? Maybe, with the help of Razor Helpers?",
            "link": "https://stackoverflow.com/questions/49934960/net-mvc-dynamically-add-remove-items-without-using-javascript",
            "title": ".NET MVC Dynamically add/remove items without using javascript",
            "body": "<p>I am on a C# .NET MVC project, and have a form that can dynamically add/remove n number of complex objects in a list. This complex object, for example represents a Person. This person has FirstName and Address properties. </p>\n\n<p>When the user loads the page, all the People in the system are displayed in a list. When the user presses the 'add' button, two new text boxes show up for the Person's FirstName and Address properties. When the user presses the submit button, it will make a POST request to the server. </p>\n\n<p>I know that you can write regular html in the View, and can use Javascript to add the new DOM elements for the FirstName and Address properties. </p>\n\n<p>And with regards to when the user submits, I can use javascript to scrape all the data in the screen, and send a POST request to the server. Theoretically, another method is instead of using javascript, just make the button submit the form to the POST action of the controller; if I give my DOM elements the proper name attribute, the Action should recognize the data.</p>\n\n<p>However, is there a MVC way of doing this? Maybe, with the help of Razor Helpers?</p>\n"
        },
        {
            "tags": [
                "sql-server",
                "mongodb",
                "mongodb-query",
                "aggregation"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 7407960,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/96209d1054132e0d4050831bc968537e?s=128&d=identicon&r=PG&f=1",
                "display_name": "addon mehul",
                "link": "https://stackoverflow.com/users/7407960/addon-mehul"
            },
            "is_answered": false,
            "view_count": 30,
            "closed_date": 1524221962,
            "answer_count": 0,
            "score": -5,
            "last_activity_date": 1524203930,
            "creation_date": 1524202769,
            "last_edit_date": 1524203930,
            "question_id": 49934729,
            "body_markdown": "I have an SQL query like this:\r\n\r\n\r\n    WITH marked AS ( SELECT *, grp = ROW_NUMBER() OVER (PARTITION BY no ORDER BY date) - ROW_NUMBER() OVER (PARTITION BY no, ignition ORDER BY date) FROM tbl_data where no= 123 and date between &#39;2018-04-01&#39; and &#39;2018-04-20&#39; )\r\n    \r\n         SELECT\r\n          Start1=(select TOP(1) L1 from tbl_data m where m.date=MIN(mr.date) AND m.no=&#39;123&#39;),\r\n          Start2=(select TOP(1) L2 from tbl_data m where m.date=MIN(mr.date) AND m.no=&#39;123&#39;),\r\n          End1=(select TOP(1) L1 from tbl_data m where m.date=MAX(mr.date) AND m.no=&#39;123&#39;),\r\n          End2=(select TOP(1) L2 from tbl_data m where m.date=MAX(mr.date) AND m.no=&#39;123&#39;),\r\n          startdate = MIN(mr.date),\r\n          enddate=MAX(mr.date),\r\n          Status=(case when ignition=0 then &#39;Stop&#39; Else &#39;Start&#39; END),\r\n          Duration = DATEDIFF(MINUTE, MIN(mr.date), MAX(mr.date)),\r\n          DATEDIFF(second,MIN(mr.date),MAX(mr.date)) as DifferenceData,\r\n          Distance=coalesce((select SUM(CAST(odo as float)) \r\n          from tbl_data m where date between MIN(mr.date) and MAX(mr.date) AND m.no=&#39;123&#39; and m.speed &gt;7),0)\r\n\r\n         FROM marked mr where no= &#39;123&#39;  and  date between &#39;2018-04-01&#39; and &#39;2018-04-20&#39;\r\n\r\n         GROUP BY\r\n          no,\r\n          ignition,\r\n          grp  \r\n          ORDER BY\r\n          MIN(mr.date)\r\n\r\n\r\nhow to convert this query into mongodb?\r\nanyone can help for converting SQL query to mongodb?\r\nThanks.\r\n",
            "link": "https://stackoverflow.com/questions/49934729/how-to-write-row-number-partition-query-in-mongodb",
            "closed_reason": "duplicate",
            "title": "How to write row_number partition query in mongodb",
            "body": "<p>I have an SQL query like this:</p>\n\n<pre><code>WITH marked AS ( SELECT *, grp = ROW_NUMBER() OVER (PARTITION BY no ORDER BY date) - ROW_NUMBER() OVER (PARTITION BY no, ignition ORDER BY date) FROM tbl_data where no= 123 and date between '2018-04-01' and '2018-04-20' )\n\n     SELECT\n      Start1=(select TOP(1) L1 from tbl_data m where m.date=MIN(mr.date) AND m.no='123'),\n      Start2=(select TOP(1) L2 from tbl_data m where m.date=MIN(mr.date) AND m.no='123'),\n      End1=(select TOP(1) L1 from tbl_data m where m.date=MAX(mr.date) AND m.no='123'),\n      End2=(select TOP(1) L2 from tbl_data m where m.date=MAX(mr.date) AND m.no='123'),\n      startdate = MIN(mr.date),\n      enddate=MAX(mr.date),\n      Status=(case when ignition=0 then 'Stop' Else 'Start' END),\n      Duration = DATEDIFF(MINUTE, MIN(mr.date), MAX(mr.date)),\n      DATEDIFF(second,MIN(mr.date),MAX(mr.date)) as DifferenceData,\n      Distance=coalesce((select SUM(CAST(odo as float)) \n      from tbl_data m where date between MIN(mr.date) and MAX(mr.date) AND m.no='123' and m.speed &gt;7),0)\n\n     FROM marked mr where no= '123'  and  date between '2018-04-01' and '2018-04-20'\n\n     GROUP BY\n      no,\n      ignition,\n      grp  \n      ORDER BY\n      MIN(mr.date)\n</code></pre>\n\n<p>how to convert this query into mongodb?\nanyone can help for converting SQL query to mongodb?\nThanks.</p>\n"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 228
}