{
    "items": [
        {
            "tags": [
                "scala"
            ],
            "owner": {
                "reputation": 763,
                "user_id": 4353033,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/599e46280c78d89345d3dc1b150c00ef?s=128&d=identicon&r=PG&f=1",
                "display_name": "Anurag Sharma",
                "link": "https://stackoverflow.com/users/4353033/anurag-sharma"
            },
            "is_answered": true,
            "view_count": 43,
            "answer_count": 2,
            "score": 4,
            "last_activity_date": 1524165812,
            "creation_date": 1524125790,
            "question_id": 49916037,
            "body_markdown": "[![enter image description here][1]][1]\r\n\r\n\r\nI am referring to official [documentation][2]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/0vJLB.png\r\n  [2]: https://docs.scala-lang.org/overviews/collections/performance-characteristics.html\r\n\r\nwhich shows prepend complexity of Vector as &quot;effectively constant&quot; (eC). But my understanding is that for a vector, prepend would mean that all other indexes need to be adjusted as well which will make the operation O(n) or L (linear). Could anyone please explain how is prepend in vector eC (effectively constant).",
            "link": "https://stackoverflow.com/questions/49916037/prepend-complexity-of-scala-vector",
            "title": "Prepend complexity of scala vector",
            "body": "<p><a href=\"https://i.stack.imgur.com/0vJLB.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0vJLB.png\" alt=\"enter image description here\"></a></p>\n\n<p>I am referring to official <a href=\"https://docs.scala-lang.org/overviews/collections/performance-characteristics.html\" rel=\"nofollow noreferrer\">documentation</a></p>\n\n<p>which shows prepend complexity of Vector as \"effectively constant\" (eC). But my understanding is that for a vector, prepend would mean that all other indexes need to be adjusted as well which will make the operation O(n) or L (linear). Could anyone please explain how is prepend in vector eC (effectively constant).</p>\n"
        },
        {
            "tags": [
                "c++",
                "opencl"
            ],
            "owner": {
                "reputation": 1950,
                "user_id": 982049,
                "user_type": "registered",
                "accept_rate": 98,
                "profile_image": "https://i.stack.imgur.com/eq1S9.jpg?s=128&g=1",
                "display_name": "Cool_Coder",
                "link": "https://stackoverflow.com/users/982049/cool-coder"
            },
            "is_answered": true,
            "view_count": 1300,
            "accepted_answer_id": 22119936,
            "answer_count": 4,
            "score": 4,
            "last_activity_date": 1524165809,
            "creation_date": 1393598584,
            "question_id": 22098210,
            "body_markdown": "I am currently learning OpencL and am finding it somewhat difficult to understand how it actually works.\r\nI am using MinGW compiler with ATI APP SDK.\r\nWhen I run the target I get error message\r\n\r\n![enter image description here][1]\r\n\r\nI have not placed any OpenCL.dll in the same folder as my application.\r\nNow searching a bit on Windows I can find this dll in\r\n\r\n    C:/Windows/SysWOW64\r\n    C:/Windows/System32/DriverStore/...\r\n    C:/Windows/System32\r\n    C:/Program Files(x86)/AMD APP SDK /...\r\n\r\nSo my question is how should I deploy my application?\r\nShould I distribute OpenCL.dll with my application?\r\n\r\n  [1]: http://i.stack.imgur.com/bdmwE.png",
            "link": "https://stackoverflow.com/questions/22098210/deploying-opencl-application",
            "title": "Deploying OpenCL application?",
            "body": "<p>I am currently learning OpencL and am finding it somewhat difficult to understand how it actually works.\nI am using MinGW compiler with ATI APP SDK.\nWhen I run the target I get error message</p>\n\n<p><img src=\"https://i.stack.imgur.com/bdmwE.png\" alt=\"enter image description here\"></p>\n\n<p>I have not placed any OpenCL.dll in the same folder as my application.\nNow searching a bit on Windows I can find this dll in</p>\n\n<pre><code>C:/Windows/SysWOW64\nC:/Windows/System32/DriverStore/...\nC:/Windows/System32\nC:/Program Files(x86)/AMD APP SDK /...\n</code></pre>\n\n<p>So my question is how should I deploy my application?\nShould I distribute OpenCL.dll with my application?</p>\n"
        },
        {
            "tags": [
                "c#",
                "algorithm"
            ],
            "owner": {
                "reputation": 1301,
                "user_id": 3394884,
                "user_type": "registered",
                "accept_rate": 68,
                "profile_image": "https://i.stack.imgur.com/LqQhR.png?s=128&g=1",
                "display_name": "kuskmen",
                "link": "https://stackoverflow.com/users/3394884/kuskmen"
            },
            "is_answered": true,
            "view_count": 81,
            "answer_count": 4,
            "score": -3,
            "last_activity_date": 1524165794,
            "creation_date": 1524086846,
            "last_edit_date": 1524088624,
            "question_id": 49909276,
            "body_markdown": "I want to solve following problem using Quicksort.\r\n\r\nI have *n* string in an array where each string is guaranteed to be positive positive number with no leading zeros and digits between 1 and 10^6 inclusive. I did it using regular quicksort with `BigInteger` struct but I&#39;ve got a lot of timeout cases which led me to think I need to optimize my way of comparisons and drop the parsing from `string[]` and back to `BigInteger[]` and back to `string[]` so I&#39;ve decided to sort it as it is. Here is my code:\r\n\r\n    static void swap(string[] array, int first, int second)\r\n    {\r\n        var temp = array[first];\r\n        array[first] = array[second];\r\n        array[second] = temp;\r\n    }\r\n\r\n    static void quickSort(string[] array, int left, int right)\r\n    {\r\n        if (left &gt;= right) return;\r\n        var pivot = array[(left + right) / 2];\r\n        var index = partition(array, left, right, pivot);\r\n        quickSort(array, left, index - 1);\r\n        quickSort(array, index, right);\r\n    }\r\n\r\n    static int partition(string[] array, int left, int right, string pivot)\r\n    {\r\n        while(left &lt;= right)\r\n        {\r\n            while (left &lt; array.Length &amp;&amp; !array[left].IsBigger(pivot)) left++;\r\n            while (right &lt; array.Length &amp;&amp; array[right].IsBigger(pivot)) right--;\r\n            if (left &lt;= right)\r\n            {\r\n                swap(array, left, right);\r\n                left++;\r\n                right--;\r\n            }\r\n        }\r\n\r\n        return left;\r\n    }\r\n\r\n    static bool IsBigger(this string a, string b)\r\n    {\r\n        if (a.Length &lt; b.Length) return false;\r\n        else if(a.Length &gt; b.Length) return true;\r\n\r\n        for (int i = 0; i &lt; a.Length; i++)\r\n        {\r\n            if (a[i] &gt; b[i]) return true;\r\n            else return false;\r\n        }\r\n\r\n        return false;\r\n    }\r\n\r\nBut then I am getting SO exception in `IsBigger` function when the input is so small as `[ &quot;31415926535897932384626433832795&quot;, &quot;1&quot;, &quot;3&quot;, &quot;10&quot;, &quot;3&quot;, &quot;5&quot; ]` and I can&#39;t seem to try why.\r\n\r\nThere is no funny moments calling quicksort - this is how I do it `quickSort(unsorted, 0, unsorted.Length - 1);`\r\n\r\n\r\n----------\r\n## What I&#39;ve tried so far ##\r\n\r\n - Sounds crazy but I&#39;ve tried to force .NET ensure that this method needs more stack size as to me everything looks okay by calling `RuntimeHelpers.EnsureSufficientExecutionStack();` in `IsBigger` but didn&#39;t work also.",
            "link": "https://stackoverflow.com/questions/49909276/why-am-i-getting-stackoverflow-exception-in-this-helper-function-of-quicksort",
            "title": "Why am I getting stackoverflow exception in this helper function of quicksort?",
            "body": "<p>I want to solve following problem using Quicksort.</p>\n\n<p>I have <em>n</em> string in an array where each string is guaranteed to be positive positive number with no leading zeros and digits between 1 and 10^6 inclusive. I did it using regular quicksort with <code>BigInteger</code> struct but I've got a lot of timeout cases which led me to think I need to optimize my way of comparisons and drop the parsing from <code>string[]</code> and back to <code>BigInteger[]</code> and back to <code>string[]</code> so I've decided to sort it as it is. Here is my code:</p>\n\n<pre><code>static void swap(string[] array, int first, int second)\n{\n    var temp = array[first];\n    array[first] = array[second];\n    array[second] = temp;\n}\n\nstatic void quickSort(string[] array, int left, int right)\n{\n    if (left &gt;= right) return;\n    var pivot = array[(left + right) / 2];\n    var index = partition(array, left, right, pivot);\n    quickSort(array, left, index - 1);\n    quickSort(array, index, right);\n}\n\nstatic int partition(string[] array, int left, int right, string pivot)\n{\n    while(left &lt;= right)\n    {\n        while (left &lt; array.Length &amp;&amp; !array[left].IsBigger(pivot)) left++;\n        while (right &lt; array.Length &amp;&amp; array[right].IsBigger(pivot)) right--;\n        if (left &lt;= right)\n        {\n            swap(array, left, right);\n            left++;\n            right--;\n        }\n    }\n\n    return left;\n}\n\nstatic bool IsBigger(this string a, string b)\n{\n    if (a.Length &lt; b.Length) return false;\n    else if(a.Length &gt; b.Length) return true;\n\n    for (int i = 0; i &lt; a.Length; i++)\n    {\n        if (a[i] &gt; b[i]) return true;\n        else return false;\n    }\n\n    return false;\n}\n</code></pre>\n\n<p>But then I am getting SO exception in <code>IsBigger</code> function when the input is so small as <code>[ \"31415926535897932384626433832795\", \"1\", \"3\", \"10\", \"3\", \"5\" ]</code> and I can't seem to try why.</p>\n\n<p>There is no funny moments calling quicksort - this is how I do it <code>quickSort(unsorted, 0, unsorted.Length - 1);</code></p>\n\n<hr>\n\n<h2>What I've tried so far</h2>\n\n<ul>\n<li>Sounds crazy but I've tried to force .NET ensure that this method needs more stack size as to me everything looks okay by calling <code>RuntimeHelpers.EnsureSufficientExecutionStack();</code> in <code>IsBigger</code> but didn't work also.</li>\n</ul>\n"
        },
        {
            "tags": [
                "c++",
                "kruskals-algorithm",
                "prims-algorithm"
            ],
            "owner": {
                "reputation": 15,
                "user_id": 2387629,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/6ea3f54cae9dd287516b9e13bb38b3d5?s=128&d=identicon&r=PG",
                "display_name": "Jordan Ward",
                "link": "https://stackoverflow.com/users/2387629/jordan-ward"
            },
            "is_answered": false,
            "view_count": 22,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165783,
            "creation_date": 1524165783,
            "question_id": 49928741,
            "body_markdown": "I wrote this program for my computer science class but my professor told us there is another algorithm called prim&#39;s algorithm. I want to convert my MST function written using Kruskal&#39;s algorithm to be written using Prim&#39;s algorithm and nothing else to be changed. Can someone help me out with this? Not sure if you will want to see all of my code so if you don&#39;t need to see some parts, let me know so I can edit this question. Thanks!\r\n\r\n    #include &lt;cstdio&gt;\r\n    #include &lt;iostream&gt;\r\n    #include &lt;algorithm&gt;\r\n    #include &lt;vector&gt;\r\n\r\n    using namespace std;\r\n\r\n    #define MAX 1000\r\n\r\n    struct Edge {\r\n\t    int c1, c2, w;\r\n    };\r\n\r\n    int parents[MAX + 5];\r\n    vector&lt;Edge&gt; graph; // Store the inputted graph (src, dest, weight).\r\n    vector&lt;Edge&gt; selected_edges; // Store the edges which is selected for the MST from given graph.\r\n\r\n    bool comp(const Edge&amp;, const Edge&amp;);\r\n    void make_set(int);\r\n    int findParent(int);\r\n    int Kruskal_MST(int);\r\n\r\n\r\n    int main() {\r\n\t    Edge e;\r\n\t    int cities, edges, testCases;\r\n\t\r\n\t    cin &gt;&gt; testCases;\r\n\t\r\n\t    for(int i = 0; i &lt; testCases; i++) {\r\n\t\t    cin &gt;&gt; cities;\r\n\t\t    cin &gt;&gt; edges;\r\n\t\r\n\t\t    for(int j = 0; j &lt; edges; j++) {\t\t\r\n\t\t\t    int city1, city2, weight;\r\n\t\t\t    cin &gt;&gt; city1 &gt;&gt; city2 &gt;&gt; weight;\r\n\t\t\r\n\t\t\t    e.c1 = city1;\r\n\t\t\t    e.c2 = city2;\r\n\t\t\t    e.w = weight;\r\n\t\t\t    graph.push_back(e);\r\n\t\t    }\r\n\t\r\n\t\t    int maxweight = Kruskal_MST(cities);\r\n\t\r\n\t\t    cout &lt;&lt; maxweight &lt;&lt; &quot;\\n&quot;;\r\n\t\r\n\t\t    for(int i = 0; i &lt; selected_edges.size(); i++) {\r\n\t\t\t    cout &lt;&lt; &quot;(&quot; &lt;&lt; selected_edges[i].c1 &lt;&lt; &quot;, &quot; &lt;&lt; selected_edges[i].c2 &lt;&lt; &quot;, &quot; &lt;&lt; selected_edges[i].w &lt;&lt; &quot;) &quot;;\r\n\t\t    }\r\n\t\t\r\n\t\tcout &lt;&lt; &quot;\\n&quot;;\r\n\t    }\r\n\t\r\n\t    return 0;\r\n    }\r\n\r\n    bool comp (const Edge&amp; l, const Edge&amp; r) {\r\n\t\r\n\t    return l.w &lt; r.w;\r\n    }\r\n\r\n    int Kruskal_MST(int cities) {\r\n\t\r\n\t    make_set(cities);\r\n\t\r\n\t    sort(graph.begin(), graph.end(), comp);\r\n\t\r\n\t    int edgeCounter = 0;\r\n\t    int maxweight = 0;\r\n\t    int len = graph.size();\r\n\t\r\n\t    for(int i = 0; i &lt; len; i++){\r\n\t\t\r\n\t\t    int parent_of_u = findParent(graph[i].c1);\r\n\t\t    int parent_of_v = findParent(graph[i].c2);\r\n\t\t\r\n\t\t    if(parent_of_u != parent_of_v) {\r\n\t\t\t    if(graph[i].w &gt; maxweight)\r\n\t\t\t\t    maxweight = graph[i].w;\r\n\t\t\t\r\n\t\t\t    parents[parent_of_u] = parent_of_v;\r\n\t\t\t    selected_edges.push_back(graph[i]);\r\n\t\t\t\r\n\t\t\t    edgeCounter++;\r\n\t\t\t    if(edgeCounter == cities - 1)\r\n\t\t\t\t    break;\r\n\t\t    }\r\n\t\t\r\n\t    }\r\n\t\r\n\t    return maxweight;\r\n    }\r\n\r\n    void make_set(int cities) {\r\n\t    for(int i = 1; i &lt;= cities; i++)\r\n\t\t    parents[i] = i;\r\n\t\r\n\t    return;\r\n    }\r\n\r\n    int findParent(int r) {\r\n\t    if(r == parents[r])\r\n\t\t    return r;\r\n\t\r\n\t    return parents[r] = findParent(parents[r]);\r\n    }\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49928741/how-to-convert-my-kruskal-mst-function-to-prims-algorithm",
            "title": "How to convert my Kruskal MST function to Prim&#39;s algorithm?",
            "body": "<p>I wrote this program for my computer science class but my professor told us there is another algorithm called prim's algorithm. I want to convert my MST function written using Kruskal's algorithm to be written using Prim's algorithm and nothing else to be changed. Can someone help me out with this? Not sure if you will want to see all of my code so if you don't need to see some parts, let me know so I can edit this question. Thanks!</p>\n\n<pre><code>#include &lt;cstdio&gt;\n#include &lt;iostream&gt;\n#include &lt;algorithm&gt;\n#include &lt;vector&gt;\n\nusing namespace std;\n\n#define MAX 1000\n\nstruct Edge {\n    int c1, c2, w;\n};\n\nint parents[MAX + 5];\nvector&lt;Edge&gt; graph; // Store the inputted graph (src, dest, weight).\nvector&lt;Edge&gt; selected_edges; // Store the edges which is selected for the MST from given graph.\n\nbool comp(const Edge&amp;, const Edge&amp;);\nvoid make_set(int);\nint findParent(int);\nint Kruskal_MST(int);\n\n\nint main() {\n    Edge e;\n    int cities, edges, testCases;\n\n    cin &gt;&gt; testCases;\n\n    for(int i = 0; i &lt; testCases; i++) {\n        cin &gt;&gt; cities;\n        cin &gt;&gt; edges;\n\n        for(int j = 0; j &lt; edges; j++) {        \n            int city1, city2, weight;\n            cin &gt;&gt; city1 &gt;&gt; city2 &gt;&gt; weight;\n\n            e.c1 = city1;\n            e.c2 = city2;\n            e.w = weight;\n            graph.push_back(e);\n        }\n\n        int maxweight = Kruskal_MST(cities);\n\n        cout &lt;&lt; maxweight &lt;&lt; \"\\n\";\n\n        for(int i = 0; i &lt; selected_edges.size(); i++) {\n            cout &lt;&lt; \"(\" &lt;&lt; selected_edges[i].c1 &lt;&lt; \", \" &lt;&lt; selected_edges[i].c2 &lt;&lt; \", \" &lt;&lt; selected_edges[i].w &lt;&lt; \") \";\n        }\n\n    cout &lt;&lt; \"\\n\";\n    }\n\n    return 0;\n}\n\nbool comp (const Edge&amp; l, const Edge&amp; r) {\n\n    return l.w &lt; r.w;\n}\n\nint Kruskal_MST(int cities) {\n\n    make_set(cities);\n\n    sort(graph.begin(), graph.end(), comp);\n\n    int edgeCounter = 0;\n    int maxweight = 0;\n    int len = graph.size();\n\n    for(int i = 0; i &lt; len; i++){\n\n        int parent_of_u = findParent(graph[i].c1);\n        int parent_of_v = findParent(graph[i].c2);\n\n        if(parent_of_u != parent_of_v) {\n            if(graph[i].w &gt; maxweight)\n                maxweight = graph[i].w;\n\n            parents[parent_of_u] = parent_of_v;\n            selected_edges.push_back(graph[i]);\n\n            edgeCounter++;\n            if(edgeCounter == cities - 1)\n                break;\n        }\n\n    }\n\n    return maxweight;\n}\n\nvoid make_set(int cities) {\n    for(int i = 1; i &lt;= cities; i++)\n        parents[i] = i;\n\n    return;\n}\n\nint findParent(int r) {\n    if(r == parents[r])\n        return r;\n\n    return parents[r] = findParent(parents[r]);\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "centos",
                "firewall",
                "firewalld"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9351387,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/2555699d1f473caab32011351999885c?s=128&d=identicon&r=PG&f=1",
                "display_name": "nemean lion",
                "link": "https://stackoverflow.com/users/9351387/nemean-lion"
            },
            "is_answered": false,
            "view_count": 6,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165763,
            "creation_date": 1524164339,
            "last_edit_date": 1524165763,
            "question_id": 49928372,
            "body_markdown": "I&#39;ve been put in charge of troubleshooting connection errors with a web application hosted on a company Centos 7 server.\r\n\r\nUpon initial inspection it turned out that the Firewalld settings for the active zone did not include http/https, and that \r\n\r\n    sudo firewall-cmd --permanent --add-service=http\r\n    sudo firewall-cmd --reload\r\n\r\nwould resolve the issue, but only temporarily, in spite of the `--permanent` flag.\r\n\r\nThe `--permanent` rule change persists through httpd and Firewalld restarts, but occasionally is overruled and reset to the default zone configuration, without http or https enabled, at specific points in the day.  \r\n\r\nIf anyone has any advice about what might be overruling Firewalld or how to diagnose this issue I would be most appreciative.",
            "link": "https://stackoverflow.com/questions/49928372/firewalld-zone-resetting",
            "title": "Firewalld zone resetting",
            "body": "<p>I've been put in charge of troubleshooting connection errors with a web application hosted on a company Centos 7 server.</p>\n\n<p>Upon initial inspection it turned out that the Firewalld settings for the active zone did not include http/https, and that </p>\n\n<pre><code>sudo firewall-cmd --permanent --add-service=http\nsudo firewall-cmd --reload\n</code></pre>\n\n<p>would resolve the issue, but only temporarily, in spite of the <code>--permanent</code> flag.</p>\n\n<p>The <code>--permanent</code> rule change persists through httpd and Firewalld restarts, but occasionally is overruled and reset to the default zone configuration, without http or https enabled, at specific points in the day.  </p>\n\n<p>If anyone has any advice about what might be overruling Firewalld or how to diagnose this issue I would be most appreciative.</p>\n"
        },
        {
            "tags": [
                "azure-data-lake"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 4436428,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/683727741/picture?type=large",
                "display_name": "Vipinkumar Jha",
                "link": "https://stackoverflow.com/users/4436428/vipinkumar-jha"
            },
            "is_answered": false,
            "view_count": 14,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165758,
            "creation_date": 1523968686,
            "question_id": 49878362,
            "body_markdown": "I have 3 folder on on prem servefr, and each folder having several files .\r\nmy aim to load the files from onprem server to data lake incrementally , so once we copied the file to data lake next time only new files need to be moved .\r\n\r\nthanks in advance\r\nvipin jha\r\n",
            "link": "https://stackoverflow.com/questions/49878362/azure-data-lake-incremental-copy-task-from-onprem-to-data-lake-storage",
            "title": "azure data lake incremental copy task from onprem to data lake storage",
            "body": "<p>I have 3 folder on on prem servefr, and each folder having several files .\nmy aim to load the files from onprem server to data lake incrementally , so once we copied the file to data lake next time only new files need to be moved .</p>\n\n<p>thanks in advance\nvipin jha</p>\n"
        },
        {
            "tags": [
                "python",
                "fabric"
            ],
            "owner": {
                "reputation": 3217,
                "user_id": 633961,
                "user_type": "registered",
                "accept_rate": 66,
                "profile_image": "https://i.stack.imgur.com/0c29q.jpg?s=128&g=1",
                "display_name": "guettli",
                "link": "https://stackoverflow.com/users/633961/guettli"
            },
            "is_answered": true,
            "view_count": 6502,
            "accepted_answer_id": 19338483,
            "answer_count": 3,
            "score": 11,
            "last_activity_date": 1524165757,
            "creation_date": 1381497041,
            "last_edit_date": 1397037350,
            "question_id": 19319014,
            "body_markdown": "I want to get the content of a remote file with fabric, without creating a temporary file.\r\n\r\n",
            "link": "https://stackoverflow.com/questions/19319014/how-to-get-the-content-of-a-remote-file-without-a-local-temporary-file-with-fabr",
            "title": "How to get the content of a remote file without a local temporary file with fabric",
            "body": "<p>I want to get the content of a remote file with fabric, without creating a temporary file.</p>\n"
        },
        {
            "tags": [
                "tweets"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 2105895,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/8d4f7cfc9662fcc664883318af14a0a1?s=128&d=identicon&r=PG",
                "display_name": "Don Baechtel",
                "link": "https://stackoverflow.com/users/2105895/don-baechtel"
            },
            "is_answered": false,
            "view_count": 11,
            "answer_count": 0,
            "score": -3,
            "last_activity_date": 1524165755,
            "creation_date": 1524165755,
            "question_id": 49928730,
            "body_markdown": "How come no one ever responds to my tweets to @azuresupport #azTechHelp ?\r\n\r\nWhy isn&#39;t this Azure support channel working?",
            "link": "https://stackoverflow.com/questions/49928730/no-response-to-tweets-azuresupport-aztechhelp",
            "title": "No Response to tweets @azuresupport #azTechHelp",
            "body": "<p>How come no one ever responds to my tweets to @azuresupport #azTechHelp ?</p>\n\n<p>Why isn't this Azure support channel working?</p>\n"
        },
        {
            "tags": [
                "android",
                "gradle",
                "dart",
                "flutter"
            ],
            "owner": {
                "reputation": 1244,
                "user_id": 1173794,
                "user_type": "registered",
                "accept_rate": 45,
                "profile_image": "https://www.gravatar.com/avatar/66d73a8a5284ac9cce9bc79983c93b43?s=128&d=identicon&r=PG",
                "display_name": "HotIceCream",
                "link": "https://stackoverflow.com/users/1173794/hoticecream"
            },
            "is_answered": true,
            "view_count": 15,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165744,
            "creation_date": 1524160941,
            "question_id": 49927441,
            "body_markdown": "I have an existing Android project.\r\nAlso, I created a new flutter project. I copied my project to it. Now I have such tree in the file system:\r\n\r\n\r\n    my_flutter_project/\r\n        android/\r\n            my_android_module_name/\r\n               src/...\r\n        lib/...\r\n        ios/...\r\n\r\nWhen I try to run flutter project I have such error:\r\n\r\n    No application found for TargetPlatform.android_arm64.\r\n    Is your project missing an android/app/src/main/AndroidManifest.xml?\r\n\r\nSo I should somewhere write `my_android_module_name` instead `app` but where?",
            "link": "https://stackoverflow.com/questions/49927441/use-custom-name-for-android-module-in-flutter-project",
            "title": "Use custom name for android module in flutter project",
            "body": "<p>I have an existing Android project.\nAlso, I created a new flutter project. I copied my project to it. Now I have such tree in the file system:</p>\n\n<pre><code>my_flutter_project/\n    android/\n        my_android_module_name/\n           src/...\n    lib/...\n    ios/...\n</code></pre>\n\n<p>When I try to run flutter project I have such error:</p>\n\n<pre><code>No application found for TargetPlatform.android_arm64.\nIs your project missing an android/app/src/main/AndroidManifest.xml?\n</code></pre>\n\n<p>So I should somewhere write <code>my_android_module_name</code> instead <code>app</code> but where?</p>\n"
        },
        {
            "tags": [
                "ios",
                "dynamic",
                "swift"
            ],
            "owner": {
                "reputation": 1958,
                "user_id": 770313,
                "user_type": "registered",
                "accept_rate": 75,
                "profile_image": "https://i.stack.imgur.com/Vjtmx.png?s=128&g=1",
                "display_name": "possen",
                "link": "https://stackoverflow.com/users/770313/possen"
            },
            "is_answered": true,
            "view_count": 1514,
            "accepted_answer_id": 26290606,
            "answer_count": 1,
            "score": 5,
            "last_activity_date": 1524165732,
            "creation_date": 1412903948,
            "last_edit_date": 1429913608,
            "question_id": 26290469,
            "body_markdown": "How do you instantiate a type dynamically based upon a lookup value in a dictionary in Swift? \r\n\r\n",
            "link": "https://stackoverflow.com/questions/26290469/create-a-swift-object-from-a-dictionary",
            "title": "Create a Swift Object from a Dictionary",
            "body": "<p>How do you instantiate a type dynamically based upon a lookup value in a dictionary in Swift? </p>\n"
        },
        {
            "tags": [
                "python",
                "unit-testing"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 5352483,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e3dbaeb70e6883507ec898894c86847d?s=128&d=identicon&r=PG&f=1",
                "display_name": "X.S",
                "link": "https://stackoverflow.com/users/5352483/x-s"
            },
            "is_answered": false,
            "view_count": 17,
            "closed_date": 1524165922,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165725,
            "creation_date": 1524165725,
            "question_id": 49928723,
            "body_markdown": "How do I test for a re-raised exception in Python ?\r\n\r\nHere is my function that I want to test:\r\n\r\n    def myfunc(self):\r\n        try:\r\n            temp = otherfunc.get(&#39;key&#39;)\r\n        except KeyError as e:\r\n            raise CustomException\r\n\r\nHere is my test function (assuming otherfunc always raises KeyError):\r\n\r\n    def test_myfunc(self):\r\n        self.assertRaises(CustomException, myfunc())\r\n\r\nResults in error !\r\n\r\n        ======================================================================\r\n    ERROR: \r\n    ---------------------------------------------------------------------\r\n    Traceback (most recent call last):\r\n    KeyError\r\n\r\nI want to make sure that myfunc raises a CustomException when otherfunc raises KeyError. How can I do this ?",
            "link": "https://stackoverflow.com/questions/49928723/python-unit-test-re-raised-exception",
            "closed_reason": "duplicate",
            "title": "Python unit test re-raised exception",
            "body": "<p>How do I test for a re-raised exception in Python ?</p>\n\n<p>Here is my function that I want to test:</p>\n\n<pre><code>def myfunc(self):\n    try:\n        temp = otherfunc.get('key')\n    except KeyError as e:\n        raise CustomException\n</code></pre>\n\n<p>Here is my test function (assuming otherfunc always raises KeyError):</p>\n\n<pre><code>def test_myfunc(self):\n    self.assertRaises(CustomException, myfunc())\n</code></pre>\n\n<p>Results in error !</p>\n\n<pre><code>    ======================================================================\nERROR: \n---------------------------------------------------------------------\nTraceback (most recent call last):\nKeyError\n</code></pre>\n\n<p>I want to make sure that myfunc raises a CustomException when otherfunc raises KeyError. How can I do this ?</p>\n"
        },
        {
            "tags": [
                "python",
                "validation",
                "tensorflow",
                "dropout"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 6307437,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/6e7fc32a6e3abe444ccd0e74d4a3a105?s=128&d=identicon&r=PG&f=1",
                "display_name": "Manel Guzm&#225;n",
                "link": "https://stackoverflow.com/users/6307437/manel-guzm%c3%a1n"
            },
            "is_answered": false,
            "view_count": 59,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524165713,
            "creation_date": 1524012046,
            "last_edit_date": 1524098681,
            "question_id": 49889421,
            "body_markdown": "I have the following problem. \r\n\r\nI am trying to train a 3d CNN in tensorflow. I have separated the data in three data sets, train, validation and test. \r\n\r\nThe main problem is that when I test the validation set after 5 epoch of training the output of the model is the nearly the same for the 5 images.\r\n(this is the output of the last layer without any softmax)\r\n\r\n    2018-04-17 23:30:35.134318 Prediction: [[0.8185656  2.7571523 ]                     \r\n    [0.8200048  2.7590456 ]\r\n     [0.8185656  2.7571523 ]\r\n     [0.8200048  2.7590458 ]\r\n     [0.7751368  2.7532804 ]\r\n     [0.82061136 2.7588618 ]\r\n     [0.8130686  2.7821052 ]\r\n     [0.83537185 2.7514493 ]\r\n     [0.8200041  2.7590454 ]\r\n     [0.81701267 2.7519925 ]\r\n     [0.8424163  2.8674953 ]\r\n     [0.82000506 2.7590454 ]\r\n     [0.81999433 2.7590487 ]\r\n     [0.81701267 2.7519925 ]\r\n\r\nHowever, if i do the same for trainning set I get a conventional prediction.\r\n\r\nI have fully check the data sets and both are correct and in the same conditions. \r\n\r\nThis is my mode used to build the model and do the training:  \r\n\r\nclass Cnn3DMRI(object):\r\n\r\n\r\n    def weight_variable(self, shape):\r\n        initial = tf.truncated_normal(shape, stddev=0.1)\r\n        return tf.Variable(initial)\r\n\r\n    def bias_variable(self, shape):\r\n        initial = tf.constant(0.1, shape=shape)\r\n        return tf.Variable(initial)\r\n\r\n    def conv3d(self, x, W):\r\n        return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding=&#39;SAME&#39;)\r\n\r\n    def maxpool3d(self, x):\r\n        #                        size of window         movement of window\r\n        return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding=&#39;SAME&#39;)\r\n\r\n    def dense_to_one_hot(self, labels_dense, num_classes):\r\n        &quot;&quot;&quot;Convert class labels from scalars to one-hot vectors.&quot;&quot;&quot;\r\n        num_labels = labels_dense.shape[0]\r\n        index_offset = np.arange(num_labels) * num_classes\r\n        labels_one_hot = np.zeros((num_labels, num_classes))\r\n        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\r\n        return labels_one_hot\r\n\r\n\r\n    def wrapper_image(self, full_image_set, full_label_set, last_batch=0, batch_size=5):\r\n        batch_img = full_image_set[last_batch:batch_size+last_batch, :, :, :]\r\n        batch_label = full_label_set[last_batch:batch_size+last_batch]\r\n        return batch_img, batch_label, batch_size+last_batch\r\n\r\n\r\n    def convolutional_neural_network(self, x, img_sz, n_slices):\r\n        weights = {\r\n            &#39;W_conv1&#39;: self.weight_variable([6, 8, 8, 1, 32]),\r\n            &#39;W_conv2&#39;: self.weight_variable([2, 5, 5, 32, 48]),\r\n            &#39;W_conv3&#39;: self.weight_variable([2, 3, 3, 48, 64]),\r\n            &#39;W_conv4&#39;: self.weight_variable([2, 2, 2, 64, 64]),\r\n            &#39;W_fc&#39;: self.weight_variable([int(\r\n                math.ceil(n_slices / 8) * (math.ceil(img_sz / 8) * math.ceil(img_sz / 8) *\r\n                                            64)),\r\n                                          2048]),\r\n            &#39;W_fc2&#39;: self.weight_variable([2048, 1024]),\r\n            &#39;out&#39;: self.weight_variable([1024, 2])\r\n        }\r\n\r\n        biases = {\r\n            &#39;b_conv1&#39;: self.bias_variable([32]),\r\n            &#39;b_conv2&#39;: self.bias_variable([48]),\r\n            &#39;b_conv3&#39;: self.bias_variable([64]),\r\n            &#39;b_conv4&#39;: self.bias_variable([64]),\r\n            &#39;b_fc&#39;: self.bias_variable([2048]),\r\n            &#39;b_fc2&#39;: self.bias_variable([1024]),\r\n            &#39;out&#39;: self.bias_variable([2])\r\n        }\r\n\r\n        self.x_im = tf.reshape(x, shape=[-1, n_slices, img_sz, img_sz, 1])\r\n\r\n        conv1 = tf.tanh(self.conv3d(self.x_im, weights[&#39;W_conv1&#39;]) + biases[&#39;b_conv1&#39;])\r\n        conv1 =self.maxpool3d(conv1)\r\n\r\n        conv2 = tf.tanh(self.conv3d(conv1, weights[&#39;W_conv2&#39;]) + biases[&#39;b_conv2&#39;])\r\n        conv2 = self.maxpool3d(conv2)\r\n\r\n        conv3 = tf.tanh(self.conv3d(conv2, weights[&#39;W_conv3&#39;]) + biases[&#39;b_conv3&#39;])\r\n        conv3 = self.maxpool3d(conv3)\r\n        conv4 = tf.tanh(self.conv3d(conv3, weights[&#39;W_conv4&#39;]) + biases[&#39;b_conv4&#39;])\r\n\r\n        fc = tf.reshape(conv4, [-1,int(math.ceil(n_slices/8)*math.ceil(img_sz/8)*math.ceil(\r\n            img_sz/8))*64])\r\n        fc = tf.tanh(tf.matmul(fc, weights[&#39;W_fc&#39;])+biases[&#39;b_fc&#39;])\r\n        fc = tf.tanh(tf.matmul(fc, weights[&#39;W_fc2&#39;])+biases[&#39;b_fc2&#39;])\r\n        fc = tf.nn.dropout(fc, self.keep_prob)\r\n\r\n        output = tf.matmul(fc, weights[&#39;out&#39;])+biases[&#39;out&#39;]\r\n        return output\r\n\r\n    def test_validation_set(self, sess, data_validation, label_validation, valid_batch_size=60):\r\n\r\n        batch_img, batch_label, last_batch = self.wrapper_image(\r\n            data_validation, label_validation, self.last_valid_batch, valid_batch_size\r\n        )\r\n\r\n        \r\n        batch_label = self.dense_to_one_hot(\r\n            np.array(batch_label, dtype=np.int),2\r\n            ).astype(np.float32)\r\n\r\n\r\n        if last_batch+valid_batch_size &lt; len(label_validation):\r\n            self.last_valid_batch = last_batch\r\n        else:\r\n            self.last_valid_batch = 0\r\n\r\n        pred, c, validation_accuracy = sess.run(\r\n            [self.prediction, self.cost, self.accuracy], feed_dict={\r\n                self.x: batch_img, self.y_: batch_label, self.keep_prob: 1.0\r\n            }\r\n        )\r\n        \r\n\r\n        self.log(&quot;Prediction: &quot;+str(pred))\r\n        self.log(&quot;Label: &quot;+str(batch_label))\r\n\r\n        self.log(&quot;Validation accuracy: &quot;+str(validation_accuracy))\r\n        self.log(&quot;Validation cost: &quot;+str(c))\r\n        return validation_accuracy, c\r\n\r\n\r\n    def train_neural_network(self, data_img, labels,  data_validation, label_validation,\r\n                             batch_size, img_sz, n_slices, last_batch,\r\n                             keep_rate, model_path):\r\n\r\n        self.prediction = self.convolutional_neural_network(self.x, img_sz, n_slices)\r\n        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y_,\r\n                                                                      logits=self.prediction))\r\n        optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\r\n        correct_prediction = tf.equal(tf.argmax(self.prediction, 1), tf.argmax(self.y_, 1))\r\n        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\n\r\n        hm_epochs = 1000\r\n        saver = tf.train.Saver(tf.trainable_variables())\r\n        epoch_loss = 0\r\n        epoch_loss_mean = []\r\n        n_epoch = 0\r\n        learning_rate = 1e-4\r\n        self.last_valid_batch = 0\r\n        min_valid_cost = 0\r\n        all_valid_cost = []\r\n        model_path_train = &#39;model_train/my_model.ckpt&#39;\r\n\r\n        with tf.Session() as sess:\r\n            sess.run(tf.global_variables_initializer())\r\n            if model_path:\r\n                pass\r\n                #saver.restore(sess, model_path_train)\r\n            while n_epoch &lt; hm_epochs:\r\n                if len(data_img)&gt;last_batch+batch_size:\r\n                    with tf.device(&#39;/cpu:0&#39;):\r\n                        #batch_img, batch_label, last_batch = self.get_image(\r\n                        #    data_img, labels, last_batch, batch_size, img_sz, n_slices\r\n                        #)\r\n                        batch_img, batch_label, last_batch = self.wrapper_image(data_img, labels, last_batch, batch_size)\r\n\r\n                    print &quot;Batch label images: &quot;+str(batch_label)\r\n                    batch_label = self.dense_to_one_hot(np.array(batch_label, dtype=np.int),\r\n                                                        2).astype(np.float32)\r\n                else:\r\n                    with tf.device(&#39;/cpu:0&#39;):\r\n                        restbatch = last_batch + batch_size - len(data_img)\r\n\r\n                        batch_img = np.concatenate((\r\n                            self.wrapper_image(data_img, labels, last_batch, len(data_img) -\r\n                                               last_batch)[0],\r\n                            self.wrapper_image(data_img, labels, last_batch, len(data_img) -\r\n                                               last_batch)[0]\r\n                        ))\r\n\r\n                        batch_label = np.concatenate((\r\n                            self.wrapper_image(data_img, labels, last_batch, len(data_img) -\r\n                                               last_batch)[1],\r\n                            self.wrapper_image(data_img, labels, last_batch, len(data_img) -\r\n                                               last_batch)[1]\r\n                        ))\r\n\r\n                    batch_label = self.dense_to_one_hot(np.array(batch_label, dtype=np.int),\r\n                                                        2).astype(\r\n                    np.float32)\r\n                    last_batch = restbatch\r\n\r\n                    ####### at the end of EACH EPOCH ###\r\n                    epoch_loss_mean.append(epoch_loss)\r\n                    print &quot;epoch loss mean: &quot;+str(epoch_loss_mean)\r\n                    epoch_loss = 0\r\n                    n_epoch += 1\r\n                    print &quot;n_epoch: &quot;+str(n_epoch)\r\n                    if model_path:\r\n                        saver.save(sess, model_path_train)\r\n\r\n                    if not n_epoch % 5:\r\n                        valid_accuracy, valid_cost = self.test_validation_set(sess,data_validation,\r\n                                                               label_validation, 60)\r\n                        if valid_cost &lt; min_valid_cost - 2:\r\n                            min_valid_cost = valid_cost\r\n                            if model_path:\r\n                                saver.save(sess, model_path)\r\n                        all_valid_cost.append(valid_cost)\r\n                        print all_valid_cost\r\n\r\n                    if self.last_valid_batch == 0:\r\n                        self.shufle_data(data_validation, label_validation)\r\n\r\n                    train_accuracy = self.accuracy.eval(\r\n                        feed_dict={self.x: batch_img, self.y_: batch_label, self.keep_prob: 1.0})\r\n                    print &quot;trainning accuracy: &quot; + str(train_accuracy)\r\n\r\n                    self.shufle_data(data_img, labels)\r\n\r\n                _, c, pred = sess.run(\r\n                    [optimizer, self.cost,], feed_dict={\r\n                        self.x: batch_img, self.y_: batch_label, self.keep_prob: keep_rate,\r\n                        self.learning_rate: learning_rate\r\n                    }\r\n                )\r\n\r\n                print &#39;epoch_loss: &#39;+str(c)\r\n\r\n\r\n\r\n    def main(self, data_dir, labels_dir, img_sz, n_slices, batch_size=5, last_batch=0, train=False,\r\n             model_path=None, keep_rate=0.5):\r\n        &quot;&quot;&quot;\r\n\r\n        Args:\r\n            data_dir(list): directories of the image to be tested\r\n            labels_dir: (str): directory of the csv file where the image are labeled, the index\r\n            colum is the number 2 and the labels header is &#39;Diag&#39;.\r\n            img_sz: the spatial image size the be transformed to. that is the sizes with which\r\n            the image will be trainned. width and hight must be the same\r\n            n_slices: the number of slices for the image to be trained\r\n            last_batch: the batch at which you want to start the trainning\r\n            train: boolean to set trainning: 0 or testing :1\r\n            model_path: the path where the model is saved, if there is no previous model you can\r\n            set a path here to start a new one.\r\n            keep_rate: the keep_probability of firing a node by means of dropout\r\n\r\n        Returns:\r\n\r\n        &quot;&quot;&quot;\r\n\r\n\r\n        self.train = train\r\n        data_path_trainning, label_trainning, data_path_validation, label_validation, \\\r\n        data_testing, label_testing = self.load_dataset(data_dir, labels_dir,)\r\n\r\n        data_trainning, label_trainning_final = self.load_image(data_path_trainning,\r\n                                                                label_trainning, img_sz, n_slices\r\n                                                                )\r\n\r\n        data_validation, label_validation_final = self.load_image(\r\n            data_path_validation, label_validation, img_sz, n_slices\r\n        )\r\n\r\n\r\n        self.x = tf.placeholder(tf.float32, shape=[None, n_slices, img_sz, img_sz]) #batch_size,\r\n        # image_Size\r\n        self.y_ = tf.placeholder(tf.float32, shape=[None, 3]) #batch_size, label_size\r\n        self.learning_rate = tf.placeholder(tf.float32)\r\n        self.keep_prob = tf.placeholder(tf.float32)\r\n        if train:\r\n            self.train_neural_network(data_trainning, label_trainning_final, data_validation,\r\n                                      label_validation_final, batch_size, img_sz, n_slices,\r\n                                      last_batch, keep_rate, model_path\r\n                                      )\r\n\r\n\r\nI have already tried tf.set_random_seed( 1 )  but no correction is seen\r\n\r\nDo anyone have any idea about, please?\r\n\r\nthanks so much \r\n\r\nEDITED: \r\n\r\nThe data to be classified are 3d images of 150x150x40 pixels in a biclass problem. I have a total 400 images approaximatly half of each class. I have separated the dataset in train (75%), validation (10%) and test(15%)\r\n\r\n\r\n\r\n \r\n\r\n",
            "link": "https://stackoverflow.com/questions/49889421/tensorflow-validation-prediction-outs-the-same-for-each-image",
            "title": "Tensorflow: validation prediction outs the same for each image",
            "body": "<p>I have the following problem. </p>\n\n<p>I am trying to train a 3d CNN in tensorflow. I have separated the data in three data sets, train, validation and test. </p>\n\n<p>The main problem is that when I test the validation set after 5 epoch of training the output of the model is the nearly the same for the 5 images.\n(this is the output of the last layer without any softmax)</p>\n\n<pre><code>2018-04-17 23:30:35.134318 Prediction: [[0.8185656  2.7571523 ]                     \n[0.8200048  2.7590456 ]\n [0.8185656  2.7571523 ]\n [0.8200048  2.7590458 ]\n [0.7751368  2.7532804 ]\n [0.82061136 2.7588618 ]\n [0.8130686  2.7821052 ]\n [0.83537185 2.7514493 ]\n [0.8200041  2.7590454 ]\n [0.81701267 2.7519925 ]\n [0.8424163  2.8674953 ]\n [0.82000506 2.7590454 ]\n [0.81999433 2.7590487 ]\n [0.81701267 2.7519925 ]\n</code></pre>\n\n<p>However, if i do the same for trainning set I get a conventional prediction.</p>\n\n<p>I have fully check the data sets and both are correct and in the same conditions. </p>\n\n<p>This is my mode used to build the model and do the training:  </p>\n\n<p>class Cnn3DMRI(object):</p>\n\n<pre><code>def weight_variable(self, shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial)\n\ndef bias_variable(self, shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial)\n\ndef conv3d(self, x, W):\n    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n\ndef maxpool3d(self, x):\n    #                        size of window         movement of window\n    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n\ndef dense_to_one_hot(self, labels_dense, num_classes):\n    \"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"\n    num_labels = labels_dense.shape[0]\n    index_offset = np.arange(num_labels) * num_classes\n    labels_one_hot = np.zeros((num_labels, num_classes))\n    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n    return labels_one_hot\n\n\ndef wrapper_image(self, full_image_set, full_label_set, last_batch=0, batch_size=5):\n    batch_img = full_image_set[last_batch:batch_size+last_batch, :, :, :]\n    batch_label = full_label_set[last_batch:batch_size+last_batch]\n    return batch_img, batch_label, batch_size+last_batch\n\n\ndef convolutional_neural_network(self, x, img_sz, n_slices):\n    weights = {\n        'W_conv1': self.weight_variable([6, 8, 8, 1, 32]),\n        'W_conv2': self.weight_variable([2, 5, 5, 32, 48]),\n        'W_conv3': self.weight_variable([2, 3, 3, 48, 64]),\n        'W_conv4': self.weight_variable([2, 2, 2, 64, 64]),\n        'W_fc': self.weight_variable([int(\n            math.ceil(n_slices / 8) * (math.ceil(img_sz / 8) * math.ceil(img_sz / 8) *\n                                        64)),\n                                      2048]),\n        'W_fc2': self.weight_variable([2048, 1024]),\n        'out': self.weight_variable([1024, 2])\n    }\n\n    biases = {\n        'b_conv1': self.bias_variable([32]),\n        'b_conv2': self.bias_variable([48]),\n        'b_conv3': self.bias_variable([64]),\n        'b_conv4': self.bias_variable([64]),\n        'b_fc': self.bias_variable([2048]),\n        'b_fc2': self.bias_variable([1024]),\n        'out': self.bias_variable([2])\n    }\n\n    self.x_im = tf.reshape(x, shape=[-1, n_slices, img_sz, img_sz, 1])\n\n    conv1 = tf.tanh(self.conv3d(self.x_im, weights['W_conv1']) + biases['b_conv1'])\n    conv1 =self.maxpool3d(conv1)\n\n    conv2 = tf.tanh(self.conv3d(conv1, weights['W_conv2']) + biases['b_conv2'])\n    conv2 = self.maxpool3d(conv2)\n\n    conv3 = tf.tanh(self.conv3d(conv2, weights['W_conv3']) + biases['b_conv3'])\n    conv3 = self.maxpool3d(conv3)\n    conv4 = tf.tanh(self.conv3d(conv3, weights['W_conv4']) + biases['b_conv4'])\n\n    fc = tf.reshape(conv4, [-1,int(math.ceil(n_slices/8)*math.ceil(img_sz/8)*math.ceil(\n        img_sz/8))*64])\n    fc = tf.tanh(tf.matmul(fc, weights['W_fc'])+biases['b_fc'])\n    fc = tf.tanh(tf.matmul(fc, weights['W_fc2'])+biases['b_fc2'])\n    fc = tf.nn.dropout(fc, self.keep_prob)\n\n    output = tf.matmul(fc, weights['out'])+biases['out']\n    return output\n\ndef test_validation_set(self, sess, data_validation, label_validation, valid_batch_size=60):\n\n    batch_img, batch_label, last_batch = self.wrapper_image(\n        data_validation, label_validation, self.last_valid_batch, valid_batch_size\n    )\n\n\n    batch_label = self.dense_to_one_hot(\n        np.array(batch_label, dtype=np.int),2\n        ).astype(np.float32)\n\n\n    if last_batch+valid_batch_size &lt; len(label_validation):\n        self.last_valid_batch = last_batch\n    else:\n        self.last_valid_batch = 0\n\n    pred, c, validation_accuracy = sess.run(\n        [self.prediction, self.cost, self.accuracy], feed_dict={\n            self.x: batch_img, self.y_: batch_label, self.keep_prob: 1.0\n        }\n    )\n\n\n    self.log(\"Prediction: \"+str(pred))\n    self.log(\"Label: \"+str(batch_label))\n\n    self.log(\"Validation accuracy: \"+str(validation_accuracy))\n    self.log(\"Validation cost: \"+str(c))\n    return validation_accuracy, c\n\n\ndef train_neural_network(self, data_img, labels,  data_validation, label_validation,\n                         batch_size, img_sz, n_slices, last_batch,\n                         keep_rate, model_path):\n\n    self.prediction = self.convolutional_neural_network(self.x, img_sz, n_slices)\n    self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=self.y_,\n                                                                  logits=self.prediction))\n    optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n    correct_prediction = tf.equal(tf.argmax(self.prediction, 1), tf.argmax(self.y_, 1))\n    self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    hm_epochs = 1000\n    saver = tf.train.Saver(tf.trainable_variables())\n    epoch_loss = 0\n    epoch_loss_mean = []\n    n_epoch = 0\n    learning_rate = 1e-4\n    self.last_valid_batch = 0\n    min_valid_cost = 0\n    all_valid_cost = []\n    model_path_train = 'model_train/my_model.ckpt'\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        if model_path:\n            pass\n            #saver.restore(sess, model_path_train)\n        while n_epoch &lt; hm_epochs:\n            if len(data_img)&gt;last_batch+batch_size:\n                with tf.device('/cpu:0'):\n                    #batch_img, batch_label, last_batch = self.get_image(\n                    #    data_img, labels, last_batch, batch_size, img_sz, n_slices\n                    #)\n                    batch_img, batch_label, last_batch = self.wrapper_image(data_img, labels, last_batch, batch_size)\n\n                print \"Batch label images: \"+str(batch_label)\n                batch_label = self.dense_to_one_hot(np.array(batch_label, dtype=np.int),\n                                                    2).astype(np.float32)\n            else:\n                with tf.device('/cpu:0'):\n                    restbatch = last_batch + batch_size - len(data_img)\n\n                    batch_img = np.concatenate((\n                        self.wrapper_image(data_img, labels, last_batch, len(data_img) -\n                                           last_batch)[0],\n                        self.wrapper_image(data_img, labels, last_batch, len(data_img) -\n                                           last_batch)[0]\n                    ))\n\n                    batch_label = np.concatenate((\n                        self.wrapper_image(data_img, labels, last_batch, len(data_img) -\n                                           last_batch)[1],\n                        self.wrapper_image(data_img, labels, last_batch, len(data_img) -\n                                           last_batch)[1]\n                    ))\n\n                batch_label = self.dense_to_one_hot(np.array(batch_label, dtype=np.int),\n                                                    2).astype(\n                np.float32)\n                last_batch = restbatch\n\n                ####### at the end of EACH EPOCH ###\n                epoch_loss_mean.append(epoch_loss)\n                print \"epoch loss mean: \"+str(epoch_loss_mean)\n                epoch_loss = 0\n                n_epoch += 1\n                print \"n_epoch: \"+str(n_epoch)\n                if model_path:\n                    saver.save(sess, model_path_train)\n\n                if not n_epoch % 5:\n                    valid_accuracy, valid_cost = self.test_validation_set(sess,data_validation,\n                                                           label_validation, 60)\n                    if valid_cost &lt; min_valid_cost - 2:\n                        min_valid_cost = valid_cost\n                        if model_path:\n                            saver.save(sess, model_path)\n                    all_valid_cost.append(valid_cost)\n                    print all_valid_cost\n\n                if self.last_valid_batch == 0:\n                    self.shufle_data(data_validation, label_validation)\n\n                train_accuracy = self.accuracy.eval(\n                    feed_dict={self.x: batch_img, self.y_: batch_label, self.keep_prob: 1.0})\n                print \"trainning accuracy: \" + str(train_accuracy)\n\n                self.shufle_data(data_img, labels)\n\n            _, c, pred = sess.run(\n                [optimizer, self.cost,], feed_dict={\n                    self.x: batch_img, self.y_: batch_label, self.keep_prob: keep_rate,\n                    self.learning_rate: learning_rate\n                }\n            )\n\n            print 'epoch_loss: '+str(c)\n\n\n\ndef main(self, data_dir, labels_dir, img_sz, n_slices, batch_size=5, last_batch=0, train=False,\n         model_path=None, keep_rate=0.5):\n    \"\"\"\n\n    Args:\n        data_dir(list): directories of the image to be tested\n        labels_dir: (str): directory of the csv file where the image are labeled, the index\n        colum is the number 2 and the labels header is 'Diag'.\n        img_sz: the spatial image size the be transformed to. that is the sizes with which\n        the image will be trainned. width and hight must be the same\n        n_slices: the number of slices for the image to be trained\n        last_batch: the batch at which you want to start the trainning\n        train: boolean to set trainning: 0 or testing :1\n        model_path: the path where the model is saved, if there is no previous model you can\n        set a path here to start a new one.\n        keep_rate: the keep_probability of firing a node by means of dropout\n\n    Returns:\n\n    \"\"\"\n\n\n    self.train = train\n    data_path_trainning, label_trainning, data_path_validation, label_validation, \\\n    data_testing, label_testing = self.load_dataset(data_dir, labels_dir,)\n\n    data_trainning, label_trainning_final = self.load_image(data_path_trainning,\n                                                            label_trainning, img_sz, n_slices\n                                                            )\n\n    data_validation, label_validation_final = self.load_image(\n        data_path_validation, label_validation, img_sz, n_slices\n    )\n\n\n    self.x = tf.placeholder(tf.float32, shape=[None, n_slices, img_sz, img_sz]) #batch_size,\n    # image_Size\n    self.y_ = tf.placeholder(tf.float32, shape=[None, 3]) #batch_size, label_size\n    self.learning_rate = tf.placeholder(tf.float32)\n    self.keep_prob = tf.placeholder(tf.float32)\n    if train:\n        self.train_neural_network(data_trainning, label_trainning_final, data_validation,\n                                  label_validation_final, batch_size, img_sz, n_slices,\n                                  last_batch, keep_rate, model_path\n                                  )\n</code></pre>\n\n<p>I have already tried tf.set_random_seed( 1 )  but no correction is seen</p>\n\n<p>Do anyone have any idea about, please?</p>\n\n<p>thanks so much </p>\n\n<p>EDITED: </p>\n\n<p>The data to be classified are 3d images of 150x150x40 pixels in a biclass problem. I have a total 400 images approaximatly half of each class. I have separated the dataset in train (75%), validation (10%) and test(15%)</p>\n"
        },
        {
            "tags": [
                "emacs",
                "verilog"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9529880,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Roarer",
                "link": "https://stackoverflow.com/users/9529880/roarer"
            },
            "is_answered": false,
            "view_count": 20,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165708,
            "creation_date": 1524153885,
            "last_edit_date": 1524165708,
            "question_id": 49925558,
            "body_markdown": "I am usinh emacs verilog-mode to build some verilog source code. However I observe that when the code becomes large(like in a case statement), I find it difficult to understand which begin is paired with which end block. \r\n\r\nVerilog mode has an emacs function that adds a comments to every end block showing which begin it is paired with. However, this does show for every begin and end block.\r\n\r\nI was wondering what are the options when navigating verilog in emacs? Is there any function which will do code-folding given the delimiter used in the language(I should be able to specify begin,end are me delimiters instead of {} in C).\r\n\r\nCould someone help me out?\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49925558/navigating-verilog-begin-and-end-blocks-using-emacs-to-show-structure",
            "title": "Navigating verilog begin and end blocks using emacs to show structure",
            "body": "<p>I am usinh emacs verilog-mode to build some verilog source code. However I observe that when the code becomes large(like in a case statement), I find it difficult to understand which begin is paired with which end block. </p>\n\n<p>Verilog mode has an emacs function that adds a comments to every end block showing which begin it is paired with. However, this does show for every begin and end block.</p>\n\n<p>I was wondering what are the options when navigating verilog in emacs? Is there any function which will do code-folding given the delimiter used in the language(I should be able to specify begin,end are me delimiters instead of {} in C).</p>\n\n<p>Could someone help me out?</p>\n"
        },
        {
            "tags": [
                "haskell"
            ],
            "owner": {
                "reputation": 519,
                "user_id": 5200466,
                "user_type": "registered",
                "accept_rate": 81,
                "profile_image": "https://www.gravatar.com/avatar/abb1362cec6e1f0a2416a6d98a93cd6c?s=128&d=identicon&r=PG&f=1",
                "display_name": "matthias",
                "link": "https://stackoverflow.com/users/5200466/matthias"
            },
            "is_answered": true,
            "view_count": 91,
            "answer_count": 1,
            "score": 2,
            "last_activity_date": 1524165706,
            "creation_date": 1523410582,
            "question_id": 49765136,
            "body_markdown": "I am going through some old courses online and came across this task:\r\n\r\n    data Tree a = Leaf \r\n                | Branch a (Tree a) (Tree a) \r\n                deriving (Show, Eq)\r\n    \r\n    fold :: (a -&gt; b -&gt; b -&gt; b) -&gt; b -&gt; Tree a -&gt; b\r\n    fold _ acc Leaf           = acc\r\n    fold f acc (Branch v l r) = f v (fold f acc l) (fold f acc r)\r\n    \r\n    foldRT :: (a -&gt; b -&gt; b) -&gt; b -&gt; Tree a -&gt; b\r\n    foldRT _ acc Leaf = acc\r\n    foldRT f acc (Branch v l r) = foldRT f (f v (foldRT f acc r)) l\r\n\r\nThe task is to rewrite `foldRT` in terms of `fold`. I have been stuck on it for ages and can&#39;t wrap my head around it.\r\n\r\nA walk through would be greatly appreciated.\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49765136/haskell-folding-over-trees",
            "title": "Haskell: Folding over trees",
            "body": "<p>I am going through some old courses online and came across this task:</p>\n\n<pre><code>data Tree a = Leaf \n            | Branch a (Tree a) (Tree a) \n            deriving (Show, Eq)\n\nfold :: (a -&gt; b -&gt; b -&gt; b) -&gt; b -&gt; Tree a -&gt; b\nfold _ acc Leaf           = acc\nfold f acc (Branch v l r) = f v (fold f acc l) (fold f acc r)\n\nfoldRT :: (a -&gt; b -&gt; b) -&gt; b -&gt; Tree a -&gt; b\nfoldRT _ acc Leaf = acc\nfoldRT f acc (Branch v l r) = foldRT f (f v (foldRT f acc r)) l\n</code></pre>\n\n<p>The task is to rewrite <code>foldRT</code> in terms of <code>fold</code>. I have been stuck on it for ages and can't wrap my head around it.</p>\n\n<p>A walk through would be greatly appreciated.</p>\n"
        },
        {
            "tags": [
                "rest",
                "web-services",
                "talend"
            ],
            "owner": {
                "reputation": 18,
                "user_id": 7370436,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/a1689fd0632ce74abc2a70d69da98c25?s=128&d=identicon&r=PG&f=1",
                "display_name": "sylikon",
                "link": "https://stackoverflow.com/users/7370436/sylikon"
            },
            "is_answered": false,
            "view_count": 39,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165704,
            "creation_date": 1524136866,
            "last_edit_date": 1524165704,
            "question_id": 49919821,
            "body_markdown": "I have got a Talend job that as a finish product prepares zip package, now i want to expose this job as a REST server with GET request, so each time clients calls service the package is made and available to download. I know that there is a thread with exact same name [expose job as web service][1] but accepted answer has links that are no longer valid. \r\n\r\n\r\nCurrently my job looks like this [![designer view][2]][2] [![tJavaRow code][3]][3][![tMap view][4]][4][![tRestResponse View][5]][5]\r\n\r\nAnd the idea standing behind this design is that i got one column in output flow in tRESTRequest named &quot;userfile&quot; of type byte array, calling GET request tJavaRow starts and wrap file into byte array, then i transfer it through tMap to tRestRespone body as byte array. What am I missing?\r\n\r\n  [1]: https://stackoverflow.com/questions/14749634/expose-talend-etl-job-as-a-web-service\r\n  [2]: https://i.stack.imgur.com/55FKH.png\r\n  [3]: https://i.stack.imgur.com/nxOph.png\r\n  [4]: https://i.stack.imgur.com/je9sK.png\r\n  [5]: https://i.stack.imgur.com/G87Uq.png",
            "link": "https://stackoverflow.com/questions/49919821/expose-job-as-web-service-talend",
            "title": "Expose job as Web Service Talend",
            "body": "<p>I have got a Talend job that as a finish product prepares zip package, now i want to expose this job as a REST server with GET request, so each time clients calls service the package is made and available to download. I know that there is a thread with exact same name <a href=\"https://stackoverflow.com/questions/14749634/expose-talend-etl-job-as-a-web-service\">expose job as web service</a> but accepted answer has links that are no longer valid. </p>\n\n<p>Currently my job looks like this <a href=\"https://i.stack.imgur.com/55FKH.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/55FKH.png\" alt=\"designer view\"></a> <a href=\"https://i.stack.imgur.com/nxOph.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/nxOph.png\" alt=\"tJavaRow code\"></a><a href=\"https://i.stack.imgur.com/je9sK.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/je9sK.png\" alt=\"tMap view\"></a><a href=\"https://i.stack.imgur.com/G87Uq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/G87Uq.png\" alt=\"tRestResponse View\"></a></p>\n\n<p>And the idea standing behind this design is that i got one column in output flow in tRESTRequest named \"userfile\" of type byte array, calling GET request tJavaRow starts and wrap file into byte array, then i transfer it through tMap to tRestRespone body as byte array. What am I missing?</p>\n"
        },
        {
            "tags": [
                "c++",
                "opengl",
                "profiling",
                "nvidia",
                "nsight"
            ],
            "owner": {
                "reputation": 1040,
                "user_id": 6202327,
                "user_type": "registered",
                "accept_rate": 100,
                "profile_image": "https://www.gravatar.com/avatar/121536c2a1c0f8759d25a0cfec534589?s=128&d=identicon&r=PG&f=1",
                "display_name": "Makogan",
                "link": "https://stackoverflow.com/users/6202327/makogan"
            },
            "is_answered": false,
            "view_count": 17,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165702,
            "creation_date": 1524165702,
            "question_id": 49928718,
            "body_markdown": "When I run my OpenGL application in the eclipse editor fo Nsight on linux, the application runs but I get the message: &quot;No Timeline&quot;.\r\n\r\nI did not create the project in Nsight. I used a different editor and simply attempted to import the project into nsight as a makefile project. \r\n\r\nAccording to the documentation there is no need to explicetly call an nvidia api function in order to have some basic profiling going. \r\n\r\nSo I am not sure why I get no data in the visual profiler.\r\n\r\nTo run the project i click on the `Run-&gt;profile` button.  Which launches a message saying &quot;generating tmeline&quot;.\r\n\r\nBut upon closing the application I see no data.\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49928718/understanding-profiling-with-nvidia-nsight",
            "title": "Understanding Profiling with Nvidia Nsight",
            "body": "<p>When I run my OpenGL application in the eclipse editor fo Nsight on linux, the application runs but I get the message: \"No Timeline\".</p>\n\n<p>I did not create the project in Nsight. I used a different editor and simply attempted to import the project into nsight as a makefile project. </p>\n\n<p>According to the documentation there is no need to explicetly call an nvidia api function in order to have some basic profiling going. </p>\n\n<p>So I am not sure why I get no data in the visual profiler.</p>\n\n<p>To run the project i click on the <code>Run-&gt;profile</code> button.  Which launches a message saying \"generating tmeline\".</p>\n\n<p>But upon closing the application I see no data.</p>\n"
        },
        {
            "tags": [
                "javascript",
                "websocket",
                "frontend"
            ],
            "owner": {
                "reputation": 19,
                "user_id": 6267537,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/10154135589772152/picture?type=large",
                "display_name": "Jonathan Chevalier",
                "link": "https://stackoverflow.com/users/6267537/jonathan-chevalier"
            },
            "is_answered": false,
            "view_count": 23,
            "answer_count": 0,
            "score": -1,
            "last_activity_date": 1524165698,
            "creation_date": 1524061772,
            "last_edit_date": 1524165698,
            "question_id": 49902353,
            "body_markdown": "I tried without success to modify WebSocket.onmessage function for being able add a switch case dynamically:\r\n\r\n    socket.onmessage = function (event) {\r\n\r\n      let message = JSON.parse(event.data) \r\n    \r\n      switch(event.type) { \r\n    \r\n      case &quot;UPDATE_USER&quot;: \r\n        // update user\r\n      case &quot;UPDATE_FOO&quot;: \r\n       // update FOO\r\n      case &quot;UPDATE_BAR&quot;: \r\n      // update FOO\r\n    \r\n    }\r\n\r\nSocket.IO is doing what I am trying to implement with the .on function:\r\n\r\n    socket.on(&#39;ACTION&#39;, (data) =&gt; {\r\n      // update socket with another action case\r\n    });\r\n\r\n\r\nSocket.io is capable of updating the equivalent of onmessage function by adding a listener to any message.type you will receive.\r\n\r\nThanks a lot for your help.",
            "link": "https://stackoverflow.com/questions/49902353/websocket-html5-create-onmessage-function-similar-to-socket-io-on-function",
            "title": "Websocket HTML5 create onmessage function similar to socket.IO .on function",
            "body": "<p>I tried without success to modify WebSocket.onmessage function for being able add a switch case dynamically:</p>\n\n<pre><code>socket.onmessage = function (event) {\n\n  let message = JSON.parse(event.data) \n\n  switch(event.type) { \n\n  case \"UPDATE_USER\": \n    // update user\n  case \"UPDATE_FOO\": \n   // update FOO\n  case \"UPDATE_BAR\": \n  // update FOO\n\n}\n</code></pre>\n\n<p>Socket.IO is doing what I am trying to implement with the .on function:</p>\n\n<pre><code>socket.on('ACTION', (data) =&gt; {\n  // update socket with another action case\n});\n</code></pre>\n\n<p>Socket.io is capable of updating the equivalent of onmessage function by adding a listener to any message.type you will receive.</p>\n\n<p>Thanks a lot for your help.</p>\n"
        },
        {
            "tags": [
                "dataframe",
                "sapply",
                "anova",
                "tukeyhsd"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9417332,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/7ad8795417e043b8ae304aee5157bc93?s=128&d=identicon&r=PG&f=1",
                "display_name": "Marjanne",
                "link": "https://stackoverflow.com/users/9417332/marjanne"
            },
            "is_answered": false,
            "view_count": 26,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165691,
            "creation_date": 1520498958,
            "question_id": 49168959,
            "body_markdown": "I would like to perform a Tukey Post Hoc test on a list of dataframes. As outcome I would like to have letters indicating which groups are significantly different from each other. The HSD.test() of the agricolae package does this, but I can&#39;t figure out how to apply this on several variables at once. This will save me a lot of time as my dataset contains a lot of variables.   \r\n\r\nThis is part of my data: \r\n\r\n    category &lt;- c(rep(&quot;young&quot;, 3), rep(&quot;Middle&quot;, 4), rep(&quot;old&quot;, 5))\r\n    fat &lt;- c(1857.87, 1953.90, 1440.70, 1553.81, 1785.91, 1893.82, 1483.75, 1784.99, 2011.01, 2023.04, 2011.05, 1788.81)\r\n    BMI &lt;- c(21.1, 23.2, 24.5, 25.6, 21.8, 18.0, 19.2, 20.1, 22.1, 25.0, 26.1, 25.1)\r\n    age &lt;- c(25, 23, 27, 55, 58, 62, 45, 75, 80, 75, 83, 89)\r\n    df2 &lt;- data.frame(fat, BMI, age, category)\r\n\r\nI know how to do the anova and HSD.test() on one variable.  \r\n\r\n    lm.fat &lt;- (lm(fat ~ as.factor(category), data = df2))\r\n    anova(lm.fat)\r\n    require(agricolae)\r\n    HSD.test(lm.fat, &quot;as.factor(category)&quot;, group = TRUE, console = TRUE)\r\n\r\nIn addition, I know how to apply the anova to all my variables in my dataset by using the sapply() function:\r\n\r\n    an &lt;- lapply(df, function(x) aov(x~category, data = df))\r\n    sapply(an, anova, simplify=FALSE)\r\n\r\nBut I don&#39;t know how to peform the posthoc HSD.test() on these outcomes. I tried this:\r\n   \r\n    lapply(an, function(m) HSD.test((m), &quot;as.factor(category)&quot;, group = TRUE, console = TRUE))\r\n\r\n    Name:  as.factor(category) \r\n     category \r\n    Name:  as.factor(category) \r\n     category \r\n    Name:  as.factor(category) \r\n     category \r\n    \r\n    $fat\r\n    NULL\r\n\r\n    $BMI\r\n    NULL\r\n\r\n    $age\r\n    NULL\r\n\r\nI get NULL as outcome, so something went wrong, but I can&#39;t figure out what. I tried also another function of the Tukey post hoc test, namely: TukeyHSD().  \r\n\r\n    lapply(an, function(m) TukeyHSD(aov(m)))\r\n    $fat\r\n    Tukey multiple comparisons of means\r\n    95% family-wise confidence level\r\n\r\n    Fit: aov(formula = m)\r\n\r\n    $category\r\n                       diff       lwr      upr     p adj\r\n    old-Middle    244.45750 -110.2508 599.1658 0.1874162\r\n    young-Middle   71.50083 -332.3523 475.3540 0.8757638\r\n    young-old    -172.95667 -559.1142 213.2008 0.4554780\r\n\r\n\r\n    $BMI\r\n      Tukey multiple comparisons of means\r\n        95% family-wise confidence level\r\n\r\n    Fit: aov(formula = m)\r\n\r\n    $category\r\n                       diff       lwr      upr     p adj\r\n    old-Middle    2.5300000 -2.494240 7.554240 0.3781804\r\n    young-Middle  1.7833333 -3.937015 7.503682 0.6711525\r\n    young-old    -0.7466667 -6.216366 4.723033 0.9237118\r\n    \r\n    \r\n    $age\r\n      Tukey multiple comparisons of means\r\n        95% family-wise confidence level\r\n    \r\n    Fit: aov(formula = m)\r\n    \r\n    $category\r\n                  diff       lwr       upr     p adj\r\n    old-Middle    25.4  14.49330  36.30670 0.0002928\r\n    young-Middle -30.0 -42.41783 -17.58217 0.0002219\r\n    young-old    -55.4 -67.27372 -43.52628 0.0000010\r\n\r\nThis works for my dataset, but this function doesn&#39;t give the letters, which I really would like to have. Does someone know how I can do the same with HSD.test() so that I will obtain the letters? Thanks! \r\n\r\n\r\n\r\n  \r\n",
            "link": "https://stackoverflow.com/questions/49168959/how-to-perform-tukey-hsd-test-on-list-of-dataframes",
            "title": "How to perform Tukey HSD.test() on list of dataframes?",
            "body": "<p>I would like to perform a Tukey Post Hoc test on a list of dataframes. As outcome I would like to have letters indicating which groups are significantly different from each other. The HSD.test() of the agricolae package does this, but I can't figure out how to apply this on several variables at once. This will save me a lot of time as my dataset contains a lot of variables.   </p>\n\n<p>This is part of my data: </p>\n\n<pre><code>category &lt;- c(rep(\"young\", 3), rep(\"Middle\", 4), rep(\"old\", 5))\nfat &lt;- c(1857.87, 1953.90, 1440.70, 1553.81, 1785.91, 1893.82, 1483.75, 1784.99, 2011.01, 2023.04, 2011.05, 1788.81)\nBMI &lt;- c(21.1, 23.2, 24.5, 25.6, 21.8, 18.0, 19.2, 20.1, 22.1, 25.0, 26.1, 25.1)\nage &lt;- c(25, 23, 27, 55, 58, 62, 45, 75, 80, 75, 83, 89)\ndf2 &lt;- data.frame(fat, BMI, age, category)\n</code></pre>\n\n<p>I know how to do the anova and HSD.test() on one variable.  </p>\n\n<pre><code>lm.fat &lt;- (lm(fat ~ as.factor(category), data = df2))\nanova(lm.fat)\nrequire(agricolae)\nHSD.test(lm.fat, \"as.factor(category)\", group = TRUE, console = TRUE)\n</code></pre>\n\n<p>In addition, I know how to apply the anova to all my variables in my dataset by using the sapply() function:</p>\n\n<pre><code>an &lt;- lapply(df, function(x) aov(x~category, data = df))\nsapply(an, anova, simplify=FALSE)\n</code></pre>\n\n<p>But I don't know how to peform the posthoc HSD.test() on these outcomes. I tried this:</p>\n\n<pre><code>lapply(an, function(m) HSD.test((m), \"as.factor(category)\", group = TRUE, console = TRUE))\n\nName:  as.factor(category) \n category \nName:  as.factor(category) \n category \nName:  as.factor(category) \n category \n\n$fat\nNULL\n\n$BMI\nNULL\n\n$age\nNULL\n</code></pre>\n\n<p>I get NULL as outcome, so something went wrong, but I can't figure out what. I tried also another function of the Tukey post hoc test, namely: TukeyHSD().  </p>\n\n<pre><code>lapply(an, function(m) TukeyHSD(aov(m)))\n$fat\nTukey multiple comparisons of means\n95% family-wise confidence level\n\nFit: aov(formula = m)\n\n$category\n                   diff       lwr      upr     p adj\nold-Middle    244.45750 -110.2508 599.1658 0.1874162\nyoung-Middle   71.50083 -332.3523 475.3540 0.8757638\nyoung-old    -172.95667 -559.1142 213.2008 0.4554780\n\n\n$BMI\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = m)\n\n$category\n                   diff       lwr      upr     p adj\nold-Middle    2.5300000 -2.494240 7.554240 0.3781804\nyoung-Middle  1.7833333 -3.937015 7.503682 0.6711525\nyoung-old    -0.7466667 -6.216366 4.723033 0.9237118\n\n\n$age\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = m)\n\n$category\n              diff       lwr       upr     p adj\nold-Middle    25.4  14.49330  36.30670 0.0002928\nyoung-Middle -30.0 -42.41783 -17.58217 0.0002219\nyoung-old    -55.4 -67.27372 -43.52628 0.0000010\n</code></pre>\n\n<p>This works for my dataset, but this function doesn't give the letters, which I really would like to have. Does someone know how I can do the same with HSD.test() so that I will obtain the letters? Thanks! </p>\n"
        },
        {
            "tags": [
                "php",
                "codeigniter",
                "codeigniter-3"
            ],
            "owner": {
                "reputation": 16,
                "user_id": 5564775,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/3b9e2b785ccfa9ff50ee5027ee4e8257?s=128&d=identicon&r=PG&f=1",
                "display_name": "Akash lal",
                "link": "https://stackoverflow.com/users/5564775/akash-lal"
            },
            "is_answered": false,
            "view_count": 36,
            "answer_count": 3,
            "score": 0,
            "last_activity_date": 1524165689,
            "creation_date": 1524116199,
            "last_edit_date": 1524121932,
            "question_id": 49913452,
            "body_markdown": "I am unable to send email via following configuration.\r\n                                  \r\n    $config = array();\r\n    $config[&#39;protocol&#39;] = &#39;smtp&#39;;\r\n    $config[&#39;mailtype&#39;] = &#39;text&#39;;\r\n    $config[&#39;charset&#39;]=&#39;utf-8&#39;;\r\n    $config[&#39;crlf&#39;]=&quot;\\r\\n&quot;;\r\n    $config[&#39;newline&#39;]=&quot;\\r\\n&quot;;\r\n    $config[&#39;priority&#39;]=3;\r\n    $config[&#39;smtp_host&#39;] = &#39;smtp.office365.com&#39;;\r\n    $config[&#39;smtp_port&#39;]=587;\r\n    $config[&#39;smtp_crypto&#39;]=&quot;tls&quot;;\r\n    $config[&#39;smtp_user&#39;] = &#39;************&#39;;  \r\n    $config[&#39;smtp_pass&#39;] = &#39;************&#39;; \r\n    $config[&#39;smtp_timeout&#39;] = 120;\r\n    $this-&gt;email-&gt;initialize($config);    \r\n    $this-&gt;email-&gt;set_newline(&quot;\\r\\n&quot;);\r\n\r\nI have checked millions of blog and articles. \r\nSame configuration is working properly on production but not on staging environment.\r\n\r\nFollowing error is generated:\r\n\r\n&gt; Message: stream_socket_enable_crypto(): SSL: Handshake timed out\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49913452/not-able-to-send-email-codeigniter",
            "title": "Not able to send email - Codeigniter",
            "body": "<p>I am unable to send email via following configuration.</p>\n\n<pre><code>$config = array();\n$config['protocol'] = 'smtp';\n$config['mailtype'] = 'text';\n$config['charset']='utf-8';\n$config['crlf']=\"\\r\\n\";\n$config['newline']=\"\\r\\n\";\n$config['priority']=3;\n$config['smtp_host'] = 'smtp.office365.com';\n$config['smtp_port']=587;\n$config['smtp_crypto']=\"tls\";\n$config['smtp_user'] = '************';  \n$config['smtp_pass'] = '************'; \n$config['smtp_timeout'] = 120;\n$this-&gt;email-&gt;initialize($config);    \n$this-&gt;email-&gt;set_newline(\"\\r\\n\");\n</code></pre>\n\n<p>I have checked millions of blog and articles. \nSame configuration is working properly on production but not on staging environment.</p>\n\n<p>Following error is generated:</p>\n\n<blockquote>\n  <p>Message: stream_socket_enable_crypto(): SSL: Handshake timed out</p>\n</blockquote>\n"
        },
        {
            "tags": [
                "node.js",
                "xml",
                "express"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9540704,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "savejais",
                "link": "https://stackoverflow.com/users/9540704/savejais"
            },
            "is_answered": false,
            "view_count": 16,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165687,
            "creation_date": 1524151581,
            "last_edit_date": 1524165687,
            "question_id": 49924805,
            "body_markdown": "Im trying to render a new page when the server gets the `post` method, but its not rendering.\r\nIf i use a callback for the `res.render`, i can `console.log` the html file, but the page is just not loading\r\n\r\n**Server side**\r\n\r\n`app.post(&#39;/test&#39;, jsonParser, function(req, res) {\r\nres.render(&#39;test&#39;, {something: req.something, something2: req.body})\r\n})`\r\n\r\n**Client side**\r\n\r\n    function sendInfob(info){\r\n        var jInfos = JSON.stringify(info);\r\n        xhttp.open(&#39;post&#39;, &#39;http://localhost:8080/test&#39;, true);\r\n        xhttp.setRequestHeader(&#39;Content-Type&#39;, &#39;application/json&#39;);\r\n        xhttp.send(jInfos);\r\n    }",
            "link": "https://stackoverflow.com/questions/49924805/express-post-method-not-rendering-my-view",
            "title": "express post method not rendering my view",
            "body": "<p>Im trying to render a new page when the server gets the <code>post</code> method, but its not rendering.\nIf i use a callback for the <code>res.render</code>, i can <code>console.log</code> the html file, but the page is just not loading</p>\n\n<p><strong>Server side</strong></p>\n\n<p><code>app.post('/test', jsonParser, function(req, res) {\nres.render('test', {something: req.something, something2: req.body})\n})</code></p>\n\n<p><strong>Client side</strong></p>\n\n<pre><code>function sendInfob(info){\n    var jInfos = JSON.stringify(info);\n    xhttp.open('post', 'http://localhost:8080/test', true);\n    xhttp.setRequestHeader('Content-Type', 'application/json');\n    xhttp.send(jInfos);\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "asp.net-core-mvc",
                "asp.net-core-2.0"
            ],
            "owner": {
                "reputation": 103,
                "user_id": 9430427,
                "user_type": "registered",
                "accept_rate": 88,
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Jp Duminy",
                "link": "https://stackoverflow.com/users/9430427/jp-duminy"
            },
            "is_answered": true,
            "view_count": 21,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524165679,
            "creation_date": 1524067131,
            "question_id": 49904133,
            "body_markdown": "Here i&#39;m new to mvc core2.0 please help me why my Routing Is not working\r\nMy Routing Class\r\n \r\n\r\n    public static class ApplicationRoteProfiler\r\n        {\r\n            public static void Routeing(IRouteBuilder builder)\r\n            {\r\n                builder.MapRoute(&quot;route1&quot;, &quot;&quot;, new\r\n                {\r\n                    Controllers = &quot;Department&quot;,\r\n                    Action = &quot;Add&quot;,\r\n    \r\n                });\r\n                builder.MapRoute(&quot;route2&quot;, &quot;Department/Add&quot;, new\r\n                {\r\n                    Controllers = &quot;Department&quot;,\r\n                    Action = &quot;Index&quot;\r\n    \r\n                });\r\n            }\r\nThis class file i register in startup.config file\r\n\r\n     public void Configure(IApplicationBuilder app)\r\n            {\r\n                app.UseStaticFiles();\r\n                app.UseMvc();\r\n                app.UseMvcWithDefaultRoute();\r\n                app.UseMvc(routes =&gt;\r\n                {\r\n                    ApplicationRoteProfiler.Routeing(routes);\r\n                });\r\n    \r\n            }\r\n\r\nWhen i hit my server as `http://localhost:1588/Department/Add` its should redirect to Department/Index But its hitting Department/Add\r\n",
            "link": "https://stackoverflow.com/questions/49904133/mvc-core2-0-routing-is-not-workin",
            "title": "mvc core2.0 routing is not Workin",
            "body": "<p>Here i'm new to mvc core2.0 please help me why my Routing Is not working\nMy Routing Class</p>\n\n<pre><code>public static class ApplicationRoteProfiler\n    {\n        public static void Routeing(IRouteBuilder builder)\n        {\n            builder.MapRoute(\"route1\", \"\", new\n            {\n                Controllers = \"Department\",\n                Action = \"Add\",\n\n            });\n            builder.MapRoute(\"route2\", \"Department/Add\", new\n            {\n                Controllers = \"Department\",\n                Action = \"Index\"\n\n            });\n        }\n</code></pre>\n\n<p>This class file i register in startup.config file</p>\n\n<pre><code> public void Configure(IApplicationBuilder app)\n        {\n            app.UseStaticFiles();\n            app.UseMvc();\n            app.UseMvcWithDefaultRoute();\n            app.UseMvc(routes =&gt;\n            {\n                ApplicationRoteProfiler.Routeing(routes);\n            });\n\n        }\n</code></pre>\n\n<p>When i hit my server as <code>http://localhost:1588/Department/Add</code> its should redirect to Department/Index But its hitting Department/Add</p>\n"
        },
        {
            "tags": [
                "spring-boot",
                "proxy",
                "netflix",
                "netflix-feign",
                "netflix-ribbon"
            ],
            "owner": {
                "reputation": 21,
                "user_id": 3326875,
                "user_type": "registered",
                "accept_rate": 100,
                "profile_image": "https://www.gravatar.com/avatar/c29d0b10a381d219ef421b199eb0a3e2?s=128&d=identicon&r=PG&f=1",
                "display_name": "Guido Zockoll",
                "link": "https://stackoverflow.com/users/3326875/guido-zockoll"
            },
            "is_answered": true,
            "view_count": 780,
            "accepted_answer_id": 44245595,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524165676,
            "creation_date": 1494311313,
            "last_edit_date": 1522391867,
            "question_id": 43862594,
            "body_markdown": "I want to consume a REST service from the outside world behind a corporate proxy with authentication.\r\n\r\nHow do I configure Spring Boot + Spring Cloud Feign/Ribbon to use our proxy?",
            "link": "https://stackoverflow.com/questions/43862594/spring-cloud-feign-ribbon-with-corporate-proxy",
            "title": "Spring Cloud Feign/Ribbon with corporate proxy",
            "body": "<p>I want to consume a REST service from the outside world behind a corporate proxy with authentication.</p>\n\n<p>How do I configure Spring Boot + Spring Cloud Feign/Ribbon to use our proxy?</p>\n"
        },
        {
            "tags": [
                "mongodb",
                "populate"
            ],
            "owner": {
                "reputation": 146,
                "user_id": 3959744,
                "user_type": "registered",
                "accept_rate": 0,
                "profile_image": "https://i.stack.imgur.com/CBrLa.jpg?s=128&g=1",
                "display_name": "Ali Abbas",
                "link": "https://stackoverflow.com/users/3959744/ali-abbas"
            },
            "is_answered": false,
            "view_count": 143,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524165674,
            "creation_date": 1497013108,
            "last_edit_date": 1524165674,
            "question_id": 44458487,
            "body_markdown": "I am facing an error, error is\r\n\r\n`Cast to ObjectId failed for value “” at path “_id” for model “Child ” in populate`\r\n\r\n**Detail,**\r\nI have two schema one is parent and other is a child, Some of the children records containing the null and empty reference of the parent. I don&#39; want this error to come, If some parent do not have any parent references, then I do not need any reference. Those children should come without parent details  \r\n\r\nI am using this method \r\n\r\n    Children.find({}).populate(&#39;parent&#39;) \r\nHere is my schema/model structure. \r\n\r\n    const Parent = new Schema({\r\n        name: {\r\n                type: String,\r\n                required: true\r\n            },\r\n    });\r\n\r\n    const Children = new Schema({\r\n        name: {\r\n                type: String,\r\n                required: true\r\n            },\r\n        parent: { type: mongoose.Schema.ObjectId, ref: &#39;Companies&#39;, \r\n                  required: false,default: {} \r\n                }, \r\n    }); ",
            "link": "https://stackoverflow.com/questions/44458487/cast-to-objectid-failed-for-value-at-path-id-for-model-child-in-populat",
            "title": "Cast to ObjectId failed for value &quot;&quot; at path &quot;_id&quot; for model &quot;Child &quot; in populate",
            "body": "<p>I am facing an error, error is</p>\n\n<p><code>Cast to ObjectId failed for value “” at path “_id” for model “Child ” in populate</code></p>\n\n<p><strong>Detail,</strong>\nI have two schema one is parent and other is a child, Some of the children records containing the null and empty reference of the parent. I don' want this error to come, If some parent do not have any parent references, then I do not need any reference. Those children should come without parent details  </p>\n\n<p>I am using this method </p>\n\n<pre><code>Children.find({}).populate('parent') \n</code></pre>\n\n<p>Here is my schema/model structure. </p>\n\n<pre><code>const Parent = new Schema({\n    name: {\n            type: String,\n            required: true\n        },\n});\n\nconst Children = new Schema({\n    name: {\n            type: String,\n            required: true\n        },\n    parent: { type: mongoose.Schema.ObjectId, ref: 'Companies', \n              required: false,default: {} \n            }, \n}); \n</code></pre>\n"
        },
        {
            "tags": [
                "visual-studio",
                "powershell",
                "terminal",
                "visual-studio-2017"
            ],
            "owner": {
                "reputation": 26010,
                "user_id": 9382,
                "user_type": "registered",
                "accept_rate": 77,
                "profile_image": "https://www.gravatar.com/avatar/bc7b9ac824e43ce9d62bf7dfb37b6393?s=128&d=identicon&r=PG",
                "display_name": "AngryHacker",
                "link": "https://stackoverflow.com/users/9382/angryhacker"
            },
            "is_answered": false,
            "view_count": 18,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165672,
            "creation_date": 1524161588,
            "question_id": 49927600,
            "body_markdown": "I am using a Powershell terminal via the Whack Whack Terminal add-in.  For whatever reason, the links open in Internet Explorer 11.  \r\n\r\nIs there anyway to change it to a default browser?  \r\n\r\nI&#39;ve followed the path from clicking a link and it seems like Internet Explorer is being kicked off from svchost.exe.  \r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/0Ag3l.png",
            "link": "https://stackoverflow.com/questions/49927600/visual-studio-2017-opens-links-in-ie11-how-to-change-that",
            "title": "Visual Studio 2017 opens links in IE11. How to change that?",
            "body": "<p>I am using a Powershell terminal via the Whack Whack Terminal add-in.  For whatever reason, the links open in Internet Explorer 11.  </p>\n\n<p>Is there anyway to change it to a default browser?  </p>\n\n<p>I've followed the path from clicking a link and it seems like Internet Explorer is being kicked off from svchost.exe.  </p>\n\n<p><a href=\"https://i.stack.imgur.com/0Ag3l.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/0Ag3l.png\" alt=\"enter image description here\"></a></p>\n"
        },
        {
            "tags": [
                "apache-spark",
                "spark-submit"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 7623678,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/c54831af1b6c84e51e1685d402589925?s=128&d=identicon&r=PG&f=1",
                "display_name": "user7623678",
                "link": "https://stackoverflow.com/users/7623678/user7623678"
            },
            "is_answered": false,
            "view_count": 34,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1524165668,
            "creation_date": 1524063456,
            "question_id": 49902987,
            "body_markdown": "I have set up spark on a cluster of 3 nodes, one is my namenode-master (named h1) and other two are my datanode-workers (named h2 and h3). When I give the command to run a spark job on my master, it seems like the job is not getting distributed to the workers and it is just being done on the master. The command I gave to run the spark job is \r\n\r\n    bin/spark-submit --class org.dataalgorithms.chap07.spark.FindAssociationRules /home/ubuntu/project_spark/data-algorithms-1.0.0.jar ./in/xaa\r\n\r\nThe reason why I think its just running on the master is because when I go on the Spark Application GUI I just see the master h1 in the executor list. I would  think I should see h2 and h3 my worker nodes too here? \r\n[SparkUI][1]\r\n\r\nCorrect me if I am wrong. I am a newbie so please excuse me for my ignorance.\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/8LEM5.png",
            "link": "https://stackoverflow.com/questions/49902987/spark-job-not-using-the-worker-nodes-on-the-cluster",
            "title": "Spark job not using the worker nodes on the cluster",
            "body": "<p>I have set up spark on a cluster of 3 nodes, one is my namenode-master (named h1) and other two are my datanode-workers (named h2 and h3). When I give the command to run a spark job on my master, it seems like the job is not getting distributed to the workers and it is just being done on the master. The command I gave to run the spark job is </p>\n\n<pre><code>bin/spark-submit --class org.dataalgorithms.chap07.spark.FindAssociationRules /home/ubuntu/project_spark/data-algorithms-1.0.0.jar ./in/xaa\n</code></pre>\n\n<p>The reason why I think its just running on the master is because when I go on the Spark Application GUI I just see the master h1 in the executor list. I would  think I should see h2 and h3 my worker nodes too here? \n<a href=\"https://i.stack.imgur.com/8LEM5.png\" rel=\"nofollow noreferrer\">SparkUI</a></p>\n\n<p>Correct me if I am wrong. I am a newbie so please excuse me for my ignorance.</p>\n"
        },
        {
            "tags": [
                "android",
                "android-webview",
                "android-view",
                "android-5.0-lollipop",
                "mutable-context-wrapper"
            ],
            "owner": {
                "reputation": 143,
                "user_id": 1464245,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/HnMKw.jpg?s=128&g=1",
                "display_name": "lpmfilho",
                "link": "https://stackoverflow.com/users/1464245/lpmfilho"
            },
            "is_answered": false,
            "view_count": 431,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524165662,
            "creation_date": 1443128803,
            "last_edit_date": 1524165662,
            "question_id": 32770919,
            "body_markdown": "I needed to pass a WebView to another Activity, and I couldn&#39;t create a new WebView in the new Activity because the html content can not be loaded twice. So I managed to solve the problem using a static blackboard and the [MutableContextWrapper][1].\r\n\r\nThe approach was: (i) The original Activity instantiates the WebView with a [MutableContextWrapper][1], and before to start the second Activity, (ii) I detach the WebView from the original Activity, (iii) store it in a static blackboard, and when the second Activity is started, (iv) it gets the instance of WebView on the blackboard, (v) updates its Context using the [MutableContextWrapper][1], (vi) and attach it to the new Activity. When the second Activity is closed, the reverse way is followed to put back the WebView in the original Activity.\r\n\r\nThis approach works very well in the most Android versions, but since the Lollipop version, the WebView does not refresh its content while it is attached to the second Activity. However when the second Activity is closed and the WebView goes back to the original Activity, it works fine.\r\n\r\nIn my researches, I discovered about the new behavior of the WebViews from the Android L that reduces memory footprint and increases performance by intelligently choosing the portion of the HTML document that needs to be drawn. \r\n\r\nSo I suspected that this feature could interfere in the WebView&#39;s refreshing, but even calling the [enableSlowWholeDocumentDraw()][2] method, the WebView continues not working properly.\r\n\r\nSomeone would know explain the cause for this behavior? \r\n\r\n\r\n  [1]: http://developer.android.com/reference/android/content/MutableContextWrapper.html\r\n  [2]: http://developer.android.com/reference/android/webkit/WebView.html#enableSlowWholeDocumentDraw()",
            "link": "https://stackoverflow.com/questions/32770919/the-webview-does-not-refresh-properly-when-it-is-passed-from-an-activity-to-anot",
            "title": "The WebView does not refresh properly when it is passed from an Activity to another",
            "body": "<p>I needed to pass a WebView to another Activity, and I couldn't create a new WebView in the new Activity because the html content can not be loaded twice. So I managed to solve the problem using a static blackboard and the <a href=\"http://developer.android.com/reference/android/content/MutableContextWrapper.html\" rel=\"nofollow\">MutableContextWrapper</a>.</p>\n\n<p>The approach was: (i) The original Activity instantiates the WebView with a <a href=\"http://developer.android.com/reference/android/content/MutableContextWrapper.html\" rel=\"nofollow\">MutableContextWrapper</a>, and before to start the second Activity, (ii) I detach the WebView from the original Activity, (iii) store it in a static blackboard, and when the second Activity is started, (iv) it gets the instance of WebView on the blackboard, (v) updates its Context using the <a href=\"http://developer.android.com/reference/android/content/MutableContextWrapper.html\" rel=\"nofollow\">MutableContextWrapper</a>, (vi) and attach it to the new Activity. When the second Activity is closed, the reverse way is followed to put back the WebView in the original Activity.</p>\n\n<p>This approach works very well in the most Android versions, but since the Lollipop version, the WebView does not refresh its content while it is attached to the second Activity. However when the second Activity is closed and the WebView goes back to the original Activity, it works fine.</p>\n\n<p>In my researches, I discovered about the new behavior of the WebViews from the Android L that reduces memory footprint and increases performance by intelligently choosing the portion of the HTML document that needs to be drawn. </p>\n\n<p>So I suspected that this feature could interfere in the WebView's refreshing, but even calling the <a href=\"http://developer.android.com/reference/android/webkit/WebView.html#enableSlowWholeDocumentDraw()\" rel=\"nofollow\">enableSlowWholeDocumentDraw()</a> method, the WebView continues not working properly.</p>\n\n<p>Someone would know explain the cause for this behavior? </p>\n"
        },
        {
            "tags": [
                "javascript",
                "popup",
                "jekyll",
                "mailchimp",
                "github-pages"
            ],
            "owner": {
                "reputation": 5,
                "user_id": 8345469,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/effa754fdcba7b9d51a84e7d4ac3e1b2?s=128&d=identicon&r=PG&f=1",
                "display_name": "Pat",
                "link": "https://stackoverflow.com/users/8345469/pat"
            },
            "is_answered": true,
            "view_count": 26,
            "accepted_answer_id": 49928706,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165660,
            "creation_date": 1524144281,
            "last_edit_date": 1524152733,
            "question_id": 49922267,
            "body_markdown": "Trying to make Mailchimp&#39;s pop-up form work on-click for my Jekyll Powered Github Page.\r\n\r\nSteps I&#39;ve followed:\r\n\r\n1. I&#39;ve created a link on my site to trigger the pop-up with:\r\n\r\n    &lt;!-- language: lang-html --&gt;\r\n\r\n        &lt;a href=&quot;#&quot; id=&quot;open-popup&quot; onclick =&quot;showMailingPopUp(); return false;&quot;&gt;Join Newsletter&lt;/a&gt;\r\n\r\n  The above sits in the HTML for my navigation bar (`masthead.html`).\r\n\r\n2. I&#39;ve then created an HTML for the mailchimp pop-up code (`newsletter.html`). And yes, uuids and lids were replaced by my own hashes\r\n\r\n    &lt;!-- language: lang-html --&gt;\r\n\r\n        &lt;script type=&quot;text/javascript&quot; src=&quot;//downloads.mailchimp.com/js/signup-forms/popup/embed.js&quot; data-dojo-config=&quot;usePlainJson: true, isDebug: false&quot;&gt;&lt;/script&gt;\r\n        &lt;script&gt;\r\n          function showMailingPopUp() {\r\n            require(\r\n              [&quot;mojo/signup-forms/Loader&quot;],\r\n              function(L) {\r\n                L.start({&quot;baseUrl&quot;:&quot;mc.us12.list-manage.com&quot;,&quot;uuid&quot;:&quot;myuuid&quot;,&quot;lid&quot;:&quot;mylid&quot;})\r\n              }\r\n            );\r\n    \r\n            document.cookie = &quot;MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC;&quot;;\r\n            document.cookie = &quot;MCPopupSubscribed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC;&quot;;\r\n          }\r\n    \r\n          document.getElementById(&quot;open-popup&quot;).onclick = function() {showMailingPopUp()};\r\n        &lt;/script&gt;\r\n\r\n3. Calling `newsletter.html` with an include added to `masthead.html` right before `&lt;/body&gt;` with:\r\n\r\n    &lt;!-- language: lang-none --&gt;\r\n\r\n        {% include newsletter.html %}\r\n\r\n4. No luck with all above :-(\r\n\r\n\r\n**Any pointers on how to fix it?**\r\n",
            "link": "https://stackoverflow.com/questions/49922267/making-mailchimp-pop-up-work-on-click-for-jekyll-github-pages",
            "title": "Making Mailchimp pop-up work on-click for Jekyll/Github Pages",
            "body": "<p>Trying to make Mailchimp's pop-up form work on-click for my Jekyll Powered Github Page.</p>\n\n<p>Steps I've followed:</p>\n\n<ol>\n<li><p>I've created a link on my site to trigger the pop-up with:</p>\n\n<pre class=\"lang-html prettyprint-override\"><code>&lt;a href=\"#\" id=\"open-popup\" onclick =\"showMailingPopUp(); return false;\"&gt;Join Newsletter&lt;/a&gt;\n</code></pre>\n\n<p>The above sits in the HTML for my navigation bar (<code>masthead.html</code>).</p></li>\n<li><p>I've then created an HTML for the mailchimp pop-up code (<code>newsletter.html</code>). And yes, uuids and lids were replaced by my own hashes</p>\n\n<pre class=\"lang-html prettyprint-override\"><code>&lt;script type=\"text/javascript\" src=\"//downloads.mailchimp.com/js/signup-forms/popup/embed.js\" data-dojo-config=\"usePlainJson: true, isDebug: false\"&gt;&lt;/script&gt;\n&lt;script&gt;\n  function showMailingPopUp() {\n    require(\n      [\"mojo/signup-forms/Loader\"],\n      function(L) {\n        L.start({\"baseUrl\":\"mc.us12.list-manage.com\",\"uuid\":\"myuuid\",\"lid\":\"mylid\"})\n      }\n    );\n\n    document.cookie = \"MCPopupClosed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC;\";\n    document.cookie = \"MCPopupSubscribed=;path=/;expires=Thu, 01 Jan 1970 00:00:00 UTC;\";\n  }\n\n  document.getElementById(\"open-popup\").onclick = function() {showMailingPopUp()};\n&lt;/script&gt;\n</code></pre></li>\n<li><p>Calling <code>newsletter.html</code> with an include added to <code>masthead.html</code> right before <code>&lt;/body&gt;</code> with:</p>\n\n<pre class=\"lang-none prettyprint-override\"><code>{% include newsletter.html %}\n</code></pre></li>\n<li><p>No luck with all above :-(</p></li>\n</ol>\n\n<p><strong>Any pointers on how to fix it?</strong></p>\n"
        },
        {
            "tags": [
                "django",
                "django-rest-framework",
                "crud"
            ],
            "owner": {
                "reputation": 41,
                "user_id": 3846831,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/DUdlr.jpg?s=128&g=1",
                "display_name": "shahab",
                "link": "https://stackoverflow.com/users/3846831/shahab"
            },
            "is_answered": true,
            "view_count": 46,
            "accepted_answer_id": 49921588,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524165659,
            "creation_date": 1524138802,
            "question_id": 49920470,
            "body_markdown": "I&#39;m working on a Django REST API project for a restaurant.\r\n\r\nI have to get client requests and for some requests send model objects and for the update or delete requests send a feedback to the client. \r\n\r\nSuppose that my `models.py` is like:\r\n\r\n    # models.py\r\n    ---------------------------------------------------------------------------\r\n    class Table(models.Model):\r\n        id = models.AutoField(primary_key=True)\r\n        name = models.CharField(max_length=30, null=False, blank=False)\r\n        is_free = models.BooleanField(default=True)\r\n\r\n        def __str__(self):\r\n            return &#39;%s %s %s&#39; % (self.id, self.name, self.is_free)\r\n\r\n\r\n    class Order(models.Model):\r\n        order_id = models.AutoField(primary_key=True)\r\n        table_id = models.ForeignKey(Table, on_delete=models.CASCADE)\r\n        total_price = models.IntegerField()\r\n\r\n        def __str__(self):\r\n            return &#39;%s %s&#39; % (self.order_id, self.total_price)\r\n\r\nI want to send a list of all orders for client GET request, send feedback for the update and delete requests, and send True or False whether if a specific table with an id that sent from the client is free or not.\r\n\r\nunfortunately, I&#39;m confused after reading so many documents.\r\n\r\nWould you please give a simple example to achieve these purposes?\r\n\r\nAfter that can you give me an example of how to serialize a none model object for clients uses?\r\n\r\nThanks in advance.\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49920470/simple-example-about-django-rest-crud",
            "title": "simple example about django REST CRUD",
            "body": "<p>I'm working on a Django REST API project for a restaurant.</p>\n\n<p>I have to get client requests and for some requests send model objects and for the update or delete requests send a feedback to the client. </p>\n\n<p>Suppose that my <code>models.py</code> is like:</p>\n\n<pre><code># models.py\n---------------------------------------------------------------------------\nclass Table(models.Model):\n    id = models.AutoField(primary_key=True)\n    name = models.CharField(max_length=30, null=False, blank=False)\n    is_free = models.BooleanField(default=True)\n\n    def __str__(self):\n        return '%s %s %s' % (self.id, self.name, self.is_free)\n\n\nclass Order(models.Model):\n    order_id = models.AutoField(primary_key=True)\n    table_id = models.ForeignKey(Table, on_delete=models.CASCADE)\n    total_price = models.IntegerField()\n\n    def __str__(self):\n        return '%s %s' % (self.order_id, self.total_price)\n</code></pre>\n\n<p>I want to send a list of all orders for client GET request, send feedback for the update and delete requests, and send True or False whether if a specific table with an id that sent from the client is free or not.</p>\n\n<p>unfortunately, I'm confused after reading so many documents.</p>\n\n<p>Would you please give a simple example to achieve these purposes?</p>\n\n<p>After that can you give me an example of how to serialize a none model object for clients uses?</p>\n\n<p>Thanks in advance.</p>\n"
        },
        {
            "tags": [
                "ruby-on-rails-3",
                "mongomapper",
                "devise"
            ],
            "owner": {
                "reputation": 6245,
                "user_id": 377920,
                "user_type": "registered",
                "accept_rate": 60,
                "profile_image": "https://www.gravatar.com/avatar/d5d06662b6d5701f9633e83761ab5ac3?s=128&d=identicon&r=PG",
                "display_name": "randomguy",
                "link": "https://stackoverflow.com/users/377920/randomguy"
            },
            "is_answered": true,
            "view_count": 18933,
            "accepted_answer_id": 9124676,
            "answer_count": 4,
            "score": 15,
            "last_activity_date": 1524165659,
            "creation_date": 1285583031,
            "question_id": 3802913,
            "body_markdown": "    gem &#39;rails&#39;, &#39;3.0.0&#39;\r\n    gem &#39;devise&#39;\r\n    gem &#39;bson_ext&#39;, &#39;&gt;= 1.0.7&#39;\r\n    gem &#39;bson&#39;, &#39;&gt;= 1.0.7&#39;\r\n    gem &#39;mongo_mapper&#39;, :branch =&gt; &#39;rails3&#39;, :git =&gt; &#39;http://github.com/jnunemaker/mongomapper.git&#39;\r\n    gem &#39;devise-mongo_mapper&#39;, :git =&gt; &#39;git://github.com/collectiveidea/devise-mongo_mapper&#39;\r\n\r\nWith the above setup I get the following errors on requests:\r\n\r\n    Started GET &quot;/users/sign_out&quot; for 127.0.0.1 at 2010-09-27 13:16:30 +0300\r\n      Processing by Devise::SessionsController#destroy as HTML\r\n    Redirected to http://localhost:3000/\r\n    Completed 302 Found in 19ms\r\n    [2010-09-27 13:16:31] ERROR Errno::ECONNRESET: Connection reset by peer\r\n    \t/usr/local/ruby/lib/ruby/1.9.1/webrick/httpserver.rb:56:in `eof?&#39;\r\n    \t/usr/local/ruby/lib/ruby/1.9.1/webrick/httpserver.rb:56:in `run&#39;\r\n    \t/usr/local/ruby/lib/ruby/1.9.1/webrick/server.rb:183:in `block in start_thread&#39;\r\n    \r\n    \r\n    Started GET &quot;/users/edit&quot; for 127.0.0.1 at 2010-09-27 13:16:35 +0300\r\n      Processing by Devise::RegistrationsController#edit as HTML\r\n    Completed   in 16ms\r\n    [2010-09-27 13:16:35] ERROR Errno::ECONNRESET: Connection reset by peer\r\n    \t/usr/local/ruby/lib/ruby/1.9.1/webrick/httpserver.rb:56:in `eof?&#39;\r\n    \t/usr/local/ruby/lib/ruby/1.9.1/webrick/httpserver.rb:56:in `run&#39;\r\n    \t/usr/local/ruby/lib/ruby/1.9.1/webrick/server.rb:183:in `block in start_thread&#39;\r\n\r\nThe user model:\r\n\r\n    class User\r\n      include MongoMapper::Document\r\n      plugin MongoMapper::Devise\r\n      devise :registerable, :database_authenticatable, :recoverable\r\n    end\r\n\r\nIdeas?",
            "link": "https://stackoverflow.com/questions/3802913/error-errnoeconnreset-connection-reset-by-peer",
            "title": "ERROR Errno::ECONNRESET: Connection reset by peer",
            "body": "<pre><code>gem 'rails', '3.0.0'\ngem 'devise'\ngem 'bson_ext', '&gt;= 1.0.7'\ngem 'bson', '&gt;= 1.0.7'\ngem 'mongo_mapper', :branch =&gt; 'rails3', :git =&gt; 'http://github.com/jnunemaker/mongomapper.git'\ngem 'devise-mongo_mapper', :git =&gt; 'git://github.com/collectiveidea/devise-mongo_mapper'\n</code></pre>\n\n<p>With the above setup I get the following errors on requests:</p>\n\n<pre><code>Started GET \"/users/sign_out\" for 127.0.0.1 at 2010-09-27 13:16:30 +0300\n  Processing by Devise::SessionsController#destroy as HTML\nRedirected to http://localhost:3000/\nCompleted 302 Found in 19ms\n[2010-09-27 13:16:31] ERROR Errno::ECONNRESET: Connection reset by peer\n    /usr/local/ruby/lib/ruby/1.9.1/webrick/httpserver.rb:56:in `eof?'\n    /usr/local/ruby/lib/ruby/1.9.1/webrick/httpserver.rb:56:in `run'\n    /usr/local/ruby/lib/ruby/1.9.1/webrick/server.rb:183:in `block in start_thread'\n\n\nStarted GET \"/users/edit\" for 127.0.0.1 at 2010-09-27 13:16:35 +0300\n  Processing by Devise::RegistrationsController#edit as HTML\nCompleted   in 16ms\n[2010-09-27 13:16:35] ERROR Errno::ECONNRESET: Connection reset by peer\n    /usr/local/ruby/lib/ruby/1.9.1/webrick/httpserver.rb:56:in `eof?'\n    /usr/local/ruby/lib/ruby/1.9.1/webrick/httpserver.rb:56:in `run'\n    /usr/local/ruby/lib/ruby/1.9.1/webrick/server.rb:183:in `block in start_thread'\n</code></pre>\n\n<p>The user model:</p>\n\n<pre><code>class User\n  include MongoMapper::Document\n  plugin MongoMapper::Devise\n  devise :registerable, :database_authenticatable, :recoverable\nend\n</code></pre>\n\n<p>Ideas?</p>\n"
        },
        {
            "tags": [
                "payload",
                "drone",
                "dji-sdk"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 9622167,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Dan Vrekalic",
                "link": "https://stackoverflow.com/users/9622167/dan-vrekalic"
            },
            "is_answered": true,
            "view_count": 19,
            "accepted_answer_id": 49928705,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524165656,
            "creation_date": 1523321215,
            "question_id": 49743621,
            "body_markdown": "I would like to add a payload release system on the Matrice M210 drone.  I have seen the diagram for the expansion port on the rear of the machine.  There is a note in the documentation that says * coming soon.  I am not clear if it referring to this functionality or something else on the page.  Has anyone mapped an external device and been able to access it via Cedence radio?\r\n\r\nAny advice or information on how to accomplish this task would be much appreciated.",
            "link": "https://stackoverflow.com/questions/49743621/m210-dji-drone-expansion-port-access-for-payload-release",
            "title": "M210 DJI Drone expansion port access for payload release",
            "body": "<p>I would like to add a payload release system on the Matrice M210 drone.  I have seen the diagram for the expansion port on the rear of the machine.  There is a note in the documentation that says * coming soon.  I am not clear if it referring to this functionality or something else on the page.  Has anyone mapped an external device and been able to access it via Cedence radio?</p>\n\n<p>Any advice or information on how to accomplish this task would be much appreciated.</p>\n"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 143
}