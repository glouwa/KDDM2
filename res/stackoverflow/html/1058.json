{
    "items": [
        {
            "tags": [
                "keras",
                "cross-entropy",
                "loss-function"
            ],
            "owner": {
                "reputation": 45,
                "user_id": 7960084,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/bac8b640cedb1bb7aa4303b9eee9bba1?s=128&d=identicon&r=PG",
                "display_name": "snoozzz",
                "link": "https://stackoverflow.com/users/7960084/snoozzz"
            },
            "is_answered": true,
            "view_count": 199,
            "accepted_answer_id": 50018745,
            "answer_count": 1,
            "score": 2,
            "last_activity_date": 1524656581,
            "creation_date": 1496402897,
            "last_edit_date": 1524656581,
            "question_id": 44327814,
            "body_markdown": "I have a neural network, trained on MNIST, with categorical cross entropy as its loss function.\r\n\r\nFor theoretical purposes my output layer is ReLu. Therefore a lot of\r\nits outputs are 0.\r\n\r\nNow I stumbled across the following question:\r\n\r\nWhy don&#39;t I get a lot of errors, since certainly there will be a lot of\r\nzeros in my output, which I will take the log of.\r\n\r\nHere, for convenience, the formula for categorical cross entropy.\r\n\r\n![L = \\sum_{i=1}^m \\sum_j L_{i,j} \\log y_{i,j}](https://chart.googleapis.com/chart?cht=tx&amp;chl=L%20=%20\\sum_{i=1}^m%20\\sum_j%20L_{i,j}%20\\log%20y_{i,j})",
            "link": "https://stackoverflow.com/questions/44327814/how-does-keras-deal-with-log0-for-categorical-cross-entropy",
            "title": "How does Keras deal with log(0) for categorical cross entropy?",
            "body": "<p>I have a neural network, trained on MNIST, with categorical cross entropy as its loss function.</p>\n\n<p>For theoretical purposes my output layer is ReLu. Therefore a lot of\nits outputs are 0.</p>\n\n<p>Now I stumbled across the following question:</p>\n\n<p>Why don't I get a lot of errors, since certainly there will be a lot of\nzeros in my output, which I will take the log of.</p>\n\n<p>Here, for convenience, the formula for categorical cross entropy.</p>\n\n<p><img src=\"https://chart.googleapis.com/chart?cht=tx&amp;chl=L%20=%20%5Csum_%7Bi=1%7D%5Em%20%5Csum_j%20L_%7Bi,j%7D%20%5Clog%20y_%7Bi,j%7D\" alt=\"L = \\sum_{i=1}^m \\sum_j L_{i,j} \\log y_{i,j}\"></p>\n"
        },
        {
            "tags": [
                "shell",
                "sed",
                "grep"
            ],
            "owner": {
                "reputation": 46,
                "user_id": 3702858,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/140cb0a0025204f6ecea4a3f93aa9b77?s=128&d=identicon&r=PG&f=1",
                "display_name": "user3702858",
                "link": "https://stackoverflow.com/users/3702858/user3702858"
            },
            "is_answered": true,
            "view_count": 17771,
            "answer_count": 3,
            "score": 8,
            "last_activity_date": 1524656580,
            "creation_date": 1401795460,
            "last_edit_date": 1401797424,
            "question_id": 24014194,
            "body_markdown": "I have a file with contents,\r\n\r\n    x\r\n    a\r\n    x\r\n    b\r\n    x\r\n    c\r\n\r\nI want to grep the last occurrence,\r\n\r\n    x\r\n    c\r\n\r\nwhen I try\r\n\r\n    sed -n  &quot;/x/,/b/p&quot; file\r\n\r\nit lists all the lines. beginning x to c",
            "link": "https://stackoverflow.com/questions/24014194/how-to-grep-the-last-occurrence-of-the-line-pattern",
            "title": "how to grep the last occurrence of the line pattern",
            "body": "<p>I have a file with contents,</p>\n\n<pre><code>x\na\nx\nb\nx\nc\n</code></pre>\n\n<p>I want to grep the last occurrence,</p>\n\n<pre><code>x\nc\n</code></pre>\n\n<p>when I try</p>\n\n<pre><code>sed -n  \"/x/,/b/p\" file\n</code></pre>\n\n<p>it lists all the lines. beginning x to c</p>\n"
        },
        {
            "tags": [
                "email",
                "pentaho",
                "pentaho-data-integration",
                "pentaho-report-designer",
                "pentaho-design-studio"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9117145,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/cee3ca75b4f296888ee2f286e5d756be?s=128&d=identicon&r=PG&f=1",
                "display_name": "Swapnil Solanki",
                "link": "https://stackoverflow.com/users/9117145/swapnil-solanki"
            },
            "is_answered": false,
            "view_count": 38,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524656569,
            "creation_date": 1514964712,
            "last_edit_date": 1514981581,
            "question_id": 48073022,
            "body_markdown": "How to schedule reports in `Pentaho User Console`.\r\nAlso let me know how to email scheduled reports particular address in \r\n`Pentaho User Console`.",
            "link": "https://stackoverflow.com/questions/48073022/schedule-reports-in-pentaho-user-console",
            "title": "Schedule reports in Pentaho user console",
            "body": "<p>How to schedule reports in <code>Pentaho User Console</code>.\nAlso let me know how to email scheduled reports particular address in \n<code>Pentaho User Console</code>.</p>\n"
        },
        {
            "tags": [
                "ssh",
                "gcloud"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 5021008,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/39f18a178e4e375ab071f171ebd4c831?s=128&d=identicon&r=PG&f=1",
                "display_name": "rod_lopez",
                "link": "https://stackoverflow.com/users/5021008/rod-lopez"
            },
            "is_answered": false,
            "view_count": 19,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524656568,
            "creation_date": 1524299239,
            "question_id": 49953826,
            "body_markdown": "So I&#39;m trying to connect to a gcloud instance where I&#39;ve installed several packages and started to develop my code with no problem. During the week, I use a certificate and putty to login since I work with a windows machine. \r\n\r\nHowever now that I&#39;m home, I tried to connect to the instance using my mac where I installed the Google Cloud SDK and after configuring all the parameters using \r\n\r\n    gcloud init\r\n\r\nI get logged to an empty instance that doesn&#39;t have all of the packages and scripts I mentioned above.\r\n\r\nWhat am I doing wrong? I can confirm that I&#39;m connecting to an instance with the same name, in the same region and all, but it is completely different.\r\n\r\nCheers!",
            "link": "https://stackoverflow.com/questions/49953826/gcloud-compute-ssh-connects-to-a-different-instance-than-ssh-certificate",
            "title": "Gcloud compute SSH connects to a different Instance than SSH + certificate",
            "body": "<p>So I'm trying to connect to a gcloud instance where I've installed several packages and started to develop my code with no problem. During the week, I use a certificate and putty to login since I work with a windows machine. </p>\n\n<p>However now that I'm home, I tried to connect to the instance using my mac where I installed the Google Cloud SDK and after configuring all the parameters using </p>\n\n<pre><code>gcloud init\n</code></pre>\n\n<p>I get logged to an empty instance that doesn't have all of the packages and scripts I mentioned above.</p>\n\n<p>What am I doing wrong? I can confirm that I'm connecting to an instance with the same name, in the same region and all, but it is completely different.</p>\n\n<p>Cheers!</p>\n"
        },
        {
            "tags": [
                "django",
                "django-rest-framework"
            ],
            "owner": {
                "reputation": 1458,
                "user_id": 5341676,
                "user_type": "registered",
                "accept_rate": 56,
                "profile_image": "https://www.gravatar.com/avatar/e7ad6979d956fb591165c56b4ff1819c?s=128&d=identicon&r=PG&f=1",
                "display_name": "Nitish",
                "link": "https://stackoverflow.com/users/5341676/nitish"
            },
            "is_answered": false,
            "view_count": 36,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524656562,
            "creation_date": 1524655262,
            "question_id": 50020990,
            "body_markdown": "I have a model:\r\n\r\n    class Scenario(models.Model):\r\n    \ttasks = models.ManyToManyField(Task, blank=True)\r\n\r\nIts serializer:\r\n\r\n    class ScenarioSerializer(serializers.ModelSerializer):\r\n    \t\r\n    \tclass Meta:\r\n    \t\tmodel = Scenario\r\n    \t\tfields = &#39;__all__&#39;\r\n\r\nand a view to create a scenario:\r\n\r\n    @api_view([&#39;GET&#39;, &#39;POST&#39;])\r\n    def scenarios_list(request):\r\n        &quot;&quot;&quot;\r\n        List all scenarios, or create a new.\r\n        &quot;&quot;&quot;\r\n        if request.method == &#39;GET&#39;:\r\n        \tscenarios = Scenario.objects.all()\r\n            serializer = ScenarioSerializer(scenarios, many=True)\r\n            return Response(serializer.data)\r\n    \r\n        elif request.method == &#39;POST&#39;:\r\n            serializer = ScenarioSerializer(data=request.data)\r\n            if serializer.is_valid():\r\n                serializer.save()\r\n                return Response(serializer.data, status=status.HTTP_201_CREATED)\r\n            else:\r\n                return Response(\r\n                    serializer.errors, status=status.HTTP_400_BAD_REQUEST)\r\n\r\nI am sending following data from my frontend:\r\n\r\n    [\r\n    \t{id: 3, title: &quot;Three&quot;, how_often: &quot;DS&quot;, how_important_task: &quot;EI&quot;, role: &quot;Lorem&quot;, …},\r\n    \r\n    \t{id: 1, title: &quot;One&quot;, how_often: &quot;MO&quot;, how_important_task: &quot;RI&quot;, role: &quot;Lorem&quot;, …},\r\n    \r\n    \t{id: 6, title: &quot;Six&quot;, how_often: &quot;WO&quot;, how_important_task: &quot;EI&quot;, role: &quot;&quot;, …},\r\n    \r\n    \t{id: 4, title: &quot;Four&quot;, how_often: &quot;&quot;, how_important_task: &quot;&quot;, role: &quot;&quot;, …}\r\n    ]\r\n\r\nWhich throws me BAD REQUEST error. What am I doing wrong?",
            "link": "https://stackoverflow.com/questions/50020990/django-rest-bad-request-error",
            "title": "Django rest bad request error",
            "body": "<p>I have a model:</p>\n\n<pre><code>class Scenario(models.Model):\n    tasks = models.ManyToManyField(Task, blank=True)\n</code></pre>\n\n<p>Its serializer:</p>\n\n<pre><code>class ScenarioSerializer(serializers.ModelSerializer):\n\n    class Meta:\n        model = Scenario\n        fields = '__all__'\n</code></pre>\n\n<p>and a view to create a scenario:</p>\n\n<pre><code>@api_view(['GET', 'POST'])\ndef scenarios_list(request):\n    \"\"\"\n    List all scenarios, or create a new.\n    \"\"\"\n    if request.method == 'GET':\n        scenarios = Scenario.objects.all()\n        serializer = ScenarioSerializer(scenarios, many=True)\n        return Response(serializer.data)\n\n    elif request.method == 'POST':\n        serializer = ScenarioSerializer(data=request.data)\n        if serializer.is_valid():\n            serializer.save()\n            return Response(serializer.data, status=status.HTTP_201_CREATED)\n        else:\n            return Response(\n                serializer.errors, status=status.HTTP_400_BAD_REQUEST)\n</code></pre>\n\n<p>I am sending following data from my frontend:</p>\n\n<pre><code>[\n    {id: 3, title: \"Three\", how_often: \"DS\", how_important_task: \"EI\", role: \"Lorem\", …},\n\n    {id: 1, title: \"One\", how_often: \"MO\", how_important_task: \"RI\", role: \"Lorem\", …},\n\n    {id: 6, title: \"Six\", how_often: \"WO\", how_important_task: \"EI\", role: \"\", …},\n\n    {id: 4, title: \"Four\", how_often: \"\", how_important_task: \"\", role: \"\", …}\n]\n</code></pre>\n\n<p>Which throws me BAD REQUEST error. What am I doing wrong?</p>\n"
        },
        {
            "tags": [
                "svn",
                "tortoisesvn"
            ],
            "owner": {
                "reputation": 483,
                "user_id": 270875,
                "user_type": "registered",
                "accept_rate": 44,
                "profile_image": "https://www.gravatar.com/avatar/cbf7d23b31f686154ff0c1425f5c4d06?s=128&d=identicon&r=PG",
                "display_name": "Terman",
                "link": "https://stackoverflow.com/users/270875/terman"
            },
            "is_answered": true,
            "view_count": 36099,
            "answer_count": 13,
            "score": 21,
            "last_activity_date": 1524656555,
            "creation_date": 1342428940,
            "last_edit_date": 1342430007,
            "question_id": 11500954,
            "body_markdown": "I keep getting the error listed blow in attempting a merge from a private branch:\r\n\r\ndatabase is locked, executing statement &#39;RELEASE   s0&#39;\r\n\r\nI run collabnet subversion edge server: 1.7.5-3220.94\r\n\r\nI run the tortoise svn client: TortoiseSVN 1.7.7, Build 22907 - 64 Bit , 2012/05/15 12:16:05\r\n\r\nCan anyone please point me to what&#39;s causing this, and how to resolve this. The references on the Web suggest some process is using the sqlite backend. The generic &quot;Release lock&quot; action from svn client contextual menu doesn&#39;t seem to help?\r\n \r\n\r\nThanks.\r\n\r\n",
            "link": "https://stackoverflow.com/questions/11500954/svn-database-is-locked-executing-statement-release-s0",
            "title": "svn: database is locked, executing statement &#39;RELEASE s0&#39;",
            "body": "<p>I keep getting the error listed blow in attempting a merge from a private branch:</p>\n\n<p>database is locked, executing statement 'RELEASE   s0'</p>\n\n<p>I run collabnet subversion edge server: 1.7.5-3220.94</p>\n\n<p>I run the tortoise svn client: TortoiseSVN 1.7.7, Build 22907 - 64 Bit , 2012/05/15 12:16:05</p>\n\n<p>Can anyone please point me to what's causing this, and how to resolve this. The references on the Web suggest some process is using the sqlite backend. The generic \"Release lock\" action from svn client contextual menu doesn't seem to help?</p>\n\n<p>Thanks.</p>\n"
        },
        {
            "tags": [
                "intellij-idea",
                "jetty",
                "port"
            ],
            "owner": {
                "reputation": 858,
                "user_id": 767547,
                "user_type": "registered",
                "accept_rate": 50,
                "profile_image": "https://www.gravatar.com/avatar/b541defd2b03092465151d9ee1e4bbab?s=128&d=identicon&r=PG",
                "display_name": "Martin",
                "link": "https://stackoverflow.com/users/767547/martin"
            },
            "is_answered": true,
            "view_count": 8172,
            "accepted_answer_id": 23122157,
            "answer_count": 5,
            "score": 10,
            "last_activity_date": 1524656543,
            "creation_date": 1397551689,
            "last_edit_date": 1495539981,
            "question_id": 23078745,
            "body_markdown": "In IntelliJ 13.0.2 Ultimate I&#39;ve set up a web application module using Jetty 9.1.4.\r\n\r\nI&#39;d like to test my application on port 8100, but I can&#39;t figure out a way to change the port of my &quot;Local&quot; Jetty run configuration. It always seems to use the default port 8080.\r\n\r\nThere is a setting for the port in the IntelliJ run configuration but it only appears when configuring a &quot;remote&quot; server.\r\n\r\nI&#39;ve tried adding my own .mod file to the Jetty Server Settings containing the following but it seems to be ignored.\r\n\r\n    [ini-template]\r\n    jetty.port=8100\r\n\r\nOne of the answers in [this post](https://stackoverflow.com/questions/15654476/how-can-i-start-jetty-from-intellij-on-windows) says the port is 8080 unless you change it, but he doesn&#39;t say how to change it.\r\n\r\nCan someone point me in the right direction? Thanks!\r\n",
            "link": "https://stackoverflow.com/questions/23078745/in-intellij-how-to-set-the-server-port-in-an-internal-jetty-run-configuration",
            "title": "In IntelliJ, how to set the server port in an internal jetty run configuration",
            "body": "<p>In IntelliJ 13.0.2 Ultimate I've set up a web application module using Jetty 9.1.4.</p>\n\n<p>I'd like to test my application on port 8100, but I can't figure out a way to change the port of my \"Local\" Jetty run configuration. It always seems to use the default port 8080.</p>\n\n<p>There is a setting for the port in the IntelliJ run configuration but it only appears when configuring a \"remote\" server.</p>\n\n<p>I've tried adding my own .mod file to the Jetty Server Settings containing the following but it seems to be ignored.</p>\n\n<pre><code>[ini-template]\njetty.port=8100\n</code></pre>\n\n<p>One of the answers in <a href=\"https://stackoverflow.com/questions/15654476/how-can-i-start-jetty-from-intellij-on-windows\">this post</a> says the port is 8080 unless you change it, but he doesn't say how to change it.</p>\n\n<p>Can someone point me in the right direction? Thanks!</p>\n"
        },
        {
            "tags": [
                "mysql",
                "linux"
            ],
            "owner": {
                "reputation": 64,
                "user_id": 9628596,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/kp8A0.png?s=128&g=1",
                "display_name": "arjun",
                "link": "https://stackoverflow.com/users/9628596/arjun"
            },
            "is_answered": false,
            "view_count": 20,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524656538,
            "creation_date": 1524656538,
            "question_id": 50021432,
            "body_markdown": "I have a mysql M-M replication setup configured, all Writes are directed to Server1 and reads on to server2. Load on Server1 is very high but very low on Server2. Whether I can write on both servers but different databases (say write on server1 database A, and the server2 one database B), then is it safer? Performance wise does it make sense to balance utilization of both servers?",
            "link": "https://stackoverflow.com/questions/50021432/mysql-master-master-replication-causes-high-load-on-master1",
            "title": "Mysql Master -Master replication causes high load on Master1",
            "body": "<p>I have a mysql M-M replication setup configured, all Writes are directed to Server1 and reads on to server2. Load on Server1 is very high but very low on Server2. Whether I can write on both servers but different databases (say write on server1 database A, and the server2 one database B), then is it safer? Performance wise does it make sense to balance utilization of both servers?</p>\n"
        },
        {
            "tags": [
                "c#",
                "jquery",
                "asp.net-mvc",
                "vb.net",
                "export-to-excel"
            ],
            "owner": {
                "reputation": 666,
                "user_id": 2393790,
                "user_type": "registered",
                "accept_rate": 82,
                "profile_image": "https://www.gravatar.com/avatar/154864ee1644082a99d4f0d807b72773?s=128&d=identicon&r=PG",
                "display_name": "Valuk",
                "link": "https://stackoverflow.com/users/2393790/valuk"
            },
            "is_answered": true,
            "view_count": 131612,
            "accepted_answer_id": 16670517,
            "answer_count": 8,
            "score": 66,
            "last_activity_date": 1524656538,
            "creation_date": 1369139858,
            "last_edit_date": 1495541445,
            "question_id": 16670209,
            "body_markdown": "I have a large(ish) form in MVC.\r\n\r\nI need to be able to generate an excel file containing data from a subset of that form. \r\n\r\nThe tricky bit is that this shouldn&#39;t affect the rest of the form and so I want to do it via AJAX. I&#39;ve come across a few questions on SO that seem to be related, but I can&#39;t quite work out what the answers mean.\r\n\r\nThis one seems the closest to what I&#39;m after: [asp-net-mvc-downloading-excel][1] - but I&#39;m not sure I understand the response, and it is a couple years old now. I also came across another article (can&#39;t find it anymore) about using an iframe to handle the file download, but I&#39;m not sure how to get this working with MVC.\r\n\r\nMy excel file returns fine if I&#39;m doing a full post back but I can&#39;t get it working with AJAX in mvc.\r\n\r\n\r\n  [1]: https://stackoverflow.com/questions/6747532/asp-net-mvc-downloading-excel",
            "link": "https://stackoverflow.com/questions/16670209/download-excel-file-via-ajax-mvc",
            "title": "Download Excel file via AJAX MVC",
            "body": "<p>I have a large(ish) form in MVC.</p>\n\n<p>I need to be able to generate an excel file containing data from a subset of that form. </p>\n\n<p>The tricky bit is that this shouldn't affect the rest of the form and so I want to do it via AJAX. I've come across a few questions on SO that seem to be related, but I can't quite work out what the answers mean.</p>\n\n<p>This one seems the closest to what I'm after: <a href=\"https://stackoverflow.com/questions/6747532/asp-net-mvc-downloading-excel\">asp-net-mvc-downloading-excel</a> - but I'm not sure I understand the response, and it is a couple years old now. I also came across another article (can't find it anymore) about using an iframe to handle the file download, but I'm not sure how to get this working with MVC.</p>\n\n<p>My excel file returns fine if I'm doing a full post back but I can't get it working with AJAX in mvc.</p>\n"
        },
        {
            "tags": [
                "glassfish"
            ],
            "owner": {
                "reputation": 303,
                "user_id": 2223820,
                "user_type": "registered",
                "accept_rate": 17,
                "profile_image": "https://www.gravatar.com/avatar/2a8bf5e62c36e7975289cfe0d646281b?s=128&d=identicon&r=PG",
                "display_name": "user2223820",
                "link": "https://stackoverflow.com/users/2223820/user2223820"
            },
            "is_answered": true,
            "view_count": 2031,
            "answer_count": 2,
            "score": 1,
            "last_activity_date": 1524656529,
            "creation_date": 1390908249,
            "last_edit_date": 1473632514,
            "question_id": 21404270,
            "body_markdown": "I am facing to following error when I try to deploy ear to GlassFish server.\r\nDo you have any idea?\r\n\r\n    [#|2014-01-28T19:54:39.068+0900|SEVERE|glassfish3.1.1|javax.enterprise.system.tools.admin.org.glassfish.deployment.admin|_ThreadID=24;_ThreadName=Thread-2;|Exception while loading the app : EJB Container initialization error\r\n    java.lang.RuntimeException: IIOP Protocol Manager initialization failed.  Possible cause is that ORB is not available in this container\r\n    \tat com.sun.ejb.containers.BaseContainer.initializeProtocolManager(BaseContainer.java:821)\r\n    \tat com.sun.ejb.containers.BaseContainer.&lt;init&gt;(BaseContainer.java:566)\r\n    \tat com.sun.ejb.containers.StatelessSessionContainer.&lt;init&gt;(StatelessSessionContainer.java:155)\r\n    \tat com.sun.ejb.containers.StatelessSessionContainer.&lt;init&gt;(StatelessSessionContainer.java:149)\r\n    \tat com.sun.ejb.containers.ContainerFactoryImpl.createContainer(ContainerFactoryImpl.java:105)\r\n    \tat org.glassfish.ejb.startup.EjbApplication.loadContainers(EjbApplication.java:230)\r\n    \tat org.glassfish.ejb.startup.EjbDeployer.load(EjbDeployer.java:290)\r\n    \tat org.glassfish.ejb.startup.EjbDeployer.load(EjbDeployer.java:101)\r\n    \tat org.glassfish.internal.data.ModuleInfo.load(ModuleInfo.java:186)\r\n    \tat org.glassfish.internal.data.ApplicationInfo.load(ApplicationInfo.java:257)\r\n    \tat com.sun.enterprise.v3.server.ApplicationLifecycle.deploy(ApplicationLifecycle.java:461)\r\n    \tat com.sun.enterprise.v3.server.ApplicationLifecycle.deploy(ApplicationLifecycle.java:240)\r\n    \tat org.glassfish.deployment.admin.DeployCommand.execute(DeployCommand.java:382)\r\n    \tat com.sun.enterprise.v3.admin.CommandRunnerImpl$1.execute(CommandRunnerImpl.java:355)\r\n    \tat com.sun.enterprise.v3.admin.CommandRunnerImpl.doCommand(CommandRunnerImpl.java:370)\r\n    \tat com.sun.enterprise.v3.admin.CommandRunnerImpl.doCommand(CommandRunnerImpl.java:1064)\r\n    \tat com.sun.enterprise.v3.admin.CommandRunnerImpl.access$1200(CommandRunnerImpl.java:96)\r\n    \tat com.sun.enterprise.v3.admin.CommandRunnerImpl$ExecutionContext.execute(CommandRunnerImpl.java:1244)\r\n    \tat com.sun.enterprise.v3.admin.CommandRunnerImpl$ExecutionContext.execute(CommandRunnerImpl.java:1232)\r\n    \tat org.glassfish.admin.rest.ResourceUtil.runCommand(ResourceUtil.java:202)\r\n    \tat org.glassfish.admin.rest.ResourceUtil.runCommand(ResourceUtil.java:195)\r\n    \tat org.glassfish.admin.rest.resources.TemplateListOfResource.createResource(TemplateListOfResource.java:148)\r\n    \tat sun.reflect.GeneratedMethodAccessor1819.invoke(Unknown Source)\r\n    \tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\r\n    \tat java.lang.reflect.Method.invoke(Method.java:597)\r\n    \tat com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\r\n    \tat com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)\r\n    \tat com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\r\n    \tat com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\r\n    \tat com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:134)\r\n    \tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\r\n    \tat com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:134)\r\n    \tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\r\n    \tat com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\r\n    \tat com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\r\n    \tat com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\r\n    \tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\r\n    \tat com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\r\n    \tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\r\n    \tat com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\r\n    \tat com.sun.jersey.server.impl.container.grizzly.GrizzlyContainer._service(GrizzlyContainer.java:182)\r\n    \tat com.sun.jersey.server.impl.container.grizzly.GrizzlyContainer.service(GrizzlyContainer.java:147)\r\n    \tat org.glassfish.admin.rest.adapter.RestAdapter.service(RestAdapter.java:184)\r\n    \tat com.sun.grizzly.tcp.http11.GrizzlyAdapter.service(GrizzlyAdapter.java:168)\r\n    \tat com.sun.enterprise.v3.server.HK2Dispatcher.dispath(HK2Dispatcher.java:117)\r\n    \tat com.sun.enterprise.v3.services.impl.ContainerMapper.service(ContainerMapper.java:238)\r\n    \tat com.sun.grizzly.http.ProcessorTask.invokeAdapter(ProcessorTask.java:828)\r\n    \tat com.sun.grizzly.http.ProcessorTask.doProcess(ProcessorTask.java:725)\r\n    \tat com.sun.grizzly.http.ProcessorTask.process(ProcessorTask.java:1019)\r\n    \tat com.sun.grizzly.http.DefaultProtocolFilter.execute(DefaultProtocolFilter.java:225)\r\n    \tat com.sun.grizzly.DefaultProtocolChain.executeProtocolFilter(DefaultProtocolChain.java:137)\r\n    \tat com.sun.grizzly.DefaultProtocolChain.execute(DefaultProtocolChain.java:104)\r\n    \tat com.sun.grizzly.DefaultProtocolChain.execute(DefaultProtocolChain.java:90)\r\n    \tat com.sun.grizzly.http.HttpProtocolChain.execute(HttpProtocolChain.java:79)\r\n    \tat com.sun.grizzly.ProtocolChainContextTask.doCall(ProtocolChainContextTask.java:54)\r\n    \tat com.sun.grizzly.SelectionKeyContextTask.call(SelectionKeyContextTask.java:59)\r\n    \tat com.sun.grizzly.ContextTask.run(ContextTask.java:71)\r\n    \tat com.sun.grizzly.util.AbstractThreadPool$Worker.doWork(AbstractThreadPool.java:532)\r\n    \tat com.sun.grizzly.util.AbstractThreadPool$Worker.run(AbstractThreadPool.java:513)\r\n    \tat java.lang.Thread.run(Thread.java:662)\r\n    Caused by: java.lang.RuntimeException: Orb initialization erorr\r\n    \tat org.glassfish.enterprise.iiop.api.GlassFishORBHelper.getORB(GlassFishORBHelper.java:180)\r\n    \tat org.glassfish.enterprise.iiop.api.GlassFishORBHelper.getProtocolManager(GlassFishORBHelper.java:219)\r\n    \tat com.sun.ejb.containers.BaseContainer.initializeProtocolManager(BaseContainer.java:818)\r\n    \t... 59 more\r\n    Caused by: java.lang.RuntimeException: java.lang.IllegalStateException: Invalid iiop-listener orb-listener-1. Lazy-init not supported for SSL iiop-listeners\r\n    \tat org.glassfish.enterprise.iiop.impl.GlassFishORBManager.initORB(GlassFishORBManager.java:622)\r\n    \tat org.glassfish.enterprise.iiop.impl.GlassFishORBManager.getORB(GlassFishORBManager.java:263)\r\n    \tat org.glassfish.enterprise.iiop.impl.GlassFishORBFactoryImpl.createORB(GlassFishORBFactoryImpl.java:93)\r\n    \tat org.glassfish.enterprise.iiop.api.GlassFishORBHelper.getORB(GlassFishORBHelper.java:152)\r\n    \t... 61 more\r\n    Caused by: java.lang.IllegalStateException: Invalid iiop-listener orb-listener-1. Lazy-init not supported for SSL iiop-listeners\r\n    \tat org.glassfish.enterprise.iiop.impl.GlassFishORBManager.validateIiopListeners(GlassFishORBManager.java:758)\r\n    \tat org.glassfish.enterprise.iiop.impl.GlassFishORBManager.initORB(GlassFishORBManager.java:504)\r\n    \t... 64 more",
            "link": "https://stackoverflow.com/questions/21404270/error-in-deploying-ear-to-glassfish",
            "title": "Error in deploying ear to GlassFish",
            "body": "<p>I am facing to following error when I try to deploy ear to GlassFish server.\nDo you have any idea?</p>\n\n<pre><code>[#|2014-01-28T19:54:39.068+0900|SEVERE|glassfish3.1.1|javax.enterprise.system.tools.admin.org.glassfish.deployment.admin|_ThreadID=24;_ThreadName=Thread-2;|Exception while loading the app : EJB Container initialization error\njava.lang.RuntimeException: IIOP Protocol Manager initialization failed.  Possible cause is that ORB is not available in this container\n    at com.sun.ejb.containers.BaseContainer.initializeProtocolManager(BaseContainer.java:821)\n    at com.sun.ejb.containers.BaseContainer.&lt;init&gt;(BaseContainer.java:566)\n    at com.sun.ejb.containers.StatelessSessionContainer.&lt;init&gt;(StatelessSessionContainer.java:155)\n    at com.sun.ejb.containers.StatelessSessionContainer.&lt;init&gt;(StatelessSessionContainer.java:149)\n    at com.sun.ejb.containers.ContainerFactoryImpl.createContainer(ContainerFactoryImpl.java:105)\n    at org.glassfish.ejb.startup.EjbApplication.loadContainers(EjbApplication.java:230)\n    at org.glassfish.ejb.startup.EjbDeployer.load(EjbDeployer.java:290)\n    at org.glassfish.ejb.startup.EjbDeployer.load(EjbDeployer.java:101)\n    at org.glassfish.internal.data.ModuleInfo.load(ModuleInfo.java:186)\n    at org.glassfish.internal.data.ApplicationInfo.load(ApplicationInfo.java:257)\n    at com.sun.enterprise.v3.server.ApplicationLifecycle.deploy(ApplicationLifecycle.java:461)\n    at com.sun.enterprise.v3.server.ApplicationLifecycle.deploy(ApplicationLifecycle.java:240)\n    at org.glassfish.deployment.admin.DeployCommand.execute(DeployCommand.java:382)\n    at com.sun.enterprise.v3.admin.CommandRunnerImpl$1.execute(CommandRunnerImpl.java:355)\n    at com.sun.enterprise.v3.admin.CommandRunnerImpl.doCommand(CommandRunnerImpl.java:370)\n    at com.sun.enterprise.v3.admin.CommandRunnerImpl.doCommand(CommandRunnerImpl.java:1064)\n    at com.sun.enterprise.v3.admin.CommandRunnerImpl.access$1200(CommandRunnerImpl.java:96)\n    at com.sun.enterprise.v3.admin.CommandRunnerImpl$ExecutionContext.execute(CommandRunnerImpl.java:1244)\n    at com.sun.enterprise.v3.admin.CommandRunnerImpl$ExecutionContext.execute(CommandRunnerImpl.java:1232)\n    at org.glassfish.admin.rest.ResourceUtil.runCommand(ResourceUtil.java:202)\n    at org.glassfish.admin.rest.ResourceUtil.runCommand(ResourceUtil.java:195)\n    at org.glassfish.admin.rest.resources.TemplateListOfResource.createResource(TemplateListOfResource.java:148)\n    at sun.reflect.GeneratedMethodAccessor1819.invoke(Unknown Source)\n    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)\n    at java.lang.reflect.Method.invoke(Method.java:597)\n    at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)\n    at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)\n    at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)\n    at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:288)\n    at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:134)\n    at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n    at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:134)\n    at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n    at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)\n    at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)\n    at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)\n    at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1469)\n    at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1400)\n    at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1349)\n    at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1339)\n    at com.sun.jersey.server.impl.container.grizzly.GrizzlyContainer._service(GrizzlyContainer.java:182)\n    at com.sun.jersey.server.impl.container.grizzly.GrizzlyContainer.service(GrizzlyContainer.java:147)\n    at org.glassfish.admin.rest.adapter.RestAdapter.service(RestAdapter.java:184)\n    at com.sun.grizzly.tcp.http11.GrizzlyAdapter.service(GrizzlyAdapter.java:168)\n    at com.sun.enterprise.v3.server.HK2Dispatcher.dispath(HK2Dispatcher.java:117)\n    at com.sun.enterprise.v3.services.impl.ContainerMapper.service(ContainerMapper.java:238)\n    at com.sun.grizzly.http.ProcessorTask.invokeAdapter(ProcessorTask.java:828)\n    at com.sun.grizzly.http.ProcessorTask.doProcess(ProcessorTask.java:725)\n    at com.sun.grizzly.http.ProcessorTask.process(ProcessorTask.java:1019)\n    at com.sun.grizzly.http.DefaultProtocolFilter.execute(DefaultProtocolFilter.java:225)\n    at com.sun.grizzly.DefaultProtocolChain.executeProtocolFilter(DefaultProtocolChain.java:137)\n    at com.sun.grizzly.DefaultProtocolChain.execute(DefaultProtocolChain.java:104)\n    at com.sun.grizzly.DefaultProtocolChain.execute(DefaultProtocolChain.java:90)\n    at com.sun.grizzly.http.HttpProtocolChain.execute(HttpProtocolChain.java:79)\n    at com.sun.grizzly.ProtocolChainContextTask.doCall(ProtocolChainContextTask.java:54)\n    at com.sun.grizzly.SelectionKeyContextTask.call(SelectionKeyContextTask.java:59)\n    at com.sun.grizzly.ContextTask.run(ContextTask.java:71)\n    at com.sun.grizzly.util.AbstractThreadPool$Worker.doWork(AbstractThreadPool.java:532)\n    at com.sun.grizzly.util.AbstractThreadPool$Worker.run(AbstractThreadPool.java:513)\n    at java.lang.Thread.run(Thread.java:662)\nCaused by: java.lang.RuntimeException: Orb initialization erorr\n    at org.glassfish.enterprise.iiop.api.GlassFishORBHelper.getORB(GlassFishORBHelper.java:180)\n    at org.glassfish.enterprise.iiop.api.GlassFishORBHelper.getProtocolManager(GlassFishORBHelper.java:219)\n    at com.sun.ejb.containers.BaseContainer.initializeProtocolManager(BaseContainer.java:818)\n    ... 59 more\nCaused by: java.lang.RuntimeException: java.lang.IllegalStateException: Invalid iiop-listener orb-listener-1. Lazy-init not supported for SSL iiop-listeners\n    at org.glassfish.enterprise.iiop.impl.GlassFishORBManager.initORB(GlassFishORBManager.java:622)\n    at org.glassfish.enterprise.iiop.impl.GlassFishORBManager.getORB(GlassFishORBManager.java:263)\n    at org.glassfish.enterprise.iiop.impl.GlassFishORBFactoryImpl.createORB(GlassFishORBFactoryImpl.java:93)\n    at org.glassfish.enterprise.iiop.api.GlassFishORBHelper.getORB(GlassFishORBHelper.java:152)\n    ... 61 more\nCaused by: java.lang.IllegalStateException: Invalid iiop-listener orb-listener-1. Lazy-init not supported for SSL iiop-listeners\n    at org.glassfish.enterprise.iiop.impl.GlassFishORBManager.validateIiopListeners(GlassFishORBManager.java:758)\n    at org.glassfish.enterprise.iiop.impl.GlassFishORBManager.initORB(GlassFishORBManager.java:504)\n    ... 64 more\n</code></pre>\n"
        },
        {
            "tags": [
                "java",
                "lambda",
                "java-8",
                "method-reference"
            ],
            "owner": {
                "reputation": 181,
                "user_id": 1773702,
                "user_type": "registered",
                "accept_rate": 44,
                "profile_image": "https://www.gravatar.com/avatar/c8a1f07bf80fa3a855d8bdc0f2062892?s=128&d=identicon&r=PG",
                "display_name": "azaveri7",
                "link": "https://stackoverflow.com/users/1773702/azaveri7"
            },
            "is_answered": false,
            "view_count": 49,
            "closed_date": 1524656472,
            "answer_count": 0,
            "score": -1,
            "last_activity_date": 1524656525,
            "creation_date": 1524656135,
            "question_id": 50021279,
            "body_markdown": "I have written a code as follows;\r\n\r\n    employee.getAddress().stream().map(y -&gt; y.getBusinessCode()).collect(Collectors.toList());\r\n\r\nBasically I want to return list of business code contained in each address object.\r\ngetAddress() method of Employee returns a list of employee.\r\n\r\nThe above code is working fine but giving a warning in sonar as \r\n\r\n    y -&gt; y.getBusinessCode()\r\n\r\n \r\n\r\nLambda should be converted to method reference and it is bad code smell.\r\n\r\nWhat could be changed here?",
            "link": "https://stackoverflow.com/questions/50021279/how-to-replace-lambda-with-method-reference",
            "closed_reason": "duplicate",
            "title": "How to replace lambda with method reference",
            "body": "<p>I have written a code as follows;</p>\n\n<pre><code>employee.getAddress().stream().map(y -&gt; y.getBusinessCode()).collect(Collectors.toList());\n</code></pre>\n\n<p>Basically I want to return list of business code contained in each address object.\ngetAddress() method of Employee returns a list of employee.</p>\n\n<p>The above code is working fine but giving a warning in sonar as </p>\n\n<pre><code>y -&gt; y.getBusinessCode()\n</code></pre>\n\n<p>Lambda should be converted to method reference and it is bad code smell.</p>\n\n<p>What could be changed here?</p>\n"
        },
        {
            "tags": [
                "mysql",
                "druid"
            ],
            "owner": {
                "reputation": 1444,
                "user_id": 3736230,
                "user_type": "registered",
                "accept_rate": 82,
                "profile_image": "https://www.gravatar.com/avatar/f2e379224cbcbebe468a74406ba85fed?s=128&d=identicon&r=PG",
                "display_name": "Set Kyar Wa Lar",
                "link": "https://stackoverflow.com/users/3736230/set-kyar-wa-lar"
            },
            "is_answered": false,
            "view_count": 23,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524656524,
            "creation_date": 1524109634,
            "question_id": 49912394,
            "body_markdown": "I finish setting up Druid on my computer by reading [quickstart guide](http://druid.io/docs/latest/tutorials/quickstart.html). I do setup MySQL extension by reading [MySQL Metadata Store](http://druid.io/docs/latest/development/extensions-core/mysql.html) as well.\r\n\r\nBut, when I sign to mysql to \r\n\r\n    mysql -u druid -p dirud\r\n\r\nI got `druid` table only.I don&#39;t have any data that I imported with the following command via example.\r\n\r\n    curl -X &#39;POST&#39; -H &#39;Content-Type:application/json&#39; -d @quickstart/wikiticker-index.json localhost:8090/druid/indexer/v1/task\r\n\r\nI saw `Success` status on Druid console `http://localhost:8090/console.html` as well. \r\n\r\nThe following is my `common.runtime.properties` for mysql setup\r\n\r\n    druid.metadata.storage.type=mysql\r\n    druid.metadata.storage.connector.connectURI=jdbc:mysql://127.0.0.1:3306/druid\r\n    druid.metadata.storage.connector.user=druid\r\n    druid.metadata.storage.connector.password=diurd\r\n\r\nIs something wrong with my setup?\r\n\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49912394/connecting-druid-with-mysql",
            "title": "Connecting Druid with MySQL",
            "body": "<p>I finish setting up Druid on my computer by reading <a href=\"http://druid.io/docs/latest/tutorials/quickstart.html\" rel=\"nofollow noreferrer\">quickstart guide</a>. I do setup MySQL extension by reading <a href=\"http://druid.io/docs/latest/development/extensions-core/mysql.html\" rel=\"nofollow noreferrer\">MySQL Metadata Store</a> as well.</p>\n\n<p>But, when I sign to mysql to </p>\n\n<pre><code>mysql -u druid -p dirud\n</code></pre>\n\n<p>I got <code>druid</code> table only.I don't have any data that I imported with the following command via example.</p>\n\n<pre><code>curl -X 'POST' -H 'Content-Type:application/json' -d @quickstart/wikiticker-index.json localhost:8090/druid/indexer/v1/task\n</code></pre>\n\n<p>I saw <code>Success</code> status on Druid console <code>http://localhost:8090/console.html</code> as well. </p>\n\n<p>The following is my <code>common.runtime.properties</code> for mysql setup</p>\n\n<pre><code>druid.metadata.storage.type=mysql\ndruid.metadata.storage.connector.connectURI=jdbc:mysql://127.0.0.1:3306/druid\ndruid.metadata.storage.connector.user=druid\ndruid.metadata.storage.connector.password=diurd\n</code></pre>\n\n<p>Is something wrong with my setup?</p>\n"
        },
        {
            "tags": [
                "java",
                "parallel-processing",
                "aes",
                "executorservice",
                "multicore"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 7974675,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/1898208403783860/picture?type=large",
                "display_name": "Sohel",
                "link": "https://stackoverflow.com/users/7974675/sohel"
            },
            "is_answered": false,
            "view_count": 60,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524656509,
            "creation_date": 1524654857,
            "last_edit_date": 1524656509,
            "question_id": 50020861,
            "body_markdown": "This program takes input files sequentially but all tasks execute in parallel using a single core. The execution time for all tasks is longer than sequential execution time. I want to reduce the execution time using multiple cores by executing the tasks in parallel. How can I do that? How can I use multi-core in this program? I want to use at least two cores.\r\n\r\n    package TestParallel;\r\n\r\n    import java.io.File;\r\n    import java.io.FileInputStream;\r\n    import java.io.FileOutputStream;\r\n    import java.io.ObjectOutputStream;\r\n    import java.util.concurrent.ExecutorService;\r\n    import java.util.concurrent.Executors;\r\n    import java.util.concurrent.TimeUnit;\r\n    import java.util.logging.Level;\r\n    import java.util.logging.Logger;\r\n    import javax.crypto.Cipher;\r\n    import javax.crypto.CipherOutputStream;\r\n    import javax.crypto.KeyGenerator;\r\n    import javax.crypto.SecretKey;\r\n\r\n    /**\r\n     *\r\n     * @author Sohel Rana\r\n     */\r\n    public class Executor {\r\n\r\n        public void encrypt(File fname) throws Exception {\r\n            System.out.println(&quot;Encryption Started : &quot; + System.currentTimeMillis() + &quot; File Name : &quot; + fname);\r\n            KeyGenerator keyGen = KeyGenerator.getInstance(&quot;AES&quot;);\r\n            keyGen.init(256);  //using AES-256\r\n            SecretKey key = keyGen.generateKey();  //generating key\r\n            //  System.out.println(&quot;Key = &quot; + bytesToHex(key.getEncoded()));\r\n            Cipher aesCipher = Cipher.getInstance(&quot;AES&quot;);  //getting cipher for AES\r\n            aesCipher.init(Cipher.ENCRYPT_MODE, key);  //initializing cipher for encryption with key\r\n\r\n            //creating file output stream to write to file\r\n            try (FileOutputStream fos = new FileOutputStream(fname + &quot;.aes&quot;)) {\r\n                //creating object output stream to write objects to file\r\n                ObjectOutputStream oos = new ObjectOutputStream(fos);\r\n                oos.writeObject(key);  //saving key to file for use during decryption\r\n\r\n                //creating file input stream to read contents for encryption\r\n                try (FileInputStream fis = new FileInputStream(fname)) {\r\n                    //creating cipher output stream to write encrypted contents\r\n                    try (CipherOutputStream cos = new CipherOutputStream(fos, aesCipher)) {\r\n                        int read;\r\n                        byte buf[] = new byte[4096];\r\n                        while ((read = fis.read(buf)) != -1) //reading from file\r\n                        {\r\n                            cos.write(buf, 0, read);  //encrypting and writing to file\r\n                        }\r\n                    }\r\n                }\r\n                System.out.print(&quot;\\nComplete Time = &quot; + System.currentTimeMillis());\r\n                System.out.println(&quot; \\tand file task complete :&quot; + fname);\r\n                //  fname.delete();\r\n            }\r\n\r\n        }\r\n\r\n        public static void main(final String[] args) throws InterruptedException {\r\n            // final ExecutorService pool = Executors.newFixedThreadPool(4);\r\n            int cores = Runtime.getRuntime().availableProcessors();\r\n            System.out.println(&quot;Available processor cores is &quot; + cores);\r\n            File file1 = new File(&quot;C:\\\\Users\\\\Sohel Rana\\\\Desktop\\\\test\\\\Khushnuma Official Video HD - Suyyash Rai &amp; Kishwer Merchant_HD.mp4&quot;);\r\n            File file2 = new File(&quot;C:\\\\Users\\\\Sohel Rana\\\\Desktop\\\\test\\\\EK MULAQAT - Sonali Cable HD.mp4&quot;);\r\n            File file3 = new File(&quot;C:\\\\Users\\\\Sohel Rana\\\\Desktop\\\\test\\\\Java Cryptography Tutorials 1 AES Encryption and Decryption using Java.mp4&quot;);\r\n            File file4 = new File(&quot;C:\\\\Users\\\\Sohel Rana\\\\Desktop\\\\test\\\\01. Nath Nath.MP4&quot;);\r\n\r\n            Executor ex = new Executor();\r\n            final ExecutorService executor = Executors.newFixedThreadPool(cores);\r\n            long startTime = System.currentTimeMillis();\r\n            for (File f : new File[]{file1, file2, file3, file4}) {\r\n                startTime = System.currentTimeMillis();\r\n                executor.execute(() -&gt; {\r\n                    try {\r\n                        ex.encrypt(f);\r\n                        //System.out.println(f);\r\n                    } catch (Exception ex1) {\r\n                        Logger.getLogger(Executor.class.getName()).log(Level.SEVERE, null, ex1);\r\n\r\n                    }\r\n                });\r\n            }\r\n\r\n            executor.shutdown();\r\n\r\n            if (executor.awaitTermination(1, TimeUnit.DAYS)) {\r\n            } else {\r\n                executor.shutdownNow();\r\n            }\r\n            long endTime = System.currentTimeMillis();\r\n\r\n            System.out.println(&quot;\\nParalle Execution Time : &quot; + (endTime - startTime)\r\n                    + &quot; milliseconds.&quot;);\r\n\r\n        }\r\n    }\r\n",
            "link": "https://stackoverflow.com/questions/50020861/multi-core-programming-in-java",
            "title": "Multi-core programming in Java",
            "body": "<p>This program takes input files sequentially but all tasks execute in parallel using a single core. The execution time for all tasks is longer than sequential execution time. I want to reduce the execution time using multiple cores by executing the tasks in parallel. How can I do that? How can I use multi-core in this program? I want to use at least two cores.</p>\n\n<pre><code>package TestParallel;\n\nimport java.io.File;\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.io.ObjectOutputStream;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.TimeUnit;\nimport java.util.logging.Level;\nimport java.util.logging.Logger;\nimport javax.crypto.Cipher;\nimport javax.crypto.CipherOutputStream;\nimport javax.crypto.KeyGenerator;\nimport javax.crypto.SecretKey;\n\n/**\n *\n * @author Sohel Rana\n */\npublic class Executor {\n\n    public void encrypt(File fname) throws Exception {\n        System.out.println(\"Encryption Started : \" + System.currentTimeMillis() + \" File Name : \" + fname);\n        KeyGenerator keyGen = KeyGenerator.getInstance(\"AES\");\n        keyGen.init(256);  //using AES-256\n        SecretKey key = keyGen.generateKey();  //generating key\n        //  System.out.println(\"Key = \" + bytesToHex(key.getEncoded()));\n        Cipher aesCipher = Cipher.getInstance(\"AES\");  //getting cipher for AES\n        aesCipher.init(Cipher.ENCRYPT_MODE, key);  //initializing cipher for encryption with key\n\n        //creating file output stream to write to file\n        try (FileOutputStream fos = new FileOutputStream(fname + \".aes\")) {\n            //creating object output stream to write objects to file\n            ObjectOutputStream oos = new ObjectOutputStream(fos);\n            oos.writeObject(key);  //saving key to file for use during decryption\n\n            //creating file input stream to read contents for encryption\n            try (FileInputStream fis = new FileInputStream(fname)) {\n                //creating cipher output stream to write encrypted contents\n                try (CipherOutputStream cos = new CipherOutputStream(fos, aesCipher)) {\n                    int read;\n                    byte buf[] = new byte[4096];\n                    while ((read = fis.read(buf)) != -1) //reading from file\n                    {\n                        cos.write(buf, 0, read);  //encrypting and writing to file\n                    }\n                }\n            }\n            System.out.print(\"\\nComplete Time = \" + System.currentTimeMillis());\n            System.out.println(\" \\tand file task complete :\" + fname);\n            //  fname.delete();\n        }\n\n    }\n\n    public static void main(final String[] args) throws InterruptedException {\n        // final ExecutorService pool = Executors.newFixedThreadPool(4);\n        int cores = Runtime.getRuntime().availableProcessors();\n        System.out.println(\"Available processor cores is \" + cores);\n        File file1 = new File(\"C:\\\\Users\\\\Sohel Rana\\\\Desktop\\\\test\\\\Khushnuma Official Video HD - Suyyash Rai &amp; Kishwer Merchant_HD.mp4\");\n        File file2 = new File(\"C:\\\\Users\\\\Sohel Rana\\\\Desktop\\\\test\\\\EK MULAQAT - Sonali Cable HD.mp4\");\n        File file3 = new File(\"C:\\\\Users\\\\Sohel Rana\\\\Desktop\\\\test\\\\Java Cryptography Tutorials 1 AES Encryption and Decryption using Java.mp4\");\n        File file4 = new File(\"C:\\\\Users\\\\Sohel Rana\\\\Desktop\\\\test\\\\01. Nath Nath.MP4\");\n\n        Executor ex = new Executor();\n        final ExecutorService executor = Executors.newFixedThreadPool(cores);\n        long startTime = System.currentTimeMillis();\n        for (File f : new File[]{file1, file2, file3, file4}) {\n            startTime = System.currentTimeMillis();\n            executor.execute(() -&gt; {\n                try {\n                    ex.encrypt(f);\n                    //System.out.println(f);\n                } catch (Exception ex1) {\n                    Logger.getLogger(Executor.class.getName()).log(Level.SEVERE, null, ex1);\n\n                }\n            });\n        }\n\n        executor.shutdown();\n\n        if (executor.awaitTermination(1, TimeUnit.DAYS)) {\n        } else {\n            executor.shutdownNow();\n        }\n        long endTime = System.currentTimeMillis();\n\n        System.out.println(\"\\nParalle Execution Time : \" + (endTime - startTime)\n                + \" milliseconds.\");\n\n    }\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "jmeter"
            ],
            "owner": {
                "reputation": 133,
                "user_id": 5615185,
                "user_type": "registered",
                "accept_rate": 94,
                "profile_image": "https://www.gravatar.com/avatar/296bd9a45daccda359dee5c219f6625f?s=128&d=identicon&r=PG&f=1",
                "display_name": "J. Doem",
                "link": "https://stackoverflow.com/users/5615185/j-doem"
            },
            "is_answered": true,
            "view_count": 17,
            "accepted_answer_id": 50020743,
            "answer_count": 2,
            "score": 1,
            "last_activity_date": 1524656508,
            "creation_date": 1524654076,
            "last_edit_date": 1524655526,
            "question_id": 50020601,
            "body_markdown": "I have condition where I need to load properties file and assign prop value to JMeter UDV.\r\n\r\nI have been able to load property file successful, however I can not assign prop value to UDV\r\n\r\nI have try the following:\r\n\r\n 1. Load prop file contain key value (i.e `var_from_prop_file=1000`)\r\n 2. Create UDV (with keyname &quot;`my.var`&quot; and value &quot;`${var_from_prop_file}`&quot;)\r\n\r\nRun debug script with debug sampler, I can see `var_from_prop_file` assigned to value `1000`\r\n\r\nHowever my.var still empty (no value). \r\nmy expectation when creating UDV with `my.var = ${var_from_prop_file}`, `my.var` value will be `1000` too, but it doesn&#39;t happen here.\r\n\r\nI have try with `__eval` and _`_evalVar` - no luck so far.\r\n\r\nIs it possible to reference jmeter variable to properties file key?\r\nand call variable in other place?\r\n\r\n\r\nSo far from debug sampler - looks like jmeter load UDV first and then jmeter properties not the way around.",
            "link": "https://stackoverflow.com/questions/50020601/load-properties-file-in-jmeter-then-assign-properties-value-to-jmeter-variable",
            "title": "Load properties file in jmeter then assign properties value to JMeter variable",
            "body": "<p>I have condition where I need to load properties file and assign prop value to JMeter UDV.</p>\n\n<p>I have been able to load property file successful, however I can not assign prop value to UDV</p>\n\n<p>I have try the following:</p>\n\n<ol>\n<li>Load prop file contain key value (i.e <code>var_from_prop_file=1000</code>)</li>\n<li>Create UDV (with keyname \"<code>my.var</code>\" and value \"<code>${var_from_prop_file}</code>\")</li>\n</ol>\n\n<p>Run debug script with debug sampler, I can see <code>var_from_prop_file</code> assigned to value <code>1000</code></p>\n\n<p>However my.var still empty (no value). \nmy expectation when creating UDV with <code>my.var = ${var_from_prop_file}</code>, <code>my.var</code> value will be <code>1000</code> too, but it doesn't happen here.</p>\n\n<p>I have try with <code>__eval</code> and _<code>_evalVar</code> - no luck so far.</p>\n\n<p>Is it possible to reference jmeter variable to properties file key?\nand call variable in other place?</p>\n\n<p>So far from debug sampler - looks like jmeter load UDV first and then jmeter properties not the way around.</p>\n"
        },
        {
            "tags": [
                "javascript",
                "html",
                "svg",
                "w3c"
            ],
            "owner": {
                "reputation": 603,
                "user_id": 2105307,
                "user_type": "registered",
                "accept_rate": 55,
                "profile_image": "https://www.gravatar.com/avatar/168fc5da6bf6836cd3a66e18b4d61fa3?s=128&d=identicon&r=PG",
                "display_name": "NikosDim",
                "link": "https://stackoverflow.com/users/2105307/nikosdim"
            },
            "is_answered": true,
            "view_count": 721,
            "accepted_answer_id": 21777774,
            "answer_count": 2,
            "score": 3,
            "last_activity_date": 1524656507,
            "creation_date": 1392375194,
            "question_id": 21777376,
            "body_markdown": "I just started reading about `svg` and I came up with the following question\r\n\r\nI am creating a simple `svg` with a `text` inside as shown below. \r\n\r\nFrom my reading I understood that `x` and `y` of the `text` tag declares the position of the text inside the `svg` space. \r\n\r\nWhy when I set both `x` and `y` to `0` the text does not appear and when I change `x` and `y` to `10` for example it is displayed? Isn&#39;t `x=0` and `y=0` meaning the top left corner of the svg tag? \r\n\r\nThanks\r\n\r\n    &lt;svg width=&quot;200&quot; height=&quot;100&quot;&gt;\r\n       &lt;text x=&quot;0&quot; y=&quot;0&quot;&gt;hello&lt;/text&gt;\r\n    &lt;/svg&gt;",
            "link": "https://stackoverflow.com/questions/21777376/why-svg-text-disappears-when-setting-x-and-y-to-0",
            "title": "Why svg text disappears when setting x and y to 0?",
            "body": "<p>I just started reading about <code>svg</code> and I came up with the following question</p>\n\n<p>I am creating a simple <code>svg</code> with a <code>text</code> inside as shown below. </p>\n\n<p>From my reading I understood that <code>x</code> and <code>y</code> of the <code>text</code> tag declares the position of the text inside the <code>svg</code> space. </p>\n\n<p>Why when I set both <code>x</code> and <code>y</code> to <code>0</code> the text does not appear and when I change <code>x</code> and <code>y</code> to <code>10</code> for example it is displayed? Isn't <code>x=0</code> and <code>y=0</code> meaning the top left corner of the svg tag? </p>\n\n<p>Thanks</p>\n\n<pre><code>&lt;svg width=\"200\" height=\"100\"&gt;\n   &lt;text x=\"0\" y=\"0\"&gt;hello&lt;/text&gt;\n&lt;/svg&gt;\n</code></pre>\n"
        },
        {
            "tags": [
                "scala",
                "apache-spark",
                "spark-dataframe"
            ],
            "owner": {
                "reputation": 74,
                "user_id": 6203336,
                "user_type": "registered",
                "accept_rate": 77,
                "profile_image": "https://www.gravatar.com/avatar/69fbb998f318006a5bed1a34b9de6bb0?s=128&d=identicon&r=PG&f=1",
                "display_name": "Mert",
                "link": "https://stackoverflow.com/users/6203336/mert"
            },
            "is_answered": false,
            "view_count": 24,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524656505,
            "creation_date": 1524656505,
            "question_id": 50021421,
            "body_markdown": "I am new to Spark and I would like to read a CSV-file to a Dataframe.\r\n\r\nSpark 1.3.0 / Scala 2.3.0\r\n\r\nThis is what I have so far:\r\n\r\n    # Start Scala with CSV Package Module\r\n    spark-shell --packages com.databricks:spark-csv_2.10:1.3.0\r\n    \r\n    # Import Spark Classes\r\n    import org.apache.spark.SparkContext\r\n    import org.apache.spark.SparkConf\r\n    import org.apache.spark.sql.SQLContext\r\n    import sqlCtx ._\r\n    \r\n    # Create SparkConf\r\n    val conf = new SparkConf().setAppName(&quot;local&quot;).setMaster(&quot;master&quot;)\r\n    val sc = new SparkContext(conf)\r\n    \r\n    # Create SQLContext\r\n    val sqlCtx = new SQLContext(sc)\r\n    \r\n    # Create SparkSession and use it for all purposes:\r\n    val session = SparkSession.builder().appName(&quot;local&quot;).master(&quot;master&quot;).getOrCreate()\r\n    \r\n    # Read CSV-File and turn it into Dataframe.\r\n    val df_fc = sqlContext.read.format(&quot;com.databricks.spark.csv&quot;).option(&quot;header&quot;, &quot;true&quot;).load(&quot;/home/Desktop/test.csv&quot;)\r\n\r\nHowever at `SparkSession.builder()` it gives the following error:\r\n\r\n[![enter image description here][1]][1]\r\n                     ^\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/Hv1k5.png\r\n\r\n\r\nHow can I fix this error?",
            "link": "https://stackoverflow.com/questions/50021421/how-to-fix-22-error-not-found-value-sparksession-in-scala",
            "title": "How to fix 22: error: not found: value SparkSession in Scala?",
            "body": "<p>I am new to Spark and I would like to read a CSV-file to a Dataframe.</p>\n\n<p>Spark 1.3.0 / Scala 2.3.0</p>\n\n<p>This is what I have so far:</p>\n\n<pre><code># Start Scala with CSV Package Module\nspark-shell --packages com.databricks:spark-csv_2.10:1.3.0\n\n# Import Spark Classes\nimport org.apache.spark.SparkContext\nimport org.apache.spark.SparkConf\nimport org.apache.spark.sql.SQLContext\nimport sqlCtx ._\n\n# Create SparkConf\nval conf = new SparkConf().setAppName(\"local\").setMaster(\"master\")\nval sc = new SparkContext(conf)\n\n# Create SQLContext\nval sqlCtx = new SQLContext(sc)\n\n# Create SparkSession and use it for all purposes:\nval session = SparkSession.builder().appName(\"local\").master(\"master\").getOrCreate()\n\n# Read CSV-File and turn it into Dataframe.\nval df_fc = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").load(\"/home/Desktop/test.csv\")\n</code></pre>\n\n<p>However at <code>SparkSession.builder()</code> it gives the following error:</p>\n\n<p><a href=\"https://i.stack.imgur.com/Hv1k5.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/Hv1k5.png\" alt=\"enter image description here\"></a>\n                     ^</p>\n\n<p>How can I fix this error?</p>\n"
        },
        {
            "tags": [
                "reactjs",
                "react-redux"
            ],
            "owner": {
                "reputation": 1484,
                "user_id": 1901521,
                "user_type": "registered",
                "accept_rate": 67,
                "profile_image": "https://www.gravatar.com/avatar/04cb82d8c5717b69cfcf3efdc1a56b63?s=128&d=identicon&r=PG",
                "display_name": "Bomber",
                "link": "https://stackoverflow.com/users/1901521/bomber"
            },
            "is_answered": true,
            "view_count": 38,
            "accepted_answer_id": 50021417,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524656500,
            "creation_date": 1524648938,
            "last_edit_date": 1524650049,
            "question_id": 50018806,
            "body_markdown": "I have the following action:\r\n\r\n`{type: &quot;SET_GROUP&quot;, group: 68, categories: Array(3), year: 64}`\r\n\r\nIn my reducer I have the following code:\r\n\r\n        case &quot;SET_GROUP&quot;:\r\n            const { group } = action;\r\n\r\n            const showStudent = !checkEmptyArray(action);\r\n            return { ...state, group, showStudent };\r\n\r\nHowever, `group` is never added to the state:\r\n\r\n    {year: 64, group: 0, student: 0, showStudent: true}\r\n\r\nAny ideas?\r\n\r\nReducer:\r\n\r\n    export function setCredentials(state = initialState, action) {\r\n        switch (action.type) {\r\n            case &quot;SET_YEAR&quot;:\r\n                return {\r\n                    ...state,\r\n                    year: action.year,\r\n                    group: 0,\r\n                    student: 0\r\n                };\r\n            case &quot;SET_STUDENT&quot;:\r\n                return { ...state, student: action.student };\r\n            case &quot;SET_GROUP&quot;:\r\n                const { group } = action;\r\n    \r\n                const showStudent = !checkEmptyArray(action);\r\n    \r\n                return { ...state, group, showStudent };\r\n            case &quot;CLEAR_CREDENTIALS&quot;:\r\n                return initialState;\r\n    \r\n            default:\r\n                return state;\r\n        }\r\n    }\r\n\r\nInitialState:\r\n\r\n    const initialState = {\r\n        year: 0,\r\n        group: 0,\r\n        student: 0,\r\n        showStudent: false\r\n    };",
            "link": "https://stackoverflow.com/questions/50018806/reducer-not-updating-state-with-destructed-property",
            "title": "Reducer not updating state with destructed property",
            "body": "<p>I have the following action:</p>\n\n<p><code>{type: \"SET_GROUP\", group: 68, categories: Array(3), year: 64}</code></p>\n\n<p>In my reducer I have the following code:</p>\n\n<pre><code>    case \"SET_GROUP\":\n        const { group } = action;\n\n        const showStudent = !checkEmptyArray(action);\n        return { ...state, group, showStudent };\n</code></pre>\n\n<p>However, <code>group</code> is never added to the state:</p>\n\n<pre><code>{year: 64, group: 0, student: 0, showStudent: true}\n</code></pre>\n\n<p>Any ideas?</p>\n\n<p>Reducer:</p>\n\n<pre><code>export function setCredentials(state = initialState, action) {\n    switch (action.type) {\n        case \"SET_YEAR\":\n            return {\n                ...state,\n                year: action.year,\n                group: 0,\n                student: 0\n            };\n        case \"SET_STUDENT\":\n            return { ...state, student: action.student };\n        case \"SET_GROUP\":\n            const { group } = action;\n\n            const showStudent = !checkEmptyArray(action);\n\n            return { ...state, group, showStudent };\n        case \"CLEAR_CREDENTIALS\":\n            return initialState;\n\n        default:\n            return state;\n    }\n}\n</code></pre>\n\n<p>InitialState:</p>\n\n<pre><code>const initialState = {\n    year: 0,\n    group: 0,\n    student: 0,\n    showStudent: false\n};\n</code></pre>\n"
        },
        {
            "tags": [
                "c++",
                "types"
            ],
            "owner": {
                "reputation": 191,
                "user_id": 6860744,
                "user_type": "registered",
                "accept_rate": 79,
                "profile_image": "https://lh5.googleusercontent.com/-3_2Ewze_gI8/AAAAAAAAAAI/AAAAAAAAACQ/fz_BqGtzSd4/photo.jpg?sz=128",
                "display_name": "Darius Duesentrieb",
                "link": "https://stackoverflow.com/users/6860744/darius-duesentrieb"
            },
            "is_answered": true,
            "view_count": 61,
            "accepted_answer_id": 50019287,
            "answer_count": 3,
            "score": 1,
            "last_activity_date": 1524656498,
            "creation_date": 1524649004,
            "last_edit_date": 1524650208,
            "question_id": 50018829,
            "body_markdown": "I want to use a datatype with a different name (create a duplicate of a type).\r\nI don&#39;t want to use &#39;typedef&#39; since that only creates a `#define`/macro like an alias.\r\n\r\n    #include &lt;iostream&gt;\r\n\r\n    typedef int AnInt;\r\n    \r\n    struct Number\r\n    {\r\n        int a;\r\n    };\r\n    \r\n    template&lt;typename T&gt;\r\n    T var;\r\n    \r\n    int main()\r\n    {\r\n        var&lt;int&gt; = 5;\r\n        var&lt;AnInt&gt; = 7; // does not what i want (this changes var&lt;int&gt;)\r\n        var&lt;Number&gt;.a = 7;\r\n        return 0;\r\n    }\r\n\r\nThis works exactly how I want it to work but I always need to access the type with the postfix `.a`.\r\nIs there a way to avoid this?\r\n\r\n##Edit:\r\n\r\nThe real-world application is that I have a `vec3` datatype and now I need to different datatypes `Position` and `Velocity` that are essentially a single `vec3`. They need to be different because I use an entity-component system that is based on templates.",
            "link": "https://stackoverflow.com/questions/50018829/c-how-to-duplicate-a-datatype",
            "title": "C++: How to duplicate a datatype?",
            "body": "<p>I want to use a datatype with a different name (create a duplicate of a type).\nI don't want to use 'typedef' since that only creates a <code>#define</code>/macro like an alias.</p>\n\n<pre><code>#include &lt;iostream&gt;\n\ntypedef int AnInt;\n\nstruct Number\n{\n    int a;\n};\n\ntemplate&lt;typename T&gt;\nT var;\n\nint main()\n{\n    var&lt;int&gt; = 5;\n    var&lt;AnInt&gt; = 7; // does not what i want (this changes var&lt;int&gt;)\n    var&lt;Number&gt;.a = 7;\n    return 0;\n}\n</code></pre>\n\n<p>This works exactly how I want it to work but I always need to access the type with the postfix <code>.a</code>.\nIs there a way to avoid this?</p>\n\n<h2>Edit:</h2>\n\n<p>The real-world application is that I have a <code>vec3</code> datatype and now I need to different datatypes <code>Position</code> and <code>Velocity</code> that are essentially a single <code>vec3</code>. They need to be different because I use an entity-component system that is based on templates.</p>\n"
        },
        {
            "tags": [
                "hbase"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 5323723,
                "user_type": "registered",
                "profile_image": "https://lh6.googleusercontent.com/-Dcrfn0cN0Uc/AAAAAAAAAAI/AAAAAAAAABg/4moLcPx_VWc/photo.jpg?sz=128",
                "display_name": "junjie lee",
                "link": "https://stackoverflow.com/users/5323723/junjie-lee"
            },
            "is_answered": false,
            "view_count": 8,
            "closed_date": 1524668512,
            "answer_count": 0,
            "score": -2,
            "last_activity_date": 1524656497,
            "creation_date": 1524656497,
            "question_id": 50021415,
            "body_markdown": "\r\n[hbase UI web &quot;Num. Compacted KVs&quot;，why the number is bigger than others. thanks!][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/fnSXV.png\r\n",
            "link": "https://stackoverflow.com/questions/50021415/hbase-num-compacted-kvs-maldistribution",
            "closed_reason": "unclear what you&#39;re asking",
            "title": "hbase Num. Compacted KVs maldistribution",
            "body": "<p><a href=\"https://i.stack.imgur.com/fnSXV.png\" rel=\"nofollow noreferrer\">hbase UI web \"Num. Compacted KVs\"，why the number is bigger than others. thanks!</a></p>\n"
        },
        {
            "tags": [
                "r",
                "testthat",
                "covr"
            ],
            "owner": {
                "reputation": 37,
                "user_id": 3286743,
                "user_type": "registered",
                "accept_rate": 75,
                "profile_image": "https://www.gravatar.com/avatar/d4dc2f1d439265d626302a5a811c1a4c?s=128&d=identicon&r=PG&f=1",
                "display_name": "Robert",
                "link": "https://stackoverflow.com/users/3286743/robert"
            },
            "is_answered": false,
            "view_count": 10,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524656484,
            "creation_date": 1524656484,
            "question_id": 50021412,
            "body_markdown": "I would like to run tests for a package with `testthat` and compute code coverage with `covr`. Furthermore, the results from `testthat` should be saved in the JUnit XML format and the results from `covr` should be saved in the Cobertura format.\r\n\r\nThe following code does the trick (when `getwd()` is the root of the package):\r\n\r\n    options(&quot;testthat.output_file&quot; = &quot;test-results.xml&quot;)\r\n    devtools::test(reporter = testthat::JunitReporter$new())\r\n    \r\n    cov &lt;- covr::package_coverage()\r\n    covr::to_cobertura(cov, &quot;coverage.xml&quot;)\r\n\r\nHowever, the tests are executed *twice*. Once with `devtools::test` and once with `covr::package_coverage`. \r\n\r\nMy understanding is that `covr::package_coverage` executes the tests, but it does not produce `test-results.xml`.\r\n\r\nAs the title suggests, I would like get both `test-results.xml` and `coverage.xml` with a single execution of the test suite.",
            "link": "https://stackoverflow.com/questions/50021412/testthat-and-covr-in-one-go",
            "title": "Testthat and covr in one go",
            "body": "<p>I would like to run tests for a package with <code>testthat</code> and compute code coverage with <code>covr</code>. Furthermore, the results from <code>testthat</code> should be saved in the JUnit XML format and the results from <code>covr</code> should be saved in the Cobertura format.</p>\n\n<p>The following code does the trick (when <code>getwd()</code> is the root of the package):</p>\n\n<pre><code>options(\"testthat.output_file\" = \"test-results.xml\")\ndevtools::test(reporter = testthat::JunitReporter$new())\n\ncov &lt;- covr::package_coverage()\ncovr::to_cobertura(cov, \"coverage.xml\")\n</code></pre>\n\n<p>However, the tests are executed <em>twice</em>. Once with <code>devtools::test</code> and once with <code>covr::package_coverage</code>. </p>\n\n<p>My understanding is that <code>covr::package_coverage</code> executes the tests, but it does not produce <code>test-results.xml</code>.</p>\n\n<p>As the title suggests, I would like get both <code>test-results.xml</code> and <code>coverage.xml</code> with a single execution of the test suite.</p>\n"
        },
        {
            "tags": [
                "mysql",
                "database",
                "oracle",
                "design",
                "middleware"
            ],
            "owner": {
                "reputation": 65,
                "user_id": 9062446,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/4b8db106a0b4ebaf4a762a20d4cb6a5d?s=128&d=identicon&r=PG&f=1",
                "display_name": "Juli&#225;n",
                "link": "https://stackoverflow.com/users/9062446/juli%c3%a1n"
            },
            "is_answered": false,
            "view_count": 20,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524656477,
            "creation_date": 1524656477,
            "question_id": 50021410,
            "body_markdown": "I work with Apache Camel and sometimes I have to insert or update databases with complex JSON/XML files created in the front and I&#39;m doubting whether I should manage those JSON/XML files in Camel and send them as a series of queries to the Database or sending them to the database after some data validation and let a store procedure do the work.\r\n\r\nI like the latter the most, as I see Camel as a messaging application. But I do know that it can ve a very powerful tool for this kind of thing. I&#39;m also somewhat new to Camel and I find it VERY difficult to learn and get the information I need.\r\n\r\nOn the other hand I&#39;m experienced with databases and I have no problem creating a stored procedure that reads JSON/XML. However, we have multiple databases from multiple brands, mainly Oracle and MySQL, and I can see how code maintenance can be a bit of a problem here. \r\n\r\nMiddle may be the only option in case of lack privileges.\r\n\r\nCan someone tell me what&#39;s the best design route or what things I should consider when dealing with this kind of problem?\r\n\r\nI&#39;ve left the frontend out of the question, but it can also be considered.",
            "link": "https://stackoverflow.com/questions/50021410/data-processing-in-middle-vs-back",
            "title": "Data processing in middle vs back",
            "body": "<p>I work with Apache Camel and sometimes I have to insert or update databases with complex JSON/XML files created in the front and I'm doubting whether I should manage those JSON/XML files in Camel and send them as a series of queries to the Database or sending them to the database after some data validation and let a store procedure do the work.</p>\n\n<p>I like the latter the most, as I see Camel as a messaging application. But I do know that it can ve a very powerful tool for this kind of thing. I'm also somewhat new to Camel and I find it VERY difficult to learn and get the information I need.</p>\n\n<p>On the other hand I'm experienced with databases and I have no problem creating a stored procedure that reads JSON/XML. However, we have multiple databases from multiple brands, mainly Oracle and MySQL, and I can see how code maintenance can be a bit of a problem here. </p>\n\n<p>Middle may be the only option in case of lack privileges.</p>\n\n<p>Can someone tell me what's the best design route or what things I should consider when dealing with this kind of problem?</p>\n\n<p>I've left the frontend out of the question, but it can also be considered.</p>\n"
        },
        {
            "tags": [
                "android",
                "firebase",
                "firebase-cloud-messaging",
                "dagger"
            ],
            "owner": {
                "reputation": 66,
                "user_id": 4562580,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/364799797055312/picture?type=large",
                "display_name": "Viktor  Burmaka",
                "link": "https://stackoverflow.com/users/4562580/viktor-burmaka"
            },
            "is_answered": false,
            "view_count": 381,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524656471,
            "creation_date": 1491837412,
            "last_edit_date": 1491907470,
            "question_id": 43326991,
            "body_markdown": "I try to migrate from GCM to FCM. I read this [guide][1]. I clone code from [firebase quikstart app][2] everything works great. But if I try to implement in my app I have a ploblem.\r\n\r\nI try to send several messages from firebase console and status some of them &quot;Completed&quot; but I receive nothing in my app... Excluding the first few messages I get all the time: Unregistered registration token. For sending I use token from FirebaseInstanceId.getInstance().getToken() \r\n[![firebase dashboard][3]][3]\r\n\r\nI don&#39;t uderstand that is problem.\r\n\r\nmy InstanceIdService:\r\n\r\n    public class MyInstanceIDListenerService\r\n            extends FirebaseInstanceIdService {\r\n    \r\n        @Inject\r\n        FCMTokenProvider FCMTokenProvider;\r\n    \r\n        @Override\r\n        public void onCreate() {\r\n            super.onCreate();\r\n            MyApplication application = (MyApplication)getApplication();\r\n            application.getComponent().inject(this);\r\n        }\r\n    \r\n        @Override\r\n        public void onTokenRefresh() {\r\n        String newToken = FirebaseInstanceId.getInstance().getToken();\r\n        FCMTokenProvider.initialize(getApplicationContext());\r\n        }\r\n    }\r\n\r\n my FirebaseMessagingService:\r\n\r\n    @EService\r\n    public class FcmMessageListenerService\r\n        extends FirebaseMessagingService {\r\n\r\n    @Inject\r\n    MessageDispatcher messageDispatcher;\r\n\r\n    @Override\r\n    public void onCreate() {\r\n        super.onCreate();\r\n        MyApplication application = (MyApplication)getApplication();\r\n        application.getComponent().inject(this);\r\n    }\r\n\r\n\r\n\r\n    @Override\r\n    public void onMessageReceived(RemoteMessage message){\r\n                MyApplication application = (MyApplication)getApplication();\r\n\r\n\r\n        if(application == null)\r\n            return;\r\n\r\n        if (message == null)\r\n            return;\r\n\r\n        String from = message.getFrom();\r\n\r\n        Map&lt;String, String&gt; stringData = message.getData();\r\n        Bundle data = new Bundle();\r\n        for(String key: stringData.keySet()){\r\n            data.putString(key, stringData.get(key));\r\n        }\r\n        messageDispatcher.handleMessage(from, data,application.getCurrentActivity());\r\n    }\r\n    }\r\n\r\npart of my Manifest:\r\n\r\n    &lt;application&gt;\r\n    ...\r\n    &lt;service\r\n       android:name=&quot;.infrastructure.fcm.services.FcmMessageListenerService_&quot;&gt;\r\n         &lt;intent-filter&gt;\r\n           &lt;action android:name=&quot;com.google.firebase.MESSAGING_EVENT&quot;/&gt;\r\n         &lt;/intent-filter&gt;\r\n    &lt;/service&gt;\r\n    &lt;service\r\n       android:name=&quot;.infrastructure.fcm.services.MyInstanceIDListenerService&quot;&gt;\r\n      &lt;intent-filter&gt;\r\n        &lt;action android:name=&quot;com.google.firebase.INSTANCE_ID_EVENT&quot;/&gt;\r\n      &lt;/intent-filter&gt;\r\n    &lt;/service&gt;\r\n    ...\r\n    &lt;/application&gt;\r\n\r\npart of my build.gradle:\r\n\r\n    def GcmVersion = &#39;10.2.1&#39;\r\n    ...\r\n    compile &quot;com.google.android.gms:play-services-base:$GcmVersion&quot;\r\n    compile &quot;com.google.android.gms:play-services-identity:$GcmVersion&quot;\r\n    compile &quot;com.google.android.gms:play-services-maps:$GcmVersion&quot;\r\n    compile &quot;com.google.android.gms:play-services-location:$GcmVersion&quot;\r\n    compile &quot;com.google.android.gms:play-services-wallet:$GcmVersion&quot;\r\n    compile &quot;com.google.android.gms:play-services-ads:$GcmVersion&quot;\r\n    compile &quot;com.google.android.gms:play-services-auth:$GcmVersion&quot;\r\n    compile &quot;com.google.android.gms:play-services-cast-framework:$GcmVersion&quot;\r\n    compile &quot;com.google.android.gms:play-services-vision:$GcmVersion&quot;\r\n    compile &quot;com.google.android.gms:play-services-places:$GcmVersion&quot;\r\n\r\n    compile &quot;com.google.firebase:firebase-core:$GcmVersion&quot;\r\n    compile &quot;com.google.firebase:firebase-appindexing:$GcmVersion&quot;\r\n    compile &quot;com.google.firebase:firebase-messaging:$GcmVersion&quot;\r\n    ...\r\n    apply plugin: &#39;com.google.gms.google-services&#39;\r\n\r\nI had one problem with the old version of Dagger 2 and Firebase. I just updated the version of Dagger 2 to 2.9\r\n\r\nI will be grateful for any help.\r\n\r\n**UPDATE**\r\n\r\nmy renamed and updated GCMTokenProvider:\r\n\r\n    @Singleton\r\n    public class FCMTokenProvider {\r\n    \r\n        private static final String TAG = &quot;FCMTokenProvider&quot;;\r\n    \r\n        private String fcmToken;\r\n    \r\n        @Inject\r\n        public FCMTokenProvider(){\r\n    \r\n        }\r\n    \r\n        public void initialize(Context applicationContext){\r\n                this.fcmToken = FirebaseInstanceId.getInstance().getToken();\r\n                if(!Strings.isNullOrEmpty(fcmToken)){\r\n                    EventBus.getDefault().post(new FcmToken(fcmToken));\r\n                }\r\n    \r\n                Log.d(TAG, &quot;run: fcm token: &quot;+ fcmToken);\r\n        }\r\n    \r\n        public String getFcmToken() {\r\n            return fcmToken;\r\n        }\r\n    \r\n    }\r\n\r\ninitialize() is called on every app start.\r\n\r\n  [1]: https://developers.google.com/cloud-messaging/android/android-migrate-fcm\r\n  [2]: https://github.com/firebase/quickstart-android\r\n  [3]: https://i.stack.imgur.com/399nq.png\r\n",
            "link": "https://stackoverflow.com/questions/43326991/gcm-to-fcm-migrate-firebase-not-working-unregistered-registration-token",
            "title": "GCM to FCM migrate. Firebase not working. Unregistered registration token",
            "body": "<p>I try to migrate from GCM to FCM. I read this <a href=\"https://developers.google.com/cloud-messaging/android/android-migrate-fcm\" rel=\"nofollow noreferrer\">guide</a>. I clone code from <a href=\"https://github.com/firebase/quickstart-android\" rel=\"nofollow noreferrer\">firebase quikstart app</a> everything works great. But if I try to implement in my app I have a ploblem.</p>\n\n<p>I try to send several messages from firebase console and status some of them \"Completed\" but I receive nothing in my app... Excluding the first few messages I get all the time: Unregistered registration token. For sending I use token from FirebaseInstanceId.getInstance().getToken() \n<a href=\"https://i.stack.imgur.com/399nq.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/399nq.png\" alt=\"firebase dashboard\"></a></p>\n\n<p>I don't uderstand that is problem.</p>\n\n<p>my InstanceIdService:</p>\n\n<pre><code>public class MyInstanceIDListenerService\n        extends FirebaseInstanceIdService {\n\n    @Inject\n    FCMTokenProvider FCMTokenProvider;\n\n    @Override\n    public void onCreate() {\n        super.onCreate();\n        MyApplication application = (MyApplication)getApplication();\n        application.getComponent().inject(this);\n    }\n\n    @Override\n    public void onTokenRefresh() {\n    String newToken = FirebaseInstanceId.getInstance().getToken();\n    FCMTokenProvider.initialize(getApplicationContext());\n    }\n}\n</code></pre>\n\n<p>my FirebaseMessagingService:</p>\n\n<pre><code>@EService\npublic class FcmMessageListenerService\n    extends FirebaseMessagingService {\n\n@Inject\nMessageDispatcher messageDispatcher;\n\n@Override\npublic void onCreate() {\n    super.onCreate();\n    MyApplication application = (MyApplication)getApplication();\n    application.getComponent().inject(this);\n}\n\n\n\n@Override\npublic void onMessageReceived(RemoteMessage message){\n            MyApplication application = (MyApplication)getApplication();\n\n\n    if(application == null)\n        return;\n\n    if (message == null)\n        return;\n\n    String from = message.getFrom();\n\n    Map&lt;String, String&gt; stringData = message.getData();\n    Bundle data = new Bundle();\n    for(String key: stringData.keySet()){\n        data.putString(key, stringData.get(key));\n    }\n    messageDispatcher.handleMessage(from, data,application.getCurrentActivity());\n}\n}\n</code></pre>\n\n<p>part of my Manifest:</p>\n\n<pre><code>&lt;application&gt;\n...\n&lt;service\n   android:name=\".infrastructure.fcm.services.FcmMessageListenerService_\"&gt;\n     &lt;intent-filter&gt;\n       &lt;action android:name=\"com.google.firebase.MESSAGING_EVENT\"/&gt;\n     &lt;/intent-filter&gt;\n&lt;/service&gt;\n&lt;service\n   android:name=\".infrastructure.fcm.services.MyInstanceIDListenerService\"&gt;\n  &lt;intent-filter&gt;\n    &lt;action android:name=\"com.google.firebase.INSTANCE_ID_EVENT\"/&gt;\n  &lt;/intent-filter&gt;\n&lt;/service&gt;\n...\n&lt;/application&gt;\n</code></pre>\n\n<p>part of my build.gradle:</p>\n\n<pre><code>def GcmVersion = '10.2.1'\n...\ncompile \"com.google.android.gms:play-services-base:$GcmVersion\"\ncompile \"com.google.android.gms:play-services-identity:$GcmVersion\"\ncompile \"com.google.android.gms:play-services-maps:$GcmVersion\"\ncompile \"com.google.android.gms:play-services-location:$GcmVersion\"\ncompile \"com.google.android.gms:play-services-wallet:$GcmVersion\"\ncompile \"com.google.android.gms:play-services-ads:$GcmVersion\"\ncompile \"com.google.android.gms:play-services-auth:$GcmVersion\"\ncompile \"com.google.android.gms:play-services-cast-framework:$GcmVersion\"\ncompile \"com.google.android.gms:play-services-vision:$GcmVersion\"\ncompile \"com.google.android.gms:play-services-places:$GcmVersion\"\n\ncompile \"com.google.firebase:firebase-core:$GcmVersion\"\ncompile \"com.google.firebase:firebase-appindexing:$GcmVersion\"\ncompile \"com.google.firebase:firebase-messaging:$GcmVersion\"\n...\napply plugin: 'com.google.gms.google-services'\n</code></pre>\n\n<p>I had one problem with the old version of Dagger 2 and Firebase. I just updated the version of Dagger 2 to 2.9</p>\n\n<p>I will be grateful for any help.</p>\n\n<p><strong>UPDATE</strong></p>\n\n<p>my renamed and updated GCMTokenProvider:</p>\n\n<pre><code>@Singleton\npublic class FCMTokenProvider {\n\n    private static final String TAG = \"FCMTokenProvider\";\n\n    private String fcmToken;\n\n    @Inject\n    public FCMTokenProvider(){\n\n    }\n\n    public void initialize(Context applicationContext){\n            this.fcmToken = FirebaseInstanceId.getInstance().getToken();\n            if(!Strings.isNullOrEmpty(fcmToken)){\n                EventBus.getDefault().post(new FcmToken(fcmToken));\n            }\n\n            Log.d(TAG, \"run: fcm token: \"+ fcmToken);\n    }\n\n    public String getFcmToken() {\n        return fcmToken;\n    }\n\n}\n</code></pre>\n\n<p>initialize() is called on every app start.</p>\n"
        },
        {
            "tags": [
                "c++",
                "oop"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 9578954,
                "user_type": "registered",
                "profile_image": "https://lh6.googleusercontent.com/-UMOTbzUeTFo/AAAAAAAAAAI/AAAAAAAAADU/I7_yZaXefDE/photo.jpg?sz=128",
                "display_name": "Aiden",
                "link": "https://stackoverflow.com/users/9578954/aiden"
            },
            "is_answered": false,
            "view_count": 64,
            "answer_count": 1,
            "score": -2,
            "last_activity_date": 1524656469,
            "creation_date": 1524635163,
            "last_edit_date": 1524635912,
            "question_id": 50014808,
            "body_markdown": "------ I changed sample code to my actual code ------\r\n\r\nIf I define objects like this(int separate function), how can i delete all of them in one function?\r\n\r\n\r\n    template &lt;typename T&gt;\r\n\tclass LinkedList\r\n\t{\r\n\r\n\tprivate:\r\n\t\tNode&lt;T&gt;*            mHead;\r\n\t\tunsigned int\t\tmSize;\r\n\r\n\tpublic:\r\n\t\tLinkedList();\r\n\t\t~LinkedList();\r\n\r\n\t\tvirtual T               get(const int index) const;\r\n\t\tvirtual bool\t\t\tset(const int index, const T&amp; data);\r\n\r\n\t\tvirtual bool\t\t\tinsert(const T&amp; data);\r\n\t\tvirtual bool\t\t\tinsert(const int index, const T&amp; data);\r\n\t\t//2번\r\n\t\tvirtual bool\t\t\tinsertHead(const T&amp; data); // 1번\r\n\r\n\t\tvirtual bool\t\t\tpop();\r\n\t\tvirtual bool\t\t\tpop(const int index);\r\n\r\n\t\tvirtual unsigned int    size()\tconst;\r\n\t\tvirtual bool\t\t\tempty() const;\r\n\r\n\t\tvirtual void\t\t\tclear();\r\n        .\r\n        .\r\n        .\r\n    }\r\n\r\n    template &lt;typename T&gt;\r\n\tbool LinkedList&lt;T&gt;::insertHead(const T&amp; data)\r\n\t{\r\n\t\tNode&lt;T&gt;* node = new Node&lt;T&gt;(data, mHead);\r\n\t\tmHead = node;\r\n\t\tmSize++;\r\n\r\n\t\treturn true;\r\n\t}\r\n\r\n    template &lt;typename T&gt;\r\n\tbool LinkedList&lt;T&gt;::insert(const T&amp; data)\r\n\t{\r\n\t\tif (mHead == NULL) \r\n\t\t{\r\n\t\t\treturn insertHead(data);\r\n\t\t\tmSize++;\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\tNode&lt;T&gt;* node = new Node&lt;T&gt;*(data);\r\n\t\t\tnode-&gt;mNextNode = mHead-&gt;mData;\r\n\t\t\tmSize++;\r\n\t\t}\r\n\t\treturn true;\r\n\t}\r\n    \r\nIn this code, I define `Node&lt;T&gt;* node` twice. Are they delete automatically when each function finished? If not, is there any way to delete each nodes in clear function?\r\n\r\n---If need more code, please comment---",
            "link": "https://stackoverflow.com/questions/50014808/how-can-i-delete-all-the-objectsmade-by-new-c",
            "title": "How can I `delete` all the objects(made by `new`)? - C++",
            "body": "<p>------ I changed sample code to my actual code ------</p>\n\n<p>If I define objects like this(int separate function), how can i delete all of them in one function?</p>\n\n<pre><code>template &lt;typename T&gt;\nclass LinkedList\n{\n\nprivate:\n    Node&lt;T&gt;*            mHead;\n    unsigned int        mSize;\n\npublic:\n    LinkedList();\n    ~LinkedList();\n\n    virtual T               get(const int index) const;\n    virtual bool            set(const int index, const T&amp; data);\n\n    virtual bool            insert(const T&amp; data);\n    virtual bool            insert(const int index, const T&amp; data);\n    //2번\n    virtual bool            insertHead(const T&amp; data); // 1번\n\n    virtual bool            pop();\n    virtual bool            pop(const int index);\n\n    virtual unsigned int    size()  const;\n    virtual bool            empty() const;\n\n    virtual void            clear();\n    .\n    .\n    .\n}\n\ntemplate &lt;typename T&gt;\nbool LinkedList&lt;T&gt;::insertHead(const T&amp; data)\n{\n    Node&lt;T&gt;* node = new Node&lt;T&gt;(data, mHead);\n    mHead = node;\n    mSize++;\n\n    return true;\n}\n\ntemplate &lt;typename T&gt;\nbool LinkedList&lt;T&gt;::insert(const T&amp; data)\n{\n    if (mHead == NULL) \n    {\n        return insertHead(data);\n        mSize++;\n    }\n    else\n    {\n        Node&lt;T&gt;* node = new Node&lt;T&gt;*(data);\n        node-&gt;mNextNode = mHead-&gt;mData;\n        mSize++;\n    }\n    return true;\n}\n</code></pre>\n\n<p>In this code, I define <code>Node&lt;T&gt;* node</code> twice. Are they delete automatically when each function finished? If not, is there any way to delete each nodes in clear function?</p>\n\n<p>---If need more code, please comment---</p>\n"
        },
        {
            "tags": [
                "ios",
                "json",
                "swift",
                "nsdate"
            ],
            "owner": {
                "reputation": 93,
                "user_id": 4420197,
                "user_type": "registered",
                "accept_rate": 50,
                "profile_image": "https://www.gravatar.com/avatar/34c8cf05edd628064eb5459ffacf81aa?s=128&d=identicon&r=PG&f=1",
                "display_name": "Kacper Cz",
                "link": "https://stackoverflow.com/users/4420197/kacper-cz"
            },
            "is_answered": false,
            "view_count": 34,
            "closed_date": 1524728860,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524656462,
            "creation_date": 1524656462,
            "question_id": 50021405,
            "body_markdown": "I&#39;m developing an application which shows a list of stores. The target behaviour is to use user&#39;s device locale settings to format weekday and opening times eg. (`Mon-Fri, 10:00-19:00` or `Monday-Friday, 10AM-7PM`)?\r\n\r\nWhat would be the most convenient way to transfer opening and closing times over the network using JSON format? Is there a way to convert ex. `Monday 10:00` to some kind of an integer and decode using `NSDateFormatter`, as it&#39;s done with Unix epoch time?",
            "link": "https://stackoverflow.com/questions/50021405/sending-store-opening-times-through-json",
            "closed_reason": "primarily opinion-based",
            "title": "Sending store opening times through JSON",
            "body": "<p>I'm developing an application which shows a list of stores. The target behaviour is to use user's device locale settings to format weekday and opening times eg. (<code>Mon-Fri, 10:00-19:00</code> or <code>Monday-Friday, 10AM-7PM</code>)?</p>\n\n<p>What would be the most convenient way to transfer opening and closing times over the network using JSON format? Is there a way to convert ex. <code>Monday 10:00</code> to some kind of an integer and decode using <code>NSDateFormatter</code>, as it's done with Unix epoch time?</p>\n"
        },
        {
            "tags": [
                "java",
                "mapreduce",
                "hadoop2"
            ],
            "owner": {
                "reputation": 268,
                "user_id": 2427078,
                "user_type": "registered",
                "accept_rate": 45,
                "profile_image": "https://i.stack.imgur.com/FqBsb.jpg?s=128&g=1",
                "display_name": "Mandrek",
                "link": "https://stackoverflow.com/users/2427078/mandrek"
            },
            "is_answered": false,
            "view_count": 21,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524656461,
            "creation_date": 1524476595,
            "last_edit_date": 1524506326,
            "question_id": 49977923,
            "body_markdown": "I have a dataset which contains emoployee satisfaction level index,dept ,last evaluation, number of projects etc.From that file i have to find the average satisfation index of each dept.I have used a custom  partitioner which is dividing the dataset according to the number of dept and calculating their avg satisfaction index.For example i have 9 depts in the input file,so the job has created 9 files but none of the file contains any data, I haveno idea how to solve this .Here is mycomplete code and the dataset,\r\n\r\n    satisfaction_level,last_evaluation,number_project,average_montly_hours,time_spend_company,Work_accident,left,promotion_last_5years,sales,salary\r\n    0.38,0.53,2,157,3,0,1,0,sales,low\r\n    0.8,0.86,5,262,6,0,1,0,sales,medium\r\n    0.11,0.88,7,272,4,0,1,0,sales,medium\r\n    0.41,0.46,2,128,3,0,1,0,accounting,low\r\n    0.38,0.5,2,132,3,0,1,0,accounting,low\r\n    0.09,0.62,6,294,4,0,1,0,accounting,low\r\n    0.45,0.57,2,134,3,0,1,0,hr,low\r\n    0.4,0.51,2,145,3,0,1,0,hr,low\r\n    0.45,0.55,2,140,3,0,1,0,hr,low\r\n    0.84,0.87,4,246,6,0,1,0,hr,low\r\n    0.1,0.94,6,255,4,0,1,0,technical,low\r\n    0.38,0.46,2,137,3,0,1,0,technical,low\r\n    0.45,0.5,2,126,3,0,1,0,technical,low\r\n    ................................  etc\r\nCode \r\n\r\nThe mapper\r\n\r\n    public class AverageSatisfactionMapper extends Mapper&lt;LongWritable,Text,Text,FloatWritable&gt;{\r\n\r\n\t\r\n\tpublic void map(LongWritable key,Text value,Context context){\r\n\t\t\r\n\t\tString [] tokens = value.toString().split(&quot;,&quot;);\r\n\t\ttry{\r\n\t\t\tFloat satisfactionIndex = Float.parseFloat(tokens[0]);\r\n\t\t\tcontext.write(value, new FloatWritable(satisfactionIndex));\r\n\t\t}catch(Exception exception){\r\n\t\t\texception.printStackTrace();\r\n\t\t}\r\n\t\t\r\n\t}\r\n    }\r\n\r\nThe Reducer\r\n\r\n      public class AverageSatisfactionReducer extends Reducer&lt;Text, FloatWritable, Text, Text&gt;{\r\n\r\n\tpublic void reduce(Text key,Iterable&lt;FloatWritable&gt; valueList,Context context){\r\n\t\ttry{\r\n\t\t\tFloat total = (float)0;\r\n\t\t\tint count =0;\r\n\t\t\tfor(FloatWritable var:valueList){\r\n\t\t\t\ttotal+=var.get();\r\n\t\t\t\tSystem.out.println(&quot;reducer :&quot;+var.get());\r\n\t\t\t\tcount++;\r\n\t\t\t}\r\n\t\t\tFloat avg = (Float)total/count;\r\n\t\t\tString out = &quot;Total: &quot; + total + &quot; :: &quot; + &quot;Average: &quot; + avg;\r\n\t\t\tcontext.write(key, new Text(out));\r\n\t\t}catch(Exception e){\r\n\t\te.printStackTrace();\r\n\t\t}\r\n\t}\r\n    }\r\n\r\nThe Partitioner\r\n\r\n   public class AverageSatisfactionPartitioner extends Partitioner&lt;Text,Text&gt;{\r\n\r\n\t@Override\r\n\tpublic int getPartition(Text key, Text value, int numReduceTasks) {\r\n\t\tint partitionNo = 0;\r\n\t\tString [] tokens = value.toString().split(&quot;,&quot;);\r\n\t\tString dept = tokens[8];\r\n\t\tif(numReduceTasks!=0){\r\n\t\t\tif(dept.equals(&quot;sales&quot;))\r\n\t\t\t\tpartitionNo = 0;\r\n\t\t\telse if(dept.equals(&quot;accounting&quot;))\r\n\t\t\t\tpartitionNo = 1;\r\n\t\t\telse if(dept.equals(&quot;hr&quot;))\r\n\t\t\t\tpartitionNo=2;\r\n\t\t\telse if(dept.equals(&quot;technical&quot;))\r\n\t\t\t\tpartitionNo=3;\r\n\t\t\telse if(dept.equals(&quot;support&quot;))\r\n\t\t\t\tpartitionNo=4;\r\n\t\t\telse if(dept.equals(&quot;IT&quot;))\r\n\t\t\t\tpartitionNo=5;\r\n\t\t\telse if(dept.equals(&quot;product_mng&quot;))\r\n\t\t\t\tpartitionNo=6;\r\n\t\t\telse if(dept.equals(&quot;marketing&quot;))\r\n\t\t\t\tpartitionNo=7;\r\n\t\t\telse if(dept.equals(&quot;management&quot;))\r\n\t\t\t\tpartitionNo=8;\r\n\t\t}\r\n\t\treturn partitionNo;\r\n\t}\r\n\r\n     }\r\n\r\nThe Driver class\r\n\r\n\r\n    public class AverageSatisfactionDriver {\r\n\r\n\tpublic static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {\r\n\t\tConfiguration conf = new Configuration();\r\n\t\tString[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\r\n\t\tif (otherArgs.length != 2)\r\n\t\t{\r\n\t\t\tSystem.err.println(&quot;Usage: Employee Salary Anaysis &lt;input&gt; &lt;output&gt;&quot;);\r\n\t\t\tSystem.exit(2);\r\n\t\t}\r\n\t\tJob job = new Job(conf, &quot;Employee Satisfaction Anaysis&quot;);\r\n\t\tjob.setJobName(&quot;Custmom Patitioner&quot;);\r\n\t\tjob.setJarByClass(AverageSatisfactionDriver.class);\r\n\t\tjob.setMapperClass(AverageSatisfactionMapper.class);\r\n\t\tjob.setReducerClass(AverageSatisfactionReducer.class);\r\n\t\tjob.setPartitionerClass(AverageSatisfactionPartitioner.class);\t\t\t\t//Set custom partitioner class\r\n\r\n\t\tjob.setNumReduceTasks(9);\r\n\t\tjob.setMapOutputKeyClass(Text.class);\r\n\t\tjob.setMapOutputValueClass(Text.class);\r\n\t\tjob.setOutputKeyClass(NullWritable.class);\r\n\t\tjob.setOutputValueClass(Text.class);\r\n\t\t\r\n\t\tFileInputFormat.addInputPath(job, new Path(otherArgs[0]));\r\n\t\tFileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));\r\n\t\tSystem.exit(job.waitForCompletion(true) ? 0 : 1);\r\n\t\t\r\n\r\n\t}\r\n\r\n    }\r\nThis is the output log of the job \r\n\r\n\r\n\r\n    18/04/23 14:16:54 INFO mapreduce.Job:  map 0% reduce 0%\r\n    18/04/23 14:17:42 INFO mapreduce.Job:  map 13% reduce 0%\r\n    18/04/23 14:17:46 INFO mapreduce.Job:  map 22% reduce 0%\r\n    18/04/23 14:17:49 INFO mapreduce.Job:  map 30% reduce 0%\r\n    18/04/23 14:17:52 INFO mapreduce.Job:  map 40% reduce 0%\r\n    18/04/23 14:17:55 INFO mapreduce.Job:  map 54% reduce 0%\r\n    18/04/23 14:17:58 INFO mapreduce.Job:  map 63% reduce 0%\r\n    18/04/23 14:18:00 INFO mapreduce.Job:  map 100% reduce 0%\r\n    18/04/23 14:18:47 INFO mapreduce.Job:  map 100% reduce 7%\r\n    18/04/23 14:18:52 INFO mapreduce.Job:  map 100% reduce 11%\r\n    18/04/23 14:19:03 INFO mapreduce.Job:  map 100% reduce 19%\r\n    18/04/23 14:19:09 INFO mapreduce.Job:  map 100% reduce 22%\r\n    18/04/23 14:19:16 INFO mapreduce.Job:  map 100% reduce 33%\r\n    18/04/23 14:19:25 INFO mapreduce.Job:  map 100% reduce 44%\r\n    18/04/23 14:19:29 INFO mapreduce.Job:  map 100% reduce 52%\r\n    18/04/23 14:19:42 INFO mapreduce.Job:  map 100% reduce 63%\r\n    18/04/23 14:19:45 INFO mapreduce.Job:  map 100% reduce 67%\r\n    18/04/23 14:20:09 INFO mapreduce.Job:  map 100% reduce 78%\r\n    18/04/23 14:20:11 INFO mapreduce.Job:  map 100% reduce 89%\r\n    18/04/23 14:20:13 INFO mapreduce.Job:  map 100% reduce 100%\r\n    18/04/23 14:20:16 INFO mapreduce.Job: Job job_1523849056360_0028 completed successfully\r\n    18/04/23 14:20:16 INFO mapreduce.Job: Counters: 50\r\n\t  File System Counters\r\n\t\tFILE: Number of bytes read=54\r\n\t\tFILE: Number of bytes written=1041435\r\n\t\tFILE: Number of read operations=0\r\n\t\tFILE: Number of large read operations=0\r\n\t\tFILE: Number of write operations=0\r\n\t\tHDFS: Number of bytes read=566904\r\n\t\tHDFS: Number of bytes written=0\r\n\t\tHDFS: Number of read operations=30\r\n\t\tHDFS: Number of large read operations=0\r\n\t\tHDFS: Number of write operations=18\r\n\tJob Counters \r\n\t\tKilled reduce tasks=3\r\n\t\tLaunched map tasks=1\r\n\t\tLaunched reduce tasks=12\r\n\t\t    Data-local map tasks=1\r\n\t\tTotal time spent by all maps in occupied slots (ms)=63182\r\n\t\tTotal time spent by all reduces in occupied slots (ms)=675539\r\n\t\tTotal time spent by all map tasks (ms)=63182\r\n\t\tTotal time spent by all reduce tasks (ms)=675539\r\n\t\tTotal vcore-seconds taken by all map tasks=63182\r\n\t\tTotal vcore-seconds taken by all reduce tasks=675539\r\n\t\tTotal megabyte-seconds taken by all map tasks=64698368\r\n\t\tTotal megabyte-seconds taken by all reduce tasks=691751936\r\n\t    Map-Reduce Framework\r\n\t\tMap input records=15000\r\n\t\tMap output records=0\r\n\t\tMap output bytes=0\r\n\t\tMap output materialized bytes=54\r\n\t\tInput split bytes=126\r\n\t\tCombine input records=0\r\n\t\tCombine output records=0\r\n\t\tReduce input groups=0\r\n\t\tReduce shuffle bytes=54\r\n\t\tReduce input records=0\r\n\t\tReduce output records=0\r\n\t\tSpilled Records=0\r\n\t\tShuffled Maps =9\r\n\t\tFailed Shuffles=0\r\n\t\tMerged Map outputs=9\r\n\t\tGC time elapsed (ms)=31305\r\n\t\tCPU time spent (ms)=55940\r\n\t\tPhysical memory (bytes) snapshot=763138048\r\n\t\tVirtual memory (bytes) snapshot=3485786112\r\n\t\tTotal committed heap usage (bytes)=268046336\r\n\t    Shuffle Errors\r\n\t\tBAD_ID=0\r\n\t\tCONNECTION=0\r\n\t\tIO_ERROR=0\r\n\t\tWRONG_LENGTH=0\r\n\t\tWRONG_MAP=0\r\n\t\tWRONG_REDUCE=0\r\n\t    File Input Format Counters \r\n\t\tBytes Read=566778\r\n\t    File Output Format Counters \r\n\t\tBytes Written=0\r\n\r\n \r\nPlease help me ",
            "link": "https://stackoverflow.com/questions/49977923/mapreduce-output-file-is-blank-when-trying-to-partition-the-dataset-on-some-cond",
            "title": "MapReduce Output file is blank when trying to partition the dataset on some condition",
            "body": "<p>I have a dataset which contains emoployee satisfaction level index,dept ,last evaluation, number of projects etc.From that file i have to find the average satisfation index of each dept.I have used a custom  partitioner which is dividing the dataset according to the number of dept and calculating their avg satisfaction index.For example i have 9 depts in the input file,so the job has created 9 files but none of the file contains any data, I haveno idea how to solve this .Here is mycomplete code and the dataset,</p>\n\n<pre><code>satisfaction_level,last_evaluation,number_project,average_montly_hours,time_spend_company,Work_accident,left,promotion_last_5years,sales,salary\n0.38,0.53,2,157,3,0,1,0,sales,low\n0.8,0.86,5,262,6,0,1,0,sales,medium\n0.11,0.88,7,272,4,0,1,0,sales,medium\n0.41,0.46,2,128,3,0,1,0,accounting,low\n0.38,0.5,2,132,3,0,1,0,accounting,low\n0.09,0.62,6,294,4,0,1,0,accounting,low\n0.45,0.57,2,134,3,0,1,0,hr,low\n0.4,0.51,2,145,3,0,1,0,hr,low\n0.45,0.55,2,140,3,0,1,0,hr,low\n0.84,0.87,4,246,6,0,1,0,hr,low\n0.1,0.94,6,255,4,0,1,0,technical,low\n0.38,0.46,2,137,3,0,1,0,technical,low\n0.45,0.5,2,126,3,0,1,0,technical,low\n................................  etc\n</code></pre>\n\n<p>Code </p>\n\n<p>The mapper</p>\n\n<pre><code>public class AverageSatisfactionMapper extends Mapper&lt;LongWritable,Text,Text,FloatWritable&gt;{\n\n\npublic void map(LongWritable key,Text value,Context context){\n\n    String [] tokens = value.toString().split(\",\");\n    try{\n        Float satisfactionIndex = Float.parseFloat(tokens[0]);\n        context.write(value, new FloatWritable(satisfactionIndex));\n    }catch(Exception exception){\n        exception.printStackTrace();\n    }\n\n}\n}\n</code></pre>\n\n<p>The Reducer</p>\n\n<pre><code>  public class AverageSatisfactionReducer extends Reducer&lt;Text, FloatWritable, Text, Text&gt;{\n\npublic void reduce(Text key,Iterable&lt;FloatWritable&gt; valueList,Context context){\n    try{\n        Float total = (float)0;\n        int count =0;\n        for(FloatWritable var:valueList){\n            total+=var.get();\n            System.out.println(\"reducer :\"+var.get());\n            count++;\n        }\n        Float avg = (Float)total/count;\n        String out = \"Total: \" + total + \" :: \" + \"Average: \" + avg;\n        context.write(key, new Text(out));\n    }catch(Exception e){\n    e.printStackTrace();\n    }\n}\n}\n</code></pre>\n\n<p>The Partitioner</p>\n\n<p>public class AverageSatisfactionPartitioner extends Partitioner{</p>\n\n<pre><code>@Override\npublic int getPartition(Text key, Text value, int numReduceTasks) {\n    int partitionNo = 0;\n    String [] tokens = value.toString().split(\",\");\n    String dept = tokens[8];\n    if(numReduceTasks!=0){\n        if(dept.equals(\"sales\"))\n            partitionNo = 0;\n        else if(dept.equals(\"accounting\"))\n            partitionNo = 1;\n        else if(dept.equals(\"hr\"))\n            partitionNo=2;\n        else if(dept.equals(\"technical\"))\n            partitionNo=3;\n        else if(dept.equals(\"support\"))\n            partitionNo=4;\n        else if(dept.equals(\"IT\"))\n            partitionNo=5;\n        else if(dept.equals(\"product_mng\"))\n            partitionNo=6;\n        else if(dept.equals(\"marketing\"))\n            partitionNo=7;\n        else if(dept.equals(\"management\"))\n            partitionNo=8;\n    }\n    return partitionNo;\n}\n\n }\n</code></pre>\n\n<p>The Driver class</p>\n\n<pre><code>public class AverageSatisfactionDriver {\n\npublic static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {\n    Configuration conf = new Configuration();\n    String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\n    if (otherArgs.length != 2)\n    {\n        System.err.println(\"Usage: Employee Salary Anaysis &lt;input&gt; &lt;output&gt;\");\n        System.exit(2);\n    }\n    Job job = new Job(conf, \"Employee Satisfaction Anaysis\");\n    job.setJobName(\"Custmom Patitioner\");\n    job.setJarByClass(AverageSatisfactionDriver.class);\n    job.setMapperClass(AverageSatisfactionMapper.class);\n    job.setReducerClass(AverageSatisfactionReducer.class);\n    job.setPartitionerClass(AverageSatisfactionPartitioner.class);              //Set custom partitioner class\n\n    job.setNumReduceTasks(9);\n    job.setMapOutputKeyClass(Text.class);\n    job.setMapOutputValueClass(Text.class);\n    job.setOutputKeyClass(NullWritable.class);\n    job.setOutputValueClass(Text.class);\n\n    FileInputFormat.addInputPath(job, new Path(otherArgs[0]));\n    FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));\n    System.exit(job.waitForCompletion(true) ? 0 : 1);\n\n\n}\n\n}\n</code></pre>\n\n<p>This is the output log of the job </p>\n\n<pre><code>18/04/23 14:16:54 INFO mapreduce.Job:  map 0% reduce 0%\n18/04/23 14:17:42 INFO mapreduce.Job:  map 13% reduce 0%\n18/04/23 14:17:46 INFO mapreduce.Job:  map 22% reduce 0%\n18/04/23 14:17:49 INFO mapreduce.Job:  map 30% reduce 0%\n18/04/23 14:17:52 INFO mapreduce.Job:  map 40% reduce 0%\n18/04/23 14:17:55 INFO mapreduce.Job:  map 54% reduce 0%\n18/04/23 14:17:58 INFO mapreduce.Job:  map 63% reduce 0%\n18/04/23 14:18:00 INFO mapreduce.Job:  map 100% reduce 0%\n18/04/23 14:18:47 INFO mapreduce.Job:  map 100% reduce 7%\n18/04/23 14:18:52 INFO mapreduce.Job:  map 100% reduce 11%\n18/04/23 14:19:03 INFO mapreduce.Job:  map 100% reduce 19%\n18/04/23 14:19:09 INFO mapreduce.Job:  map 100% reduce 22%\n18/04/23 14:19:16 INFO mapreduce.Job:  map 100% reduce 33%\n18/04/23 14:19:25 INFO mapreduce.Job:  map 100% reduce 44%\n18/04/23 14:19:29 INFO mapreduce.Job:  map 100% reduce 52%\n18/04/23 14:19:42 INFO mapreduce.Job:  map 100% reduce 63%\n18/04/23 14:19:45 INFO mapreduce.Job:  map 100% reduce 67%\n18/04/23 14:20:09 INFO mapreduce.Job:  map 100% reduce 78%\n18/04/23 14:20:11 INFO mapreduce.Job:  map 100% reduce 89%\n18/04/23 14:20:13 INFO mapreduce.Job:  map 100% reduce 100%\n18/04/23 14:20:16 INFO mapreduce.Job: Job job_1523849056360_0028 completed successfully\n18/04/23 14:20:16 INFO mapreduce.Job: Counters: 50\n  File System Counters\n    FILE: Number of bytes read=54\n    FILE: Number of bytes written=1041435\n    FILE: Number of read operations=0\n    FILE: Number of large read operations=0\n    FILE: Number of write operations=0\n    HDFS: Number of bytes read=566904\n    HDFS: Number of bytes written=0\n    HDFS: Number of read operations=30\n    HDFS: Number of large read operations=0\n    HDFS: Number of write operations=18\nJob Counters \n    Killed reduce tasks=3\n    Launched map tasks=1\n    Launched reduce tasks=12\n        Data-local map tasks=1\n    Total time spent by all maps in occupied slots (ms)=63182\n    Total time spent by all reduces in occupied slots (ms)=675539\n    Total time spent by all map tasks (ms)=63182\n    Total time spent by all reduce tasks (ms)=675539\n    Total vcore-seconds taken by all map tasks=63182\n    Total vcore-seconds taken by all reduce tasks=675539\n    Total megabyte-seconds taken by all map tasks=64698368\n    Total megabyte-seconds taken by all reduce tasks=691751936\n    Map-Reduce Framework\n    Map input records=15000\n    Map output records=0\n    Map output bytes=0\n    Map output materialized bytes=54\n    Input split bytes=126\n    Combine input records=0\n    Combine output records=0\n    Reduce input groups=0\n    Reduce shuffle bytes=54\n    Reduce input records=0\n    Reduce output records=0\n    Spilled Records=0\n    Shuffled Maps =9\n    Failed Shuffles=0\n    Merged Map outputs=9\n    GC time elapsed (ms)=31305\n    CPU time spent (ms)=55940\n    Physical memory (bytes) snapshot=763138048\n    Virtual memory (bytes) snapshot=3485786112\n    Total committed heap usage (bytes)=268046336\n    Shuffle Errors\n    BAD_ID=0\n    CONNECTION=0\n    IO_ERROR=0\n    WRONG_LENGTH=0\n    WRONG_MAP=0\n    WRONG_REDUCE=0\n    File Input Format Counters \n    Bytes Read=566778\n    File Output Format Counters \n    Bytes Written=0\n</code></pre>\n\n<p>Please help me </p>\n"
        },
        {
            "tags": [
                "c#",
                "tpl-dataflow"
            ],
            "owner": {
                "reputation": 382,
                "user_id": 1254089,
                "user_type": "registered",
                "accept_rate": 40,
                "profile_image": "https://www.gravatar.com/avatar/a2c65ab6f58c25021c7d4bee012fbff0?s=128&d=identicon&r=PG",
                "display_name": "cubesnyc",
                "link": "https://stackoverflow.com/users/1254089/cubesnyc"
            },
            "is_answered": false,
            "view_count": 16,
            "answer_count": 1,
            "score": -1,
            "last_activity_date": 1524656445,
            "creation_date": 1524643897,
            "question_id": 50017165,
            "body_markdown": "I would like several buffer blocks (producers) to dump into one bufferblock (consumer). I tried an extension of the code below, but the consumer is not being populated with any producer data. What am I doing wrong here? \r\n\r\n            var bbA = new BufferBlock&lt;int&gt;();\r\n            var bbB = new BufferBlock&lt;int&gt;();\r\n            bbB.LinkTo(bbA);\r\n            bbA.SendAsync(1).Wait();\r\n            bbA.SendAsync(2).Wait();\r\n            //bbB is still empty here despite the linking? ",
            "link": "https://stackoverflow.com/questions/50017165/how-to-properly-link-several-bufferblocks-together",
            "title": "How to properly link several BufferBlocks together?",
            "body": "<p>I would like several buffer blocks (producers) to dump into one bufferblock (consumer). I tried an extension of the code below, but the consumer is not being populated with any producer data. What am I doing wrong here? </p>\n\n<pre><code>        var bbA = new BufferBlock&lt;int&gt;();\n        var bbB = new BufferBlock&lt;int&gt;();\n        bbB.LinkTo(bbA);\n        bbA.SendAsync(1).Wait();\n        bbA.SendAsync(2).Wait();\n        //bbB is still empty here despite the linking? \n</code></pre>\n"
        },
        {
            "tags": [
                "c++",
                "curl",
                "visual-studio-2017",
                "linker-errors",
                "libcurl"
            ],
            "owner": {
                "reputation": 131,
                "user_id": 1314987,
                "user_type": "registered",
                "accept_rate": 12,
                "profile_image": "https://www.gravatar.com/avatar/dfa1da20e1b90c7852e6b6fa22361354?s=128&d=identicon&r=PG",
                "display_name": "pushE",
                "link": "https://stackoverflow.com/users/1314987/pushe"
            },
            "is_answered": false,
            "view_count": 13,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524656444,
            "creation_date": 1524653028,
            "last_edit_date": 1524656444,
            "question_id": 50020252,
            "body_markdown": "I followed the tutorial here on this to **add libcurl to my VS project**\r\n\r\n[http://mariusbancila.ro/blog/2018/03/13/using-curl-library-from-c-on-windows/][1]\r\n\r\n\r\n  [1]: http://mariusbancila.ro/blog/2018/03/13/using-curl-library-from-c-on-windows/\r\n\r\nAfter following all the steps still i get below linking errors.\r\n\r\n    error LNK2019: unresolved external symbol _curl_global_init referenced\r\n    error LNK2019: unresolved external symbol _curl_easy_init referenced in function\r\n\r\nIts 5 hours trying same,but still cant resolve.Please help!!\r\n\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50020252/curlvs2017-error-lnk2019-unresolved-external-symbol-curl-global-init-refer",
            "title": "[CURL][VS2017] error LNK2019: unresolved external symbol _curl_global_init referenced",
            "body": "<p>I followed the tutorial here on this to <strong>add libcurl to my VS project</strong></p>\n\n<p><a href=\"http://mariusbancila.ro/blog/2018/03/13/using-curl-library-from-c-on-windows/\" rel=\"nofollow noreferrer\">http://mariusbancila.ro/blog/2018/03/13/using-curl-library-from-c-on-windows/</a></p>\n\n<p>After following all the steps still i get below linking errors.</p>\n\n<pre><code>error LNK2019: unresolved external symbol _curl_global_init referenced\nerror LNK2019: unresolved external symbol _curl_easy_init referenced in function\n</code></pre>\n\n<p>Its 5 hours trying same,but still cant resolve.Please help!!</p>\n"
        },
        {
            "tags": [
                "python",
                "json",
                "flask",
                "sqlalchemy",
                "flask-sqlalchemy"
            ],
            "owner": {
                "reputation": 87,
                "user_id": 1638828,
                "user_type": "registered",
                "accept_rate": 45,
                "profile_image": "https://www.gravatar.com/avatar/a9e2a248723a90dc1ae9bfd88e10c53e?s=128&d=identicon&r=PG",
                "display_name": "meddy",
                "link": "https://stackoverflow.com/users/1638828/meddy"
            },
            "is_answered": true,
            "view_count": 32,
            "accepted_answer_id": 50019648,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524656438,
            "creation_date": 1524607562,
            "last_edit_date": 1524614487,
            "question_id": 50011349,
            "body_markdown": "I am building an endpoint in python that will return my catalog with all items within each category. I would like to join two tables (**Catalog and Items**) in my database based on a foreign key constraint and output this in a JSON format.\r\n\r\n**Currently I have tried**\r\n\r\n    @app.route(&#39;/catalog/JSON/&#39;)\r\n    @login_required\r\n      def getCatalog():\r\n      categories = session.query(Category).join(Item).all()\r\n      return jsonify(Catalog=[r.serializable for r in categories])\r\n\r\nHowever, this only returns item data and data about the catalog such a name.\r\n\r\n**My Current Models**\r\n\r\n    class Category(Base):\r\n    __tablename__ = &#39;category&#39;\r\n    id = Column(Integer, primary_key=True)\r\n    name = Column(String(32), nullable=False)\r\n\r\n    @property\r\n    def serializable(self):\r\n        return {&#39;id&#39;: self.id, &#39;username&#39;: self.username}\r\n\r\n    class Item(Base):\r\n    __tablename__ = &#39;item&#39;\r\n    id = Column(Integer, primary_key=True)\r\n    name = Column(String(32), nullable=False)\r\n    description = Column(String(255))\r\n    user_id = Column(Integer, ForeignKey(&#39;user.id&#39;))\r\n    user = relationship(User)\r\n    category_id = Column(Integer, ForeignKey(&#39;category.id&#39;))\r\n    category = relationship(Category)\r\n\r\n    @property\r\n    def serializable(self):\r\n        return {\r\n            &#39;id&#39;: self.id,\r\n            &#39;name&#39;: self.name,\r\n            &#39;description&#39;: self.description,\r\n            &#39;category_id&#39;: self.category_id,\r\n            &#39;user_id&#39;: self.user_id\r\n        }\r\n\r\nI am new to flask so I&#39;m not 100% sure if what I am trying to accomplish is something already resolved by the framework or by sqlalchemy.",
            "link": "https://stackoverflow.com/questions/50011349/return-joined-tables-in-json-format-with-sqlalchemy-and-flask-jsonify",
            "title": "Return joined tables in JSON format with SQLAlchemy and Flask jsonify",
            "body": "<p>I am building an endpoint in python that will return my catalog with all items within each category. I would like to join two tables (<strong>Catalog and Items</strong>) in my database based on a foreign key constraint and output this in a JSON format.</p>\n\n<p><strong>Currently I have tried</strong></p>\n\n<pre><code>@app.route('/catalog/JSON/')\n@login_required\n  def getCatalog():\n  categories = session.query(Category).join(Item).all()\n  return jsonify(Catalog=[r.serializable for r in categories])\n</code></pre>\n\n<p>However, this only returns item data and data about the catalog such a name.</p>\n\n<p><strong>My Current Models</strong></p>\n\n<pre><code>class Category(Base):\n__tablename__ = 'category'\nid = Column(Integer, primary_key=True)\nname = Column(String(32), nullable=False)\n\n@property\ndef serializable(self):\n    return {'id': self.id, 'username': self.username}\n\nclass Item(Base):\n__tablename__ = 'item'\nid = Column(Integer, primary_key=True)\nname = Column(String(32), nullable=False)\ndescription = Column(String(255))\nuser_id = Column(Integer, ForeignKey('user.id'))\nuser = relationship(User)\ncategory_id = Column(Integer, ForeignKey('category.id'))\ncategory = relationship(Category)\n\n@property\ndef serializable(self):\n    return {\n        'id': self.id,\n        'name': self.name,\n        'description': self.description,\n        'category_id': self.category_id,\n        'user_id': self.user_id\n    }\n</code></pre>\n\n<p>I am new to flask so I'm not 100% sure if what I am trying to accomplish is something already resolved by the framework or by sqlalchemy.</p>\n"
        },
        {
            "tags": [
                "php",
                "telegram",
                "telegram-bot"
            ],
            "owner": {
                "reputation": 639,
                "user_id": 4548006,
                "user_type": "registered",
                "accept_rate": 66,
                "profile_image": "https://www.gravatar.com/avatar/b6fc9a8815129f8c1342736b6c48367d?s=128&d=identicon&r=PG&f=1",
                "display_name": "NVO",
                "link": "https://stackoverflow.com/users/4548006/nvo"
            },
            "is_answered": true,
            "view_count": 26,
            "answer_count": 2,
            "score": 1,
            "last_activity_date": 1524656436,
            "creation_date": 1524648886,
            "last_edit_date": 1524655858,
            "question_id": 50018785,
            "body_markdown": "I want to send an message via the Telegram API in a `&lt;pre&gt;` block or ` ``` ` (HTML or markdown parse mode, I have no preference).\r\n\r\nThe text is a long string with some line breaks. To make it easy to read I want to send it as code. The new lines are in the `\\n` format, so the Telegram API can handle that. \r\n\r\nBut in the code block I can&#39;t see the newlines. I&#39;ve used other bots that can send me some lines in a code block, so I&#39;m reasobaly sure it&#39;s possible. \r\n\r\nCan somebody help me with this?\r\n\r\nThis is the code that I&#39;m currently using:\r\n\r\n    $url = &quot;https://api.telegram.org/$telegram_apikey/sendMessage?chat_id=$telegram_chatid&amp;parse_mode=Markdown&amp;text=```&quot; . $message .&quot;```&quot;;\r\n    \t\t$telegramResult = file_get_contents($url\r\n    );\r\n\r\nWhere message is something like this: \r\n\r\n    -------------------------------------------- \\n\r\n    ------------ IMPORT RESULTS ---------------- \\n\r\n    -------------------------------------------- \\n\r\n    Product count: 12345 \\n\r\n    Created: 1234 \\n\r\n    Total time:  200 \\n\r\n    -------------------------------------------- \\n",
            "link": "https://stackoverflow.com/questions/50018785/telegram-rest-api-send-newline-in-message-text",
            "title": "Telegram REST API, send newline in message text?",
            "body": "<p>I want to send an message via the Telegram API in a <code>&lt;pre&gt;</code> block or <code>```</code> (HTML or markdown parse mode, I have no preference).</p>\n\n<p>The text is a long string with some line breaks. To make it easy to read I want to send it as code. The new lines are in the <code>\\n</code> format, so the Telegram API can handle that. </p>\n\n<p>But in the code block I can't see the newlines. I've used other bots that can send me some lines in a code block, so I'm reasobaly sure it's possible. </p>\n\n<p>Can somebody help me with this?</p>\n\n<p>This is the code that I'm currently using:</p>\n\n<pre><code>$url = \"https://api.telegram.org/$telegram_apikey/sendMessage?chat_id=$telegram_chatid&amp;parse_mode=Markdown&amp;text=```\" . $message .\"```\";\n        $telegramResult = file_get_contents($url\n);\n</code></pre>\n\n<p>Where message is something like this: </p>\n\n<pre><code>-------------------------------------------- \\n\n------------ IMPORT RESULTS ---------------- \\n\n-------------------------------------------- \\n\nProduct count: 12345 \\n\nCreated: 1234 \\n\nTotal time:  200 \\n\n-------------------------------------------- \\n\n</code></pre>\n"
        },
        {
            "tags": [
                "compiler-construction",
                "clang",
                "llvm",
                "vectorization"
            ],
            "owner": {
                "reputation": 26,
                "user_id": 4874549,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/0621f1782aedf0f0533a309177f27301?s=128&d=identicon&r=PG&f=1",
                "display_name": "Michael",
                "link": "https://stackoverflow.com/users/4874549/michael"
            },
            "is_answered": false,
            "view_count": 548,
            "answer_count": 1,
            "score": 3,
            "last_activity_date": 1524656429,
            "creation_date": 1430996084,
            "question_id": 30099046,
            "body_markdown": "I&#39;m struggling with understanding inner works of polly (polyhedral optimizer for LLVM) and I&#39;m stuck at a problem: I know how to turn off vectorization in Clang (-fno-vectorize command option does it), but doing the same in opt eludes me. Documentation shows only how to turn this pass ON, not off. The only way to omit it is, as far as I know, using clang, which can&#39;t print stats of passes (or I couldn&#39;t find how to).\r\nCan anyone help me? Thanks!\r\n\r\nI&#39;m using the following commands to run the programs:\r\n\r\n    clang -Xclang -load -Xclang ~/llvm_build/tools/polly/Debug+Asserts/lib/LLVMPolly.so -O3 -fno-vectorize -mllvm -polly -mllvm -polly-vectorizer=polly -S -emit-llvm in.c -o out.ll\r\n    opt -load ~/{Polly shared lib}.so -O3 -polly -polly-vectorizer=polly -stats in.ll -o out.ll\r\n\r\nFirst one omits clang vectorization, but does not print stats, second prints stats, but uses the vectorization I don&#39;t want.\r\n\r\n",
            "link": "https://stackoverflow.com/questions/30099046/how-to-turn-off-vectorization-in-opt-llvm",
            "title": "How to turn off vectorization in opt (LLVM)",
            "body": "<p>I'm struggling with understanding inner works of polly (polyhedral optimizer for LLVM) and I'm stuck at a problem: I know how to turn off vectorization in Clang (-fno-vectorize command option does it), but doing the same in opt eludes me. Documentation shows only how to turn this pass ON, not off. The only way to omit it is, as far as I know, using clang, which can't print stats of passes (or I couldn't find how to).\nCan anyone help me? Thanks!</p>\n\n<p>I'm using the following commands to run the programs:</p>\n\n<pre><code>clang -Xclang -load -Xclang ~/llvm_build/tools/polly/Debug+Asserts/lib/LLVMPolly.so -O3 -fno-vectorize -mllvm -polly -mllvm -polly-vectorizer=polly -S -emit-llvm in.c -o out.ll\nopt -load ~/{Polly shared lib}.so -O3 -polly -polly-vectorizer=polly -stats in.ll -o out.ll\n</code></pre>\n\n<p>First one omits clang vectorization, but does not print stats, second prints stats, but uses the vectorization I don't want.</p>\n"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 112
}