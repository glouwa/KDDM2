{
    "items": [
        {
            "tags": [
                "r",
                "google-maps-api-3",
                "distance",
                "duration"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9110629,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/1440179179343386/picture?type=large",
                "display_name": "Jo&#227;o Mour&#227;o",
                "link": "https://stackoverflow.com/users/9110629/jo%c3%a3o-mour%c3%a3o"
            },
            "is_answered": false,
            "view_count": 26,
            "answer_count": 0,
            "score": -3,
            "last_activity_date": 1524171701,
            "creation_date": 1524171551,
            "last_edit_date": 1524171701,
            "question_id": 49930148,
            "body_markdown": "I want to calculate ,in R, how long does it usually take to go from `a` to `b`, by car. Being `&quot;a&quot;` and `&quot;b&quot;` two addresses. I figure it out how to do it using `mapsapi`, as follows:\r\n\r\n    ----------\r\n\r\n    escola &lt;- c(&quot;R. Artur Orlando, 907 - Vila Jaguara&quot;)\r\n    \r\n    polo &lt;-  c(&quot;Av. Eng. Armando de Arruda Pereira, 707&quot;)\r\n    \r\n    c &lt;- mp_matrix(polo, escola, mode = c(&quot;driving&quot;), departure_time = a)\r\n    \r\n    r &lt;- mp_get_matrix(c, value = &quot;duration_s&quot;)\r\n    \r\n    r[1]\r\n    \r\n    ----------\r\n\r\nHowever, my data frame has more than 169 thousands lines, therefore, it is impossible to use `mapsapi` within the limits imposed by Google. Is there any alternative way of obtaining the same result using a free package without user`s limits?\r\n",
            "link": "https://stackoverflow.com/questions/49930148/how-to-calculate-how-long-it-takes-to-go-from-one-address-to-another",
            "title": "How to calculate how long it takes to go from one address to another?",
            "body": "<p>I want to calculate ,in R, how long does it usually take to go from <code>a</code> to <code>b</code>, by car. Being <code>\"a\"</code> and <code>\"b\"</code> two addresses. I figure it out how to do it using <code>mapsapi</code>, as follows:</p>\n\n<pre><code>----------\n\nescola &lt;- c(\"R. Artur Orlando, 907 - Vila Jaguara\")\n\npolo &lt;-  c(\"Av. Eng. Armando de Arruda Pereira, 707\")\n\nc &lt;- mp_matrix(polo, escola, mode = c(\"driving\"), departure_time = a)\n\nr &lt;- mp_get_matrix(c, value = \"duration_s\")\n\nr[1]\n\n----------\n</code></pre>\n\n<p>However, my data frame has more than 169 thousands lines, therefore, it is impossible to use <code>mapsapi</code> within the limits imposed by Google. Is there any alternative way of obtaining the same result using a free package without user`s limits?</p>\n"
        },
        {
            "tags": [
                "batch-file",
                "command-line",
                "texturepacker"
            ],
            "owner": {
                "reputation": 1353,
                "user_id": 2481696,
                "user_type": "registered",
                "accept_rate": 59,
                "profile_image": "https://www.gravatar.com/avatar/393948fa6f45e4c700c58f926072bfb2?s=128&d=identicon&r=PG",
                "display_name": "Joshua Barnett",
                "link": "https://stackoverflow.com/users/2481696/joshua-barnett"
            },
            "is_answered": true,
            "view_count": 360,
            "accepted_answer_id": 49930119,
            "answer_count": 1,
            "score": 2,
            "last_activity_date": 1524171697,
            "creation_date": 1384355367,
            "question_id": 19957253,
            "body_markdown": "I&#39;m currently writing a batch script to generate sprite sheets using [TexturePacker](http://www.codeandweb.com/texturepacker)&#39;s Command-line Tool.\r\n\r\n    for /f &quot;delims=&quot; %%i in (&#39;dir /b sprites&#39;) do (\r\n    \tTexturePacker --format &quot;json&quot; --data &quot;sheets/%%i.json&quot; --sheet &quot;sheets/%%i.png&quot; &quot;sprites/%%i&quot;\r\n    )\r\n\r\nQuite simple so far but I was wondering if it were possible to generate a [*.tps] file from the tool as well. So that if someone wants to check the properties of the export they can do so through the TexturePackerGUI.",
            "link": "https://stackoverflow.com/questions/19957253/generate-tps-from-command-line-tool",
            "title": "Generate (*.tps) from command-line tool?",
            "body": "<p>I'm currently writing a batch script to generate sprite sheets using <a href=\"http://www.codeandweb.com/texturepacker\" rel=\"nofollow\">TexturePacker</a>'s Command-line Tool.</p>\n\n<pre><code>for /f \"delims=\" %%i in ('dir /b sprites') do (\n    TexturePacker --format \"json\" --data \"sheets/%%i.json\" --sheet \"sheets/%%i.png\" \"sprites/%%i\"\n)\n</code></pre>\n\n<p>Quite simple so far but I was wondering if it were possible to generate a [*.tps] file from the tool as well. So that if someone wants to check the properties of the export they can do so through the TexturePackerGUI.</p>\n"
        },
        {
            "tags": [
                "sql",
                "sql-server",
                "pivot",
                "pivot-table"
            ],
            "owner": {
                "reputation": 1071,
                "user_id": 2267015,
                "user_type": "registered",
                "accept_rate": 71,
                "profile_image": "https://i.stack.imgur.com/t9xiO.png?s=128&g=1",
                "display_name": "Jeff",
                "link": "https://stackoverflow.com/users/2267015/jeff"
            },
            "is_answered": true,
            "view_count": 550428,
            "protected_date": 1446713164,
            "accepted_answer_id": 15931734,
            "answer_count": 7,
            "score": 203,
            "last_activity_date": 1524171694,
            "creation_date": 1365611918,
            "last_edit_date": 1392101355,
            "question_id": 15931607,
            "body_markdown": "Well I guess I am really dense. I have read the stuff on MS pivot tables and I am still having problems getting this correct. I have seen some of you that seem to eat and sleep this stuff, so I just decided to sign-up and ask the question.\r\n\r\nI have a temp table that is being created, we will say that column 1 is a Store number, and column 2 is a week number and lastly column 3 is a total of some type. Also the Week numbers are dynamic, the store numbers are static.\r\n\r\n    Store      Week     xCount\r\n    -------    ----     ------\r\n    102        1        96\r\n    101        1        138\r\n    105        1        37\r\n    109        1        59\r\n    101        2        282\r\n    102        2        212\r\n    105        2        78\r\n    109        2        97\r\n    105        3        60\r\n    102        3        123\r\n    101        3        220\r\n    109        3        87\r\n\r\nI would like it to come out as a pivot table, like this:\r\n\r\n    Store        1          2          3        4        5        6....\r\n    ----- \r\n    101        138        282        220\r\n    102         96        212        123\r\n    105         37        \r\n    109\r\n\r\nStore numbers down the side and weeks across the top.\r\n\r\nThanks for the help.\r\n\r\n",
            "link": "https://stackoverflow.com/questions/15931607/convert-rows-to-columns-using-pivot-in-sql-server",
            "title": "Convert Rows to columns using &#39;Pivot&#39; in SQL Server",
            "body": "<p>Well I guess I am really dense. I have read the stuff on MS pivot tables and I am still having problems getting this correct. I have seen some of you that seem to eat and sleep this stuff, so I just decided to sign-up and ask the question.</p>\n\n<p>I have a temp table that is being created, we will say that column 1 is a Store number, and column 2 is a week number and lastly column 3 is a total of some type. Also the Week numbers are dynamic, the store numbers are static.</p>\n\n<pre><code>Store      Week     xCount\n-------    ----     ------\n102        1        96\n101        1        138\n105        1        37\n109        1        59\n101        2        282\n102        2        212\n105        2        78\n109        2        97\n105        3        60\n102        3        123\n101        3        220\n109        3        87\n</code></pre>\n\n<p>I would like it to come out as a pivot table, like this:</p>\n\n<pre><code>Store        1          2          3        4        5        6....\n----- \n101        138        282        220\n102         96        212        123\n105         37        \n109\n</code></pre>\n\n<p>Store numbers down the side and weeks across the top.</p>\n\n<p>Thanks for the help.</p>\n"
        },
        {
            "tags": [
                "u-boot",
                "imx6"
            ],
            "owner": {
                "reputation": 1342,
                "user_id": 2842573,
                "user_type": "registered",
                "accept_rate": 0,
                "profile_image": "https://i.stack.imgur.com/iJ1Wp.jpg?s=128&g=1",
                "display_name": "Dennis Kerrisk",
                "link": "https://stackoverflow.com/users/2842573/dennis-kerrisk"
            },
            "is_answered": false,
            "view_count": 18,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524171680,
            "creation_date": 1524171680,
            "question_id": 49930186,
            "body_markdown": "I am trying to set the u-boot console on an imx6 board to UART4. And it is not working. UART1 stops working, but I never get output. \r\n\r\nIn my board .h file:\r\n\r\n        #define CONFIG_MXC_UART\r\n    #define CONFIG_MXC_UART_BASE\t\tUART4_BASE\r\n    #define CONSOLE_DEV &quot;ttymxc3&quot;\t\t\t/* added to changee console to UART4 */\r\n\r\n\r\nin my board .c file:\r\n\r\n    static struct mxc_serial_platdata mxc_serial_plat = {\r\n\t.reg = (struct mxc_uart *)UART4_BASE,\r\n\t.use_dte = false,\r\n    };\r\n\r\n    U_BOOT_DEVICE(mxc_serial) = {\r\n\t    .name = &quot;serial_mxc&quot;,\r\n\t    .platdata = &amp;mxc_serial_plat,\r\n    };\r\n\r\n\r\nI have enabled the pins via the IOMUX. What am I missing? Why can&#39;t I get any output?\r\n\r\nDennis\r\n",
            "link": "https://stackoverflow.com/questions/49930186/u-boot-imx6-how-to-set-console-to-uart4",
            "title": "u-boot imx6 how to set console to UART4",
            "body": "<p>I am trying to set the u-boot console on an imx6 board to UART4. And it is not working. UART1 stops working, but I never get output. </p>\n\n<p>In my board .h file:</p>\n\n<pre><code>    #define CONFIG_MXC_UART\n#define CONFIG_MXC_UART_BASE        UART4_BASE\n#define CONSOLE_DEV \"ttymxc3\"           /* added to changee console to UART4 */\n</code></pre>\n\n<p>in my board .c file:</p>\n\n<pre><code>static struct mxc_serial_platdata mxc_serial_plat = {\n.reg = (struct mxc_uart *)UART4_BASE,\n.use_dte = false,\n};\n\nU_BOOT_DEVICE(mxc_serial) = {\n    .name = \"serial_mxc\",\n    .platdata = &amp;mxc_serial_plat,\n};\n</code></pre>\n\n<p>I have enabled the pins via the IOMUX. What am I missing? Why can't I get any output?</p>\n\n<p>Dennis</p>\n"
        },
        {
            "tags": [
                "c",
                "linux",
                "timer",
                "posix",
                "embedded-linux"
            ],
            "owner": {
                "reputation": 322,
                "user_id": 1226614,
                "user_type": "registered",
                "accept_rate": 87,
                "profile_image": "https://www.gravatar.com/avatar/3e9fa269db03d0dab7c29f7f8027c9c0?s=128&d=identicon&r=PG",
                "display_name": "Kreuzade",
                "link": "https://stackoverflow.com/users/1226614/kreuzade"
            },
            "is_answered": false,
            "view_count": 12,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524171680,
            "creation_date": 1524171680,
            "question_id": 49930185,
            "body_markdown": "I have a Linux application that needs to perform an action after 5 seconds if the same application doesn&#39;t &#39;kick&#39; or reset the 5 second timer before it expires. What mechanism is best for this?\r\n\r\nI was considering using `alarm(5)` and &#39;kick&#39; it with `alarm(5)` when needed but I was hoping to avoid needing to handle a `SIGALRM`.\r\n\r\nI was reading up on `timer_create()` as well but I&#39;m not seeing a way to configure a callback or reset the timer.\r\n\r\nI&#39;m looking for something similar to a watchdog timer but within my application only.",
            "link": "https://stackoverflow.com/questions/49930185/trigger-callback-if-time-expires-without-being-kicked-first",
            "title": "Trigger callback if time expires without being &#39;kicked&#39; first",
            "body": "<p>I have a Linux application that needs to perform an action after 5 seconds if the same application doesn't 'kick' or reset the 5 second timer before it expires. What mechanism is best for this?</p>\n\n<p>I was considering using <code>alarm(5)</code> and 'kick' it with <code>alarm(5)</code> when needed but I was hoping to avoid needing to handle a <code>SIGALRM</code>.</p>\n\n<p>I was reading up on <code>timer_create()</code> as well but I'm not seeing a way to configure a callback or reset the timer.</p>\n\n<p>I'm looking for something similar to a watchdog timer but within my application only.</p>\n"
        },
        {
            "tags": [
                "java",
                "mongodb",
                "dbobject"
            ],
            "owner": {
                "reputation": 19593,
                "user_id": 69803,
                "user_type": "registered",
                "accept_rate": 65,
                "profile_image": "https://www.gravatar.com/avatar/eed28c92944b219aa031f96fc6f71577?s=128&d=identicon&r=PG",
                "display_name": "Ankur",
                "link": "https://stackoverflow.com/users/69803/ankur"
            },
            "is_answered": true,
            "view_count": 43267,
            "accepted_answer_id": 7684293,
            "answer_count": 5,
            "score": 15,
            "last_activity_date": 1524171678,
            "creation_date": 1317972438,
            "last_edit_date": 1317973568,
            "question_id": 7684223,
            "body_markdown": "MongoDB seems to return BSON/JSON objects.\r\n\r\nI thought that surely you&#39;d be able to retrieve values as Strings, ints etc. which can then be saved as POJO.\r\n\r\nI have a DBObject (instantiated as a BasicDBObject) as a result of iterating over a list ... (cur.next()).\r\n\r\nIs the only way (other than using some sort of persistence framework) to get the data into a POJO to use a JSON serlialiser/deserialiser?\r\n\r\n\r\nMy method looks like this:\r\n\r\n    public List&lt;User&gt; findByEmail(String email){\r\n    \t\t DBCollection userColl;\r\n    \t\t try {\r\n    \t\t\tuserColl = Dao.getDB().getCollection(&quot;users&quot;); } catch (UnknownHostException e) { e.printStackTrace(); } catch (MongoException e) { e.printStackTrace();}\r\n    \t\t    DBCursor cur = userColl.find();\r\n    \t\t    List&lt;User&gt; usersWithMatchEmail = new ArrayList&lt;User&gt;();\r\n    \t\t \r\n    \t        while(cur.hasNext()) {\r\n    \t           // this is where I want to convert cur.next() into a &lt;User&gt; POJO\r\n                   usersWithMatchEmail.add(cur.next());\r\n    \t        }\r\n    \t\treturn null;\r\n      \t}\r\n\r\nEDIT: It&#39;s pretty obvious, just do something like this.",
            "link": "https://stackoverflow.com/questions/7684223/convert-dbobject-to-a-pojo-using-mongodb-java-driver",
            "title": "Convert DBObject to a POJO using MongoDB Java Driver",
            "body": "<p>MongoDB seems to return BSON/JSON objects.</p>\n\n<p>I thought that surely you'd be able to retrieve values as Strings, ints etc. which can then be saved as POJO.</p>\n\n<p>I have a DBObject (instantiated as a BasicDBObject) as a result of iterating over a list ... (cur.next()).</p>\n\n<p>Is the only way (other than using some sort of persistence framework) to get the data into a POJO to use a JSON serlialiser/deserialiser?</p>\n\n<p>My method looks like this:</p>\n\n<pre><code>public List&lt;User&gt; findByEmail(String email){\n         DBCollection userColl;\n         try {\n            userColl = Dao.getDB().getCollection(\"users\"); } catch (UnknownHostException e) { e.printStackTrace(); } catch (MongoException e) { e.printStackTrace();}\n            DBCursor cur = userColl.find();\n            List&lt;User&gt; usersWithMatchEmail = new ArrayList&lt;User&gt;();\n\n            while(cur.hasNext()) {\n               // this is where I want to convert cur.next() into a &lt;User&gt; POJO\n               usersWithMatchEmail.add(cur.next());\n            }\n        return null;\n    }\n</code></pre>\n\n<p>EDIT: It's pretty obvious, just do something like this.</p>\n"
        },
        {
            "tags": [
                "android",
                "gson"
            ],
            "owner": {
                "reputation": 140,
                "user_id": 5613246,
                "user_type": "registered",
                "accept_rate": 45,
                "profile_image": "https://www.gravatar.com/avatar/68e57d509198303dce2361d3a8325a54?s=128&d=identicon&r=PG&f=1",
                "display_name": "LMaker",
                "link": "https://stackoverflow.com/users/5613246/lmaker"
            },
            "is_answered": true,
            "view_count": 11422,
            "accepted_answer_id": 43864492,
            "answer_count": 3,
            "score": 2,
            "last_activity_date": 1524171672,
            "creation_date": 1494263244,
            "question_id": 43853436,
            "body_markdown": "So, i have a List of my custom Object and I need a JSON like this:\r\n\r\n    {\r\n\t&quot;surveys&quot;: [{\r\n\t\t&quot;survey&quot;: {\r\n\t\t\t&quot;code&quot;: &quot;05052017153632&quot;,\r\n\t\t\t&quot;date&quot;: &quot;05/05/2017 15:36:32&quot;,\r\n\t\t\t&quot;device_id&quot;: 1,\r\n\t\t\t&quot;questions_attributes&quot;: [{\r\n\t\t\t\t&quot;kind&quot;: &quot;string&quot;,\r\n\t\t\t\t&quot;label&quot;: &quot;Voc&#234; encontrou tudo o que procurava?&quot;,\r\n\t\t\t\t&quot;value&quot;: &quot;Infelizmente, n&#227;o&quot;\r\n\t\t\t}, {\r\n\t\t\t\t&quot;kind&quot;: &quot;string&quot;,\r\n\t\t\t\t&quot;label&quot;: &quot;Em qual departamento voc&#234; n&#227;o encontrou o produto?&quot;,\r\n\t\t\t\t&quot;value&quot;: &quot;FERRAMENTAS, TAPETES&quot;\r\n\t\t\t}, {\r\n\t\t\t\t&quot;kind&quot;: &quot;string&quot;,\r\n\t\t\t\t&quot;label&quot;: &quot;Deseja que a Havan entre em contato com voc&#234;?&quot;,\r\n\t\t\t\t&quot;value&quot;: &quot;N&#227;o informado&quot;\r\n\t\t\t}, {\r\n\t\t\t\t&quot;kind&quot;: &quot;string&quot;,\r\n\t\t\t\t&quot;label&quot;: &quot;Nome&quot;,\r\n\t\t\t\t&quot;value&quot;: &quot;N&#227;o informado&quot;\r\n\t\t\t}, {\r\n\t\t\t\t&quot;kind&quot;: &quot;string&quot;,\r\n\t\t\t\t&quot;label&quot;: &quot;E-mail&quot;,\r\n\t\t\t\t&quot;value&quot;: &quot;N&#227;o informado&quot;\r\n\t\t\t}, {\r\n\t\t\t\t&quot;kind&quot;: &quot;string&quot;,\r\n\t\t\t\t&quot;label&quot;: &quot;Telefone&quot;,\r\n\t\t\t\t&quot;value&quot;: &quot;N&#227;o informado&quot;\r\n\t\t\t}]\r\n\t\t}\r\n\t}]}\r\n\r\nBut I dont have any ideia how to do it using Gson.\r\nI&#39;m Using Retrofit 2 and need to pass this JSON into a body request.\r\nAny ideias?\r\n",
            "link": "https://stackoverflow.com/questions/43853436/retrofit-2-how-to-pass-a-post-json-object",
            "title": "retrofit 2 - how to pass a POST json object",
            "body": "<p>So, i have a List of my custom Object and I need a JSON like this:</p>\n\n<pre><code>{\n\"surveys\": [{\n    \"survey\": {\n        \"code\": \"05052017153632\",\n        \"date\": \"05/05/2017 15:36:32\",\n        \"device_id\": 1,\n        \"questions_attributes\": [{\n            \"kind\": \"string\",\n            \"label\": \"Você encontrou tudo o que procurava?\",\n            \"value\": \"Infelizmente, não\"\n        }, {\n            \"kind\": \"string\",\n            \"label\": \"Em qual departamento você não encontrou o produto?\",\n            \"value\": \"FERRAMENTAS, TAPETES\"\n        }, {\n            \"kind\": \"string\",\n            \"label\": \"Deseja que a Havan entre em contato com você?\",\n            \"value\": \"Não informado\"\n        }, {\n            \"kind\": \"string\",\n            \"label\": \"Nome\",\n            \"value\": \"Não informado\"\n        }, {\n            \"kind\": \"string\",\n            \"label\": \"E-mail\",\n            \"value\": \"Não informado\"\n        }, {\n            \"kind\": \"string\",\n            \"label\": \"Telefone\",\n            \"value\": \"Não informado\"\n        }]\n    }\n}]}\n</code></pre>\n\n<p>But I dont have any ideia how to do it using Gson.\nI'm Using Retrofit 2 and need to pass this JSON into a body request.\nAny ideias?</p>\n"
        },
        {
            "tags": [
                "sha512"
            ],
            "owner": {
                "reputation": 125,
                "user_id": 8716085,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/105196db6d398c854e1f0300b3702a00?s=128&d=identicon&r=PG&f=1",
                "display_name": "Ramesh",
                "link": "https://stackoverflow.com/users/8716085/ramesh"
            },
            "is_answered": false,
            "view_count": 6,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524171663,
            "creation_date": 1524170554,
            "question_id": 49929911,
            "body_markdown": "This .sha512 file is encrypting key for a zip file and inside this .sha512 file, there is a hash key and the name of the zip using which this was created from.\r\n\r\nI wanted to know if `sha512sum -c` command runs checksum on the zip file and then matches the value inside of the .sha512 file or there is another function to the command. \r\n\r\nI had this command inside a if statement, and if checksum values match then it would print Checksum matches or else prints checksum values do not match.\r\n\r\nThanks for the help.",
            "link": "https://stackoverflow.com/questions/49929911/explain-the-sha512sum-c-file-sha512-command",
            "title": "Explain the sha512sum -c file.sha512 command",
            "body": "<p>This .sha512 file is encrypting key for a zip file and inside this .sha512 file, there is a hash key and the name of the zip using which this was created from.</p>\n\n<p>I wanted to know if <code>sha512sum -c</code> command runs checksum on the zip file and then matches the value inside of the .sha512 file or there is another function to the command. </p>\n\n<p>I had this command inside a if statement, and if checksum values match then it would print Checksum matches or else prints checksum values do not match.</p>\n\n<p>Thanks for the help.</p>\n"
        },
        {
            "tags": [
                "go"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 9671735,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/f741413f1b407c3f5603d1b9cb225720?s=128&d=identicon&r=PG&f=1",
                "display_name": "kevlar73",
                "link": "https://stackoverflow.com/users/9671735/kevlar73"
            },
            "is_answered": true,
            "view_count": 35,
            "accepted_answer_id": 49930173,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524171656,
            "creation_date": 1524170292,
            "last_edit_date": 1524171151,
            "question_id": 49929846,
            "body_markdown": "I have some Go code that is returning a map of values but I only need some of the results.  Is there a way I can test/filter the key of the map against a string array (or something similar) to give a simplified result rather than a bunch of if statements?  All the samples I have looked up had fixed values to filter against.\r\n\r\nA simple example is below, but rather than supplying the string I want to have a list of possible values so I can get a reduced list.\r\n\r\n    package main\r\n    \r\n    import &quot;fmt&quot;\r\n    \r\n    type colors struct {\r\n        animal\tstring\r\n        COLOR\t[]string\r\n    }\r\n    \r\n    func main() {\r\n    \t// Map animal names to color strings.\r\n    \tcolors := map[string]string{\r\n    \t\t&quot;bird&quot;:  &quot;blue&quot;,\r\n    \t\t&quot;snake&quot;: &quot;green&quot;,\r\n    \t\t&quot;cat&quot;:   &quot;black&quot;,\r\n    \t}\r\n    \r\n    \t// Display string.\r\n    \tfmt.Println(colors)\r\n    }",
            "link": "https://stackoverflow.com/questions/49929846/retrieve-from-a-map-by-comparing-the-key-to-a-string-array",
            "title": "Retrieve from a map by comparing the key to a string array",
            "body": "<p>I have some Go code that is returning a map of values but I only need some of the results.  Is there a way I can test/filter the key of the map against a string array (or something similar) to give a simplified result rather than a bunch of if statements?  All the samples I have looked up had fixed values to filter against.</p>\n\n<p>A simple example is below, but rather than supplying the string I want to have a list of possible values so I can get a reduced list.</p>\n\n<pre><code>package main\n\nimport \"fmt\"\n\ntype colors struct {\n    animal  string\n    COLOR   []string\n}\n\nfunc main() {\n    // Map animal names to color strings.\n    colors := map[string]string{\n        \"bird\":  \"blue\",\n        \"snake\": \"green\",\n        \"cat\":   \"black\",\n    }\n\n    // Display string.\n    fmt.Println(colors)\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "node.js",
                "selenium",
                "selenium-webdriver",
                "selenium-chromedriver"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9671678,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/ec02d8f4bd092437f956dec48f14dceb?s=128&d=identicon&r=PG&f=1",
                "display_name": "Razimun",
                "link": "https://stackoverflow.com/users/9671678/razimun"
            },
            "is_answered": false,
            "view_count": 20,
            "answer_count": 0,
            "score": -3,
            "last_activity_date": 1524171653,
            "creation_date": 1524166704,
            "last_edit_date": 1524171653,
            "question_id": 49928980,
            "body_markdown": "I install selenium webdriver and running a sample test on chromedriver but seeing below error:\r\n\r\nMy Test failed\r\n\r\n&gt; (node:37537) UnhandledPromiseRejectionWarning:\r\n&gt; StaleElementReferenceError: stale element reference: element is not\r\n&gt; attached to the page document   (Session info: chrome=65.0.3325.181)  \r\n&gt; (Driver info: chromedriver=2.38.551581\r\n&gt; (2c9c29527ada10af4745ab26dd000ebb6d5e055e),platform=Mac OS X 10.13.3\r\n&gt; x86_64)\r\n&gt;     at Object.checkLegacyResponse (/Users/rahoque/node_modules/selenium-webdriver/lib/error.js:585:15)\r\n&gt;     at parseHttpResponse (/Users/rahoque/node_modules/selenium-webdriver/lib/http.js:533:13)\r\n&gt;     at Executor.execute (/Users/rahoque/node_modules/selenium-webdriver/lib/http.js:468:26)\r\n&gt;     at &lt;anonymous&gt;\r\n&gt;     at process._tickCallback (internal/process/next_tick.js:188:7) (node:37537) UnhandledPromiseRejectionWarning: Unhandled promise\r\n&gt; rejection. This error originated either by throwing inside of an async\r\n&gt; function without a catch block, or by rejecting a promise which was\r\n&gt; not handled with .catch(). (rejection id: 1) (node:37537) [DEP0018]\r\n&gt; DeprecationWarning: Unhandled promise rejections are deprecated. In\r\n&gt; the future, promise rejections that are not handled will terminate the\r\n&gt; Node.js process with a non-zero exit code.",
            "link": "https://stackoverflow.com/questions/49928980/unhandledpromiserejectionwarning-staleelementreferenceerror-stale-element-refe",
            "title": "UnhandledPromiseRejectionWarning: StaleElementReferenceError: stale element reference: element is not attached to the page document",
            "body": "<p>I install selenium webdriver and running a sample test on chromedriver but seeing below error:</p>\n\n<p>My Test failed</p>\n\n<pre><code>(node:37537) UnhandledPromiseRejectionWarning: StaleElementReferenceError: stale element reference: element is not attached to the page document   (Session info: chrome=65.0.3325.181)   (Driver info: chromedriver=2.38.551581 (2c9c29527ada10af4745ab26dd000ebb6d5e055e),platform=Mac OS X 10.13.3 x86_64)\n    at Object.checkLegacyResponse (/Users/rahoque/node_modules/selenium-webdriver/lib/error.js:585:15)\n    at parseHttpResponse (/Users/rahoque/node_modules/selenium-webdriver/lib/http.js:533:13)\n    at Executor.execute (/Users/rahoque/node_modules/selenium-webdriver/lib/http.js:468:26)\n    at &lt;anonymous&gt;\n    at process._tickCallback (internal/process/next_tick.js:188:7) (node:37537) UnhandledPromiseRejectionWarning: Unhandled promise rejection. This error originated either by throwing inside of an async function without a catch block, or by rejecting a promise which was not handled with .catch(). (rejection id: 1) (node:37537) [DEP0018] DeprecationWarning: Unhandled promise rejections are deprecated. In the future, promise rejections that are not handled will terminate the Node.js process with a non-zero exit code.\n</code></pre>\n"
        },
        {
            "tags": [
                "java",
                "security",
                "encryption",
                "cryptography"
            ],
            "owner": {
                "reputation": 96,
                "user_id": 1719690,
                "user_type": "registered",
                "accept_rate": 88,
                "profile_image": "https://www.gravatar.com/avatar/72c9fc989aad4d5dda1e3bd02a80f1e3?s=128&d=identicon&r=PG",
                "display_name": "visa",
                "link": "https://stackoverflow.com/users/1719690/visa"
            },
            "is_answered": false,
            "view_count": 45,
            "closed_date": 1524186987,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524171651,
            "creation_date": 1524164803,
            "question_id": 49928483,
            "body_markdown": "I use usernames encrypted using a function ***f*** as ids of records. Users see records identified by ***f**(username)*. I *must not* know real usernames.\r\n\r\nI want to be protected from attack when adversary who has a username *u1* and knows ***f*** generates another username *u2* such that ***f**(u1) = **f**(u2)*, logs in with this username and sees the data of user with username *u1*.\r\n\r\n\r\nSo, ***f*** must be:\r\n\r\n - **deterministic**: I use ***f**(x)* as identifier. It rejects RSA encryption with throwing out secret key.\r\n - **one-way**: I must not be able to get a real value from encrypted value.\r\n - **collision-free** to prevent attack describes above. It rejects md5/sha because as far as I understand they are easily crackable, especially because I don&#39;t use salt (unavoidable technical reasons).\r\n - **quick to compute**: I must handle tens of thousands messages per second. It rejects b/crypt.\r\n - **available on JVM** as a solid library.\r\n\r\nNote that I don&#39;t care about length of output (it may be fixed or variable).\r\n\r\nI was looking at MAC and Digital Signature algorithms but can&#39;t figure out which of them have required properties. \r\n ",
            "link": "https://stackoverflow.com/questions/49928483/is-there-a-deterministic-one-way-collision-free-crypto-algorithm-on-jvm",
            "closed_reason": "off-topic",
            "title": "Is there a deterministic one-way collision-free crypto algorithm on jvm?",
            "body": "<p>I use usernames encrypted using a function <strong><em>f</em></strong> as ids of records. Users see records identified by <strong><em>f</strong>(username)</em>. I <em>must not</em> know real usernames.</p>\n\n<p>I want to be protected from attack when adversary who has a username <em>u1</em> and knows <strong><em>f</em></strong> generates another username <em>u2</em> such that <strong><em>f</strong>(u1) = <strong>f</strong>(u2)</em>, logs in with this username and sees the data of user with username <em>u1</em>.</p>\n\n<p>So, <strong><em>f</em></strong> must be:</p>\n\n<ul>\n<li><strong>deterministic</strong>: I use <strong><em>f</strong>(x)</em> as identifier. It rejects RSA encryption with throwing out secret key.</li>\n<li><strong>one-way</strong>: I must not be able to get a real value from encrypted value.</li>\n<li><strong>collision-free</strong> to prevent attack describes above. It rejects md5/sha because as far as I understand they are easily crackable, especially because I don't use salt (unavoidable technical reasons).</li>\n<li><strong>quick to compute</strong>: I must handle tens of thousands messages per second. It rejects b/crypt.</li>\n<li><strong>available on JVM</strong> as a solid library.</li>\n</ul>\n\n<p>Note that I don't care about length of output (it may be fixed or variable).</p>\n\n<p>I was looking at MAC and Digital Signature algorithms but can't figure out which of them have required properties. </p>\n"
        },
        {
            "tags": [
                "android",
                "amazon-web-services",
                "amazon-s3",
                "lambda"
            ],
            "owner": {
                "reputation": 7,
                "user_id": 9313556,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/01736ed3af0be11814286289531c39e8?s=128&d=identicon&r=PG&f=1",
                "display_name": "Marszal",
                "link": "https://stackoverflow.com/users/9313556/marszal"
            },
            "is_answered": false,
            "view_count": 18,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524171626,
            "creation_date": 1524171626,
            "question_id": 49930166,
            "body_markdown": "Wondering if anyone used AWS Lambda to send images or other data to android application. At the moment my Lambda function triggers a SNS service. I was hoping to add possibility of sending new objects back to my app as well from same lambda function, but I’m not sure if this is possible or how to achieve this. Any help will be much appreciated regards Mat.",
            "link": "https://stackoverflow.com/questions/49930166/sending-pictures-from-s3-bucket-using-lambda-function-to-android-aws",
            "title": "Sending pictures from S3 bucket using Lambda function to Android (AWS)",
            "body": "<p>Wondering if anyone used AWS Lambda to send images or other data to android application. At the moment my Lambda function triggers a SNS service. I was hoping to add possibility of sending new objects back to my app as well from same lambda function, but I’m not sure if this is possible or how to achieve this. Any help will be much appreciated regards Mat.</p>\n"
        },
        {
            "tags": [
                "php",
                "str-replace"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 9467969,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/45ab6a028a2891f2ba1d75bfae090c12?s=128&d=identicon&r=PG&f=1",
                "display_name": "uhbc",
                "link": "https://stackoverflow.com/users/9467969/uhbc"
            },
            "is_answered": true,
            "view_count": 40,
            "closed_date": 1524172548,
            "accepted_answer_id": 49930006,
            "answer_count": 4,
            "score": -1,
            "last_activity_date": 1524171626,
            "creation_date": 1524170246,
            "last_edit_date": 1524170508,
            "question_id": 49929838,
            "body_markdown": "How can I use the str_replace() without using an array of words for turning:\r\n\r\n    some@mail.com\r\ninto\r\n\r\n    some\r\nSo, everything after the &#39;@&#39; sign includes @ as well.\r\nHow can I do that?&lt;br&gt;&lt;br&gt;\r\nAs an example, i will type &#39;adminofsite@xxxwwweeerandomstuff.com&#39;&lt;br&gt;\r\nand the output will be: &#39;adminofsite&#39;.\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49929838/use-str-replace-to-remove-after",
            "closed_reason": "duplicate",
            "title": "use str_replace to remove after @",
            "body": "<p>How can I use the str_replace() without using an array of words for turning:</p>\n\n<pre><code>some@mail.com\n</code></pre>\n\n<p>into</p>\n\n<pre><code>some\n</code></pre>\n\n<p>So, everything after the '@' sign includes @ as well.\nHow can I do that?<br><br>\nAs an example, i will type 'adminofsite@xxxwwweeerandomstuff.com'<br>\nand the output will be: 'adminofsite'.</p>\n"
        },
        {
            "tags": [
                "mysql"
            ],
            "owner": {
                "reputation": 11,
                "user_id": 9670239,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/b8463550e15bfd090ef45fcad52fe622?s=128&d=identicon&r=PG&f=1",
                "display_name": "Tim N",
                "link": "https://stackoverflow.com/users/9670239/tim-n"
            },
            "is_answered": true,
            "view_count": 16,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524171611,
            "creation_date": 1524147740,
            "last_edit_date": 1524171611,
            "question_id": 49923493,
            "body_markdown": "So I have a table that looks like this\r\n\r\n    ID     AccountType     Name                Individ\r\n    1      O               Acme Company        00\r\n    2      P               Joe Smith           00\r\n    1                      John Doe            01\r\n    1                      Steve Johnson       02\r\n    3      P               Shirley Johnson     00\r\n    2                      Jane Smith          01\r\n    1                      Kevin Lastname      03\r\n\r\nSo, O stands for Organization, and P stands for personal. Subaccounts are mixed in the table with the primary accounts, and a subaccount of an account has the same ID, but a null accounttype. I need to find a way to find all subaccounts of one AccountType, excluding subaccounts of personal accounts. I tried an INNER JOIN, but I can&#39;t join a column on itself.\r\n\r\n    SELECT * FROM &lt;schema.table&gt; \r\n    INNER JOIN &lt;schema.table&gt; ON table.id = table.id \r\n    WHERE accounttype = (&#39;B&#39; OR &#39;F&#39; OR &#39;O&#39; OR &#39;S&#39;) AND \r\n    individ != &#39;0&#39; \r\n    GROUP BY &#39;id&#39;;",
            "link": "https://stackoverflow.com/questions/49923493/how-do-i-get-mysql-to-look-at-an-id-column-to-check-if-another-row-with-the-same",
            "title": "How do I get MySQL to look at an ID column to check if another row with the same ID has a value in a different column?",
            "body": "<p>So I have a table that looks like this</p>\n\n<pre><code>ID     AccountType     Name                Individ\n1      O               Acme Company        00\n2      P               Joe Smith           00\n1                      John Doe            01\n1                      Steve Johnson       02\n3      P               Shirley Johnson     00\n2                      Jane Smith          01\n1                      Kevin Lastname      03\n</code></pre>\n\n<p>So, O stands for Organization, and P stands for personal. Subaccounts are mixed in the table with the primary accounts, and a subaccount of an account has the same ID, but a null accounttype. I need to find a way to find all subaccounts of one AccountType, excluding subaccounts of personal accounts. I tried an INNER JOIN, but I can't join a column on itself.</p>\n\n<pre><code>SELECT * FROM &lt;schema.table&gt; \nINNER JOIN &lt;schema.table&gt; ON table.id = table.id \nWHERE accounttype = ('B' OR 'F' OR 'O' OR 'S') AND \nindivid != '0' \nGROUP BY 'id';\n</code></pre>\n"
        },
        {
            "tags": [
                "angular",
                "angular-router"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 8708878,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/b08c56a88900b84175e5e208759bba86?s=128&d=identicon&r=PG&f=1",
                "display_name": "P&#233;ter Bakonyi",
                "link": "https://stackoverflow.com/users/8708878/p%c3%a9ter-bakonyi"
            },
            "is_answered": false,
            "view_count": 172,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524171589,
            "creation_date": 1506954409,
            "question_id": 46527528,
            "body_markdown": "When using `@angular/router` (v4.4):\r\n\r\n    // navigates to &#39;home#abc&#39;\r\n    router.navigate([&quot;home&quot;], { fragment: &quot;abc&quot; });\r\n\r\n    // navigates to &#39;home#abc&#39;\r\n    router.navigateByUrl(&quot;/home#abc&quot; });\r\n\r\n    // navigates to &#39;home&#39; and ignores fragment\r\n    router.navigateByUrl(&quot;/home&quot;, { fragment: &quot;abc&quot; });\r\n\r\n\r\nFirst 2 examples are ok but I would have expected that the third example also navigates to `home#abc`. I checked in angular&#39;s implementation that `navigate` first calls `createUrlTree` where `extras.fragment` is appended to url, however `navigateByUrl` simply ignores the fragment.\r\n\r\nIt would be surprising if this was a bug that no-one actually has reported yet. Still, I would like to have a confirmation that this is by design and not a bug. :)\r\n\r\nThanks!",
            "link": "https://stackoverflow.com/questions/46527528/angular-4-router-navigatebyurl-ignores-fragment-extras",
            "title": "Angular 4 - Router.navigateByUrl ignores fragment extras",
            "body": "<p>When using <code>@angular/router</code> (v4.4):</p>\n\n<pre><code>// navigates to 'home#abc'\nrouter.navigate([\"home\"], { fragment: \"abc\" });\n\n// navigates to 'home#abc'\nrouter.navigateByUrl(\"/home#abc\" });\n\n// navigates to 'home' and ignores fragment\nrouter.navigateByUrl(\"/home\", { fragment: \"abc\" });\n</code></pre>\n\n<p>First 2 examples are ok but I would have expected that the third example also navigates to <code>home#abc</code>. I checked in angular's implementation that <code>navigate</code> first calls <code>createUrlTree</code> where <code>extras.fragment</code> is appended to url, however <code>navigateByUrl</code> simply ignores the fragment.</p>\n\n<p>It would be surprising if this was a bug that no-one actually has reported yet. Still, I would like to have a confirmation that this is by design and not a bug. :)</p>\n\n<p>Thanks!</p>\n"
        },
        {
            "tags": [
                "jquery",
                "css",
                "twitter-bootstrap-3"
            ],
            "owner": {
                "reputation": 1292,
                "user_id": 584765,
                "user_type": "registered",
                "accept_rate": 79,
                "profile_image": "https://i.stack.imgur.com/zuFnS.jpg?s=128&g=1",
                "display_name": "Damien",
                "link": "https://stackoverflow.com/users/584765/damien"
            },
            "is_answered": false,
            "view_count": 18,
            "closed_date": 1524172058,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524171587,
            "creation_date": 1524170247,
            "question_id": 49929839,
            "body_markdown": "i&#39;m trying to do 2 columns in bootstrap with both being 100% height. On the right column is bascially going to be a div with a background-image and should be full height. I set the div and the container to 100% height but nothing happens. If i place text in the div, then i see the background image peek through. What am i doing wrong? here&#39;s part of the code:\r\n\r\n    &lt;div class=&quot;container-responsive&quot; id=&quot;content&quot;&gt;&lt;div class=&quot;row&quot;&gt;\r\n      &lt;div class=&quot;col-lg-6 col-md-6 col-sm-6&quot;&gt;\r\n      \r\n      &lt;/div&gt;\r\n      \r\n      &lt;div class=&quot;col-lg-6 col-md-6 col-sm-6&quot;&gt;\r\n        &lt;div class=&quot;v-image-1&quot; style=&quot;background-image: url(&#39;images/target.jpg&#39;);&quot;&gt;&lt;/div&gt;\r\n      \r\n      &lt;/div&gt;  \r\n      \r\n    &lt;/div&gt;\r\n\r\n\r\n    html, body, #content {\r\n      height:100%;\r\n      overflow-x:hidden;\r\n    }\r\n    \r\n    .v-image-1 {\r\n      min-height:100%;\r\n      background-size:cover;\r\n    }\r\n\r\nAny and all help greatly appreciated!",
            "link": "https://stackoverflow.com/questions/49929839/100-height-using-bootstrap-not-working",
            "closed_reason": "duplicate",
            "title": "100% height using bootstrap not working",
            "body": "<p>i'm trying to do 2 columns in bootstrap with both being 100% height. On the right column is bascially going to be a div with a background-image and should be full height. I set the div and the container to 100% height but nothing happens. If i place text in the div, then i see the background image peek through. What am i doing wrong? here's part of the code:</p>\n\n<pre><code>&lt;div class=\"container-responsive\" id=\"content\"&gt;&lt;div class=\"row\"&gt;\n  &lt;div class=\"col-lg-6 col-md-6 col-sm-6\"&gt;\n\n  &lt;/div&gt;\n\n  &lt;div class=\"col-lg-6 col-md-6 col-sm-6\"&gt;\n    &lt;div class=\"v-image-1\" style=\"background-image: url('images/target.jpg');\"&gt;&lt;/div&gt;\n\n  &lt;/div&gt;  \n\n&lt;/div&gt;\n\n\nhtml, body, #content {\n  height:100%;\n  overflow-x:hidden;\n}\n\n.v-image-1 {\n  min-height:100%;\n  background-size:cover;\n}\n</code></pre>\n\n<p>Any and all help greatly appreciated!</p>\n"
        },
        {
            "tags": [
                "python-3.x",
                "keras"
            ],
            "owner": {
                "reputation": 433,
                "user_id": 8793975,
                "user_type": "registered",
                "accept_rate": 70,
                "profile_image": "https://www.gravatar.com/avatar/086643c7f3fafe914727c51882e974bc?s=128&d=identicon&r=PG&f=1",
                "display_name": "enumaris",
                "link": "https://stackoverflow.com/users/8793975/enumaris"
            },
            "is_answered": false,
            "view_count": 25,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524171583,
            "creation_date": 1524096845,
            "last_edit_date": 1524171583,
            "question_id": 49910778,
            "body_markdown": "I&#39;m building a sequence to sequence model in Keras to correct simple spelling mistakes that might occur. I&#39;m following mostly [this tutorial][1].\r\n\r\nI have a pretty involved piece of code to generate random misspellings in words, and then I send the outputs of that: `([misspelled sentence,offset_sentence],original_sentence)` into the model. The model I built looks pretty much exactly the same as the one in the tutorial:\r\n\r\n        print(&#39;Training tokenizer...&#39;)\r\n        tokenizer = CharToken()\r\n        tokenizer.train_on_corpus(brown)\r\n\r\n        num_chars = len(tokenizer.char_dict)\r\n        alpha = 0.001\r\n\r\n        encoder_inputs = Input(shape=(None,num_chars))\r\n        encoder = LSTM(128,return_state=True)\r\n        encoder_outputs,state_h,state_c = encoder(encoder_inputs)\r\n\r\n        encoder_states = [state_h,state_c]\r\n\r\n        decoder_inputs = Input(shape=(None,num_chars))\r\n        decoder = LSTM(128,return_sequences=True,return_state=True)\r\n        decoder_outputs,_,_ = \r\n        decoder(decoder_inputs,initial_state=encoder_states)\r\n        decoder_dense = Dense(num_chars,activation=&#39;softmax&#39;)\r\n        decoder_outputs = decoder_dense(decoder_outputs)\r\n\r\n        model = keras.models.Model(inputs= \r\n        [encoder_inputs,decoder_inputs],outputs=decoder_outputs)\r\n        optim = keras.optimizers.rmsprop(lr=alpha,decay=1e-6)\r\n        model.compile(optimizer=optim,loss=&#39;categorical_crossentropy&#39;)\r\n        model.summary()\r\n        model.fit_generator(tokenizer.batch_generator(),\r\n        steps_per_epoch=1000,epochs=1)\r\n\r\nI&#39;m sure that the problem is not in the tokenizer since I&#39;ve gone through it and checked all of the outputs multiple times. The batch_generator method in that class outputs a tuple of one hot vectors representing `([misspelled sentence,offset_sentence],original_sentence)`. I&#39;ve tried changing the hyperparmaters, including making the learning rate a miniscule 0.00001 but no matter what I do, the training loss always starts at around 11 and then just keep increasing... \r\n\r\nCan anybody figure out what I did wrong? \r\n\r\nEDIT: I did one more step of debugging where I removed the tokenizer from the equation and just tried to train the network on 3 random one-hot arrays. I reduced the complexity a lot by limiting them to have only 10 possible inputs/outputs (characters). The loss quickly rose to ~100 and stayed there. I expect for 10 possible outcomes that random guessing would get me a loss of around `-ln(1/10)~2.3`, certainly 100 is way too high. I also expect that even though I fed the network random arrays that it would eventually memorize those arrays and over-fit and the loss would decrease, but that&#39;s not the case. The loss stays around 100. I can&#39;t figure out what&#39;s going wrong...\r\n\r\nEDIT 2: Some more debugging. I&#39;ve beaten the model into a much simpler one by forcing the inputs and outputs to have the same length. This is not too bad for a spell corrector as long as the spelling mistakes aren&#39;t deleting or inserting too many characters (I pad the sequences anyways to make them the same length which allows me to be able to train on batches). However, the model still exhibits the same behavior. I&#39;ve also tried running the model on random numbers and get the same 100ish loss:\r\n\r\n        num_chars=10\r\n        alpha = 0.001\r\n\r\n        X = np.random.randint(10,size=(10000,30,10))\r\n        Y = np.random.randint(10,size=(10000,30,10))\r\n\r\n        inputs = Input(shape=(None,num_chars))\r\n        x = LSTM(128,return_sequences=True)(inputs)\r\n        x = LSTM(128,return_sequences=True)(x)\r\n        output = Dense(num_chars,activation=&#39;softmax&#39;)(x)\r\n\r\n        model = keras.models.Model(inputs=inputs,outputs=output)\r\n        optim = keras.optimizers.rmsprop(lr=alpha,decay=1e-6)\r\n        model.compile(optimizer=optim,loss=&#39;categorical_crossentropy&#39;)\r\n        model.summary()\r\n        model.fit(X,Y) \r\n\r\nI&#39;m beginning to wonder if there&#39;s something wrong with my installation of keras or something like that. I&#39;ve run sequence models like this before many times on my other machine, and I&#39;ve never observed this strange behavior. \r\n\r\nEDIT 3: I just realized my debugging was flawed. I didn&#39;t turn the random Y array into a one-hot vector. When I do change it to a one-hot vector, the loss is as expected, about `-ln(1/num_chars)`. This means that the problem is probably in my tokenizer generator. But I can&#39;t figure out what the problem is since I&#39;ve printed out the output and saw that they were indeed one-hot vectors.\r\n\r\n\r\n  [1]: https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html",
            "link": "https://stackoverflow.com/questions/49910778/keras-sequence-to-sequence-model-loss-increases-without-bound",
            "title": "Keras sequence to sequence model loss increases without bound",
            "body": "<p>I'm building a sequence to sequence model in Keras to correct simple spelling mistakes that might occur. I'm following mostly <a href=\"https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html\" rel=\"nofollow noreferrer\">this tutorial</a>.</p>\n\n<p>I have a pretty involved piece of code to generate random misspellings in words, and then I send the outputs of that: <code>([misspelled sentence,offset_sentence],original_sentence)</code> into the model. The model I built looks pretty much exactly the same as the one in the tutorial:</p>\n\n<pre><code>    print('Training tokenizer...')\n    tokenizer = CharToken()\n    tokenizer.train_on_corpus(brown)\n\n    num_chars = len(tokenizer.char_dict)\n    alpha = 0.001\n\n    encoder_inputs = Input(shape=(None,num_chars))\n    encoder = LSTM(128,return_state=True)\n    encoder_outputs,state_h,state_c = encoder(encoder_inputs)\n\n    encoder_states = [state_h,state_c]\n\n    decoder_inputs = Input(shape=(None,num_chars))\n    decoder = LSTM(128,return_sequences=True,return_state=True)\n    decoder_outputs,_,_ = \n    decoder(decoder_inputs,initial_state=encoder_states)\n    decoder_dense = Dense(num_chars,activation='softmax')\n    decoder_outputs = decoder_dense(decoder_outputs)\n\n    model = keras.models.Model(inputs= \n    [encoder_inputs,decoder_inputs],outputs=decoder_outputs)\n    optim = keras.optimizers.rmsprop(lr=alpha,decay=1e-6)\n    model.compile(optimizer=optim,loss='categorical_crossentropy')\n    model.summary()\n    model.fit_generator(tokenizer.batch_generator(),\n    steps_per_epoch=1000,epochs=1)\n</code></pre>\n\n<p>I'm sure that the problem is not in the tokenizer since I've gone through it and checked all of the outputs multiple times. The batch_generator method in that class outputs a tuple of one hot vectors representing <code>([misspelled sentence,offset_sentence],original_sentence)</code>. I've tried changing the hyperparmaters, including making the learning rate a miniscule 0.00001 but no matter what I do, the training loss always starts at around 11 and then just keep increasing... </p>\n\n<p>Can anybody figure out what I did wrong? </p>\n\n<p>EDIT: I did one more step of debugging where I removed the tokenizer from the equation and just tried to train the network on 3 random one-hot arrays. I reduced the complexity a lot by limiting them to have only 10 possible inputs/outputs (characters). The loss quickly rose to ~100 and stayed there. I expect for 10 possible outcomes that random guessing would get me a loss of around <code>-ln(1/10)~2.3</code>, certainly 100 is way too high. I also expect that even though I fed the network random arrays that it would eventually memorize those arrays and over-fit and the loss would decrease, but that's not the case. The loss stays around 100. I can't figure out what's going wrong...</p>\n\n<p>EDIT 2: Some more debugging. I've beaten the model into a much simpler one by forcing the inputs and outputs to have the same length. This is not too bad for a spell corrector as long as the spelling mistakes aren't deleting or inserting too many characters (I pad the sequences anyways to make them the same length which allows me to be able to train on batches). However, the model still exhibits the same behavior. I've also tried running the model on random numbers and get the same 100ish loss:</p>\n\n<pre><code>    num_chars=10\n    alpha = 0.001\n\n    X = np.random.randint(10,size=(10000,30,10))\n    Y = np.random.randint(10,size=(10000,30,10))\n\n    inputs = Input(shape=(None,num_chars))\n    x = LSTM(128,return_sequences=True)(inputs)\n    x = LSTM(128,return_sequences=True)(x)\n    output = Dense(num_chars,activation='softmax')(x)\n\n    model = keras.models.Model(inputs=inputs,outputs=output)\n    optim = keras.optimizers.rmsprop(lr=alpha,decay=1e-6)\n    model.compile(optimizer=optim,loss='categorical_crossentropy')\n    model.summary()\n    model.fit(X,Y) \n</code></pre>\n\n<p>I'm beginning to wonder if there's something wrong with my installation of keras or something like that. I've run sequence models like this before many times on my other machine, and I've never observed this strange behavior. </p>\n\n<p>EDIT 3: I just realized my debugging was flawed. I didn't turn the random Y array into a one-hot vector. When I do change it to a one-hot vector, the loss is as expected, about <code>-ln(1/num_chars)</code>. This means that the problem is probably in my tokenizer generator. But I can't figure out what the problem is since I've printed out the output and saw that they were indeed one-hot vectors.</p>\n"
        },
        {
            "tags": [
                "jenkins",
                "plugins",
                "configuration",
                "clearcase"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 5386349,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/cc92c6dee3d97901a0404fe7ef435ca5?s=128&d=identicon&r=PG&f=1",
                "display_name": "Qing CZ",
                "link": "https://stackoverflow.com/users/5386349/qing-cz"
            },
            "is_answered": false,
            "view_count": 10,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524171578,
            "creation_date": 1524170943,
            "question_id": 49930023,
            "body_markdown": "I tried to following the instructions for CLearcase PlugIn for Jenkins.\r\n\r\n     https://plugins.jenkins.io/clearcase-ucm-plugin\r\n\r\nbut I am confused about where is this &quot;Main configuration screen for Clearcase UCM Plugin&quot;. Is it from clearcase UCM, or from the Jenkins I installed?",
            "link": "https://stackoverflow.com/questions/49930023/where-to-find-the-configuration-window-for-clearcase-plugin-for-jenkins",
            "title": "Where to find the configuration window for Clearcase plugin for Jenkins?",
            "body": "<p>I tried to following the instructions for CLearcase PlugIn for Jenkins.</p>\n\n<pre><code> https://plugins.jenkins.io/clearcase-ucm-plugin\n</code></pre>\n\n<p>but I am confused about where is this \"Main configuration screen for Clearcase UCM Plugin\". Is it from clearcase UCM, or from the Jenkins I installed?</p>\n"
        },
        {
            "tags": [
                "mysql",
                "events"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9578051,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/0390551b1e6950a65096dfff7e1b6cff?s=128&d=identicon&r=PG&f=1",
                "display_name": "vinay nischal",
                "link": "https://stackoverflow.com/users/9578051/vinay-nischal"
            },
            "is_answered": false,
            "view_count": 10,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524171560,
            "creation_date": 1524153717,
            "last_edit_date": 1524171560,
            "question_id": 49925483,
            "body_markdown": "How can I automatically execute MYSQL Event everyday at `02:00:00 AM` in morning that automatically updates `experience` column of `Student` table?\r\n\r\n    create event if not exists UpdateExperience\r\n    on schedule every 1 day starts &#39;2018-04-19 02:00:00&#39; \r\n    do\r\n    \tupdate test.student set Experience=floor((datediff(now(),`date`)/365));\r\n    end \r\n    DELIMITER ;",
            "link": "https://stackoverflow.com/questions/49925483/how-can-i-automatically-execute-mysql-event-everyday-at-020000-am-in-morning-t",
            "title": "how can i automatically execute MYSQL Event everyday at 02:00:00 AM in morning that automatically updates `experience` column of `Student` table?",
            "body": "<p>How can I automatically execute MYSQL Event everyday at <code>02:00:00 AM</code> in morning that automatically updates <code>experience</code> column of <code>Student</code> table?</p>\n\n<pre><code>create event if not exists UpdateExperience\non schedule every 1 day starts '2018-04-19 02:00:00' \ndo\n    update test.student set Experience=floor((datediff(now(),`date`)/365));\nend \nDELIMITER ;\n</code></pre>\n"
        },
        {
            "tags": [
                "linux",
                "bash",
                "shell"
            ],
            "owner": {
                "reputation": 2369,
                "user_id": 1172494,
                "user_type": "registered",
                "accept_rate": 56,
                "profile_image": "https://www.gravatar.com/avatar/5aff2607f660e800381a1f8070996592?s=128&d=identicon&r=PG",
                "display_name": "boltup_im_coding",
                "link": "https://stackoverflow.com/users/1172494/boltup-im-coding"
            },
            "is_answered": true,
            "view_count": 7770,
            "accepted_answer_id": 14164025,
            "answer_count": 7,
            "score": 1,
            "last_activity_date": 1524171557,
            "creation_date": 1357329002,
            "question_id": 14163922,
            "body_markdown": "I have some files named like this:\r\n\r\nfile1.c.keep.apple\r\n\r\nfile2.c.keep.apple\r\n\r\nI am trying to write a shell script so that I pass in the suffix as an argument (in this case, `apple`) and it will rename all of the files removing the `.keep.apple`.\r\n\r\nExample execution:\r\n\r\n`script.sh apple`\r\n\r\nresults in the files above being renamed to\r\n\r\nfile1.c\r\n\r\nfile2.c\r\n\r\nSo far, I have\r\n\r\n     #! /bin/sh\r\n     find . -type f -name \\&#39;*.keep.$1\\&#39; -print0 | xargs -0 rename &#39;s/\\(.keep.*)$//&#39;\r\n\r\nand the files do not get renamed. I know the `find` portion is correct. I am thinking the regex on my rename is wrong. How can I get the script working the way I want?",
            "link": "https://stackoverflow.com/questions/14163922/linux-shell-script-to-find-and-rename-files-to-remove-suffix",
            "title": "Linux shell script to find and rename files to remove suffix?",
            "body": "<p>I have some files named like this:</p>\n\n<p>file1.c.keep.apple</p>\n\n<p>file2.c.keep.apple</p>\n\n<p>I am trying to write a shell script so that I pass in the suffix as an argument (in this case, <code>apple</code>) and it will rename all of the files removing the <code>.keep.apple</code>.</p>\n\n<p>Example execution:</p>\n\n<p><code>script.sh apple</code></p>\n\n<p>results in the files above being renamed to</p>\n\n<p>file1.c</p>\n\n<p>file2.c</p>\n\n<p>So far, I have</p>\n\n<pre><code> #! /bin/sh\n find . -type f -name \\'*.keep.$1\\' -print0 | xargs -0 rename 's/\\(.keep.*)$//'\n</code></pre>\n\n<p>and the files do not get renamed. I know the <code>find</code> portion is correct. I am thinking the regex on my rename is wrong. How can I get the script working the way I want?</p>\n"
        },
        {
            "tags": [
                "c#",
                "visual-studio-2017"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 9245487,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/4d6e4a8fd954e4aa2e49cd8f8dcd394f?s=128&d=identicon&r=PG&f=1",
                "display_name": "user9245487",
                "link": "https://stackoverflow.com/users/9245487/user9245487"
            },
            "is_answered": true,
            "view_count": 40,
            "accepted_answer_id": 49930089,
            "answer_count": 2,
            "score": 1,
            "last_activity_date": 1524171556,
            "creation_date": 1524168512,
            "question_id": 49929403,
            "body_markdown": "I wrote a console app in C# on VS 2017 for mac, and the resulting build file is a .dll. I can run that fine in the IDE and from the terminal with &quot;dotnet blah.dll&quot;.\r\n\r\nWhat I really want is to give my little console app to my Windows friends who can then run it. \r\n\r\nI&#39;m not finding detail on the web or here on how to tell VS2017 mac to make me a Windows exe. ",
            "link": "https://stackoverflow.com/questions/49929403/how-do-i-build-an-exe-in-vs-17-mac-to-run-in-windows",
            "title": "How do I build an exe in VS 17 Mac to run in Windows",
            "body": "<p>I wrote a console app in C# on VS 2017 for mac, and the resulting build file is a .dll. I can run that fine in the IDE and from the terminal with \"dotnet blah.dll\".</p>\n\n<p>What I really want is to give my little console app to my Windows friends who can then run it. </p>\n\n<p>I'm not finding detail on the web or here on how to tell VS2017 mac to make me a Windows exe. </p>\n"
        },
        {
            "tags": [
                "java",
                "spring"
            ],
            "owner": {
                "reputation": 9548,
                "user_id": 258483,
                "user_type": "registered",
                "accept_rate": 46,
                "profile_image": "https://www.gravatar.com/avatar/dd4dee2094dcd427aaec8ee329d9cfd6?s=128&d=identicon&r=PG",
                "display_name": "Dims",
                "link": "https://stackoverflow.com/users/258483/dims"
            },
            "is_answered": true,
            "view_count": 2177,
            "answer_count": 2,
            "score": 2,
            "last_activity_date": 1524171552,
            "creation_date": 1490473119,
            "last_edit_date": 1512754926,
            "question_id": 43021493,
            "body_markdown": "I would like to create custom child context from some configuration and additionally add some beans to it programmatically.\r\n\r\nI read answer https://stackoverflow.com/a/4540762/258483 about `BeanDefinitionRegistryPostProcessor` but don&#39;t understand how to use it. If I write implementation of `BeanDefinitionRegistryPostProcessor` then what to do with it next? Add to context? But this is the question: how to add bean to context! If I would be able to add `BeanDefinitionRegistryPostProcessor` to context, then why I would ask how to add beans?\r\n\r\nThe problem is that I have context and want to add bean to it. \r\n\r\nI know I can instantiate beans and autowire them with\r\n\r\n    Context#getAutowireCapableBeanFactory().createBean(klass);\r\n\r\nbut this apparently just wires class, but not adds it to context?",
            "link": "https://stackoverflow.com/questions/43021493/how-to-add-bean-programmatically-to-spring-context",
            "title": "How to add bean programmatically to Spring context?",
            "body": "<p>I would like to create custom child context from some configuration and additionally add some beans to it programmatically.</p>\n\n<p>I read answer <a href=\"https://stackoverflow.com/a/4540762/258483\">https://stackoverflow.com/a/4540762/258483</a> about <code>BeanDefinitionRegistryPostProcessor</code> but don't understand how to use it. If I write implementation of <code>BeanDefinitionRegistryPostProcessor</code> then what to do with it next? Add to context? But this is the question: how to add bean to context! If I would be able to add <code>BeanDefinitionRegistryPostProcessor</code> to context, then why I would ask how to add beans?</p>\n\n<p>The problem is that I have context and want to add bean to it. </p>\n\n<p>I know I can instantiate beans and autowire them with</p>\n\n<pre><code>Context#getAutowireCapableBeanFactory().createBean(klass);\n</code></pre>\n\n<p>but this apparently just wires class, but not adds it to context?</p>\n"
        },
        {
            "tags": [
                "jquery",
                "plugins",
                "lightbox"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9603061,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-dvduiGJdj5s/AAAAAAAAAAI/AAAAAAAAFME/aFjS6l1JmoY/photo.jpg?sz=128",
                "display_name": "Muhammad Eid",
                "link": "https://stackoverflow.com/users/9603061/muhammad-eid"
            },
            "is_answered": false,
            "view_count": 8,
            "answer_count": 0,
            "score": -2,
            "last_activity_date": 1524171545,
            "creation_date": 1524171545,
            "question_id": 49930147,
            "body_markdown": "I was Search about lightbox jquery Like this can help please \r\n[enter image description here][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/RExVs.png",
            "link": "https://stackoverflow.com/questions/49930147/what-name-of-this-lightbox-plugin",
            "title": "What name of this LightBox Plugin",
            "body": "<p>I was Search about lightbox jquery Like this can help please \n<a href=\"https://i.stack.imgur.com/RExVs.png\" rel=\"nofollow noreferrer\">enter image description here</a></p>\n"
        },
        {
            "tags": [
                "python",
                "tkinter",
                "counter"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 9596866,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/10216600051139738/picture?type=large",
                "display_name": "Stavrius Mtvs",
                "link": "https://stackoverflow.com/users/9596866/stavrius-mtvs"
            },
            "is_answered": true,
            "view_count": 23,
            "answer_count": 1,
            "score": -1,
            "last_activity_date": 1524171545,
            "creation_date": 1524169509,
            "last_edit_date": 1524171545,
            "question_id": 49929663,
            "body_markdown": "I have here a function for a counter.\r\n\r\nMy question is how to set the counter to `0` again after a button click.\r\n\r\n    import tkinter\r\n    import sys\r\n\r\n    root=tkinter.Tk()\r\n    root.geometry(&quot;200x200&quot;)\r\n    root.title(&quot;His Button Increaser&quot;)\r\n\r\n    counter=tkinter.IntVar()\r\n\r\n    def OnClick(event=None):\r\n        counter.set(counter.get() + 1)\r\n\r\n    tkinter.Label(root, textvariable=counter).pack()\r\n    tkinter.Button(root, text=&quot;One up&quot;, command=onClick).pack()\r\n    root.mainloop()\r\n",
            "link": "https://stackoverflow.com/questions/49929663/how-to-set-the-counter-to-0-again-after-button-click",
            "title": "How to set the counter to 0 again after button click?",
            "body": "<p>I have here a function for a counter.</p>\n\n<p>My question is how to set the counter to <code>0</code> again after a button click.</p>\n\n<pre><code>import tkinter\nimport sys\n\nroot=tkinter.Tk()\nroot.geometry(\"200x200\")\nroot.title(\"His Button Increaser\")\n\ncounter=tkinter.IntVar()\n\ndef OnClick(event=None):\n    counter.set(counter.get() + 1)\n\ntkinter.Label(root, textvariable=counter).pack()\ntkinter.Button(root, text=\"One up\", command=onClick).pack()\nroot.mainloop()\n</code></pre>\n"
        },
        {
            "tags": [
                "winforms",
                "parallel-processing",
                "task"
            ],
            "owner": {
                "reputation": 1064,
                "user_id": 1390192,
                "user_type": "registered",
                "accept_rate": 79,
                "profile_image": "https://www.gravatar.com/avatar/2011214205e164fbfd409cf42a0d23c9?s=128&d=identicon&r=PG",
                "display_name": "tmighty",
                "link": "https://stackoverflow.com/users/1390192/tmighty"
            },
            "is_answered": false,
            "view_count": 18,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524171536,
            "creation_date": 1524171536,
            "question_id": 49930144,
            "body_markdown": "For my desktop image processing application, I need to load up to 10 bitmaps of 8192x8192 pixels from the hard drive.\r\n\r\nI use \r\n\r\n    Bitmap.FromFile()\r\n\r\nUsing an SSD drive, this takes around 1000 ms for 1 bitmap, so 10 seconds altogether.\r\n\r\nI need to minimize the loading time, so I was thinking about using parallel processing. \r\n\r\nI tried to locate an example of how to utilize &quot;Task&quot; for this, but I didn&#39;t find one. Is this not something that should be done in a parallel task for some reason?\r\n\r\nAlso, I would need to be able to keep track of which path an image originated from. A list of bitmaps wouldn&#39;t be sufficient.\r\n\r\nIf anybody can point me at how this could be done, I&#39;d be really glad.",
            "link": "https://stackoverflow.com/questions/49930144/loading-bitmaps-using-task",
            "title": "Loading bitmaps using Task",
            "body": "<p>For my desktop image processing application, I need to load up to 10 bitmaps of 8192x8192 pixels from the hard drive.</p>\n\n<p>I use </p>\n\n<pre><code>Bitmap.FromFile()\n</code></pre>\n\n<p>Using an SSD drive, this takes around 1000 ms for 1 bitmap, so 10 seconds altogether.</p>\n\n<p>I need to minimize the loading time, so I was thinking about using parallel processing. </p>\n\n<p>I tried to locate an example of how to utilize \"Task\" for this, but I didn't find one. Is this not something that should be done in a parallel task for some reason?</p>\n\n<p>Also, I would need to be able to keep track of which path an image originated from. A list of bitmaps wouldn't be sufficient.</p>\n\n<p>If anybody can point me at how this could be done, I'd be really glad.</p>\n"
        },
        {
            "tags": [
                "c",
                "image-processing",
                "virtualdub"
            ],
            "owner": {
                "reputation": 28,
                "user_id": 6416036,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/10156970694490057/picture?type=large",
                "display_name": "Captain Jack",
                "link": "https://stackoverflow.com/users/6416036/captain-jack"
            },
            "is_answered": false,
            "view_count": 38,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524171536,
            "creation_date": 1524127572,
            "last_edit_date": 1524171536,
            "question_id": 49916622,
            "body_markdown": "I am writing a VirtualDub plug-in where there&#39;s a requirement to change hue/chroma of image without affecting luminance. \r\n\r\nHere&#39;s some code:\r\n\r\n    Pixel32 *dst= fa-&gt;dst.data;\r\n\r\n    int U= (*dst&gt;&gt;16) &amp; 0xff;\r\n    int Y= (*dst&gt;&gt; 8) &amp; 0xff;\r\n    int V= (*dst    ) &amp; 0xff;\r\n\r\nBefore converting to RGB, I need to adjust the hue of UV by x angle. UV range is between -0.5 and +0.5. Is there a conversion table/formula/already-written-function to adjust, say, hue, by -45 degrees in the colour space?",
            "link": "https://stackoverflow.com/questions/49916622/adjust-hue-angle-without-affecting-luminance-of-yuv-image",
            "title": "Adjust hue/angle without affecting luminance of YUV image",
            "body": "<p>I am writing a VirtualDub plug-in where there's a requirement to change hue/chroma of image without affecting luminance. </p>\n\n<p>Here's some code:</p>\n\n<pre><code>Pixel32 *dst= fa-&gt;dst.data;\n\nint U= (*dst&gt;&gt;16) &amp; 0xff;\nint Y= (*dst&gt;&gt; 8) &amp; 0xff;\nint V= (*dst    ) &amp; 0xff;\n</code></pre>\n\n<p>Before converting to RGB, I need to adjust the hue of UV by x angle. UV range is between -0.5 and +0.5. Is there a conversion table/formula/already-written-function to adjust, say, hue, by -45 degrees in the colour space?</p>\n"
        },
        {
            "tags": [
                "python-3.x",
                "tensorflow",
                "deep-learning"
            ],
            "owner": {
                "reputation": 28,
                "user_id": 9045339,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/0f01857d9ae3c95b8ef894beb23dbba6?s=128&d=identicon&r=PG&f=1",
                "display_name": "MikeDoho",
                "link": "https://stackoverflow.com/users/9045339/mikedoho"
            },
            "is_answered": false,
            "view_count": 21,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524171529,
            "creation_date": 1523833223,
            "last_edit_date": 1524171529,
            "question_id": 49847614,
            "body_markdown": "I am trying to utilize code from a coursera course by deeplearning.ai to analyze one of my own datasets.\r\n\r\nWhen I try to implement the code, with what I thought were appropriate alterations, I see that after each epoch my cost does not change (cost = 1.459).\r\n\r\nI have tried altering the code to make it more simple by removing the minibatches but the cost is still the same. As an aside, when I did this during the course it ran as expected but again on a different dataset.\r\n\r\nCode below:\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    import pandas as pd\r\n    import math\r\n    import matplotlib.pyplot as plt\r\n    from tensorflow.python.framework import ops\r\n    from math import floor, ceil\r\n    \r\n    from sklearn.model_selection import train_test_split\r\n    # import data\r\n    \r\n    X_main = pd.read_csv(r&quot;C:\\Users\\Mike\\Desktop\\Radiation Oncology\\Glioma\\CSV data\\glioma DB X.csv&quot;)\r\n    \r\n    Y_main = pd.read_csv(r&quot;C:\\Users\\Mike\\Desktop\\Radiation Oncology\\Glioma\\CSV data\\glioma DB Y.csv&quot;)\r\n    # Need to split data into train, validate, test\r\n    \r\n    # partition with sklearn (still as dataframe)\r\n    \r\n    x_train, x_test, y_train, y_test = train_test_split(X_main, Y_main, test_size=0.3)\r\n    x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5)\r\n    # Normalize training data; will want to have the same mu and sigma for test\r\n    \r\n    def normalize_features(dataset):\r\n        mu = np.mean(dataset, axis = 0) # columns\r\n        sigma = np.std(dataset, axis = 0)\r\n        norm_parameters = {&#39;mu&#39;: mu,\r\n                    &#39;sigma&#39;: sigma}\r\n        return (dataset-mu)/(sigma+1e-10), norm_parameters\r\n    \r\n    # Normal X data; using same mu and sigma from test set; then transposed\r\n    \r\n    x_train, norm_parameters = normalize_features(x_train)\r\n    \r\n    x_val = (x_val-norm_parameters[&#39;mu&#39;])/(norm_parameters[&#39;sigma&#39;]+1e-10)\r\n    \r\n    x_test = (x_test-norm_parameters[&#39;mu&#39;])/(norm_parameters[&#39;sigma&#39;]+1e-10)\r\n    x_train = np.transpose(x_train)\r\n    x_val = np.transpose(x_val)\r\n    x_test = np.transpose(x_test)\r\n    \r\n    y_train = np.transpose(y_train)\r\n    y_val = np.transpose(y_val)\r\n    y_test = np.transpose(y_test)\r\n    # converting values from database to matrix\r\n    x_train = x_train.as_matrix()\r\n    x_val = x_val.as_matrix()\r\n    x_test = x_test.as_matrix()\r\n    \r\n    y_train = y_train.as_matrix()\r\n    y_val = y_val.as_matrix()\r\n    y_test = y_test.as_matrix()\r\n    # testing shape\r\n    \r\n    print(y_train.shape)\r\n    print(y_val.shape)\r\n    print(y_test.shape)\r\n    \r\n    print(x_train.shape)\r\n    print(x_val.shape)\r\n    print(x_test.shape)\r\n    \r\n    # convert y to array per value so 3 = [0 0 1]\r\n    \r\n    def convert_to_one_hot(Y, C):\r\n        Y = np.eye(C)[Y.reshape(-1)].T\r\n        return Y\r\n    \r\n    y_train = convert_to_one_hot(y_train, 4)\r\n    y_val = convert_to_one_hot(y_val, 4)\r\n    y_test = convert_to_one_hot(y_test, 4)\r\n    print (&quot;number of training examples = &quot; + str(x_train.shape[1]))\r\n    print (&quot;number of test examples = &quot; + str(x_test.shape[1]))\r\n    print (&quot;X_train shape: &quot; + str(x_train.shape))\r\n    print (&quot;Y_train shape: &quot; + str(y_train.shape))\r\n    print (&quot;X_test shape: &quot; + str(x_test.shape))\r\n    print (&quot;Y_test shape: &quot; + str(y_test.shape))\r\n    \r\n    # minibatches for later\r\n    \r\n    def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\r\n        &quot;&quot;&quot;\r\n        Creates a list of random minibatches from (X, Y)\r\n        \r\n        Arguments:\r\n        X -- input data, of shape (input size, number of examples)\r\n        Y -- true &quot;label&quot; vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\r\n        mini_batch_size - size of the mini-batches, integer\r\n        seed -- this is only for the purpose of grading, so that you&#39;re &quot;random minibatches are the same as ours.\r\n        \r\n        Returns:\r\n        mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\r\n        &quot;&quot;&quot;\r\n        \r\n        m = X.shape[1]                  # number of training examples\r\n        mini_batches = []\r\n        \r\n        # Step 1: Shuffle (X, Y)\r\n        permutation = list(np.random.permutation(m))\r\n        shuffled_X = X[:, permutation]\r\n        shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\r\n    \r\n        # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\r\n        num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\r\n        for k in range(0, num_complete_minibatches):\r\n            mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\r\n            mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\r\n            mini_batch = (mini_batch_X, mini_batch_Y)\r\n            mini_batches.append(mini_batch)\r\n        \r\n        # Handling the end case (last mini-batch &lt; mini_batch_size)\r\n        if m % mini_batch_size != 0:\r\n            mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\r\n            mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\r\n            mini_batch = (mini_batch_X, mini_batch_Y)\r\n            mini_batches.append(mini_batch)\r\n        \r\n        return mini_batches\r\n    \r\n    \r\n    # starting TF graph\r\n    # Create X and Y placeholders\r\n    def create_xy_placeholder(n_x, n_y):\r\n        X = tf.placeholder(tf.float32, shape = [n_x, None], name = &#39;X&#39;)\r\n        Y = tf.placeholder(tf.float32, shape = [n_y, None], name = &#39;Y&#39;)\r\n    \r\n        return X, Y\r\n    X, Y = create_xy_placeholder(x_train.shape[0],y_train.shape[0])\r\n    print(&#39;X = &#39; + str(X))\r\n    print(&#39;Y = &#39; + str(Y))\r\n    \r\n    # initialize parameters for 3 hidden layer network\r\n    def initialize_parameters():\r\n        W1 = tf.get_variable(&#39;W1&#39;, [50, 67], initializer = tf.contrib.layers.xavier_initializer())\r\n        b1 = tf.get_variable(&quot;b1&quot;, [50,1], initializer = tf.zeros_initializer())\r\n        W2 = tf.get_variable(&#39;W2&#39;, [40, 50], initializer = tf.contrib.layers.xavier_initializer())\r\n        b2 = tf.get_variable(&quot;b2&quot;, [40,1], initializer = tf.zeros_initializer())\r\n        W3 = tf.get_variable(&#39;W3&#39;, [4, 40], initializer = tf.contrib.layers.xavier_initializer())\r\n        b3 = tf.get_variable(&quot;b3&quot;, [1,1], initializer = tf.zeros_initializer())\r\n    \r\n        parameters = {&quot;W1&quot;: W1,\r\n                      &quot;b1&quot;: b1,\r\n                      &quot;W2&quot;: W2,\r\n                      &quot;b2&quot;: b2,\r\n                      &quot;W3&quot;: W3,\r\n                      &quot;b3&quot;: b3}\r\n        \r\n        return parameters\r\n    tf.reset_default_graph()\r\n    with tf.Session() as sess:\r\n        parameters = initialize_parameters()\r\n        print(&quot;W1 = &quot; + str(parameters[&quot;W1&quot;]))\r\n        print(&quot;b1 = &quot; + str(parameters[&quot;b1&quot;]))\r\n        print(&quot;W2 = &quot; + str(parameters[&quot;W2&quot;]))\r\n        print(&quot;b2 = &quot; + str(parameters[&quot;b2&quot;]))\r\n    \r\n    # forward propagation\r\n    def forward_propagation(X, parameters):   \r\n        # Retrieve the parameters from the dictionary &quot;parameters&quot; \r\n        W1 = parameters[&#39;W1&#39;]\r\n        b1 = parameters[&#39;b1&#39;]\r\n        W2 = parameters[&#39;W2&#39;]\r\n        b2 = parameters[&#39;b2&#39;]\r\n        W3 = parameters[&#39;W3&#39;]\r\n        b3 = parameters[&#39;b3&#39;]\r\n        \r\n      \r\n        Z1 = tf.matmul(W1, X) + b1  \r\n        A1 = tf.nn.relu(Z1)                                            \r\n        Z2 = tf.matmul(W2, A1) + b2                           \r\n        A2 = tf.nn.relu(Z2)                                              \r\n        Z3 = tf.matmul(W3, A2) + b3                                      \r\n        \r\n        return Z3\r\n    tf.reset_default_graph()\r\n    \r\n    with tf.Session() as sess:\r\n        X, Y = create_xy_placeholder(x_train.shape[0], y_train.shape[0])\r\n        parameters = initialize_parameters()\r\n        Z3 = forward_propagation(X, parameters)\r\n        print(&quot;Z3 = &quot; + str(Z3))\r\n    \r\n    # compute cost\r\n    def compute_cost(Z3, Y):\r\n       \r\n        logits = tf.transpose(Z3)\r\n        labels = tf.transpose(Y)\r\n        \r\n        cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, \r\n                                                                      labels = labels))\r\n        return cost\r\n    tf.reset_default_graph()\r\n    \r\n    with tf.Session() as sess:\r\n        X, Y = create_xy_placeholder(x_train.shape[0], y_train.shape[0])\r\n        parameters = initialize_parameters()\r\n        Z3 = forward_propagation(X, parameters)\r\n        cost = compute_cost(Z3, Y)\r\n        print(&quot;cost = &quot; + str(cost))\r\n    \r\n    def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\r\n              num_epochs = 1500, minibatch_size = 32, print_cost = True):\r\n           \r\n        ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\r\n        tf.set_random_seed(1)                             # to keep consistent results\r\n        seed = 3                                          # to keep consistent results\r\n        (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\r\n        n_y = Y_train.shape[0]                            # n_y : output size\r\n        costs = []                                        # To keep track of the cost\r\n        \r\n        # Create Placeholders of shape (n_x, n_y)\r\n        X, Y = create_xy_placeholder(n_x, n_y)\r\n    \r\n        # Initialize parameters\r\n        parameters = initialize_parameters()\r\n        \r\n        # Forward propagation: Build the forward propagation in the tensorflow graph\r\n        Z3 = forward_propagation(X, parameters)\r\n        \r\n        # Cost function: Add cost function to tensorflow graph\r\n        cost = compute_cost(Z3, Y)\r\n        \r\n        # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\r\n        optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\r\n        \r\n        # Initialize all the variables\r\n        init = tf.global_variables_initializer()\r\n    \r\n        config = tf.ConfigProto()\r\n        config.gpu_options.allow_growth = True\r\n        # Start the session to compute the tensorflow graph\r\n        with tf.Session(config=config) as sess:\r\n            # Run the initialization\r\n            sess.run(init)\r\n            \r\n            # Do the training loop\r\n            for epoch in range(num_epochs):\r\n    \r\n                epoch_cost = 0.                       # Defines a cost related to an epoch\r\n                num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\r\n                seed = seed + 1\r\n                minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\r\n    \r\n                for minibatch in minibatches:\r\n    \r\n                    # Select a minibatch\r\n                    (minibatch_X, minibatch_Y) = minibatch\r\n                    \r\n                    # IMPORTANT: The line that runs the graph on a minibatch.\r\n                    # Run the session to execute the &quot;optimizer&quot; and the &quot;cost&quot;, the feedict should contain a minibatch for (X,Y).\r\n                    \r\n                    _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\r\n                    \r\n                    epoch_cost += minibatch_cost / num_minibatches\r\n    \r\n                # Print the cost every epoch\r\n                if print_cost == True and epoch % 100 == 0:\r\n                    print (&quot;Cost after epoch %i: %f&quot; % (epoch, epoch_cost))\r\n                if print_cost == True and epoch % 5 == 0:\r\n                    costs.append(epoch_cost)\r\n                    \r\n            # plot the cost\r\n            plt.plot(np.squeeze(costs))\r\n            plt.ylabel(&#39;cost&#39;)\r\n            plt.xlabel(&#39;iterations (per tens)&#39;)\r\n            plt.title(&quot;Learning rate =&quot; + str(learning_rate))\r\n            plt.show()\r\n    \r\n            # lets save the parameters in a variable\r\n            parameters = sess.run(parameters)\r\n            print (&quot;Parameters have been trained!&quot;)\r\n    \r\n            # Calculate the correct predictions\r\n            correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\r\n    \r\n            # Calculate accuracy on the test set\r\n            accuracy = tf.reduce_mean(tf.cast(correct_prediction, &quot;float&quot;))\r\n    \r\n            print (&quot;Train Accuracy:&quot;, accuracy.eval({X: X_train, Y: Y_train}))\r\n            print (&quot;Test Accuracy:&quot;, accuracy.eval({X: X_test, Y: Y_test}))\r\n            \r\n            \r\n            return parameters\r\n        \r\n    parameters = model(x_train, y_train, x_test, y_test)\r\n\r\n\r\n\r\n\r\nEDIT: \r\nAfter following the trail mentioned in the comments, I was able to get the learning to improve\r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/JLme4.png",
            "link": "https://stackoverflow.com/questions/49847614/any-tips-for-assessing-unchanging-cost-function-in-tensorflow",
            "title": "Any tips for assessing unchanging cost function in Tensorflow",
            "body": "<p>I am trying to utilize code from a coursera course by deeplearning.ai to analyze one of my own datasets.</p>\n\n<p>When I try to implement the code, with what I thought were appropriate alterations, I see that after each epoch my cost does not change (cost = 1.459).</p>\n\n<p>I have tried altering the code to make it more simple by removing the minibatches but the cost is still the same. As an aside, when I did this during the course it ran as expected but again on a different dataset.</p>\n\n<p>Code below:</p>\n\n<pre><code>import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport math\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.framework import ops\nfrom math import floor, ceil\n\nfrom sklearn.model_selection import train_test_split\n# import data\n\nX_main = pd.read_csv(r\"C:\\Users\\Mike\\Desktop\\Radiation Oncology\\Glioma\\CSV data\\glioma DB X.csv\")\n\nY_main = pd.read_csv(r\"C:\\Users\\Mike\\Desktop\\Radiation Oncology\\Glioma\\CSV data\\glioma DB Y.csv\")\n# Need to split data into train, validate, test\n\n# partition with sklearn (still as dataframe)\n\nx_train, x_test, y_train, y_test = train_test_split(X_main, Y_main, test_size=0.3)\nx_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5)\n# Normalize training data; will want to have the same mu and sigma for test\n\ndef normalize_features(dataset):\n    mu = np.mean(dataset, axis = 0) # columns\n    sigma = np.std(dataset, axis = 0)\n    norm_parameters = {'mu': mu,\n                'sigma': sigma}\n    return (dataset-mu)/(sigma+1e-10), norm_parameters\n\n# Normal X data; using same mu and sigma from test set; then transposed\n\nx_train, norm_parameters = normalize_features(x_train)\n\nx_val = (x_val-norm_parameters['mu'])/(norm_parameters['sigma']+1e-10)\n\nx_test = (x_test-norm_parameters['mu'])/(norm_parameters['sigma']+1e-10)\nx_train = np.transpose(x_train)\nx_val = np.transpose(x_val)\nx_test = np.transpose(x_test)\n\ny_train = np.transpose(y_train)\ny_val = np.transpose(y_val)\ny_test = np.transpose(y_test)\n# converting values from database to matrix\nx_train = x_train.as_matrix()\nx_val = x_val.as_matrix()\nx_test = x_test.as_matrix()\n\ny_train = y_train.as_matrix()\ny_val = y_val.as_matrix()\ny_test = y_test.as_matrix()\n# testing shape\n\nprint(y_train.shape)\nprint(y_val.shape)\nprint(y_test.shape)\n\nprint(x_train.shape)\nprint(x_val.shape)\nprint(x_test.shape)\n\n# convert y to array per value so 3 = [0 0 1]\n\ndef convert_to_one_hot(Y, C):\n    Y = np.eye(C)[Y.reshape(-1)].T\n    return Y\n\ny_train = convert_to_one_hot(y_train, 4)\ny_val = convert_to_one_hot(y_val, 4)\ny_test = convert_to_one_hot(y_test, 4)\nprint (\"number of training examples = \" + str(x_train.shape[1]))\nprint (\"number of test examples = \" + str(x_test.shape[1]))\nprint (\"X_train shape: \" + str(x_train.shape))\nprint (\"Y_train shape: \" + str(y_train.shape))\nprint (\"X_test shape: \" + str(x_test.shape))\nprint (\"Y_test shape: \" + str(y_test.shape))\n\n# minibatches for later\n\ndef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n\n    Arguments:\n    X -- input data, of shape (input size, number of examples)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n    mini_batch_size - size of the mini-batches, integer\n    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n\n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n\n    m = X.shape[1]                  # number of training examples\n    mini_batches = []\n\n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[:, permutation]\n    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n\n    # Handling the end case (last mini-batch &lt; mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n\n    return mini_batches\n\n\n# starting TF graph\n# Create X and Y placeholders\ndef create_xy_placeholder(n_x, n_y):\n    X = tf.placeholder(tf.float32, shape = [n_x, None], name = 'X')\n    Y = tf.placeholder(tf.float32, shape = [n_y, None], name = 'Y')\n\n    return X, Y\nX, Y = create_xy_placeholder(x_train.shape[0],y_train.shape[0])\nprint('X = ' + str(X))\nprint('Y = ' + str(Y))\n\n# initialize parameters for 3 hidden layer network\ndef initialize_parameters():\n    W1 = tf.get_variable('W1', [50, 67], initializer = tf.contrib.layers.xavier_initializer())\n    b1 = tf.get_variable(\"b1\", [50,1], initializer = tf.zeros_initializer())\n    W2 = tf.get_variable('W2', [40, 50], initializer = tf.contrib.layers.xavier_initializer())\n    b2 = tf.get_variable(\"b2\", [40,1], initializer = tf.zeros_initializer())\n    W3 = tf.get_variable('W3', [4, 40], initializer = tf.contrib.layers.xavier_initializer())\n    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n\n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2,\n                  \"W3\": W3,\n                  \"b3\": b3}\n\n    return parameters\ntf.reset_default_graph()\nwith tf.Session() as sess:\n    parameters = initialize_parameters()\n    print(\"W1 = \" + str(parameters[\"W1\"]))\n    print(\"b1 = \" + str(parameters[\"b1\"]))\n    print(\"W2 = \" + str(parameters[\"W2\"]))\n    print(\"b2 = \" + str(parameters[\"b2\"]))\n\n# forward propagation\ndef forward_propagation(X, parameters):   \n    # Retrieve the parameters from the dictionary \"parameters\" \n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3']\n\n\n    Z1 = tf.matmul(W1, X) + b1  \n    A1 = tf.nn.relu(Z1)                                            \n    Z2 = tf.matmul(W2, A1) + b2                           \n    A2 = tf.nn.relu(Z2)                                              \n    Z3 = tf.matmul(W3, A2) + b3                                      \n\n    return Z3\ntf.reset_default_graph()\n\nwith tf.Session() as sess:\n    X, Y = create_xy_placeholder(x_train.shape[0], y_train.shape[0])\n    parameters = initialize_parameters()\n    Z3 = forward_propagation(X, parameters)\n    print(\"Z3 = \" + str(Z3))\n\n# compute cost\ndef compute_cost(Z3, Y):\n\n    logits = tf.transpose(Z3)\n    labels = tf.transpose(Y)\n\n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, \n                                                                  labels = labels))\n    return cost\ntf.reset_default_graph()\n\nwith tf.Session() as sess:\n    X, Y = create_xy_placeholder(x_train.shape[0], y_train.shape[0])\n    parameters = initialize_parameters()\n    Z3 = forward_propagation(X, parameters)\n    cost = compute_cost(Z3, Y)\n    print(\"cost = \" + str(cost))\n\ndef model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n\n    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n    tf.set_random_seed(1)                             # to keep consistent results\n    seed = 3                                          # to keep consistent results\n    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n    n_y = Y_train.shape[0]                            # n_y : output size\n    costs = []                                        # To keep track of the cost\n\n    # Create Placeholders of shape (n_x, n_y)\n    X, Y = create_xy_placeholder(n_x, n_y)\n\n    # Initialize parameters\n    parameters = initialize_parameters()\n\n    # Forward propagation: Build the forward propagation in the tensorflow graph\n    Z3 = forward_propagation(X, parameters)\n\n    # Cost function: Add cost function to tensorflow graph\n    cost = compute_cost(Z3, Y)\n\n    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n\n    # Initialize all the variables\n    init = tf.global_variables_initializer()\n\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    # Start the session to compute the tensorflow graph\n    with tf.Session(config=config) as sess:\n        # Run the initialization\n        sess.run(init)\n\n        # Do the training loop\n        for epoch in range(num_epochs):\n\n            epoch_cost = 0.                       # Defines a cost related to an epoch\n            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n            seed = seed + 1\n            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n\n            for minibatch in minibatches:\n\n                # Select a minibatch\n                (minibatch_X, minibatch_Y) = minibatch\n\n                # IMPORTANT: The line that runs the graph on a minibatch.\n                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n\n                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict = {X: minibatch_X, Y: minibatch_Y})\n\n                epoch_cost += minibatch_cost / num_minibatches\n\n            # Print the cost every epoch\n            if print_cost == True and epoch % 100 == 0:\n                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n            if print_cost == True and epoch % 5 == 0:\n                costs.append(epoch_cost)\n\n        # plot the cost\n        plt.plot(np.squeeze(costs))\n        plt.ylabel('cost')\n        plt.xlabel('iterations (per tens)')\n        plt.title(\"Learning rate =\" + str(learning_rate))\n        plt.show()\n\n        # lets save the parameters in a variable\n        parameters = sess.run(parameters)\n        print (\"Parameters have been trained!\")\n\n        # Calculate the correct predictions\n        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n\n        # Calculate accuracy on the test set\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n\n        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n\n\n        return parameters\n\nparameters = model(x_train, y_train, x_test, y_test)\n</code></pre>\n\n<p>EDIT: \nAfter following the trail mentioned in the comments, I was able to get the learning to improve</p>\n\n<p><a href=\"https://i.stack.imgur.com/JLme4.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/JLme4.png\" alt=\"enter image description here\"></a></p>\n"
        },
        {
            "tags": [
                "ios",
                "firebase",
                "firebase-authentication"
            ],
            "owner": {
                "reputation": 2248,
                "user_id": 3066714,
                "user_type": "registered",
                "accept_rate": 59,
                "profile_image": "https://www.gravatar.com/avatar/46d17a825fab86e5c529a60bbe894fed?s=128&d=identicon&r=PG&f=1",
                "display_name": "xaphod",
                "link": "https://stackoverflow.com/users/3066714/xaphod"
            },
            "is_answered": false,
            "view_count": 12,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524171510,
            "creation_date": 1524171510,
            "question_id": 49930142,
            "body_markdown": "**Scenario**: user has an iPad, where they are signed into Firebase (using email-auth-link method). Because this iPad is currently directly connected to a hardware-device via wifi, this iPad currently has no internet access. Using bluetooth, requests that require internet access are relayed to the user&#39;s second device (usually an iPhone), which has internet access. This works well for Dropbox, Twilio, and Email uploads.\r\n\r\n**Need**: I need to perform a Firebase Storage action on the iPhone, which is a different Firebase app in the same project as the app on the iPad. I want to do this without forcing the user to sign-in again on the secondary device.\r\n\r\n**Question**: How can I serialize (and deserialize) the necessary data, such that the iPhone app will have permission to perform the Storage request (put)?\r\n\r\nOther Google software such as `GTMAppAuth` make the object that performs the authorization itself conform to `NSSecureCoding`, which means that I can easily serialize / deserialize this object wherever it is needed. But I don&#39;t see any objects like this in Firebaseland....?\r\n\r\nThe best I have come up with so far (untested) is below, but it has a **fatal flaw**: the `getIDToken` call requires internet even if there&#39;s a currently logged in user. How to get around this?\r\n\r\n    func serialize(completionBlock: @escaping (FirebaseProviderPassedCredentials?)-&gt;Void) {\r\n        guard let user = Auth.auth().currentUser else {\r\n            WLog(&quot;FirebaseProvider addFirebaseCredentials: ERROR not adding credentials since no one is signed in&quot;)\r\n            completionBlock(nil)\r\n            return\r\n        }\r\n        \r\n        user.getIDToken { (token, error) in\r\n            guard let token = token else {\r\n                WLog(&quot;FirebaseProvider addFirebaseCredentials: ERROR, couldn&#39;t get ID token - \\(String(describing: error))&quot;)\r\n                completionBlock(nil)\r\n                return\r\n            }\r\n            let retval = FirebaseProviderPassedCredentials.init(firebaseUid: user.uid, firebaseProviderID: user.providerID, firebaseAccessToken: token)\r\n            completionBlock(retval)\r\n        }\r\n    }\r\n    \r\n    func deserialize(_ input: FirebaseProviderPassedCredentials, completionBlock: @escaping (Bool)-&gt;Void) {    \r\n        WLog(&quot;FirebaseProvider signInIfNeeded: Trying to sign in as uid=\\(input.firebaseUid)&quot;)\r\n\r\n        let cred = OAuthProvider.credential(withProviderID: input.firebaseProviderID, accessToken: input.firebaseAccessToken)\r\n        Auth.auth().signIn(with: cred) { (user, error) in\r\n            if let error = error {\r\n                WLog(&quot;FirebaseProvider signInIfNeeded: ERROR signing in - \\(error)&quot;)\r\n                completionBlock(false)\r\n            }\r\n            assert(user?.uid == input.firebaseUid)\r\n            WLog(&quot;FirebaseProvider signInIfNeeded: success&quot;)\r\n            completionBlock(true)\r\n        }\r\n    }\r\n",
            "link": "https://stackoverflow.com/questions/49930142/how-to-serialize-deserialize-current-firusers-credentials-for-temporary-use-o",
            "title": "How to serialize &amp; deserialize current FIRUser&#39;s credentials for temporary use on another device?",
            "body": "<p><strong>Scenario</strong>: user has an iPad, where they are signed into Firebase (using email-auth-link method). Because this iPad is currently directly connected to a hardware-device via wifi, this iPad currently has no internet access. Using bluetooth, requests that require internet access are relayed to the user's second device (usually an iPhone), which has internet access. This works well for Dropbox, Twilio, and Email uploads.</p>\n\n<p><strong>Need</strong>: I need to perform a Firebase Storage action on the iPhone, which is a different Firebase app in the same project as the app on the iPad. I want to do this without forcing the user to sign-in again on the secondary device.</p>\n\n<p><strong>Question</strong>: How can I serialize (and deserialize) the necessary data, such that the iPhone app will have permission to perform the Storage request (put)?</p>\n\n<p>Other Google software such as <code>GTMAppAuth</code> make the object that performs the authorization itself conform to <code>NSSecureCoding</code>, which means that I can easily serialize / deserialize this object wherever it is needed. But I don't see any objects like this in Firebaseland....?</p>\n\n<p>The best I have come up with so far (untested) is below, but it has a <strong>fatal flaw</strong>: the <code>getIDToken</code> call requires internet even if there's a currently logged in user. How to get around this?</p>\n\n<pre><code>func serialize(completionBlock: @escaping (FirebaseProviderPassedCredentials?)-&gt;Void) {\n    guard let user = Auth.auth().currentUser else {\n        WLog(\"FirebaseProvider addFirebaseCredentials: ERROR not adding credentials since no one is signed in\")\n        completionBlock(nil)\n        return\n    }\n\n    user.getIDToken { (token, error) in\n        guard let token = token else {\n            WLog(\"FirebaseProvider addFirebaseCredentials: ERROR, couldn't get ID token - \\(String(describing: error))\")\n            completionBlock(nil)\n            return\n        }\n        let retval = FirebaseProviderPassedCredentials.init(firebaseUid: user.uid, firebaseProviderID: user.providerID, firebaseAccessToken: token)\n        completionBlock(retval)\n    }\n}\n\nfunc deserialize(_ input: FirebaseProviderPassedCredentials, completionBlock: @escaping (Bool)-&gt;Void) {    \n    WLog(\"FirebaseProvider signInIfNeeded: Trying to sign in as uid=\\(input.firebaseUid)\")\n\n    let cred = OAuthProvider.credential(withProviderID: input.firebaseProviderID, accessToken: input.firebaseAccessToken)\n    Auth.auth().signIn(with: cred) { (user, error) in\n        if let error = error {\n            WLog(\"FirebaseProvider signInIfNeeded: ERROR signing in - \\(error)\")\n            completionBlock(false)\n        }\n        assert(user?.uid == input.firebaseUid)\n        WLog(\"FirebaseProvider signInIfNeeded: success\")\n        completionBlock(true)\n    }\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "c++",
                "class",
                "matrix",
                "text-files"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9645142,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/17f586d0cedbc8b751e560738ec03c15?s=128&d=identicon&r=PG&f=1",
                "display_name": "Alice",
                "link": "https://stackoverflow.com/users/9645142/alice"
            },
            "is_answered": false,
            "view_count": 33,
            "closed_date": 1524205159,
            "answer_count": 0,
            "score": -2,
            "last_activity_date": 1524171509,
            "creation_date": 1524171509,
            "question_id": 49930141,
            "body_markdown": "I am trying to use a textfile to fill a matrix defined as a vector in c++. Here is my code for the main elements of the class:\r\n\r\n    class DenseMatrix\r\n    {\r\n    private :\r\n        int n;\r\n        std::vector&lt;double&gt; data;\r\n    \r\n    public :\r\n         void Load(char* const filename);\r\n    };\r\n\r\n    void DenseMatrix::Load(char* const filename)\r\n    {\r\n        int size;\r\n        ifstream myfile (filename);\r\n        if(myfile.is_open())\r\n        {\r\n            myfile &gt;&gt; size ;\r\n            n = size;\r\n            DenseMatrix M2(size);\r\n            for(int i=0; i&lt;size; i++)\r\n            {\r\n            myfile &gt;&gt; M2.data[i];\r\n            i++;\r\n            }\r\n            myfile.close();\r\n        }\r\n        else cout&lt;&lt;&quot;Unable to open file&quot;&lt;&lt;endl;\r\n    }\r\n\r\nI am not exactly sure why this does not work. Would you have an idea?\r\n",
            "link": "https://stackoverflow.com/questions/49930141/c-matrix-text-file",
            "closed_reason": "off-topic",
            "title": "c++ matrix text file",
            "body": "<p>I am trying to use a textfile to fill a matrix defined as a vector in c++. Here is my code for the main elements of the class:</p>\n\n<pre><code>class DenseMatrix\n{\nprivate :\n    int n;\n    std::vector&lt;double&gt; data;\n\npublic :\n     void Load(char* const filename);\n};\n\nvoid DenseMatrix::Load(char* const filename)\n{\n    int size;\n    ifstream myfile (filename);\n    if(myfile.is_open())\n    {\n        myfile &gt;&gt; size ;\n        n = size;\n        DenseMatrix M2(size);\n        for(int i=0; i&lt;size; i++)\n        {\n        myfile &gt;&gt; M2.data[i];\n        i++;\n        }\n        myfile.close();\n    }\n    else cout&lt;&lt;\"Unable to open file\"&lt;&lt;endl;\n}\n</code></pre>\n\n<p>I am not exactly sure why this does not work. Would you have an idea?</p>\n"
        },
        {
            "tags": [
                "php",
                "arrays",
                "foreach"
            ],
            "owner": {
                "reputation": 38,
                "user_id": 7123766,
                "user_type": "registered",
                "profile_image": "https://lh5.googleusercontent.com/-DK_2ZY6ZD7M/AAAAAAAAAAI/AAAAAAABKtM/LiFV7tI1bGc/photo.jpg?sz=128",
                "display_name": "Jonas H&#252;sser",
                "link": "https://stackoverflow.com/users/7123766/jonas-h%c3%bcsser"
            },
            "is_answered": true,
            "view_count": 16,
            "accepted_answer_id": 49929877,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1524171491,
            "creation_date": 1524170115,
            "last_edit_date": 1524171491,
            "question_id": 49929807,
            "body_markdown": "I have an JSON from an API which is converted into an PHP-Array with `json_decode()`. \r\n\r\nArray with one item:\r\n\r\n        Array\r\n        (\r\n            [commentID] =&gt; 11\r\n            [authorIDFK] =&gt; 1\r\n            [comment] =&gt; Nice\r\n        )\r\n    \r\nArray with multiple itmes:\r\n   \r\n\r\n    Array\r\n        (\r\n            [0] =&gt; Array\r\n                (\r\n                    [commentID] =&gt; 11\r\n                    [authorIDFK] =&gt; 1\r\n                    [comment] =&gt; Nice\r\n                )\r\n        \r\n            [1] =&gt; Array\r\n                (\r\n                    [commentID] =&gt; 15\r\n                    [authorIDFK] =&gt; 2\r\n                    [comment] =&gt; Great\r\n                )\r\n        \r\n        )\r\n\r\nTo process the array I have something like\r\n\r\n    foreach($comments as $comment) {\r\n       echo $comment[&#39;comment&#39;];\r\n    }\r\nBut if the array only has one item, it fails to process. Any ideas how to achieve this? If I use `count()` on the 1-item-array it counts 3 entries.\r\n\r\nThank you very much for any help!",
            "link": "https://stackoverflow.com/questions/49929807/how-to-handle-php-array-with-multiple-one-item",
            "title": "How to handle PHP-Array with multiple &amp; one item",
            "body": "<p>I have an JSON from an API which is converted into an PHP-Array with <code>json_decode()</code>. </p>\n\n<p>Array with one item:</p>\n\n<pre><code>    Array\n    (\n        [commentID] =&gt; 11\n        [authorIDFK] =&gt; 1\n        [comment] =&gt; Nice\n    )\n</code></pre>\n\n<p>Array with multiple itmes:</p>\n\n<pre><code>Array\n    (\n        [0] =&gt; Array\n            (\n                [commentID] =&gt; 11\n                [authorIDFK] =&gt; 1\n                [comment] =&gt; Nice\n            )\n\n        [1] =&gt; Array\n            (\n                [commentID] =&gt; 15\n                [authorIDFK] =&gt; 2\n                [comment] =&gt; Great\n            )\n\n    )\n</code></pre>\n\n<p>To process the array I have something like</p>\n\n<pre><code>foreach($comments as $comment) {\n   echo $comment['comment'];\n}\n</code></pre>\n\n<p>But if the array only has one item, it fails to process. Any ideas how to achieve this? If I use <code>count()</code> on the 1-item-array it counts 3 entries.</p>\n\n<p>Thank you very much for any help!</p>\n"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 189
}