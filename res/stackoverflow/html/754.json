{
    "items": [
        {
            "tags": [
                "swift",
                "nsdate"
            ],
            "owner": {
                "reputation": 269,
                "user_id": 5254048,
                "user_type": "registered",
                "accept_rate": 52,
                "profile_image": "https://www.gravatar.com/avatar/59b9d2584ef1edc44a3aadd6337fa4e0?s=128&d=identicon&r=PG&f=1",
                "display_name": "kmell96",
                "link": "https://stackoverflow.com/users/5254048/kmell96"
            },
            "is_answered": true,
            "view_count": 28,
            "accepted_answer_id": 49928009,
            "answer_count": 2,
            "score": 1,
            "last_activity_date": 1524163429,
            "creation_date": 1524160990,
            "last_edit_date": 1524161815,
            "question_id": 49927456,
            "body_markdown": "If I run the following code:\r\n\r\n    let date = Date()\r\n    let midnight = Calendar.current.date(bySetting: .hour, value: 0, of: date)!\r\n    let difference = Int64(midnight.timeIntervalSince(date))\r\n    print(String(difference))\r\n\r\nDifference is a positive value of about 13 hours (since the local time is about 11 AM now). However, I would expect that the difference would be negative 11 hours; since I&#39;m setting the `.hour` value to `0` I expect that time would move backward, not forward.\r\n\r\nI would expect to have to find midnight tomorrow with this code:\r\n\r\n    let midnight = Calendar.current.date(bySetting: .hour, value: 0, of:\r\n       Calendar.current.date(byAdding: .day, value: 1, to: date)!)!\r\nBut that gives +37 hours instead of +13.\r\n\r\nThe current behavior is actually the behavior I want (I want to know the time until midnight tomorrow). But, I would like to understand why this is happening, and in particular I want to make sure that this approach of finding midnight tomorrow will work regardless of time zone. Thanks!\r\n\r\nEDIT: Note, I only care about the hours until midnight, which is why I don&#39;t change the minute or second value when finding midnight.",
            "link": "https://stackoverflow.com/questions/49927456/swift-calendar-date-by-setting-hour-to-0-changes-day",
            "title": "Swift Calendar Date By Setting Hour To 0 Changes Day",
            "body": "<p>If I run the following code:</p>\n\n<pre><code>let date = Date()\nlet midnight = Calendar.current.date(bySetting: .hour, value: 0, of: date)!\nlet difference = Int64(midnight.timeIntervalSince(date))\nprint(String(difference))\n</code></pre>\n\n<p>Difference is a positive value of about 13 hours (since the local time is about 11 AM now). However, I would expect that the difference would be negative 11 hours; since I'm setting the <code>.hour</code> value to <code>0</code> I expect that time would move backward, not forward.</p>\n\n<p>I would expect to have to find midnight tomorrow with this code:</p>\n\n<pre><code>let midnight = Calendar.current.date(bySetting: .hour, value: 0, of:\n   Calendar.current.date(byAdding: .day, value: 1, to: date)!)!\n</code></pre>\n\n<p>But that gives +37 hours instead of +13.</p>\n\n<p>The current behavior is actually the behavior I want (I want to know the time until midnight tomorrow). But, I would like to understand why this is happening, and in particular I want to make sure that this approach of finding midnight tomorrow will work regardless of time zone. Thanks!</p>\n\n<p>EDIT: Note, I only care about the hours until midnight, which is why I don't change the minute or second value when finding midnight.</p>\n"
        },
        {
            "tags": [
                "sql-server-2014"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 9670914,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "MathewT",
                "link": "https://stackoverflow.com/users/9670914/mathewt"
            },
            "is_answered": true,
            "view_count": 20,
            "accepted_answer_id": 49928117,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524163427,
            "creation_date": 1524157741,
            "question_id": 49926602,
            "body_markdown": "I am working on a project that requires reports that can dynamically group the source data on non-standard user defined intervals such as Production Shifts within a specified start and end range. Example user may want to see production information group by shift for the last two days. \r\nI created a table called ‘IntervalConfiguration’ that stores the configuration information required to create the grouping intervals with data as follow:\r\n\r\n\r\n    IntervalType\t\t\t\tSubIntervalType\t\tIntervalDuration     IntervalDurationUnits\tIntervalStartReferenceTime IntervalRepeatDuration IntervalRepeatDurationUnits\r\n    -------------------------\t-------------------\t-------------------- ---------------------\t-------------------------- ---------------------- ---------------------------\r\n    Production Day\t\t\t\tProductionDay\t\t1                    Days\t\t\t\t\t2013-01-07 07:00:00.000    1                      Days\r\n    Production Month\t\t\tProductionMonth\t\t1                    Months\t\t\t\t\t2013-01-01 07:00:00.000    1                      Months\r\n    Production Week\t\t\t\tProductionWeek\t\t1                    Weeks\t\t\t\t\t2013-01-07 08:45:00.000    1                      Weeks\r\n    Production Year\t\t\t\tProductionYear\t\t1                    Years\t\t\t\t\t2013-01-01 08:45:00.000    1                      Years\r\n    Site A - Production Shift\tDay\t\t\t\t\t12                   Hours\t\t\t\t\t2013-01-06 07:00:00.000    24                     Hours\r\n    Site A - Production Shift\tNight\t\t\t\t12                   Hours\t\t\t\t\t2013-01-06 19:00:00.000    24                     Hours\r\n    Site B - Production Shift\tDay\t\t\t\t\t12                   Hours\t\t\t\t\t2013-01-06 06:45:00.000    24                     Hours\r\n    Site B - Production Shift\tNight\t\t\t\t12                   Hours\t\t\t\t\t2013-01-06 18:45:00.000    24                     Hours\r\n\r\nIf a user selects ‘Site A - Production Shift’ as the grouping interval on the report and a start date of &#39;01/01/2018&#39; and end date of &#39;01/05/2018&#39; then the report has to create grouping intervals for day shifts where day shifts start at 7AM and ends at 7PM and night shift where night shift start at 7PM and ends at 7AM the next day. \r\nAlso, only grouping intervals completely contained within the start and end date should be returned. Below is an example of expected grouping intervals for the scenario described.\r\n\r\n    SubIntervalType\t\tIntervalStart\t\t\t IntervalEnd             \r\n    ----------------\t-----------------------\t ----------------------- \r\n    Day\t\t\t\t\t2018-01-01 07:00:00.000\t 2018-01-01 19:00:00.000 \r\n    Night\t\t\t\t2018-01-01 19:00:00.000\t 2018-01-02 07:00:00.000 \r\n    Day\t\t\t\t\t2018-01-02 07:00:00.000\t 2018-01-02 19:00:00.000 \r\n    Night\t\t\t\t2018-01-02 19:00:00.000\t 2018-01-03 07:00:00.000 \r\n    Day\t\t\t\t\t2018-01-03 07:00:00.000\t 2018-01-03 19:00:00.000 \r\n    Night\t\t\t\t2018-01-03 19:00:00.000\t 2018-01-04 07:00:00.000 \r\n    Day\t\t\t\t\t2018-01-04 07:00:00.000\t 2018-01-04 19:00:00.000\r\n\r\nIf user selects Production Month as the grouping interval with a start date of &#39;01/01/2018&#39; and end date of &#39;01/01/2019&#39; then the report should generate the following grouping intervals.\r\n\r\n\r\n    SubIntervalType\t\tIntervalStart           IntervalEnd            \r\n    -----------------\t----------------------- -----------------------\r\n    ProductionMonth\t\t2018-01-01 07:00:00.000 2018-02-01 07:00:00.000\r\n    ProductionMonth\t\t2018-02-01 07:00:00.000 2018-03-01 07:00:00.000\r\n    ProductionMonth\t\t2018-03-01 07:00:00.000 2018-04-01 07:00:00.000\r\n    ProductionMonth\t\t2018-04-01 07:00:00.000 2018-05-01 07:00:00.000\r\n    ProductionMonth\t\t2018-05-01 07:00:00.000 2018-06-01 07:00:00.000\r\n    ProductionMonth\t\t2018-06-01 07:00:00.000 2018-07-01 07:00:00.000\r\n    ProductionMonth\t\t2018-07-01 07:00:00.000 2018-08-01 07:00:00.000\r\n    ProductionMonth\t\t2018-08-01 07:00:00.000 2018-09-01 07:00:00.000\r\n    ProductionMonth\t\t2018-09-01 07:00:00.000 2018-10-01 07:00:00.000\r\n    ProductionMonth\t\t2018-10-01 07:00:00.000 2018-11-01 07:00:00.000\r\n    ProductionMonth\t\t2018-11-01 07:00:00.000 2018-12-01 07:00:00.000\r\n\r\nI have started building the following table valued function to dynamically create the desired grouping intervals. \r\n\r\n    CREATE FUNCTION [dbo].[GetIntervals]\r\n    (\r\n    \t@dateRangeStart\tdatetime,\r\n    \t@dateRangeEnd\tdatetime,\r\n    \t@groupByInterval\tNVARCHAR(200)\r\n    )\r\n    RETURNS @Intervals TABLE (\r\n    \tIntervalType\t\t\tNVARCHAR(100)\r\n    \t,SubIntervalType\t\tNVARCHAR(100)\r\n    \t,IntervalStart\t\t\tDATETIME\r\n    \t,IntervalEnd\t\t\t\tDATETIME\r\n    \t,IntervalDurationSeconds\tFLOAT\r\n    )\r\n    AS\r\n    BEGIN\r\n    \r\n    \tDECLARE @activeIntervalDateTime\tDATETIME = DATEADD(millisecond, 3, @dateRangeStart);\r\n    \tDECLARE @intervalStartTime DATETIME = DATEADD(s, 1, @dateRangeStart);\r\n    \tDECLARE @intervalEndTime DATETIME = DATEADD(s, 1, @dateRangeStart);\r\n    \tDECLARE @intervalDurationSeconds FLOAT;\r\n    \tDECLARE @intervalName NVARCHAR(100);\r\n    \tDECLARE @subIntervalType NVARCHAR(100);\r\n    \t\t\r\n    \tWHILE @intervalStartTime &lt;= @dateRangeEnd\r\n    \tBEGIN\r\n    \t\t\r\n    \t\tSELECT\t TOP 1\r\n    \t\t\t\t @intervalName = IntervalType ,@subIntervalType = SubIntervalType , @intervalStartTime = IntervalStart, @intervalEndTime = IntervalEnd\r\n    \t\tFROM\t(SELECT\t IntervalType, SubIntervalType, IntervalDuration, IntervalDurationUnits,\r\n    \t\t\t\t\t\t\tIntervalRepeatDuration, IntervalRepeatDurationUnits,\r\n    \t\t\t\t\t\t\tCASE IntervalRepeatDurationUnits\r\n    \t\t\t\t\t\t\t WHEN &#39;Hours&#39; THEN (DateAdd(HH, (DateDiff(HH, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime))\r\n    \t\t\t\t\t\t\t WHEN &#39;Days&#39; THEN (DateAdd(D, (DateDiff(D, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime))\r\n    \t\t\t\t\t\t\t WHEN &#39;Months&#39;THEN (DateAdd(MM, (DateDiff(MM, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime))\r\n    \t\t\t\t\t\t\t END AS IntervalStart,\r\n    \t\t\t\t\t\t\tCASE IntervalRepeatDurationUnits\r\n    \t\t\t\t\t\t\t WHEN &#39;Hours&#39; THEN (DateAdd(HH, IntervalDuration, DateAdd(HH, (DateDiff(HH, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\r\n    \t\t\t\t\t\t\t WHEN &#39;Days&#39; THEN \r\n    \t\t\t\t\t\t\t\tCASE IntervalDurationUnits\r\n    \t\t\t\t\t\t\t\tWHEN &#39;Hours&#39; THEN (DateAdd(HH, IntervalDuration, DateAdd(D, (DateDiff(D, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\r\n    \t\t\t\t\t\t\t\tWHEN &#39;Days&#39; THEN (DateAdd(D, IntervalDuration, DateAdd(D, (DateDiff(D, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\r\n    \t\t\t\t\t\t\t\tEND\r\n    \t\t\t\t\t\t\t WHEN &#39;Months&#39;THEN \r\n    \t\t\t\t\t\t\t\tCASE IntervalDurationUnits\r\n    \t\t\t\t\t\t\t\tWHEN &#39;Hours&#39; THEN (DateAdd(HH, IntervalDuration, DateAdd(MM, (DateDiff(MM, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\r\n    \t\t\t\t\t\t\t\tWHEN &#39;Days&#39; THEN (DateAdd(D, IntervalDuration, DateAdd(MM, (DateDiff(MM, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\r\n    \t\t\t\t\t\t\t\tWHEN &#39;Months&#39; THEN (DateAdd(MM, IntervalDuration, DateAdd(MM, (DateDiff(MM, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\r\n    \t\t\t\t\t\t\t\tEND\r\n    \t\t\t\t\t\t\t END AS IntervalEnd\r\n    \t\t\t\t\t\t\t,IntervalStartReferenceTime\r\n    \t\t\t\tFROM\t(\r\n    \t\t\t\t\t\t\tSELECT\t IntervalType, SubIntervalType, IntervalDuration, IntervalDurationUnits, IntervalRepeatDuration, IntervalRepeatDurationUnits, IntervalStartReferenceTime,\r\n    \t\t\t\t\t\t\t\t\t CASE IntervalRepeatDurationUnits\r\n    \t\t\t\t\t\t\t\t\t WHEN &#39;Hours&#39; THEN DATEADD(MILLISECOND, -1*(DATEPART(MILLISECOND, IntervalStartReferenceTime) + 3), DATEADD(SECOND, -1*DATEPART(SECOND, IntervalStartReferenceTime), DATEADD(MINUTE, -1*DATEPART(MINUTE, IntervalStartReferenceTime), @activeIntervalDateTime)))\r\n    \t\t\t\t\t\t\t\t\t WHEN &#39;Days&#39; THEN DATEADD(MILLISECOND, -1*(DATEPART(MILLISECOND, IntervalStartReferenceTime) + 3), DATEADD(SECOND, -1*DATEPART(SECOND, IntervalStartReferenceTime), DATEADD(MINUTE, -1*DATEPART(MINUTE, IntervalStartReferenceTime), DATEADD(HOUR, -1*DATEPART(HOUR, IntervalStartReferenceTime), @activeIntervalDateTime))))\r\n    \t\t\t\t\t\t\t\t\t WHEN &#39;Months&#39; THEN DATEADD(MILLISECOND, -1*(DATEPART(MILLISECOND, IntervalStartReferenceTime) + 3), DATEADD(SECOND, -1*DATEPART(SECOND, IntervalStartReferenceTime), DATEADD(MINUTE, -1*DATEPART(MINUTE, IntervalStartReferenceTime), DATEADD(HOUR, -1*DATEPART(HOUR, IntervalStartReferenceTime), DATEADD(DAY, -1*(DATEPART(DAY, IntervalStartReferenceTime) - 1), @activeIntervalDateTime)))))\r\n    \t\t\t\t\t\t\t\t\t END AS ActiveTimeNormalized\r\n    \t\t\t\t\t\t\tFROM\tdbo.IntervalConfiguration \t\t\t\t\r\n    \t\t\t\t\t\t) norm\r\n    \t\t\t\tWHERE\tIntervalType = @groupByInterval) interval\r\n    \t\tWHERE\t(@activeIntervalDateTime &gt; IntervalStart) and (@activeIntervalDateTime &lt;= IntervalEnd)\r\n    \t\tORDER BY IntervalStartReferenceTime DESC\r\n    \r\n    \r\n    \t\tSET @intervalDurationSeconds = DATEDIFF(SECOND, @intervalStartTime, @intervalEndTime);\r\n    \r\n    \t\tIF @intervalStartTime &gt;= @dateRangeStart AND @intervalEndTime &lt;= @dateRangeEnd \r\n    \t\tBEGIN\r\n    \r\n    \t\t\tINSERT INTO @Intervals(\t\r\n    \t\t\t\t\t\t\t\t\t\t IntervalType\r\n    \t\t\t\t\t\t\t\t\t\t ,SubIntervalType\t\t\t\r\n    \t\t\t\t\t\t\t\t\t\t,IntervalStart\t\t\t\r\n    \t\t\t\t\t\t\t\t\t\t,IntervalEnd\t\t\t\r\n    \t\t\t\t\t\t\t\t\t\t,IntervalDurationSeconds\t\t\t\t\t\t\t\t\t\r\n    \t\t\t\t\t\t\t\t\t  )\r\n    \t\t\tVALUES(\r\n    \t\t\t\t\t @intervalName\r\n    \t\t\t\t\t,@subIntervalType\r\n    \t\t\t\t\t,@intervalStartTime\r\n    \t\t\t\t\t,@intervalEndTime\r\n    \t\t\t\t\t,@intervalDurationSeconds\r\n    \t\t\t\t  )\r\n    \r\n    \t\tEND\r\n    \t\t\t  \r\n    \t\tSET @activeIntervalDateTime\t= DATEADD(MILLISECOND, 3, @intervalEndTime);\r\n    \t\t\r\n    \tEND\r\n    \r\n    \tRETURN;\r\n    END\r\n\r\nThis function however is getting increasingly complex and hard to debug also I would like to eliminate the need to use While loops within the function. My question is this, is there a simpler way to achieve my requirements and is it possible to eliminate the need for a while loop?\r\n",
            "link": "https://stackoverflow.com/questions/49926602/generate-dynamic-custom-intervals",
            "title": "Generate dynamic custom intervals",
            "body": "<p>I am working on a project that requires reports that can dynamically group the source data on non-standard user defined intervals such as Production Shifts within a specified start and end range. Example user may want to see production information group by shift for the last two days. \nI created a table called ‘IntervalConfiguration’ that stores the configuration information required to create the grouping intervals with data as follow:</p>\n\n<pre><code>IntervalType                SubIntervalType     IntervalDuration     IntervalDurationUnits  IntervalStartReferenceTime IntervalRepeatDuration IntervalRepeatDurationUnits\n-------------------------   ------------------- -------------------- ---------------------  -------------------------- ---------------------- ---------------------------\nProduction Day              ProductionDay       1                    Days                   2013-01-07 07:00:00.000    1                      Days\nProduction Month            ProductionMonth     1                    Months                 2013-01-01 07:00:00.000    1                      Months\nProduction Week             ProductionWeek      1                    Weeks                  2013-01-07 08:45:00.000    1                      Weeks\nProduction Year             ProductionYear      1                    Years                  2013-01-01 08:45:00.000    1                      Years\nSite A - Production Shift   Day                 12                   Hours                  2013-01-06 07:00:00.000    24                     Hours\nSite A - Production Shift   Night               12                   Hours                  2013-01-06 19:00:00.000    24                     Hours\nSite B - Production Shift   Day                 12                   Hours                  2013-01-06 06:45:00.000    24                     Hours\nSite B - Production Shift   Night               12                   Hours                  2013-01-06 18:45:00.000    24                     Hours\n</code></pre>\n\n<p>If a user selects ‘Site A - Production Shift’ as the grouping interval on the report and a start date of '01/01/2018' and end date of '01/05/2018' then the report has to create grouping intervals for day shifts where day shifts start at 7AM and ends at 7PM and night shift where night shift start at 7PM and ends at 7AM the next day. \nAlso, only grouping intervals completely contained within the start and end date should be returned. Below is an example of expected grouping intervals for the scenario described.</p>\n\n<pre><code>SubIntervalType     IntervalStart            IntervalEnd             \n----------------    -----------------------  ----------------------- \nDay                 2018-01-01 07:00:00.000  2018-01-01 19:00:00.000 \nNight               2018-01-01 19:00:00.000  2018-01-02 07:00:00.000 \nDay                 2018-01-02 07:00:00.000  2018-01-02 19:00:00.000 \nNight               2018-01-02 19:00:00.000  2018-01-03 07:00:00.000 \nDay                 2018-01-03 07:00:00.000  2018-01-03 19:00:00.000 \nNight               2018-01-03 19:00:00.000  2018-01-04 07:00:00.000 \nDay                 2018-01-04 07:00:00.000  2018-01-04 19:00:00.000\n</code></pre>\n\n<p>If user selects Production Month as the grouping interval with a start date of '01/01/2018' and end date of '01/01/2019' then the report should generate the following grouping intervals.</p>\n\n<pre><code>SubIntervalType     IntervalStart           IntervalEnd            \n-----------------   ----------------------- -----------------------\nProductionMonth     2018-01-01 07:00:00.000 2018-02-01 07:00:00.000\nProductionMonth     2018-02-01 07:00:00.000 2018-03-01 07:00:00.000\nProductionMonth     2018-03-01 07:00:00.000 2018-04-01 07:00:00.000\nProductionMonth     2018-04-01 07:00:00.000 2018-05-01 07:00:00.000\nProductionMonth     2018-05-01 07:00:00.000 2018-06-01 07:00:00.000\nProductionMonth     2018-06-01 07:00:00.000 2018-07-01 07:00:00.000\nProductionMonth     2018-07-01 07:00:00.000 2018-08-01 07:00:00.000\nProductionMonth     2018-08-01 07:00:00.000 2018-09-01 07:00:00.000\nProductionMonth     2018-09-01 07:00:00.000 2018-10-01 07:00:00.000\nProductionMonth     2018-10-01 07:00:00.000 2018-11-01 07:00:00.000\nProductionMonth     2018-11-01 07:00:00.000 2018-12-01 07:00:00.000\n</code></pre>\n\n<p>I have started building the following table valued function to dynamically create the desired grouping intervals. </p>\n\n<pre><code>CREATE FUNCTION [dbo].[GetIntervals]\n(\n    @dateRangeStart datetime,\n    @dateRangeEnd   datetime,\n    @groupByInterval    NVARCHAR(200)\n)\nRETURNS @Intervals TABLE (\n    IntervalType            NVARCHAR(100)\n    ,SubIntervalType        NVARCHAR(100)\n    ,IntervalStart          DATETIME\n    ,IntervalEnd                DATETIME\n    ,IntervalDurationSeconds    FLOAT\n)\nAS\nBEGIN\n\n    DECLARE @activeIntervalDateTime DATETIME = DATEADD(millisecond, 3, @dateRangeStart);\n    DECLARE @intervalStartTime DATETIME = DATEADD(s, 1, @dateRangeStart);\n    DECLARE @intervalEndTime DATETIME = DATEADD(s, 1, @dateRangeStart);\n    DECLARE @intervalDurationSeconds FLOAT;\n    DECLARE @intervalName NVARCHAR(100);\n    DECLARE @subIntervalType NVARCHAR(100);\n\n    WHILE @intervalStartTime &lt;= @dateRangeEnd\n    BEGIN\n\n        SELECT   TOP 1\n                 @intervalName = IntervalType ,@subIntervalType = SubIntervalType , @intervalStartTime = IntervalStart, @intervalEndTime = IntervalEnd\n        FROM    (SELECT  IntervalType, SubIntervalType, IntervalDuration, IntervalDurationUnits,\n                            IntervalRepeatDuration, IntervalRepeatDurationUnits,\n                            CASE IntervalRepeatDurationUnits\n                             WHEN 'Hours' THEN (DateAdd(HH, (DateDiff(HH, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime))\n                             WHEN 'Days' THEN (DateAdd(D, (DateDiff(D, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime))\n                             WHEN 'Months'THEN (DateAdd(MM, (DateDiff(MM, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime))\n                             END AS IntervalStart,\n                            CASE IntervalRepeatDurationUnits\n                             WHEN 'Hours' THEN (DateAdd(HH, IntervalDuration, DateAdd(HH, (DateDiff(HH, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\n                             WHEN 'Days' THEN \n                                CASE IntervalDurationUnits\n                                WHEN 'Hours' THEN (DateAdd(HH, IntervalDuration, DateAdd(D, (DateDiff(D, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\n                                WHEN 'Days' THEN (DateAdd(D, IntervalDuration, DateAdd(D, (DateDiff(D, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\n                                END\n                             WHEN 'Months'THEN \n                                CASE IntervalDurationUnits\n                                WHEN 'Hours' THEN (DateAdd(HH, IntervalDuration, DateAdd(MM, (DateDiff(MM, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\n                                WHEN 'Days' THEN (DateAdd(D, IntervalDuration, DateAdd(MM, (DateDiff(MM, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\n                                WHEN 'Months' THEN (DateAdd(MM, IntervalDuration, DateAdd(MM, (DateDiff(MM, IntervalStartReferenceTime, ActiveTimeNormalized ) / IntervalRepeatDuration) * IntervalRepeatDuration,  IntervalStartReferenceTime)))\n                                END\n                             END AS IntervalEnd\n                            ,IntervalStartReferenceTime\n                FROM    (\n                            SELECT   IntervalType, SubIntervalType, IntervalDuration, IntervalDurationUnits, IntervalRepeatDuration, IntervalRepeatDurationUnits, IntervalStartReferenceTime,\n                                     CASE IntervalRepeatDurationUnits\n                                     WHEN 'Hours' THEN DATEADD(MILLISECOND, -1*(DATEPART(MILLISECOND, IntervalStartReferenceTime) + 3), DATEADD(SECOND, -1*DATEPART(SECOND, IntervalStartReferenceTime), DATEADD(MINUTE, -1*DATEPART(MINUTE, IntervalStartReferenceTime), @activeIntervalDateTime)))\n                                     WHEN 'Days' THEN DATEADD(MILLISECOND, -1*(DATEPART(MILLISECOND, IntervalStartReferenceTime) + 3), DATEADD(SECOND, -1*DATEPART(SECOND, IntervalStartReferenceTime), DATEADD(MINUTE, -1*DATEPART(MINUTE, IntervalStartReferenceTime), DATEADD(HOUR, -1*DATEPART(HOUR, IntervalStartReferenceTime), @activeIntervalDateTime))))\n                                     WHEN 'Months' THEN DATEADD(MILLISECOND, -1*(DATEPART(MILLISECOND, IntervalStartReferenceTime) + 3), DATEADD(SECOND, -1*DATEPART(SECOND, IntervalStartReferenceTime), DATEADD(MINUTE, -1*DATEPART(MINUTE, IntervalStartReferenceTime), DATEADD(HOUR, -1*DATEPART(HOUR, IntervalStartReferenceTime), DATEADD(DAY, -1*(DATEPART(DAY, IntervalStartReferenceTime) - 1), @activeIntervalDateTime)))))\n                                     END AS ActiveTimeNormalized\n                            FROM    dbo.IntervalConfiguration               \n                        ) norm\n                WHERE   IntervalType = @groupByInterval) interval\n        WHERE   (@activeIntervalDateTime &gt; IntervalStart) and (@activeIntervalDateTime &lt;= IntervalEnd)\n        ORDER BY IntervalStartReferenceTime DESC\n\n\n        SET @intervalDurationSeconds = DATEDIFF(SECOND, @intervalStartTime, @intervalEndTime);\n\n        IF @intervalStartTime &gt;= @dateRangeStart AND @intervalEndTime &lt;= @dateRangeEnd \n        BEGIN\n\n            INSERT INTO @Intervals( \n                                         IntervalType\n                                         ,SubIntervalType           \n                                        ,IntervalStart          \n                                        ,IntervalEnd            \n                                        ,IntervalDurationSeconds                                    \n                                      )\n            VALUES(\n                     @intervalName\n                    ,@subIntervalType\n                    ,@intervalStartTime\n                    ,@intervalEndTime\n                    ,@intervalDurationSeconds\n                  )\n\n        END\n\n        SET @activeIntervalDateTime = DATEADD(MILLISECOND, 3, @intervalEndTime);\n\n    END\n\n    RETURN;\nEND\n</code></pre>\n\n<p>This function however is getting increasingly complex and hard to debug also I would like to eliminate the need to use While loops within the function. My question is this, is there a simpler way to achieve my requirements and is it possible to eliminate the need for a while loop?</p>\n"
        },
        {
            "tags": [
                "c#",
                "linq",
                "linq-expressions"
            ],
            "owner": {
                "reputation": 1267,
                "user_id": 1003150,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/TRzBI.jpg?s=128&g=1",
                "display_name": "Peter Riesz",
                "link": "https://stackoverflow.com/users/1003150/peter-riesz"
            },
            "is_answered": true,
            "view_count": 43,
            "accepted_answer_id": 49924086,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524163423,
            "creation_date": 1524148892,
            "last_edit_date": 1524163423,
            "question_id": 49923875,
            "body_markdown": "Here is a simplified example of what I am trying to achieve, I&#39;m not sure if it is even possible or if I am going about this all wrong.\r\n\r\n    Expression&lt;T, bool&gt; UseDataContext&lt;T&gt;(Expression&lt;Func&lt;DataContext, T, bool&gt;&gt; expr, Expression dataContextExpr){\r\n        // use ExpressionVisitor and return new LambaExpression\r\n    }    \r\n\r\n    Expression&lt;Func&lt;DataContext, Foo, bool&gt;&gt; fooFilterExpr = (db, foo) \r\n        =&gt; db.FilteredFoos.Any(vf =&gt; vf.FooId == foo.Id);\r\n    \r\n    Expression&lt;Func&lt;DataContext, Bar, bool&gt;&gt; barExpr = (db) =&gt; (\r\n        from bar in db.Bars\r\n        join foo in db.Foos.Where(UseDataContext(fooFilterExpr, ?db Expression?))\r\n        select bar\r\n    );",
            "link": "https://stackoverflow.com/questions/49923875/is-it-possible-to-reference-a-parameterexpression-inside-linq-query-syntax",
            "title": "Is it possible to reference a ParameterExpression inside Linq query syntax?",
            "body": "<p>Here is a simplified example of what I am trying to achieve, I'm not sure if it is even possible or if I am going about this all wrong.</p>\n\n<pre><code>Expression&lt;T, bool&gt; UseDataContext&lt;T&gt;(Expression&lt;Func&lt;DataContext, T, bool&gt;&gt; expr, Expression dataContextExpr){\n    // use ExpressionVisitor and return new LambaExpression\n}    \n\nExpression&lt;Func&lt;DataContext, Foo, bool&gt;&gt; fooFilterExpr = (db, foo) \n    =&gt; db.FilteredFoos.Any(vf =&gt; vf.FooId == foo.Id);\n\nExpression&lt;Func&lt;DataContext, Bar, bool&gt;&gt; barExpr = (db) =&gt; (\n    from bar in db.Bars\n    join foo in db.Foos.Where(UseDataContext(fooFilterExpr, ?db Expression?))\n    select bar\n);\n</code></pre>\n"
        },
        {
            "tags": [
                "algorithm",
                "time-series",
                "signal-processing"
            ],
            "owner": {
                "reputation": 95,
                "user_id": 1586996,
                "user_type": "registered",
                "accept_rate": 64,
                "profile_image": "https://www.gravatar.com/avatar/dc274abfad38e99ddaa6f3deb0769f56?s=128&d=identicon&r=PG",
                "display_name": "Jorge Kageyama",
                "link": "https://stackoverflow.com/users/1586996/jorge-kageyama"
            },
            "is_answered": false,
            "view_count": 12,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163417,
            "creation_date": 1524163417,
            "question_id": 49928114,
            "body_markdown": "I understand that dwt maps 2 time series sets to one another non linearly. And I understand how the warp path is calculated, but quoting from Wikipedia *&quot;In addition to a similarity measure between the two sequences, a so called &quot;warping path&quot; is produced, by warping according to this path the two signals may be aligned in time. The signal with an original set of points X(original), Y(original) is transformed to X(warped), Y(original). &quot;*\r\n      \r\n\r\n What I don&#39;t understand is how to use the path to transform one set. Any help would be appreciated.",
            "link": "https://stackoverflow.com/questions/49928114/dynamic-time-warping-transformation-subspace-transformation",
            "title": "Dynamic time warping transformation (subspace transformation)",
            "body": "<p>I understand that dwt maps 2 time series sets to one another non linearly. And I understand how the warp path is calculated, but quoting from Wikipedia <em>\"In addition to a similarity measure between the two sequences, a so called \"warping path\" is produced, by warping according to this path the two signals may be aligned in time. The signal with an original set of points X(original), Y(original) is transformed to X(warped), Y(original). \"</em></p>\n\n<p>What I don't understand is how to use the path to transform one set. Any help would be appreciated.</p>\n"
        },
        {
            "tags": [
                "python",
                "r",
                "python-3.x",
                "nltk"
            ],
            "owner": {
                "reputation": 26,
                "user_id": 9648851,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/a4754e8871b99c4ecf5db1cbd3213b47?s=128&d=identicon&r=PG&f=1",
                "display_name": "FlorentY",
                "link": "https://stackoverflow.com/users/9648851/florenty"
            },
            "is_answered": false,
            "view_count": 20,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163403,
            "creation_date": 1524163403,
            "question_id": 49928110,
            "body_markdown": "I&#39;m trying to transform my R code cleaning up Corpus to Python, but struggling a lot.\r\n\r\nIndeed, I succeed to partialy rewrite my code in python.\r\nBut two important problems remains.\r\n\r\n\r\n**First**, the obtained vocabulary is not as good as R, even with recommanded package extension to clean up a file (BeautifulSoup).\r\n\r\nHere&#39;s a result in R:\r\n\r\n    &quot;advanc mp player equip portabl mp player mp cd player hard disk player audiocar gadget dvd player headphon accessoriesgt search nbsp advanc search manufactur pleas select&quot;\r\n\r\nHere&#39;s a result in Python:\r\n\r\n    &quot;advanc mp player equip portabl mp playersmp cd playershard disk playersaudio car gadgetsdvd playersheadphonesaccessori search advanc search manufactur pleas selectadvanc&quot;\r\n\r\nAs you can see, result is better in R, and it&#39;s due to BeautifulSoup\r\n\r\n\r\n\r\n**Second problem**, I spend so much time reading nltk documentation, trying to update a Corpus but didn&#39;t find how to deal with. \r\n\r\nWhat I mean by update a corpus is replacing files content by new vocabulary.\r\nFor example, when I use &lt;!-- language:R training&lt;-tm_map() --&gt; in R, Corpus is updated an it&#39;s possible to directly transform it to a DataFrame and Matrix and then export into a csv.\r\n\r\nBut in python, should I update Corpus or use another way to processes data ?\r\n\r\nHere&#39;s my R code:\r\n\r\n\r\n    splash=function(x){\r\n        res=NULL\r\n        for (i in x) res=paste(res, i)\r\n        res\r\n    }\r\n    \r\n    #Removes scripts s(&lt;script .... &lt;/script&gt;)\r\n    removeScript=function(t){\r\n        #decoupage de la chaine en utilisant &quot;&lt;split&quot;\r\n        #sp=strsplit(splash(t), &quot;&lt;script&quot;)\r\n        sp=strsplit(t, &quot;&lt;script&quot;)\r\n        #pour chaque partie du split, le debut (jusqu&#39;a &lt;/script&gt; est supprime\r\n        vec=sapply(sp[[1]], gsub, pattern=&quot;.*&lt;/script&gt;&quot;, replace=&quot; &quot;)\r\n        #les elements du split nottoyes sont concatenes\r\n        PlainTextDocument(splash(vec))\r\n    }\r\n    \r\n    #Removes Tags\r\n    removeBalises=function(x){\r\n        t1=gsub(&quot;&lt;[^&gt;]*&gt;&quot;, &quot; &quot;, x)\r\n        #suppression des occurrences multiples d&#39;espaces (ou de tabulations)\r\n        PlainTextDocument(gsub(&quot;[ \\t]+&quot;,&quot; &quot;,t1))\r\n    }\r\n    \r\n    nettoyage &lt;- function(training)\r\n    {\r\n      training&lt;-tm_map(training,content_transformer(tolower))\r\n      training&lt;-tm_map(training,content_transformer(splash))\r\n      training&lt;-tm_map(training,content_transformer(removeScript))\r\n      training&lt;-tm_map(training,content_transformer(removeBalises))\r\n      training&lt;-tm_map(training,removeNumbers)\r\n      training&lt;-tm_map(training,removeWords,words=stopwords(&#39;en&#39;))\r\n      training&lt;-tm_map(training,stemDocument)\r\n      training&lt;-tm_map(training,removePunctuation)\r\n      return(training);\r\n    }\r\n\r\nNow equivalent in python\r\n\r\n    from re import sub\r\n    from nltk.corpus.reader import PlaintextCorpusReader\r\n    from string import punctuation\r\n    from nltk.stem import PorterStemmer\r\n    from bs4 import BeautifulSoup, Comment\r\n    \r\n    \r\n    def transform_space(corpusfile) -&gt; str:\r\n        &quot;&quot;&quot;\r\n        Changes \\n, \\t, \\s+ to space\r\n        :param corpusfile: str\r\n        :return: str\r\n        &quot;&quot;&quot;\r\n        return sub(r&quot;[\\n\\t\\s]+&quot;, &quot; &quot;, corpusfile)\r\n    \r\n    \r\n    def remove_number(corpusfile) -&gt; str:\r\n        &quot;&quot;&quot;\r\n        Removes numbers from a str\r\n        :param corpusfile: str\r\n        :return:\r\n        &quot;&quot;&quot;\r\n        return sub(r&quot;\\d+&quot;, &quot; &quot;, corpusfile)\r\n    \r\n    \r\n    def strip_punctuation(corpusfile):\r\n        fullpunctuation = punctuation\r\n        fullpunctuation += &quot;&#171;&#187;&quot;\r\n        for elem in fullpunctuation:\r\n            corpusfile = corpusfile.replace(elem, &#39; &#39;)\r\n        return corpusfile\r\n    \r\n    \r\n    def stemify(corpusfile) -&gt; str:\r\n        &quot;&quot;&quot;\r\n        Removes morphological affixes from words,\r\n        :param corpusfile:\r\n        :return:\r\n        &quot;&quot;&quot;\r\n        ps = PorterStemmer()\r\n        return &quot; &quot;.join([ps.stem(token) for token in corpusfile.split(&quot; &quot;)])\r\n    \r\n    \r\n    def cleanMe(corpus) -&gt; str:\r\n        &quot;&quot;&quot;\r\n        Removes scripts, style and meta tags from a html document\r\n        :param corpus:\r\n        :return:\r\n        &quot;&quot;&quot;\r\n        soup = BeautifulSoup(corpus, &quot;html5lib&quot;)\r\n        [x.extract() for x in soup.find_all(&#39;script&#39;)]\r\n        [x.extract() for x in soup.find_all(&#39;style&#39;)]\r\n        [x.extract() for x in soup.find_all(&#39;meta&#39;)]\r\n        [x.extract() for x in soup.find_all(text=lambda text: isinstance(text, Comment))]\r\n        return soup.get_text()\r\n    \r\n    \r\n    corpus_root = &#39;./full2016/commerce&#39;\r\n    corpus = PlaintextCorpusReader(corpus_root, &#39;.*\\.htm&#39;, encoding=&#39;iso-8859-1&#39;)\r\n    for elem in corpus.fileids():\r\n        corpusfile = corpus.raw(elem).lower()\r\n        corpusfile = cleanMe(corpusfile)\r\n        corpusfile = remove_number(corpusfile)\r\n        corpusfile = strip_punctuation(corpusfile)\r\n        corpusfile = transform_space(corpusfile)\r\n        corpusfile = stemify(corpusfile)\r\n        print(corpusfile)\r\n\r\nThanks",
            "link": "https://stackoverflow.com/questions/49928110/from-r-to-python-clean-up-and-update-a-corpus-with-nltk",
            "title": "From R to Python - Clean up and update a Corpus with nltk",
            "body": "<p>I'm trying to transform my R code cleaning up Corpus to Python, but struggling a lot.</p>\n\n<p>Indeed, I succeed to partialy rewrite my code in python.\nBut two important problems remains.</p>\n\n<p><strong>First</strong>, the obtained vocabulary is not as good as R, even with recommanded package extension to clean up a file (BeautifulSoup).</p>\n\n<p>Here's a result in R:</p>\n\n<pre><code>\"advanc mp player equip portabl mp player mp cd player hard disk player audiocar gadget dvd player headphon accessoriesgt search nbsp advanc search manufactur pleas select\"\n</code></pre>\n\n<p>Here's a result in Python:</p>\n\n<pre><code>\"advanc mp player equip portabl mp playersmp cd playershard disk playersaudio car gadgetsdvd playersheadphonesaccessori search advanc search manufactur pleas selectadvanc\"\n</code></pre>\n\n<p>As you can see, result is better in R, and it's due to BeautifulSoup</p>\n\n<p><strong>Second problem</strong>, I spend so much time reading nltk documentation, trying to update a Corpus but didn't find how to deal with. </p>\n\n<p>What I mean by update a corpus is replacing files content by new vocabulary.\nFor example, when I use  in R, Corpus is updated an it's possible to directly transform it to a DataFrame and Matrix and then export into a csv.</p>\n\n<p>But in python, should I update Corpus or use another way to processes data ?</p>\n\n<p>Here's my R code:</p>\n\n<pre><code>splash=function(x){\n    res=NULL\n    for (i in x) res=paste(res, i)\n    res\n}\n\n#Removes scripts s(&lt;script .... &lt;/script&gt;)\nremoveScript=function(t){\n    #decoupage de la chaine en utilisant \"&lt;split\"\n    #sp=strsplit(splash(t), \"&lt;script\")\n    sp=strsplit(t, \"&lt;script\")\n    #pour chaque partie du split, le debut (jusqu'a &lt;/script&gt; est supprime\n    vec=sapply(sp[[1]], gsub, pattern=\".*&lt;/script&gt;\", replace=\" \")\n    #les elements du split nottoyes sont concatenes\n    PlainTextDocument(splash(vec))\n}\n\n#Removes Tags\nremoveBalises=function(x){\n    t1=gsub(\"&lt;[^&gt;]*&gt;\", \" \", x)\n    #suppression des occurrences multiples d'espaces (ou de tabulations)\n    PlainTextDocument(gsub(\"[ \\t]+\",\" \",t1))\n}\n\nnettoyage &lt;- function(training)\n{\n  training&lt;-tm_map(training,content_transformer(tolower))\n  training&lt;-tm_map(training,content_transformer(splash))\n  training&lt;-tm_map(training,content_transformer(removeScript))\n  training&lt;-tm_map(training,content_transformer(removeBalises))\n  training&lt;-tm_map(training,removeNumbers)\n  training&lt;-tm_map(training,removeWords,words=stopwords('en'))\n  training&lt;-tm_map(training,stemDocument)\n  training&lt;-tm_map(training,removePunctuation)\n  return(training);\n}\n</code></pre>\n\n<p>Now equivalent in python</p>\n\n<pre><code>from re import sub\nfrom nltk.corpus.reader import PlaintextCorpusReader\nfrom string import punctuation\nfrom nltk.stem import PorterStemmer\nfrom bs4 import BeautifulSoup, Comment\n\n\ndef transform_space(corpusfile) -&gt; str:\n    \"\"\"\n    Changes \\n, \\t, \\s+ to space\n    :param corpusfile: str\n    :return: str\n    \"\"\"\n    return sub(r\"[\\n\\t\\s]+\", \" \", corpusfile)\n\n\ndef remove_number(corpusfile) -&gt; str:\n    \"\"\"\n    Removes numbers from a str\n    :param corpusfile: str\n    :return:\n    \"\"\"\n    return sub(r\"\\d+\", \" \", corpusfile)\n\n\ndef strip_punctuation(corpusfile):\n    fullpunctuation = punctuation\n    fullpunctuation += \"«»\"\n    for elem in fullpunctuation:\n        corpusfile = corpusfile.replace(elem, ' ')\n    return corpusfile\n\n\ndef stemify(corpusfile) -&gt; str:\n    \"\"\"\n    Removes morphological affixes from words,\n    :param corpusfile:\n    :return:\n    \"\"\"\n    ps = PorterStemmer()\n    return \" \".join([ps.stem(token) for token in corpusfile.split(\" \")])\n\n\ndef cleanMe(corpus) -&gt; str:\n    \"\"\"\n    Removes scripts, style and meta tags from a html document\n    :param corpus:\n    :return:\n    \"\"\"\n    soup = BeautifulSoup(corpus, \"html5lib\")\n    [x.extract() for x in soup.find_all('script')]\n    [x.extract() for x in soup.find_all('style')]\n    [x.extract() for x in soup.find_all('meta')]\n    [x.extract() for x in soup.find_all(text=lambda text: isinstance(text, Comment))]\n    return soup.get_text()\n\n\ncorpus_root = './full2016/commerce'\ncorpus = PlaintextCorpusReader(corpus_root, '.*\\.htm', encoding='iso-8859-1')\nfor elem in corpus.fileids():\n    corpusfile = corpus.raw(elem).lower()\n    corpusfile = cleanMe(corpusfile)\n    corpusfile = remove_number(corpusfile)\n    corpusfile = strip_punctuation(corpusfile)\n    corpusfile = transform_space(corpusfile)\n    corpusfile = stemify(corpusfile)\n    print(corpusfile)\n</code></pre>\n\n<p>Thanks</p>\n"
        },
        {
            "tags": [
                "apache-spark",
                "spark-dataframe"
            ],
            "owner": {
                "reputation": 153,
                "user_id": 3654730,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e852704e313441268a89ff4688e53240?s=128&d=identicon&r=PG",
                "display_name": "Derek Kaknes",
                "link": "https://stackoverflow.com/users/3654730/derek-kaknes"
            },
            "is_answered": false,
            "view_count": 9,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163397,
            "creation_date": 1524163397,
            "question_id": 49928109,
            "body_markdown": "I&#39;m having a weird issue with repartitioning Spark dataframes.  Basically, I am reading a DF from a Hive table that has more partitions than are optimal for my cluster size.  For round numbers, the hive table I read in has 100 partitions that I want to resize down to 33 partitions.  So I do the following:\r\n\r\n    val df = spark.table(&quot;db.hive_table&quot;).repartition(33)\r\n    assert(df.rdd.partitions.size == 33)\r\nThis seems to work fine, but when I then run my `pipeline.fit(df)`, each stage spawns 100 tasks - indicating that the partitions were not coalesced.  If I materialize the dataset by using `df.saveAsTable(&#39;db.repartitioned_table&#39;)` and then reload it, then the pipeline works as expected: each stage only spawns 33 tasks.  \r\n\r\nI&#39;ve tried using both `repartition` and `coalesce` but (as expected) both perform the same way.  I&#39;ve also tried using `persist` and `cache` to force the repartition, but to no effect.  My assumption is that the `repartition` is somehow not being triggered until I do some type of full collect, like `saveAsTable`, but that seems pretty cumbersome in this use case.  Is there a simple step that I&#39;m leaving out here?\r\n",
            "link": "https://stackoverflow.com/questions/49928109/spark-2-2-dataset-repartition-not-working-in-ml-pipeline",
            "title": "Spark 2.2 Dataset.repartition not working in ml.Pipeline?",
            "body": "<p>I'm having a weird issue with repartitioning Spark dataframes.  Basically, I am reading a DF from a Hive table that has more partitions than are optimal for my cluster size.  For round numbers, the hive table I read in has 100 partitions that I want to resize down to 33 partitions.  So I do the following:</p>\n\n<pre><code>val df = spark.table(\"db.hive_table\").repartition(33)\nassert(df.rdd.partitions.size == 33)\n</code></pre>\n\n<p>This seems to work fine, but when I then run my <code>pipeline.fit(df)</code>, each stage spawns 100 tasks - indicating that the partitions were not coalesced.  If I materialize the dataset by using <code>df.saveAsTable('db.repartitioned_table')</code> and then reload it, then the pipeline works as expected: each stage only spawns 33 tasks.  </p>\n\n<p>I've tried using both <code>repartition</code> and <code>coalesce</code> but (as expected) both perform the same way.  I've also tried using <code>persist</code> and <code>cache</code> to force the repartition, but to no effect.  My assumption is that the <code>repartition</code> is somehow not being triggered until I do some type of full collect, like <code>saveAsTable</code>, but that seems pretty cumbersome in this use case.  Is there a simple step that I'm leaving out here?</p>\n"
        },
        {
            "tags": [
                "r",
                "random-forest",
                "prediction"
            ],
            "owner": {
                "reputation": 11,
                "user_id": 8107822,
                "user_type": "registered",
                "profile_image": "https://lh5.googleusercontent.com/-MHCqbYDESPE/AAAAAAAAAAI/AAAAAAAAAW8/nHzhmMyqDXI/photo.jpg?sz=128",
                "display_name": "Najme Rastegar",
                "link": "https://stackoverflow.com/users/8107822/najme-rastegar"
            },
            "is_answered": true,
            "view_count": 310,
            "answer_count": 3,
            "score": 0,
            "last_activity_date": 1524163393,
            "creation_date": 1500131785,
            "last_edit_date": 1500134067,
            "question_id": 45119738,
            "body_markdown": "I am using random forest for prediction and in the `predict(fit, test_feature)` line, I get the following error. Can someone help me to overcome this. I did the same steps with another dataset and had no error. but I get error here.\r\n\r\n    Error: Error in x[, vname, drop = FALSE] : subscript out of bounds\r\n    \r\n    training_index &lt;- createDataPartition(shufflled[,487], p = 0.8, times = 1)\r\n    \r\n    training_index &lt;- unlist(training_index)\r\n    \r\n    train_set &lt;- shufflled[training_index,]\r\n    \r\n    test_set &lt;- shufflled[-training_index,]\r\n    \r\n    accuracies&lt;- c()\r\n    \r\n    k=10\r\n    \r\n    n= floor(nrow(train_set)/k)\r\n    \r\n    for(i in 1:k){\r\n    \r\n      sub1&lt;- ((i-1)*n+1)\r\n    \r\n      sub2&lt;- (i*n)\r\n    \r\n      subset&lt;- sub1:sub2\r\n    \r\n      train&lt;- train_set[-subset, ]\r\n    \r\n      test&lt;- train_set[subset, ]\r\n    \r\n      test_feature&lt;- test[ ,-487]\r\n    \r\n      True_Label&lt;- as.factor(test[ ,487])\r\n    \r\n      fit&lt;- randomForest(x= train[ ,-487], y= as.factor(train[ ,487]))\r\n    \r\n      prediction&lt;- predict(fit, test_feature)  #The error line\r\n    \r\n      correctlabel&lt;- prediction == True_Label\r\n    \r\n      t&lt;- table(prediction, True_Label)\r\n    \r\n    }",
            "link": "https://stackoverflow.com/questions/45119738/subscript-out-of-bound-error-in-predict-function-of-randomforest",
            "title": "Subscript out of bound error in predict function of randomforest",
            "body": "<p>I am using random forest for prediction and in the <code>predict(fit, test_feature)</code> line, I get the following error. Can someone help me to overcome this. I did the same steps with another dataset and had no error. but I get error here.</p>\n\n<pre><code>Error: Error in x[, vname, drop = FALSE] : subscript out of bounds\n\ntraining_index &lt;- createDataPartition(shufflled[,487], p = 0.8, times = 1)\ntraining_index &lt;- unlist(training_index)\n\ntrain_set &lt;- shufflled[training_index,]\ntest_set &lt;- shufflled[-training_index,]\n\naccuracies&lt;- c()\nk=10\nn= floor(nrow(train_set)/k)\n\nfor(i in 1:k){\n  sub1&lt;- ((i-1)*n+1)\n  sub2&lt;- (i*n)\n  subset&lt;- sub1:sub2\n  train&lt;- train_set[-subset, ]\n  test&lt;- train_set[subset, ]\n  test_feature&lt;- test[ ,-487]\n\n  True_Label&lt;- as.factor(test[ ,487])\n  fit&lt;- randomForest(x= train[ ,-487], y= as.factor(train[ ,487]))\n\n  prediction&lt;- predict(fit, test_feature)  #The error line\n  correctlabel&lt;- prediction == True_Label\n  t&lt;- table(prediction, True_Label)\n}\n</code></pre>\n"
        },
        {
            "tags": [
                "java-stream",
                "tiff",
                "apache-nifi",
                "azure-data-lake"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 6026270,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/1118064684923928/picture?type=large",
                "display_name": "Gourav Bhattacharya",
                "link": "https://stackoverflow.com/users/6026270/gourav-bhattacharya"
            },
            "is_answered": false,
            "view_count": 16,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163393,
            "creation_date": 1524163393,
            "question_id": 49928106,
            "body_markdown": "I am writing a custom processor in nifi to store a TIF file into the Azure data lake. For this I used ByteArrayOutputstream and I am getting stored TIF file there successfully but its size got increased by 2 times its original size.",
            "link": "https://stackoverflow.com/questions/49928106/how-do-i-read-and-store-tif-file-into-azure-data-lake-without-increasing-its-siz",
            "title": "How do I read and store TIF file into azure data lake without increasing its size and without data loss?",
            "body": "<p>I am writing a custom processor in nifi to store a TIF file into the Azure data lake. For this I used ByteArrayOutputstream and I am getting stored TIF file there successfully but its size got increased by 2 times its original size.</p>\n"
        },
        {
            "tags": [
                "css",
                "twitter-bootstrap",
                "html",
                "responsive-design"
            ],
            "owner": {
                "reputation": 2480,
                "user_id": 1438003,
                "user_type": "registered",
                "accept_rate": 75,
                "profile_image": "https://www.gravatar.com/avatar/94e04412d7a0b62a19148a83809260e9?s=128&d=identicon&r=PG",
                "display_name": "user1438003",
                "link": "https://stackoverflow.com/users/1438003/user1438003"
            },
            "is_answered": true,
            "view_count": 228171,
            "answer_count": 9,
            "score": 213,
            "last_activity_date": 1524163389,
            "creation_date": 1345574860,
            "question_id": 12061139,
            "body_markdown": "I want a button to take up the full width of the column, but having difficulties...\r\n\r\n    &lt;div class=&quot;span9 btn-block&quot;&gt;\r\n        &lt;button class=&quot;btn btn-large btn-block btn-primary&quot; type=&quot;button&quot;&gt;Block level button&lt;/button&gt;\r\n    &lt;/div&gt;\r\n\r\n**How do I make the button as wide as the column?**",
            "link": "https://stackoverflow.com/questions/12061139/making-button-go-full-width",
            "title": "Making button go full-width?",
            "body": "<p>I want a button to take up the full width of the column, but having difficulties...</p>\n\n<pre><code>&lt;div class=\"span9 btn-block\"&gt;\n    &lt;button class=\"btn btn-large btn-block btn-primary\" type=\"button\"&gt;Block level button&lt;/button&gt;\n&lt;/div&gt;\n</code></pre>\n\n<p><strong>How do I make the button as wide as the column?</strong></p>\n"
        },
        {
            "tags": [
                "docker",
                ".net-core",
                "sql-server-linux"
            ],
            "owner": {
                "reputation": 359,
                "user_id": 1130480,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/r5HEZ.jpg?s=128&g=1",
                "display_name": "Islam El-Khayat",
                "link": "https://stackoverflow.com/users/1130480/islam-el-khayat"
            },
            "is_answered": false,
            "view_count": 270,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1524163388,
            "creation_date": 1516203896,
            "last_edit_date": 1524163388,
            "question_id": 48304900,
            "body_markdown": "I am running a SQL server container on Ubuntu using the following command\r\n    \r\n    sudo docker run -e &#39;ACCEPT_EULA=Y&#39; -e &#39;MSSQL_SA_PASSWORD=MyPassword&#39; \\\r\n      -p 1433:1433 --name db \\\r\n      -d microsoft/mssql-server-linux:2017-latest`\r\n\r\nI have another container on the same machine running WebAPI Core application, everything work find if i specified the server ip in the connection string but if I replaced it with &quot;localhost&quot; or &quot;.&quot; it fail to connect.\r\n\r\nAnyone faced the same issue? I don&#39;t want to modify the connection string every time I run my application on a new machine. \r\n\r\n**Edit 1:**\r\nI need the my database to be up and running during the build process to apply EntityFramework code first migrations, so I cannot just add the SQL Server as a dependency in docker-compose.yml  \r\n\r\n**Edit 2**\r\nHere is my docker-compose.yml\r\n\r\n    version: &#39;3&#39;\r\n\r\n    services:\r\n      webapi:\r\n        image: webapi\r\n        build:\r\n          context: ./\r\n          dockerfile: ./WebAPI/Dockerfile\r\n          args:\r\n            - connString=Server=db;Database...;\r\n       environment:\r\n         - ASPNETCORE_ENVIRONMENT=Development\r\n         - ASPNETCORE_URLS=http://+:80\r\n         - conneString=&quot;Server=db;Database...&quot;\r\n       ports:\r\n         - 50695:80\r\n       depends_on:\r\n         - db\r\n\r\n      db:\r\n        image: &quot;microsoft/mssql-server-linux:2017-latest&quot;\r\n        container_name: db\r\n\r\n    networks:\r\n      default:\r\n        external:\r\n          name: nat\r\n\r\n\r\nAnd my docker file\r\n\r\n\tFROM microsoft/aspnetcore:2.0 AS base\r\n\tWORKDIR /app\r\n\tEXPOSE 80\r\n\r\n\tFROM microsoft/aspnetcore-build:2.0 AS build\r\n\tARG connString\r\n    ENV connString &quot;$connString&quot;\r\n\tWORKDIR /src\r\n\tCOPY *.sln ./\r\n\tCOPY WebAPI/WebAPI.csproj WebAPI/\r\n\tRUN dotnet restore\r\n\tCOPY . .\r\n\tWORKDIR /src/Repository\r\n\tRUN dotnet restore\r\n\tRUN dotnet ef database update\r\n\r\n\r\n\tWORKDIR /src/WebAPI\r\n\tRUN dotnet build -c Release -o /app\r\n\r\n\tFROM build AS publish\r\n\tRUN dotnet publish -c Release -o /app\r\n\r\n\tFROM base AS final\r\n\tWORKDIR /app\r\n\tCOPY --from=publish /app .\r\n\tENTRYPOINT [&quot;dotnet&quot;, &quot;WebAPI.dll&quot;]\r\n",
            "link": "https://stackoverflow.com/questions/48304900/connecting-to-sql-sever-docker-container-from-another-container-without-ip",
            "title": "Connecting to SQL Sever docker container from another container without IP",
            "body": "<p>I am running a SQL server container on Ubuntu using the following command</p>\n\n<pre><code>sudo docker run -e 'ACCEPT_EULA=Y' -e 'MSSQL_SA_PASSWORD=MyPassword' \\\n  -p 1433:1433 --name db \\\n  -d microsoft/mssql-server-linux:2017-latest`\n</code></pre>\n\n<p>I have another container on the same machine running WebAPI Core application, everything work find if i specified the server ip in the connection string but if I replaced it with \"localhost\" or \".\" it fail to connect.</p>\n\n<p>Anyone faced the same issue? I don't want to modify the connection string every time I run my application on a new machine. </p>\n\n<p><strong>Edit 1:</strong>\nI need the my database to be up and running during the build process to apply EntityFramework code first migrations, so I cannot just add the SQL Server as a dependency in docker-compose.yml  </p>\n\n<p><strong>Edit 2</strong>\nHere is my docker-compose.yml</p>\n\n<pre><code>version: '3'\n\nservices:\n  webapi:\n    image: webapi\n    build:\n      context: ./\n      dockerfile: ./WebAPI/Dockerfile\n      args:\n        - connString=Server=db;Database...;\n   environment:\n     - ASPNETCORE_ENVIRONMENT=Development\n     - ASPNETCORE_URLS=http://+:80\n     - conneString=\"Server=db;Database...\"\n   ports:\n     - 50695:80\n   depends_on:\n     - db\n\n  db:\n    image: \"microsoft/mssql-server-linux:2017-latest\"\n    container_name: db\n\nnetworks:\n  default:\n    external:\n      name: nat\n</code></pre>\n\n<p>And my docker file</p>\n\n<pre><code>FROM microsoft/aspnetcore:2.0 AS base\nWORKDIR /app\nEXPOSE 80\n\nFROM microsoft/aspnetcore-build:2.0 AS build\nARG connString\nENV connString \"$connString\"\nWORKDIR /src\nCOPY *.sln ./\nCOPY WebAPI/WebAPI.csproj WebAPI/\nRUN dotnet restore\nCOPY . .\nWORKDIR /src/Repository\nRUN dotnet restore\nRUN dotnet ef database update\n\n\nWORKDIR /src/WebAPI\nRUN dotnet build -c Release -o /app\n\nFROM build AS publish\nRUN dotnet publish -c Release -o /app\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app .\nENTRYPOINT [\"dotnet\", \"WebAPI.dll\"]\n</code></pre>\n"
        },
        {
            "tags": [
                "boxplot"
            ],
            "owner": {
                "reputation": 31,
                "user_id": 3976075,
                "user_type": "registered",
                "accept_rate": 86,
                "profile_image": "https://graph.facebook.com/711795216/picture?type=large",
                "display_name": "Chris Heckman",
                "link": "https://stackoverflow.com/users/3976075/chris-heckman"
            },
            "is_answered": true,
            "view_count": 367,
            "answer_count": 2,
            "score": 1,
            "last_activity_date": 1524163376,
            "creation_date": 1410129411,
            "question_id": 25715395,
            "body_markdown": "I cannot get names to work in box plot.  Is it not working because I only have a single vector?  Heres what I have tried.\r\n\r\n    tmp = c(1,1,1,1,2,2,2,2,5,5,5,5,5,6,5,4,7)\r\n    boxplot(tmp)\r\n    boxplot(tmp, names=c(&quot;today&quot;))\r\n    boxplot(tmp, names=&quot;today&quot;)\r\n    boxplot(tmp, labels=&quot;today&quot;)\r\n    boxplot(tmp, labels=c(&quot;today&quot;)",
            "link": "https://stackoverflow.com/questions/25715395/r-boxplot-names-with-single-vector",
            "title": "r: boxplot names=&quot;&quot; with single vector",
            "body": "<p>I cannot get names to work in box plot.  Is it not working because I only have a single vector?  Heres what I have tried.</p>\n\n<pre><code>tmp = c(1,1,1,1,2,2,2,2,5,5,5,5,5,6,5,4,7)\nboxplot(tmp)\nboxplot(tmp, names=c(\"today\"))\nboxplot(tmp, names=\"today\")\nboxplot(tmp, labels=\"today\")\nboxplot(tmp, labels=c(\"today\")\n</code></pre>\n"
        },
        {
            "tags": [
                "sql-server",
                "linux",
                "sql-execution-plan",
                "sql-server-linux",
                "sql-operations-studio"
            ],
            "owner": {
                "reputation": 667,
                "user_id": 2992008,
                "user_type": "registered",
                "accept_rate": 70,
                "profile_image": "https://www.gravatar.com/avatar/260caaed05402b4da466d312ab0690a3?s=128&d=identicon&r=PG&f=1",
                "display_name": "Gherman",
                "link": "https://stackoverflow.com/users/2992008/gherman"
            },
            "is_answered": true,
            "view_count": 303,
            "accepted_answer_id": 46042491,
            "answer_count": 1,
            "score": 2,
            "last_activity_date": 1524163376,
            "creation_date": 1504540266,
            "last_edit_date": 1524163376,
            "question_id": 46040555,
            "body_markdown": "I have SQL Server installed on Linux. It was installed from Microsoft&#39;s repos as described here:\r\nhttps://docs.microsoft.com/en-us/sql/linux/quickstart-install-connect-ubuntu\r\n\r\nIn MySql I used to write `EXPLAIN` in front of my query to see the execution plan. In SQL Server it doesn&#39;t seem to work. But I don&#39;t have the studio program installed, only just SQL Server and the `sqlcmd` tool.\r\n\r\nHow do I see the execution plan of a query in SQL Server on Linux?",
            "link": "https://stackoverflow.com/questions/46040555/how-to-view-execution-plans-in-sql-server-on-linux",
            "title": "How to view execution plans in SQL Server on Linux",
            "body": "<p>I have SQL Server installed on Linux. It was installed from Microsoft's repos as described here:\n<a href=\"https://docs.microsoft.com/en-us/sql/linux/quickstart-install-connect-ubuntu\" rel=\"nofollow noreferrer\">https://docs.microsoft.com/en-us/sql/linux/quickstart-install-connect-ubuntu</a></p>\n\n<p>In MySql I used to write <code>EXPLAIN</code> in front of my query to see the execution plan. In SQL Server it doesn't seem to work. But I don't have the studio program installed, only just SQL Server and the <code>sqlcmd</code> tool.</p>\n\n<p>How do I see the execution plan of a query in SQL Server on Linux?</p>\n"
        },
        {
            "tags": [
                "sql",
                "sql-server",
                "sql-server-2008",
                "etl"
            ],
            "owner": {
                "reputation": 5229,
                "user_id": 322518,
                "user_type": "registered",
                "accept_rate": 83,
                "profile_image": "https://www.gravatar.com/avatar/bfc432d64d41eef026c93901ff14d99e?s=128&d=identicon&r=PG&f=1",
                "display_name": "O.O",
                "link": "https://stackoverflow.com/users/322518/o-o"
            },
            "is_answered": true,
            "view_count": 10039,
            "accepted_answer_id": 3498164,
            "answer_count": 4,
            "score": 5,
            "last_activity_date": 1524163366,
            "creation_date": 1282000247,
            "last_edit_date": 1282145395,
            "question_id": 3498148,
            "body_markdown": "For some reason my MDF file is 154gigs, however, I only loaded 7 gigs worth of data from flat files.  Why is the MDF file so much larger than the actual source data?\r\n\r\nMore info:\r\n\r\nOnly a few tables with ~25 million rows.  No large varchar fields (biggest is 300, most are less than varchar(50).  Not very wide tables &lt; 20 columns.  Also, none of the large tables are indexed yet.  Tables with indexes have less than 1 million rows.  I don&#39;t use char, only varchar for strings. Datatype is not the issue.\r\n\r\nTurned out it was the log file, not the mdf file.  The MDF file is actually 24gigs which seems more reasonable, however still big IMHO.\r\n\r\nUPDATE:\r\n\r\nI fixed the problem with the LDF (log) file by changing the recovery model from FULL to simple.  This is okay because this server is only used for internal development and ETL processing.  In addition, before changing to SIMPLE I had to shrink the LOG file.  Shrinking is not recommended in most cases, however, this was one of those cases where the log file should have never grown so big and so fast.  For further reading see [this][1]\r\n\r\n\r\n  [1]: http://support.microsoft.com/kb/873235",
            "link": "https://stackoverflow.com/questions/3498148/mdf-file-size-much-larger-than-actual-data",
            "title": "MDF file size much larger than actual data",
            "body": "<p>For some reason my MDF file is 154gigs, however, I only loaded 7 gigs worth of data from flat files.  Why is the MDF file so much larger than the actual source data?</p>\n\n<p>More info:</p>\n\n<p>Only a few tables with ~25 million rows.  No large varchar fields (biggest is 300, most are less than varchar(50).  Not very wide tables &lt; 20 columns.  Also, none of the large tables are indexed yet.  Tables with indexes have less than 1 million rows.  I don't use char, only varchar for strings. Datatype is not the issue.</p>\n\n<p>Turned out it was the log file, not the mdf file.  The MDF file is actually 24gigs which seems more reasonable, however still big IMHO.</p>\n\n<p>UPDATE:</p>\n\n<p>I fixed the problem with the LDF (log) file by changing the recovery model from FULL to simple.  This is okay because this server is only used for internal development and ETL processing.  In addition, before changing to SIMPLE I had to shrink the LOG file.  Shrinking is not recommended in most cases, however, this was one of those cases where the log file should have never grown so big and so fast.  For further reading see <a href=\"http://support.microsoft.com/kb/873235\" rel=\"nofollow noreferrer\">this</a></p>\n"
        },
        {
            "tags": [
                "android",
                "gradle",
                "android-productflavors",
                "android-flavors"
            ],
            "owner": {
                "reputation": 501,
                "user_id": 5360809,
                "user_type": "registered",
                "accept_rate": 100,
                "profile_image": "https://graph.facebook.com/1618836835044059/picture?type=large",
                "display_name": "Max Aves",
                "link": "https://stackoverflow.com/users/5360809/max-aves"
            },
            "is_answered": false,
            "view_count": 16,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163352,
            "creation_date": 1524163352,
            "question_id": 49928094,
            "body_markdown": "Recently my project started taking too much time to build, sometimes it just gets stuck.\r\n\r\nI figured out, that the reason of this is my `productFlavors` block.\r\n\r\nI have only two flavors:\r\n\r\n    flavor1{\r\n       applicationId &#39;Some app id&#39;\r\n       manifestPlaceholders = {\r\n       appIcon: &quot;@mipmap/ic_launcher_flavor1&quot;\r\n    }\r\n    }\r\n    \r\n    flavor2{\r\n       applicationId &#39;Some app id&#39;\r\n       manifestPlaceholders = {\r\n       appIcon: &quot;@mipmap/ic_launcher_flavor2&quot;\r\n    }\r\n    }\r\n\r\n\r\nIf I remove this block  my build get done within 1-2 minutes. Are there any solutions for this?",
            "link": "https://stackoverflow.com/questions/49928094/android-gradle-build-takes-too-long-with-productflavors",
            "title": "Android. Gradle build takes too long with productFlavors",
            "body": "<p>Recently my project started taking too much time to build, sometimes it just gets stuck.</p>\n\n<p>I figured out, that the reason of this is my <code>productFlavors</code> block.</p>\n\n<p>I have only two flavors:</p>\n\n<pre><code>flavor1{\n   applicationId 'Some app id'\n   manifestPlaceholders = {\n   appIcon: \"@mipmap/ic_launcher_flavor1\"\n}\n}\n\nflavor2{\n   applicationId 'Some app id'\n   manifestPlaceholders = {\n   appIcon: \"@mipmap/ic_launcher_flavor2\"\n}\n}\n</code></pre>\n\n<p>If I remove this block  my build get done within 1-2 minutes. Are there any solutions for this?</p>\n"
        },
        {
            "tags": [
                "flutter"
            ],
            "owner": {
                "reputation": 211,
                "user_id": 3110156,
                "user_type": "registered",
                "accept_rate": 33,
                "profile_image": "https://www.gravatar.com/avatar/5fdbb90a95ce8cf30558a5c17946fc25?s=128&d=identicon&r=PG&f=1",
                "display_name": "Pieter",
                "link": "https://stackoverflow.com/users/3110156/pieter"
            },
            "is_answered": true,
            "view_count": 2658,
            "answer_count": 4,
            "score": 2,
            "last_activity_date": 1524163349,
            "creation_date": 1494361021,
            "question_id": 43879103,
            "body_markdown": "How would you approach adding a splash screen to Flutter apps? It should load and display before any other content. Currently there is a brief flash of color before the Scaffold(home:X) widget loads.",
            "link": "https://stackoverflow.com/questions/43879103/adding-a-splash-screen-to-flutter-apps",
            "title": "Adding a splash screen to Flutter apps",
            "body": "<p>How would you approach adding a splash screen to Flutter apps? It should load and display before any other content. Currently there is a brief flash of color before the Scaffold(home:X) widget loads.</p>\n"
        },
        {
            "tags": [
                "jenkins",
                "ajp",
                "winstone"
            ],
            "owner": {
                "reputation": 40,
                "user_id": 5970723,
                "user_type": "registered",
                "accept_rate": 40,
                "profile_image": "https://www.gravatar.com/avatar/81625b48d36ca241f351a5b425256c7d?s=128&d=identicon&r=PG&f=1",
                "display_name": "maddie",
                "link": "https://stackoverflow.com/users/5970723/maddie"
            },
            "is_answered": false,
            "view_count": 5,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163348,
            "creation_date": 1524163348,
            "question_id": 49928091,
            "body_markdown": "I moved from Jenkins 1.6.x installation to 2.1.1 Following error prevents Jenkins from starting.\r\n        \r\n        Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0\r\n        Running from: /usr/lib/jenkins/jenkins.war\r\n        Apr 19, 2018 2:26:44 PM Main deleteWinstoneTempContents\r\n        WARNING: Failed to delete the temporary Winstone file /tmp/winstone/jenkins.war\r\n        Apr 19, 2018 2:26:44 PM org.eclipse.jetty.util.log.Log initialized\r\n        INFO: Logging initialized @444ms to org.eclipse.jetty.util.log.JavaUtilLog\r\n        Apr 19, 2018 2:26:45 PM winstone.Logger logInternal\r\n        INFO: Beginning extraction from war file\r\n        Apr 19, 2018 2:26:45 PM org.eclipse.jetty.server.handler.ContextHandler setContextPath\r\n        WARNING: Empty contextPath\r\n        Apr 19, 2018 2:26:45 PM winstone.Logger logInternal\r\n        INFO: Winstone shutdown successfully\r\n        java.io.IOException: Failed to start a listener: winstone.Ajp13ConnectorFactory\r\n                at winstone.Launcher.spawnListener(Launcher.java:209)\r\n                at winstone.Launcher.&lt;init&gt;(Launcher.java:149)\r\n                at winstone.Launcher.main(Launcher.java:354)\r\n                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n                at java.lang.reflect.Method.invoke(Method.java:497)\r\n                at Main._main(Main.java:312)\r\n                at Main.main(Main.java:136)\r\n        Caused by: java.lang.UnsupportedOperationException: AJP support is removed in Winstone 3.0 due to Jetty 9 not supporting AJP. For reverse proxying, please use HTTP instead of AJP.\r\n                at winstone.Ajp13ConnectorFactory.start(Ajp13ConnectorFactory.java:32)\r\n                at winstone.Launcher.spawnListener(Launcher.java:207)\r\n                ... 8 more\r\n        Apr 19, 2018 2:26:45 PM winstone.Logger logInternal\r\n        SEVERE: Container startup failed\r\n        java.io.IOException: Failed to start a listener: winstone.Ajp13ConnectorFactory\r\n                at winstone.Launcher.spawnListener(Launcher.java:209)\r\n                at winstone.Launcher.&lt;init&gt;(Launcher.java:149)\r\n                at winstone.Launcher.main(Launcher.java:354)\r\n                at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n                at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n                at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n                at java.lang.reflect.Method.invoke(Method.java:497)\r\n                at Main._main(Main.java:312)\r\n                at Main.main(Main.java:136)\r\n        Caused by: java.lang.UnsupportedOperationException: AJP support is removed in Winstone 3.0 due to Jetty 9 not supporting AJP. For reverse proxying, please use HTTP instead of AJP.\r\n                at winstone.Ajp13ConnectorFactory.start(Ajp13ConnectorFactory.java:32)\r\n                at winstone.Launcher.spawnListener(Launcher.java:207)\r\n                ... 8 more\r\n        \r\n**NOTE: I tried JENKINS_AJP_PORT=&quot;-1&quot; in /etc/sysconfig/jenkins and  also tried commenting out #JENKINS_AJP_PORT=&quot;8009&quot; #JENKINS_AJP_LISTEN_ADDRESS=&quot;&quot;  and started but still see the same startup error. Please help !!",
            "link": "https://stackoverflow.com/questions/49928091/migrating-to-jenkins-2-1-1-ajp-support-is-removed-in-winstone-3-0-due-to-jetty",
            "title": "Migrating to Jenkins 2.1.1- AJP support is removed in Winstone 3.0 due to Jetty 9 not supporting AJP",
            "body": "<p>I moved from Jenkins 1.6.x installation to 2.1.1 Following error prevents Jenkins from starting.</p>\n\n<pre><code>    Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0\n    Running from: /usr/lib/jenkins/jenkins.war\n    Apr 19, 2018 2:26:44 PM Main deleteWinstoneTempContents\n    WARNING: Failed to delete the temporary Winstone file /tmp/winstone/jenkins.war\n    Apr 19, 2018 2:26:44 PM org.eclipse.jetty.util.log.Log initialized\n    INFO: Logging initialized @444ms to org.eclipse.jetty.util.log.JavaUtilLog\n    Apr 19, 2018 2:26:45 PM winstone.Logger logInternal\n    INFO: Beginning extraction from war file\n    Apr 19, 2018 2:26:45 PM org.eclipse.jetty.server.handler.ContextHandler setContextPath\n    WARNING: Empty contextPath\n    Apr 19, 2018 2:26:45 PM winstone.Logger logInternal\n    INFO: Winstone shutdown successfully\n    java.io.IOException: Failed to start a listener: winstone.Ajp13ConnectorFactory\n            at winstone.Launcher.spawnListener(Launcher.java:209)\n            at winstone.Launcher.&lt;init&gt;(Launcher.java:149)\n            at winstone.Launcher.main(Launcher.java:354)\n            at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n            at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n            at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n            at java.lang.reflect.Method.invoke(Method.java:497)\n            at Main._main(Main.java:312)\n            at Main.main(Main.java:136)\n    Caused by: java.lang.UnsupportedOperationException: AJP support is removed in Winstone 3.0 due to Jetty 9 not supporting AJP. For reverse proxying, please use HTTP instead of AJP.\n            at winstone.Ajp13ConnectorFactory.start(Ajp13ConnectorFactory.java:32)\n            at winstone.Launcher.spawnListener(Launcher.java:207)\n            ... 8 more\n    Apr 19, 2018 2:26:45 PM winstone.Logger logInternal\n    SEVERE: Container startup failed\n    java.io.IOException: Failed to start a listener: winstone.Ajp13ConnectorFactory\n            at winstone.Launcher.spawnListener(Launcher.java:209)\n            at winstone.Launcher.&lt;init&gt;(Launcher.java:149)\n            at winstone.Launcher.main(Launcher.java:354)\n            at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n            at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n            at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n            at java.lang.reflect.Method.invoke(Method.java:497)\n            at Main._main(Main.java:312)\n            at Main.main(Main.java:136)\n    Caused by: java.lang.UnsupportedOperationException: AJP support is removed in Winstone 3.0 due to Jetty 9 not supporting AJP. For reverse proxying, please use HTTP instead of AJP.\n            at winstone.Ajp13ConnectorFactory.start(Ajp13ConnectorFactory.java:32)\n            at winstone.Launcher.spawnListener(Launcher.java:207)\n            ... 8 more\n</code></pre>\n\n<p>**NOTE: I tried JENKINS_AJP_PORT=\"-1\" in /etc/sysconfig/jenkins and  also tried commenting out #JENKINS_AJP_PORT=\"8009\" #JENKINS_AJP_LISTEN_ADDRESS=\"\"  and started but still see the same startup error. Please help !!</p>\n"
        },
        {
            "tags": [
                "docker",
                "ssms",
                "sql-server-linux"
            ],
            "owner": {
                "reputation": 550,
                "user_id": 1460758,
                "user_type": "registered",
                "accept_rate": 8,
                "profile_image": "https://www.gravatar.com/avatar/ffd26870bfe98bbb9dad204461eca2c8?s=128&d=identicon&r=PG",
                "display_name": "Sam",
                "link": "https://stackoverflow.com/users/1460758/sam"
            },
            "is_answered": false,
            "view_count": 24,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524163345,
            "creation_date": 1510349483,
            "last_edit_date": 1524163345,
            "question_id": 47231416,
            "body_markdown": "I am following along in a book that has a .Net Core MVC and Angular project using the linux version of SQL Server for docker.\r\nThe project has a docker-compose.yml file like this:\r\n\r\n    version: &quot;3&quot;\r\n      \r\n    services:\r\n      database:\r\n        image: &quot;microsoft/mssql-server-linux:latest&quot;\r\n        ports:\r\n          - 5100:1433\r\n        environment: \r\n          - ACCEPT_EULA=Y\r\n          - SA_PASSWORD=mySecret123\r\n\r\nand after running dot ef migration add, docker-compose up, and finally dotnet ef update, everything works, the project runs, and the first piece of Entity Framework DataContext data is returned to a razor page and displayed. \r\n\r\nBut the only hint of the SQL Server running is the info returned in the console window after running docker-compose up.\r\nI&#39;m used to viewing and working with the data in SSMS.  How can we do this with an SQL Server running in a Docker Container?\r\nA console window just letting me know it is running isn&#39;t much used to me here.",
            "link": "https://stackoverflow.com/questions/47231416/how-can-i-view-an-sql-server-running-in-docker",
            "title": "How can I view an SQL Server running in Docker?",
            "body": "<p>I am following along in a book that has a .Net Core MVC and Angular project using the linux version of SQL Server for docker.\nThe project has a docker-compose.yml file like this:</p>\n\n<pre><code>version: \"3\"\n\nservices:\n  database:\n    image: \"microsoft/mssql-server-linux:latest\"\n    ports:\n      - 5100:1433\n    environment: \n      - ACCEPT_EULA=Y\n      - SA_PASSWORD=mySecret123\n</code></pre>\n\n<p>and after running dot ef migration add, docker-compose up, and finally dotnet ef update, everything works, the project runs, and the first piece of Entity Framework DataContext data is returned to a razor page and displayed. </p>\n\n<p>But the only hint of the SQL Server running is the info returned in the console window after running docker-compose up.\nI'm used to viewing and working with the data in SSMS.  How can we do this with an SQL Server running in a Docker Container?\nA console window just letting me know it is running isn't much used to me here.</p>\n"
        },
        {
            "tags": [
                "android"
            ],
            "owner": {
                "reputation": 124,
                "user_id": 7232539,
                "user_type": "registered",
                "accept_rate": 77,
                "profile_image": "https://i.stack.imgur.com/V8FRG.jpg?s=128&g=1",
                "display_name": "B J",
                "link": "https://stackoverflow.com/users/7232539/b-j"
            },
            "is_answered": true,
            "view_count": 13,
            "accepted_answer_id": 49928086,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524163334,
            "creation_date": 1524162806,
            "question_id": 49927942,
            "body_markdown": "I have a button and would like top and bottom of text was touching top and bottom border of button. \r\n\r\nBut I&#39;m not able to remove that padding or whatever it is and there&#39;s a considerable space between top of text and top of button border. It looks like this:\r\n\r\n[![enter image description here][1]][1]\r\n\r\nThis is code:\r\n\r\n    &lt;Button a:layout_width=&quot;wrap_content&quot; a:layout_height=&quot;match_parent&quot; a:background=&quot;#ffff0000&quot; \r\n    a:minWidth=&quot;1px&quot; \r\n    a:minHeight=&quot;1px&quot; \r\n    a:maxHeight=&quot;1000dp&quot;\r\n    a:paddingHorizontal=&quot;15dp&quot; \r\n    a:paddingVertical=&quot;0dp&quot;/&gt;\r\n\r\n  [1]: https://i.stack.imgur.com/6apBl.png\r\n\r\nAny idea or hint how to remove that spacing?",
            "link": "https://stackoverflow.com/questions/49927942/button-text-with-no-smaller-padding",
            "title": "Button text with no/smaller padding",
            "body": "<p>I have a button and would like top and bottom of text was touching top and bottom border of button. </p>\n\n<p>But I'm not able to remove that padding or whatever it is and there's a considerable space between top of text and top of button border. It looks like this:</p>\n\n<p><a href=\"https://i.stack.imgur.com/6apBl.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/6apBl.png\" alt=\"enter image description here\"></a></p>\n\n<p>This is code:</p>\n\n<pre><code>&lt;Button a:layout_width=\"wrap_content\" a:layout_height=\"match_parent\" a:background=\"#ffff0000\" \na:minWidth=\"1px\" \na:minHeight=\"1px\" \na:maxHeight=\"1000dp\"\na:paddingHorizontal=\"15dp\" \na:paddingVertical=\"0dp\"/&gt;\n</code></pre>\n\n<p>Any idea or hint how to remove that spacing?</p>\n"
        },
        {
            "tags": [
                "java",
                "git",
                "jenkins",
                "changelog"
            ],
            "owner": {
                "reputation": 15,
                "user_id": 8438717,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/1544401375581125/picture?type=large",
                "display_name": "Sanjana Patil",
                "link": "https://stackoverflow.com/users/8438717/sanjana-patil"
            },
            "is_answered": false,
            "view_count": 28,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524163331,
            "creation_date": 1503398962,
            "question_id": 45815597,
            "body_markdown": "I want to get list of commit Id&#39;s shown in Git Changelog Plugin output as post-build action and iterate through it using java. Which script/method should I use? ",
            "link": "https://stackoverflow.com/questions/45815597/how-to-access-jenkins-git-changelog-plugin-output-using-java",
            "title": "How to access Jenkins git-changelog plugin output using java?",
            "body": "<p>I want to get list of commit Id's shown in Git Changelog Plugin output as post-build action and iterate through it using java. Which script/method should I use? </p>\n"
        },
        {
            "tags": [
                "java",
                "gradle",
                "gretty"
            ],
            "owner": {
                "reputation": 858,
                "user_id": 1423583,
                "user_type": "registered",
                "accept_rate": 82,
                "profile_image": "https://www.gravatar.com/avatar/d61b0c27c3c724ec0d577d7cfc3f35df?s=128&d=identicon&r=PG",
                "display_name": "Nathan",
                "link": "https://stackoverflow.com/users/1423583/nathan"
            },
            "is_answered": false,
            "view_count": 390,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1524163328,
            "creation_date": 1458108477,
            "question_id": 36027940,
            "body_markdown": "I&#39;m using Gretty to run my web application via `gradle appRun`.  I&#39;m also using [the Gradle Asset Pipeline plugin](https://github.com/bertramdev/asset-pipeline) to compile my Less files to CSS.\r\n\r\nI want to integrate with [Gretty&#39;s Fast reload feature](http://akhikhl.github.io/gretty-doc/Fast-reload.html) so that when I change a Less file, it automatically compiles it and copies the CSS to the in-place web-app.\r\n\r\nI have implemented a solution using Gretty&#39;s `onScanFilesChanged` setting in my `build.gradle` file:\r\n\r\n    buildscript {\r\n        dependencies {\r\n            classpath &#39;org.akhikhl.gretty:gretty:1.2.4&#39;\r\n            classpath &#39;com.bertramlabs.plugins:asset-pipeline-gradle:2.7.0&#39;\r\n            classpath &#39;com.bertramlabs.plugins:less-asset-pipeline:2.7.0&#39;\r\n        }\r\n    }\r\n    \r\n    apply plugin: &#39;java&#39;\r\n    apply plugin: &#39;eclipse&#39;\r\n    apply plugin: &#39;war&#39;\r\n    apply plugin: &#39;org.akhikhl.gretty&#39;\r\n    apply plugin: &#39;com.bertramlabs.asset-pipeline&#39;\r\n    \r\n    dependencies {\r\n        // ...\r\n    }\r\n    \r\n    assets {\r\n        excludes = [&#39;bootstrap/**&#39;]\r\n    }\r\n    \r\n    war.dependsOn assetCompile\r\n    \r\n    gretty {\r\n        servletContainer = &#39;tomcat8&#39;\r\n        enableNaming = true\r\n        contextPath = &#39;/&#39;\r\n    \r\n        // This affects the war task as well\r\n        webappCopy {\r\n            from &#39;build/assets&#39;, { into &#39;stylesheet&#39; }\r\n        }\r\n    \r\n        afterEvaluate {\r\n            prepareInplaceWebAppFolder.dependsOn assetCompile\r\n        }\r\n\r\n        scanDir &quot;src/assets&quot;\r\n        fastReload &quot;src/assets&quot;\r\n        onScanFilesChanged { List&lt;String&gt; files -&gt;\r\n            if (files.findAll { it.endsWith &quot;.less&quot; }.size() &gt; 0) {\r\n                assetCompile.compile()\r\n            }\r\n        } \r\n    }\r\n\r\nIs there a neater way to do this that doesn&#39;t involve so much code in the `build.gradle` file?",
            "link": "https://stackoverflow.com/questions/36027940/fast-reload-with-in-place-web-app-and-asset-pipeline-in-gradle-gretty",
            "title": "Fast reload with in-place web app and asset pipeline in Gradle/Gretty",
            "body": "<p>I'm using Gretty to run my web application via <code>gradle appRun</code>.  I'm also using <a href=\"https://github.com/bertramdev/asset-pipeline\" rel=\"nofollow\">the Gradle Asset Pipeline plugin</a> to compile my Less files to CSS.</p>\n\n<p>I want to integrate with <a href=\"http://akhikhl.github.io/gretty-doc/Fast-reload.html\" rel=\"nofollow\">Gretty's Fast reload feature</a> so that when I change a Less file, it automatically compiles it and copies the CSS to the in-place web-app.</p>\n\n<p>I have implemented a solution using Gretty's <code>onScanFilesChanged</code> setting in my <code>build.gradle</code> file:</p>\n\n<pre><code>buildscript {\n    dependencies {\n        classpath 'org.akhikhl.gretty:gretty:1.2.4'\n        classpath 'com.bertramlabs.plugins:asset-pipeline-gradle:2.7.0'\n        classpath 'com.bertramlabs.plugins:less-asset-pipeline:2.7.0'\n    }\n}\n\napply plugin: 'java'\napply plugin: 'eclipse'\napply plugin: 'war'\napply plugin: 'org.akhikhl.gretty'\napply plugin: 'com.bertramlabs.asset-pipeline'\n\ndependencies {\n    // ...\n}\n\nassets {\n    excludes = ['bootstrap/**']\n}\n\nwar.dependsOn assetCompile\n\ngretty {\n    servletContainer = 'tomcat8'\n    enableNaming = true\n    contextPath = '/'\n\n    // This affects the war task as well\n    webappCopy {\n        from 'build/assets', { into 'stylesheet' }\n    }\n\n    afterEvaluate {\n        prepareInplaceWebAppFolder.dependsOn assetCompile\n    }\n\n    scanDir \"src/assets\"\n    fastReload \"src/assets\"\n    onScanFilesChanged { List&lt;String&gt; files -&gt;\n        if (files.findAll { it.endsWith \".less\" }.size() &gt; 0) {\n            assetCompile.compile()\n        }\n    } \n}\n</code></pre>\n\n<p>Is there a neater way to do this that doesn't involve so much code in the <code>build.gradle</code> file?</p>\n"
        },
        {
            "tags": [
                "sql-server",
                "docker",
                "virtualbox",
                "dockerfile",
                "sql-server-linux"
            ],
            "owner": {
                "reputation": 5480,
                "user_id": 1219755,
                "user_type": "registered",
                "accept_rate": 84,
                "profile_image": "https://www.gravatar.com/avatar/4be57141c161a58a09f4a50541079d51?s=128&d=identicon&r=PG&f=1",
                "display_name": "alexanoid",
                "link": "https://stackoverflow.com/users/1219755/alexanoid"
            },
            "is_answered": false,
            "view_count": 155,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524163328,
            "creation_date": 1508572185,
            "last_edit_date": 1524163328,
            "question_id": 46861210,
            "body_markdown": "I use Docker without Hyper-V with VirtualBox and Docker VM on Windows 10 Home edition. \r\n\r\nI have the following Docker build file:\r\n\r\n    FROM repositoryname/mssql-server-linux:test-db\r\n    \r\n    RUN mkdir -p /usr/src/app\r\n    WORKDIR /usr/src/app\r\n    \r\n    COPY .  /usr/src/app\r\n    \r\n    # start sql, setup db\r\n    RUN /opt/mssql/bin/sqlservr &amp; sleep 15s &amp;&amp; \\\r\n    \t/opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P pass -d master -i /usr/src/app/setup_db_1.sql &amp;&amp; \\\r\n    \t/opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P pass -d master -i /usr/src/app/setup__db_2.sql\r\n\r\nRight now MS SQL Server fails during startup with the following error:\r\n\r\n    Error 9002. The transaction log for database master is full due to NOTHING\r\n\r\nIs there anything I can do (for example add some instructions to my Docker build file) in order to prevent this error?\r\n\r\nAlso, I found the similar topic here https://social.msdn.microsoft.com/Forums/en-US/ca65a3e2-2f30-4641-a7ea-d3998c8dd8a7/the-transaction-log-for-database-master-is-full-due-to-nothing-during-updade?forum=sqlsetupandupgrade but unfortunately without the proper answer right now.",
            "link": "https://stackoverflow.com/questions/46861210/docker-and-sql-server-linux-error-9002-the-transaction-log-for-database-maste",
            "title": "Docker and SQL Server Linux - Error 9002. The transaction log for database master is full due to NOTHING",
            "body": "<p>I use Docker without Hyper-V with VirtualBox and Docker VM on Windows 10 Home edition. </p>\n\n<p>I have the following Docker build file:</p>\n\n<pre><code>FROM repositoryname/mssql-server-linux:test-db\n\nRUN mkdir -p /usr/src/app\nWORKDIR /usr/src/app\n\nCOPY .  /usr/src/app\n\n# start sql, setup db\nRUN /opt/mssql/bin/sqlservr &amp; sleep 15s &amp;&amp; \\\n    /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P pass -d master -i /usr/src/app/setup_db_1.sql &amp;&amp; \\\n    /opt/mssql-tools/bin/sqlcmd -S localhost -U sa -P pass -d master -i /usr/src/app/setup__db_2.sql\n</code></pre>\n\n<p>Right now MS SQL Server fails during startup with the following error:</p>\n\n<pre><code>Error 9002. The transaction log for database master is full due to NOTHING\n</code></pre>\n\n<p>Is there anything I can do (for example add some instructions to my Docker build file) in order to prevent this error?</p>\n\n<p>Also, I found the similar topic here <a href=\"https://social.msdn.microsoft.com/Forums/en-US/ca65a3e2-2f30-4641-a7ea-d3998c8dd8a7/the-transaction-log-for-database-master-is-full-due-to-nothing-during-updade?forum=sqlsetupandupgrade\" rel=\"nofollow noreferrer\">https://social.msdn.microsoft.com/Forums/en-US/ca65a3e2-2f30-4641-a7ea-d3998c8dd8a7/the-transaction-log-for-database-master-is-full-due-to-nothing-during-updade?forum=sqlsetupandupgrade</a> but unfortunately without the proper answer right now.</p>\n"
        },
        {
            "tags": [
                "sql-server",
                "linux",
                "docker",
                "docker-compose",
                "sql-server-linux"
            ],
            "owner": {
                "reputation": 7096,
                "user_id": 629323,
                "user_type": "registered",
                "accept_rate": 90,
                "profile_image": "https://www.gravatar.com/avatar/8f2bcde07543df4e1397d1781d645d2e?s=128&d=identicon&r=PG",
                "display_name": "GraemeMiller",
                "link": "https://stackoverflow.com/users/629323/graememiller"
            },
            "is_answered": false,
            "view_count": 107,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524163309,
            "creation_date": 1516712846,
            "last_edit_date": 1524163309,
            "question_id": 48402525,
            "body_markdown": "I am trying to setup an integration testing environment for Docker. We need to restore a bacpac to our `mssql-server-linux:latest` image so we can run tests based on the dataset.\r\n\r\nMy compose file looks like:\r\n\r\n    version: &#39;3&#39;\r\n    \r\n    services:\r\n        projectweb:\r\n            image: projectweb\r\n            build:\r\n                context: .\r\n                dockerfile: Project\\Dockerfile\r\n            depends_on:\r\n                - db\r\n        db:\r\n            image: &quot;microsoft/mssql-server-linux&quot;\r\n            environment:\r\n                SA_PASSWORD: &quot;MyVerySecurePassword&quot;\r\n                ACCEPT_EULA: &quot;Y&quot;        \r\n            volumes:\r\n                - ./database:/tmp\r\n\r\nI don&#39;t need the changes to the database to be persisted past the life of the container. I just need to script getting the data into it. I don&#39;t have a lot of experience with docker or SQL Server for Linux. I assume I need to wait for the container to be initilizsed and DB setup and started, then execute a script that reads the database bacpac from tmp folder. As far as I understand I should use sqlpackage but this doesn&#39;t [appear to be in the container][1]? Do I need another container with this SSDT/sqlpackage in it? Can I install splpackage into the container?\r\n\r\nWhat is the best way to do import bacpac data? \r\n\r\n\r\n  [1]: https://github.com/Microsoft/mssql-docker/issues/135",
            "link": "https://stackoverflow.com/questions/48402525/how-can-i-restore-a-bacpac-file-to-sql-server-linux-docker-container",
            "title": "How can I restore a bacpac file to SQL Server linux docker container?",
            "body": "<p>I am trying to setup an integration testing environment for Docker. We need to restore a bacpac to our <code>mssql-server-linux:latest</code> image so we can run tests based on the dataset.</p>\n\n<p>My compose file looks like:</p>\n\n<pre><code>version: '3'\n\nservices:\n    projectweb:\n        image: projectweb\n        build:\n            context: .\n            dockerfile: Project\\Dockerfile\n        depends_on:\n            - db\n    db:\n        image: \"microsoft/mssql-server-linux\"\n        environment:\n            SA_PASSWORD: \"MyVerySecurePassword\"\n            ACCEPT_EULA: \"Y\"        \n        volumes:\n            - ./database:/tmp\n</code></pre>\n\n<p>I don't need the changes to the database to be persisted past the life of the container. I just need to script getting the data into it. I don't have a lot of experience with docker or SQL Server for Linux. I assume I need to wait for the container to be initilizsed and DB setup and started, then execute a script that reads the database bacpac from tmp folder. As far as I understand I should use sqlpackage but this doesn't <a href=\"https://github.com/Microsoft/mssql-docker/issues/135\" rel=\"nofollow noreferrer\">appear to be in the container</a>? Do I need another container with this SSDT/sqlpackage in it? Can I install splpackage into the container?</p>\n\n<p>What is the best way to do import bacpac data? </p>\n"
        },
        {
            "tags": [
                "python",
                "selenium",
                "selenium-webdriver"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 3080783,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/2b34129801048241ae2bbae4a70ab78d?s=128&d=identicon&r=PG&f=1",
                "display_name": "mlo",
                "link": "https://stackoverflow.com/users/3080783/mlo"
            },
            "is_answered": false,
            "view_count": 14,
            "closed_date": 1524171482,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163308,
            "creation_date": 1524163308,
            "question_id": 49928076,
            "body_markdown": "I am testing a web application (using Selenium &amp; Python) that serves as a unified login for various other websites. At the end of checking the credentials, the app does some redirecting and eventually POSTs some data to the other website. \r\n\r\nBecause I&#39;m not testing this other website, and it can be slow, I was wondering if there was a way I could intercept the redirects after clicking &quot;Login&quot;, and if I saw the page that does the POST, I could terminate loading the other website. The page that does the POST only loads if the credentials are verified, so it would be a valid end-point for that test (not end-to-end, I know).\r\n\r\nUnfortunately, with Selenium being blocking as it is, I can&#39;t figure out how to click &quot;Login&quot; and also check the URLs that are hit after it, and stopping the load once the one I want is hit.\r\n\r\nDoes anybody have any ideas on how this might be achieved?",
            "link": "https://stackoverflow.com/questions/49928076/is-there-a-way-to-track-redirect-urls",
            "closed_reason": "too broad",
            "title": "Is there a way to track redirect urls?",
            "body": "<p>I am testing a web application (using Selenium &amp; Python) that serves as a unified login for various other websites. At the end of checking the credentials, the app does some redirecting and eventually POSTs some data to the other website. </p>\n\n<p>Because I'm not testing this other website, and it can be slow, I was wondering if there was a way I could intercept the redirects after clicking \"Login\", and if I saw the page that does the POST, I could terminate loading the other website. The page that does the POST only loads if the credentials are verified, so it would be a valid end-point for that test (not end-to-end, I know).</p>\n\n<p>Unfortunately, with Selenium being blocking as it is, I can't figure out how to click \"Login\" and also check the URLs that are hit after it, and stopping the load once the one I want is hit.</p>\n\n<p>Does anybody have any ideas on how this might be achieved?</p>\n"
        },
        {
            "tags": [
                "r",
                "vectorization"
            ],
            "owner": {
                "reputation": 39,
                "user_id": 7084454,
                "user_type": "registered",
                "accept_rate": 83,
                "profile_image": "https://www.gravatar.com/avatar/03c1418ee8382c7d0e1e9d08e4ca34d3?s=128&d=identicon&r=PG&f=1",
                "display_name": "jayinbluecity",
                "link": "https://stackoverflow.com/users/7084454/jayinbluecity"
            },
            "is_answered": false,
            "view_count": 33,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163307,
            "creation_date": 1524163307,
            "question_id": 49928074,
            "body_markdown": "I am writing my program which is very poorly optimized, so need to speed up the process. Reproducible example similar to my problem is like below,\r\n\r\n\r\n\r\n    x= seq(1,10000, by = 1000)\r\n\r\nFunction below, measures the time to compute the vectorized(?) operation on the matrix with given dimension row of x and column of 2.\r\n    \r\n    testy = function(x){\r\n    testmatrix &lt;- matrix(runif(x*2,0,10), nrow=x, ncol=2)\r\n    y=microbenchmark(rowSums(testmatrix),unit=&quot;ms&quot;,times=1)$time\r\n    return(y)\r\n    }\r\n    \r\nFunction below, measures the time to compute the operation on the matrix using internal for loop from R \r\n    \r\n    testy2 = function(x){\r\n    testmatrix &lt;- matrix(runif(x*2,0,10), nrow=x, ncol=2)\r\n    y=microbenchmark(apply(testmatrix, 1, function(x) sum(x)), unit=&quot;ms&quot;, times=1)$time \r\n    return(y)\r\n    }\r\n    \r\n\r\nPlotting the performance of the each function for increasing size of matrix gives dramatic difference in log scaled computation time.\r\n    \r\n    plot(x, log(sapply(x,testy2))) # apply (internal for loop)\r\n    lines(x, log(sapply(x,testy))) # vectorized operation?\r\n\r\n\r\n\r\nI suspect the problem in my program in efficiency is that I use &quot;apply&quot; version of computation on the given matrix. Then it means I need to compute this operation using somewhat vectorized version such as function testy.\r\n\r\nMy first question is \r\n\r\nIs above difference in performance is indeed from\r\n\r\nrowSums(x) vs apply(x, 1, sum) ?\r\n\r\nIn my program, the equivalent of the &quot;summing&quot; in above example, is so much more complex which involves numerical integration. \r\n\r\nthen to boost up my speed, \r\nthen it means I have to write &quot;rowSums&quot; version of my code?\r\n\r\nThank you so much guys,\r\n",
            "link": "https://stackoverflow.com/questions/49928074/speeding-up-some-computation-on-matrix-in-r",
            "title": "Speeding up some computation on matrix in R",
            "body": "<p>I am writing my program which is very poorly optimized, so need to speed up the process. Reproducible example similar to my problem is like below,</p>\n\n<pre><code>x= seq(1,10000, by = 1000)\n</code></pre>\n\n<p>Function below, measures the time to compute the vectorized(?) operation on the matrix with given dimension row of x and column of 2.</p>\n\n<pre><code>testy = function(x){\ntestmatrix &lt;- matrix(runif(x*2,0,10), nrow=x, ncol=2)\ny=microbenchmark(rowSums(testmatrix),unit=\"ms\",times=1)$time\nreturn(y)\n}\n</code></pre>\n\n<p>Function below, measures the time to compute the operation on the matrix using internal for loop from R </p>\n\n<pre><code>testy2 = function(x){\ntestmatrix &lt;- matrix(runif(x*2,0,10), nrow=x, ncol=2)\ny=microbenchmark(apply(testmatrix, 1, function(x) sum(x)), unit=\"ms\", times=1)$time \nreturn(y)\n}\n</code></pre>\n\n<p>Plotting the performance of the each function for increasing size of matrix gives dramatic difference in log scaled computation time.</p>\n\n<pre><code>plot(x, log(sapply(x,testy2))) # apply (internal for loop)\nlines(x, log(sapply(x,testy))) # vectorized operation?\n</code></pre>\n\n<p>I suspect the problem in my program in efficiency is that I use \"apply\" version of computation on the given matrix. Then it means I need to compute this operation using somewhat vectorized version such as function testy.</p>\n\n<p>My first question is </p>\n\n<p>Is above difference in performance is indeed from</p>\n\n<p>rowSums(x) vs apply(x, 1, sum) ?</p>\n\n<p>In my program, the equivalent of the \"summing\" in above example, is so much more complex which involves numerical integration. </p>\n\n<p>then to boost up my speed, \nthen it means I have to write \"rowSums\" version of my code?</p>\n\n<p>Thank you so much guys,</p>\n"
        },
        {
            "tags": [
                "html",
                "css",
                "css-position"
            ],
            "owner": {
                "reputation": 814,
                "user_id": 3606700,
                "user_type": "registered",
                "accept_rate": 57,
                "profile_image": "https://i.stack.imgur.com/8qA7V.jpg?s=128&g=1",
                "display_name": "Chase",
                "link": "https://stackoverflow.com/users/3606700/chase"
            },
            "is_answered": true,
            "view_count": 442,
            "answer_count": 2,
            "score": 2,
            "last_activity_date": 1524163302,
            "creation_date": 1500518324,
            "question_id": 45204162,
            "body_markdown": "I&#39;m trying to position an element directly above a mobile keyboard. ie: position absolute/fixed to bottom of page, but pushed up by the keyboard (or pushed up equivalent height of the keyboard).\r\n\r\nUsually this is the opposite behavior of what&#39;s desired, and there&#39;s to be a lot of people fighting to keep bottom elements in place. I feel like I remember fighting those same battle before...\r\n\r\nBut now that I want it to move, it&#39;s not. (of course!)\r\n\r\nMy focus is iOS Safari for now, but would prefer cross browser.\r\n\r\nIt seems older versions of iOS changed `window.innerHeight` when the keyboard opened, for better or worse. But that&#39;s no longer the case. Which may explain why I&#39;m not seeing what I expected to see...\r\n\r\nI&#39;ve been playing around with variously positioned parent elements with no luck. \r\n\r\nIs this even possible? Or is the keyboard now completely detached from the viewport?",
            "link": "https://stackoverflow.com/questions/45204162/position-element-above-mobile-keyboard",
            "title": "Position element above mobile keyboard",
            "body": "<p>I'm trying to position an element directly above a mobile keyboard. ie: position absolute/fixed to bottom of page, but pushed up by the keyboard (or pushed up equivalent height of the keyboard).</p>\n\n<p>Usually this is the opposite behavior of what's desired, and there's to be a lot of people fighting to keep bottom elements in place. I feel like I remember fighting those same battle before...</p>\n\n<p>But now that I want it to move, it's not. (of course!)</p>\n\n<p>My focus is iOS Safari for now, but would prefer cross browser.</p>\n\n<p>It seems older versions of iOS changed <code>window.innerHeight</code> when the keyboard opened, for better or worse. But that's no longer the case. Which may explain why I'm not seeing what I expected to see...</p>\n\n<p>I've been playing around with variously positioned parent elements with no luck. </p>\n\n<p>Is this even possible? Or is the keyboard now completely detached from the viewport?</p>\n"
        },
        {
            "tags": [
                "swift",
                "rest",
                "filter",
                "perfect"
            ],
            "owner": {
                "reputation": 2128,
                "user_id": 331747,
                "user_type": "registered",
                "accept_rate": 78,
                "profile_image": "https://www.gravatar.com/avatar/08d311db9b4893455102265ceed010b2?s=128&d=identicon&r=PG",
                "display_name": "Shadowman",
                "link": "https://stackoverflow.com/users/331747/shadowman"
            },
            "is_answered": false,
            "view_count": 6,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163299,
            "creation_date": 1524163299,
            "question_id": 49928073,
            "body_markdown": "I&#39;m writing a server-side Swift application, using [Perfect][1] as my application framework.  I have a handful of `HTTPRequestFilter`s that I would like to apply to my RESTful service `Route`s.  However, the only documentation I can find shows how to apply the filters to ALL requests.  Is it possible to apply an `HTTPRequestFilter`/`HTTPResponseFilter` on a per-route basis? \r\n\r\n\r\n  [1]: https://www.perfect.org",
            "link": "https://stackoverflow.com/questions/49928073/perfect-http-filters-on-a-per-route-basis",
            "title": "Perfect HTTP Filters on a Per-Route Basis?",
            "body": "<p>I'm writing a server-side Swift application, using <a href=\"https://www.perfect.org\" rel=\"nofollow noreferrer\">Perfect</a> as my application framework.  I have a handful of <code>HTTPRequestFilter</code>s that I would like to apply to my RESTful service <code>Route</code>s.  However, the only documentation I can find shows how to apply the filters to ALL requests.  Is it possible to apply an <code>HTTPRequestFilter</code>/<code>HTTPResponseFilter</code> on a per-route basis? </p>\n"
        },
        {
            "tags": [
                "java",
                "eclipse",
                "netbeans",
                "eclipse-plugin",
                "netbeans-plugins"
            ],
            "owner": {
                "reputation": 315,
                "user_id": 2699664,
                "user_type": "registered",
                "accept_rate": 72,
                "profile_image": "https://www.gravatar.com/avatar/18d7ab800df57e3781c66c9e4316fc35?s=128&d=identicon&r=PG&f=1",
                "display_name": "undisp",
                "link": "https://stackoverflow.com/users/2699664/undisp"
            },
            "is_answered": false,
            "view_count": 16,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1524163296,
            "creation_date": 1524159871,
            "last_edit_date": 1524163296,
            "question_id": 49927164,
            "body_markdown": "I want to develop a plugin for an IDE that gets access to some project in order to get it&#39;s code properties, such as the number of lines that some class has, the lines of code itself, or even if the compiler detected some errors during the compilation of the code.\r\n\r\nWith this, two questions raised:\r\n\r\nThe first is: is what I want to do accomplishable?\r\n\r\nThe second is: from these two, what would be the best/easiest IDE to develop a plugin to: Eclipse or Netbeans? Note that currently I have no knowledge on how to code a plugin. I still have to study how it&#39;s done.",
            "link": "https://stackoverflow.com/questions/49927164/develop-plugin-to-access-code-properties",
            "title": "Develop plugin to access code properties",
            "body": "<p>I want to develop a plugin for an IDE that gets access to some project in order to get it's code properties, such as the number of lines that some class has, the lines of code itself, or even if the compiler detected some errors during the compilation of the code.</p>\n\n<p>With this, two questions raised:</p>\n\n<p>The first is: is what I want to do accomplishable?</p>\n\n<p>The second is: from these two, what would be the best/easiest IDE to develop a plugin to: Eclipse or Netbeans? Note that currently I have no knowledge on how to code a plugin. I still have to study how it's done.</p>\n"
        },
        {
            "tags": [
                "sql-server",
                "azure-storage-blobs",
                "sql-server-2017",
                "sql-server-linux"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 9491324,
                "user_type": "registered",
                "profile_image": "https://lh5.googleusercontent.com/-FOAiLd5kU9M/AAAAAAAAAAI/AAAAAAAAAp4/dIEjqb4CRiI/photo.jpg?sz=128",
                "display_name": "Jo&#227;o Bentes",
                "link": "https://stackoverflow.com/users/9491324/jo%c3%a3o-bentes"
            },
            "is_answered": false,
            "view_count": 51,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1524163281,
            "creation_date": 1521031377,
            "last_edit_date": 1524163281,
            "question_id": 49278105,
            "body_markdown": "I tried, without success, to run a T-SQL script to Backup to URL and another one to Restore to URL on SQL Server 2017 Web Edition, which is running on Ubuntu 16.04 LTS. The credential was successfully created.\r\n\r\nHere&#39;s an example of the T-SQL for Backup that I&#39;m trying to run:\r\n\r\n    DECLARE @name varchar(100)\r\n    DECLARE @fileURL varchar(100)\r\n    SET @name = &#39;test-db&#39;\r\n    SET @fileURL = &#39;https://mystorageaccountname.blob.core.windows.net/databases/test-db.BAK&#39;\r\n           BACKUP DATABASE @name \r\n    \t   TO URL = @fileURL\r\n    \t\t\t\tWITH CREDENTIAL = &#39;mycredential&#39;\r\n    \t\t\t\t,COMPRESSION\r\n    \t\t\t\t,STATS = 5;\r\n\r\nHere&#39;s the error that I&#39;m getting on MSSQL Management Studio:\r\n\r\n    Msg 3292, Level 16, State 6, Line 5\r\n    A failure occurred while attempting to execute Backup or Restore with a URL device specified. Consult the operating system error log for details.\r\n    Msg 3013, Level 16, State 1, Line 5\r\n    BACKUP DATABASE is terminating abnormally.\r\n\r\nHere&#39;s the error that I&#39;m getting on **/var/log/syslog**:\r\n\r\n    #015VDI: &quot;C:\\binn\\BackupToUrl.exe&quot; &quot;b&quot; &quot;p&quot; &quot;680074007400700073003A002F002F0073007700650065007400640061007400610062006100730065006200610063006B007500700073002E0062006C006F0062002E0063006F00720065002E00770069006E0064006F00770073002E006E00650074002F006400610074006100620061007300650073002F0068006300640061006D006F00620069006C0065002E00420041004B00&quot; &quot;73007700650065007400640061007400610062006100730065006200610063006B00750070007300&quot; &quot;01000000D08C9DDF0115D1118C7A00C04FC297EB010000008AB2169DF1DE3A45B5514DCCD09182C3000000001200000061007A007500720065006B006500790000001066000000010000200000008ECF1319A21E667E0E32E83135C57DFCAF4E3DFF2AABDA00E3E2D814B5C88D2E000000000E8000000002000020000000E9E64579DF38EA0E66886B8D454C4F4256A682A124E70D86EC0DA087112ECA0450000000F92ED8FD343DADDE9518C412CA5EAB188316B24A6A0B407CCEA9AE142A9DBC282085ABF133BFDF017A3AFA9CEB4C5039433D15FA47A64A1339F2D030ED3383C58F81A2C3634FA945B6B819F113AB22DF40000000E9CDF76A290F18299BBE99C273FCA31E4622334C645EBFE8C5AA9C4F68C1A323A2F0EED33B8F6E8D5922B5B78DE1F6DB456864A290689C98A3631EA3F62505D3&quot; &quot;NOFORMAT&quot; &quot;4D005300530051004C00530045005200560045005200&quot; &quot;&quot; &quot;DB&quot; &quot;68006300640061006D006F00620069006C006500&quot; &quot;NOTRACE&quot;\r\n    #015BackupToUrl: couldn&#39;t load process Error Code:  80070002\r\n    #0152018-03-14 12:35:25.30 Backup      Error: 3041, Severity: 16, State: 1.\r\n    #0152018-03-14 12:35:25.30 Backup      BACKUP failed to complete the command BACKUP DATABASE hcdamobile. Check the backup application log for detailed messages.\r\n\r\nHave you guys had this problem before? Do I need to install any additional package to be able to run Backup to URL on Linux?\r\n",
            "link": "https://stackoverflow.com/questions/49278105/t-sql-backup-restore-to-from-url-does-not-work-on-sql-server-2017-web-edition-on",
            "title": "T-SQL Backup/Restore to/from URL does not work on SQL Server 2017 Web Edition on Ubuntu Linux 16.04 LTS",
            "body": "<p>I tried, without success, to run a T-SQL script to Backup to URL and another one to Restore to URL on SQL Server 2017 Web Edition, which is running on Ubuntu 16.04 LTS. The credential was successfully created.</p>\n\n<p>Here's an example of the T-SQL for Backup that I'm trying to run:</p>\n\n<pre><code>DECLARE @name varchar(100)\nDECLARE @fileURL varchar(100)\nSET @name = 'test-db'\nSET @fileURL = 'https://mystorageaccountname.blob.core.windows.net/databases/test-db.BAK'\n       BACKUP DATABASE @name \n       TO URL = @fileURL\n                WITH CREDENTIAL = 'mycredential'\n                ,COMPRESSION\n                ,STATS = 5;\n</code></pre>\n\n<p>Here's the error that I'm getting on MSSQL Management Studio:</p>\n\n<pre><code>Msg 3292, Level 16, State 6, Line 5\nA failure occurred while attempting to execute Backup or Restore with a URL device specified. Consult the operating system error log for details.\nMsg 3013, Level 16, State 1, Line 5\nBACKUP DATABASE is terminating abnormally.\n</code></pre>\n\n<p>Here's the error that I'm getting on <strong>/var/log/syslog</strong>:</p>\n\n<pre><code>#015VDI: \"C:\\binn\\BackupToUrl.exe\" \"b\" \"p\" \"680074007400700073003A002F002F0073007700650065007400640061007400610062006100730065006200610063006B007500700073002E0062006C006F0062002E0063006F00720065002E00770069006E0064006F00770073002E006E00650074002F006400610074006100620061007300650073002F0068006300640061006D006F00620069006C0065002E00420041004B00\" \"73007700650065007400640061007400610062006100730065006200610063006B00750070007300\" \"01000000D08C9DDF0115D1118C7A00C04FC297EB010000008AB2169DF1DE3A45B5514DCCD09182C3000000001200000061007A007500720065006B006500790000001066000000010000200000008ECF1319A21E667E0E32E83135C57DFCAF4E3DFF2AABDA00E3E2D814B5C88D2E000000000E8000000002000020000000E9E64579DF38EA0E66886B8D454C4F4256A682A124E70D86EC0DA087112ECA0450000000F92ED8FD343DADDE9518C412CA5EAB188316B24A6A0B407CCEA9AE142A9DBC282085ABF133BFDF017A3AFA9CEB4C5039433D15FA47A64A1339F2D030ED3383C58F81A2C3634FA945B6B819F113AB22DF40000000E9CDF76A290F18299BBE99C273FCA31E4622334C645EBFE8C5AA9C4F68C1A323A2F0EED33B8F6E8D5922B5B78DE1F6DB456864A290689C98A3631EA3F62505D3\" \"NOFORMAT\" \"4D005300530051004C00530045005200560045005200\" \"\" \"DB\" \"68006300640061006D006F00620069006C006500\" \"NOTRACE\"\n#015BackupToUrl: couldn't load process Error Code:  80070002\n#0152018-03-14 12:35:25.30 Backup      Error: 3041, Severity: 16, State: 1.\n#0152018-03-14 12:35:25.30 Backup      BACKUP failed to complete the command BACKUP DATABASE hcdamobile. Check the backup application log for detailed messages.\n</code></pre>\n\n<p>Have you guys had this problem before? Do I need to install any additional package to be able to run Backup to URL on Linux?</p>\n"
        },
        {
            "tags": [
                "r",
                "shiny"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 9591018,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Alexis",
                "link": "https://stackoverflow.com/users/9591018/alexis"
            },
            "is_answered": true,
            "view_count": 17,
            "accepted_answer_id": 49927857,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1524163276,
            "creation_date": 1524152275,
            "question_id": 49925036,
            "body_markdown": "    library(shiny)\r\n    library(frailtypack)\r\n    data(&quot;readmission&quot;, package = &quot;frailtypack&quot;)\r\n    ui &lt;- fluidPage(\r\n     sidebarPanel(\r\n      sliderInput(&quot;nb&quot;,\r\n                  h5(&quot;Number of time intervals  :&quot;),\r\n                  min = 1,\r\n                  max = 20,\r\n                  value = 10)),\r\n     mainPanel(\r\n      verbatimTextOutput(&quot;mod&quot;))\r\n    )\r\n    server &lt;- function(input, output) {\r\n    \r\n      output$mod &lt;- renderPrint({\r\n            model &lt;-frailtyPenal(Surv(time,event)~cluster(id)+ sex + dukes, data=readmission, \r\n                    hazard = &quot;Piecewise-per&quot;, nb.int = input$nb)   \r\n            print(model)\r\n          })\r\n        }\r\n        shinyApp(ui, server)\r\nHi, the code above sends me back as an error that nb.int must be numeric. While input$nb is a number.\r\nI don&#39;t understand why.\r\n\r\n  \r\n",
            "link": "https://stackoverflow.com/questions/49925036/r-shiny-error-must-be-a-numeric",
            "title": "R shiny - error : must be a numeric",
            "body": "<pre><code>library(shiny)\nlibrary(frailtypack)\ndata(\"readmission\", package = \"frailtypack\")\nui &lt;- fluidPage(\n sidebarPanel(\n  sliderInput(\"nb\",\n              h5(\"Number of time intervals  :\"),\n              min = 1,\n              max = 20,\n              value = 10)),\n mainPanel(\n  verbatimTextOutput(\"mod\"))\n)\nserver &lt;- function(input, output) {\n\n  output$mod &lt;- renderPrint({\n        model &lt;-frailtyPenal(Surv(time,event)~cluster(id)+ sex + dukes, data=readmission, \n                hazard = \"Piecewise-per\", nb.int = input$nb)   \n        print(model)\n      })\n    }\n    shinyApp(ui, server)\n</code></pre>\n\n<p>Hi, the code above sends me back as an error that nb.int must be numeric. While input$nb is a number.\nI don't understand why.</p>\n"
        },
        {
            "tags": [
                "spring",
                "aop",
                "spring-aop"
            ],
            "owner": {
                "reputation": 14,
                "user_id": 3911863,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/3e4122a393f0d6c26dea624356a1780e?s=128&d=identicon&r=PG&f=1",
                "display_name": "Shyam",
                "link": "https://stackoverflow.com/users/3911863/shyam"
            },
            "is_answered": false,
            "view_count": 9,
            "answer_count": 0,
            "score": -1,
            "last_activity_date": 1524163273,
            "creation_date": 1524163273,
            "question_id": 49928064,
            "body_markdown": "I want to implement AOP on RestClient getForObject* or getForPost* methods.\r\nI want @Around pattern so that I can call actual or mock service based on my condition.\r\n  ",
            "link": "https://stackoverflow.com/questions/49928064/spring-aop-for-restclient-methods",
            "title": "Spring AOP for RESTClient methods",
            "body": "<p>I want to implement AOP on RestClient getForObject* or getForPost* methods.\nI want @Around pattern so that I can call actual or mock service based on my condition.</p>\n"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 143
}