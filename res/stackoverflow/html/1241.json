{
    "items": [
        {
            "tags": [
                "javascript",
                "excel",
                "reactjs",
                "csv"
            ],
            "owner": {
                "reputation": 1118,
                "user_id": 4737546,
                "user_type": "registered",
                "accept_rate": 71,
                "profile_image": "https://www.gravatar.com/avatar/a6fb41b13314da5e33741b0fbed650a6?s=128&d=identicon&r=PG&f=1",
                "display_name": "Valip",
                "link": "https://stackoverflow.com/users/4737546/valip"
            },
            "is_answered": false,
            "view_count": 16,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526458447,
            "creation_date": 1526458447,
            "question_id": 50365603,
            "body_markdown": "I&#39;m trying to upload a file with the format of `.csv/.xls/.xlsx` and then read the file contents.\r\n\r\nFor example the following file\r\n\r\n[![enter image description here][1]][1]\r\n\r\nwould output:  \r\n\r\n    name,age,key  \r\n    Mark,25,1  \r\n    Jones,30,2\r\n\r\n\r\nThis is what I&#39;ve implemented so far using [react-file-reader][2] and [base-62][3] but it only works for the `.csv` files:  \r\n\r\n      onFileUpload(file) {\r\n        var decodedData = base64.decode(file.base64);\r\n      }\r\n\r\n      &lt;ReactFileReader fileTypes={[&quot;.csv&quot;,&quot;.xls&quot;, &quot;.xlsx&quot;]} base64={true} multipleFiles={false} handleFiles={this.onFileUpload}&gt;\r\n        &lt;button className=&#39;btn&#39;&gt;Upload&lt;/button&gt;\r\n      &lt;/ReactFileReader&gt;\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/SWfDS.png\r\n  [2]: https://www.npmjs.com/package/react-file-reader\r\n  [3]: https://www.npmjs.com/package/base-64\r\n\r\nIs there any way I can get the content of `.xls` and `.xlsx` files using the same way as I did for `.csv` files? Or maybe another module that does this...",
            "link": "https://stackoverflow.com/questions/50365603/how-to-upload-and-read-csv-xls-and-xlsx-in-react",
            "title": "How to upload and read .csv, .xls and .xlsx in React",
            "body": "<p>I'm trying to upload a file with the format of <code>.csv/.xls/.xlsx</code> and then read the file contents.</p>\n\n<p>For example the following file</p>\n\n<p><a href=\"https://i.stack.imgur.com/SWfDS.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/SWfDS.png\" alt=\"enter image description here\"></a></p>\n\n<p>would output:  </p>\n\n<pre><code>name,age,key  \nMark,25,1  \nJones,30,2\n</code></pre>\n\n<p>This is what I've implemented so far using <a href=\"https://www.npmjs.com/package/react-file-reader\" rel=\"nofollow noreferrer\">react-file-reader</a> and <a href=\"https://www.npmjs.com/package/base-64\" rel=\"nofollow noreferrer\">base-62</a> but it only works for the <code>.csv</code> files:  </p>\n\n<pre><code>  onFileUpload(file) {\n    var decodedData = base64.decode(file.base64);\n  }\n\n  &lt;ReactFileReader fileTypes={[\".csv\",\".xls\", \".xlsx\"]} base64={true} multipleFiles={false} handleFiles={this.onFileUpload}&gt;\n    &lt;button className='btn'&gt;Upload&lt;/button&gt;\n  &lt;/ReactFileReader&gt;\n</code></pre>\n\n<p>Is there any way I can get the content of <code>.xls</code> and <code>.xlsx</code> files using the same way as I did for <code>.csv</code> files? Or maybe another module that does this...</p>\n"
        },
        {
            "tags": [
                "algorithm",
                "data-structures",
                "logic",
                "puzzle"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 9058055,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/58001af3babb0bbee13953c3c3808e05?s=128&d=identicon&r=PG&f=1",
                "display_name": "Srin Chow",
                "link": "https://stackoverflow.com/users/9058055/srin-chow"
            },
            "is_answered": false,
            "view_count": 46,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526458437,
            "creation_date": 1526138428,
            "question_id": 50307773,
            "body_markdown": "given n+2 seats and m student.The student must be seated in such a seat so that min(l,r) is maximum where the l and r is the closest distance to nearby occupied seat to the left or right respectively.so print the l and r of the mth student.Previous m-1 students are placed as per the rule that min(l,r) of these students should be maximum.min stands for minimum.the first and last seat are occupied already.\r\n\r\n\r\nNote:\r\nMy approach was simply to place them midway always as this way we can maximize the min(l,r) function.but i couldn&#39;t think through completely,\r\n\r\nMy Idea:\r\nconsider m=2 and n=5\r\n\r\n0.....0 \r\n\r\nfirst guy should be place at n/2=7/2=3. that makes l=3 and r=3 min(l,r)=3\r\n\r\n0..0..0\r\n\r\nnow as l=r so next guy should be place at l/2 or r/2\r\n\r\n00.0..0 or 0..0.00 or 0.00..0 or 0..00.0 (all cases give min as 0)\r\n\r\n\r\nHELP ME FIND A LOGIC TO PRINT THE L AND R FOR THE MTH GUY.\r\n",
            "link": "https://stackoverflow.com/questions/50307773/how-to-think-about-the-following-and-implement-using-some-data-structure",
            "title": "how to think about the following and implement using some data structure?",
            "body": "<p>given n+2 seats and m student.The student must be seated in such a seat so that min(l,r) is maximum where the l and r is the closest distance to nearby occupied seat to the left or right respectively.so print the l and r of the mth student.Previous m-1 students are placed as per the rule that min(l,r) of these students should be maximum.min stands for minimum.the first and last seat are occupied already.</p>\n\n<p>Note:\nMy approach was simply to place them midway always as this way we can maximize the min(l,r) function.but i couldn't think through completely,</p>\n\n<p>My Idea:\nconsider m=2 and n=5</p>\n\n<p>0.....0 </p>\n\n<p>first guy should be place at n/2=7/2=3. that makes l=3 and r=3 min(l,r)=3</p>\n\n<p>0..0..0</p>\n\n<p>now as l=r so next guy should be place at l/2 or r/2</p>\n\n<p>00.0..0 or 0..0.00 or 0.00..0 or 0..00.0 (all cases give min as 0)</p>\n\n<p>HELP ME FIND A LOGIC TO PRINT THE L AND R FOR THE MTH GUY.</p>\n"
        },
        {
            "tags": [
                "c#",
                "wpf"
            ],
            "owner": {
                "reputation": 51,
                "user_id": 9241269,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/1BzUx.jpg?s=128&g=1",
                "display_name": "Michael T",
                "link": "https://stackoverflow.com/users/9241269/michael-t"
            },
            "is_answered": true,
            "view_count": 31,
            "accepted_answer_id": 50365599,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1526458433,
            "creation_date": 1526423120,
            "question_id": 50359984,
            "body_markdown": "I am programmatically creating a context menu\r\n\r\n    MenuItem item;\r\n    MenuItem subItem;\r\n    \r\n    _contextmenu.Items.Clear();\r\n    \r\n    item = new MenuItem { Header = &quot;Header Item&quot;};\r\n    item.Click += (s, e) =&gt; ShowMainWindow();\r\n    _contextmenu.Items.Add(item);\r\n    \r\n    subItem = new MenuItem { Header = &quot;Sub Item 1&quot; };\r\n    item.Items.Add(subItem);\r\n    \r\n    subItem = new MenuItem { Header = &quot;Sub Item 2&quot; };\r\n    item.Items.Add(subItem);\r\n\r\nThe click event is correctly fired for the sub menu items.\r\nHow can I get a click event for the header item?\r\n\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50359984/c-wpf-click-event-for-header-of-menuitems",
            "title": "c# wpf Click event for header of MenuItems",
            "body": "<p>I am programmatically creating a context menu</p>\n\n<pre><code>MenuItem item;\nMenuItem subItem;\n\n_contextmenu.Items.Clear();\n\nitem = new MenuItem { Header = \"Header Item\"};\nitem.Click += (s, e) =&gt; ShowMainWindow();\n_contextmenu.Items.Add(item);\n\nsubItem = new MenuItem { Header = \"Sub Item 1\" };\nitem.Items.Add(subItem);\n\nsubItem = new MenuItem { Header = \"Sub Item 2\" };\nitem.Items.Add(subItem);\n</code></pre>\n\n<p>The click event is correctly fired for the sub menu items.\nHow can I get a click event for the header item?</p>\n"
        },
        {
            "tags": [
                "java",
                "function",
                "lambda",
                "parameters",
                "java-8"
            ],
            "owner": {
                "reputation": 6450,
                "user_id": 3660134,
                "user_type": "registered",
                "accept_rate": 76,
                "profile_image": "https://i.stack.imgur.com/1jUmx.gif?s=128&g=1",
                "display_name": "Zenoo",
                "link": "https://stackoverflow.com/users/3660134/zenoo"
            },
            "is_answered": true,
            "view_count": 68,
            "accepted_answer_id": 50365479,
            "answer_count": 1,
            "score": 2,
            "last_activity_date": 1526458424,
            "creation_date": 1526457418,
            "last_edit_date": 1526458424,
            "question_id": 50365290,
            "body_markdown": "I&#39;m trying to create an equivalent to Javascript&#39;s [`Array#map`][1] in Java.\r\n\r\nI have been able to do it with \r\n\r\n    ArrayList&lt;String&gt; data = myList.stream().map(e -&gt; {\r\n        return &quot;test &quot;+e;\r\n    }).collect(Collectors.toCollection(ArrayList::new));\r\n\r\nHere, `myList` is the initial `ArrayList` and `data` is the resulting `ArrayList`.\r\n\r\nHowever, I find it very tedious to do that every time.\r\n\r\nSo I tried to create a generic function that would make my life easier :\r\n\r\n    public static ArrayList&lt;?&gt; map(ArrayList&lt;?&gt; list, Function&lt;? super Object,?&gt; callback){\r\n\t\treturn list.stream().map(callback).collect(Collectors.toCollection(ArrayList::new));\r\n\t}\r\n\r\nAnd then calling it with:\r\n\r\n    ArrayList&lt;String&gt; data = DEF.map(myList,e -&gt; {\r\n        return &quot;test &quot;+e;\r\n    });\r\n\r\nBut I get the error\r\n\r\n&gt; [Java] The method map(ArrayList&lt;?&gt;, Function&lt;? super Object,?&gt;) in the\r\n&gt; type DEF is not applicable for the arguments (List&lt;Agence&gt;, (&lt;no type&gt;\r\n&gt; e) -&gt; {})\r\n\r\nHow can I edit my generic function to accept the lambda I&#39;m using?\r\n\r\n\r\n  [1]: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map",
            "link": "https://stackoverflow.com/questions/50365290/passing-a-lambda-function-as-a-parameter",
            "title": "Passing a lambda function as a parameter",
            "body": "<p>I'm trying to create an equivalent to Javascript's <a href=\"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/map\" rel=\"nofollow noreferrer\"><code>Array#map</code></a> in Java.</p>\n\n<p>I have been able to do it with </p>\n\n<pre><code>ArrayList&lt;String&gt; data = myList.stream().map(e -&gt; {\n    return \"test \"+e;\n}).collect(Collectors.toCollection(ArrayList::new));\n</code></pre>\n\n<p>Here, <code>myList</code> is the initial <code>ArrayList</code> and <code>data</code> is the resulting <code>ArrayList</code>.</p>\n\n<p>However, I find it very tedious to do that every time.</p>\n\n<p>So I tried to create a generic function that would make my life easier :</p>\n\n<pre><code>public static ArrayList&lt;?&gt; map(ArrayList&lt;?&gt; list, Function&lt;? super Object,?&gt; callback){\n    return list.stream().map(callback).collect(Collectors.toCollection(ArrayList::new));\n}\n</code></pre>\n\n<p>And then calling it with:</p>\n\n<pre><code>ArrayList&lt;String&gt; data = DEF.map(myList,e -&gt; {\n    return \"test \"+e;\n});\n</code></pre>\n\n<p>But I get the error</p>\n\n<blockquote>\n  <p>[Java] The method map(ArrayList, Function) in the\n  type DEF is not applicable for the arguments (List, (\n  e) -> {})</p>\n</blockquote>\n\n<p>How can I edit my generic function to accept the lambda I'm using?</p>\n"
        },
        {
            "tags": [
                "python",
                "docker",
                "google-cloud-platform",
                "google-compute-engine",
                "google-cloud-pubsub"
            ],
            "owner": {
                "reputation": 1932,
                "user_id": 1739297,
                "user_type": "registered",
                "accept_rate": 86,
                "profile_image": "https://i.stack.imgur.com/PG6Q6.png?s=128&g=1",
                "display_name": "Matthias",
                "link": "https://stackoverflow.com/users/1739297/matthias"
            },
            "is_answered": false,
            "view_count": 93,
            "answer_count": 1,
            "score": 2,
            "last_activity_date": 1526458422,
            "creation_date": 1523694796,
            "last_edit_date": 1526458422,
            "question_id": 49829467,
            "body_markdown": "In my scenario I&#39;m scheduling tasks using PubSub. This is up to 2.000 PubSub messages that are than consumed by a Python script that runs inside a Docker Container within Google Compute Engine. That script consumes the PubSub messages. \r\n\r\nThe processing of each message is about 30seconds to 5min. Therefore the acknowledgement deadline is 600sec (10min). \r\n\r\n    from google.cloud import pubsub_v1\r\n    from google.cloud.pubsub_v1.subscriber.message import Message\r\n\r\n    def handle_message(message: Message):\r\n        # do your stuff here (max. 600sec)\r\n        message.ack()\r\n        return\r\n\r\n    def receive_messages(project, subscription_name):\r\n    \r\n        subscriber = pubsub_v1.SubscriberClient()\r\n        subscription_path = subscriber.subscription_path(project, subscription_name)\r\n    \r\n        flow_control = pubsub_v1.types.FlowControl(max_messages=5)\r\n        subscription = subscriber.subscribe(subscription_path, flow_control=flow_control)\r\n    \r\n        future = subscription.open(handle_message)\r\n    \r\n        # Blocks the thread while messages are coming in through the stream. Any\r\n        # exceptions that crop up on the thread will be set on the future.\r\n        # The subscriber is non-blocking, so we must keep the main thread from\r\n        # exiting to allow it to process messages in the background.\r\n        try:\r\n            future.result()\r\n        except Exception as e:\r\n            # do some logging\r\n            raise\r\n\r\nBecause I&#39;m working on so many PubSub messages, I&#39;m [creating a template][1] for a Compute Engine that uses [auto-scaling][2] in either of these two ways:\r\n\r\n    gcloud compute instance-groups managed create my-worker-group \\\r\n      --zone=europe-west3-a \\\r\n      --template=my-worker-template \\\r\n      --size=0\r\n    \r\n    gcloud beta compute instance-groups managed set-autoscaling my-worker-group \\\r\n      --zone=europe-west3-a \\\r\n      --max-num-replicas=50 \\\r\n      --min-num-replicas=0 \\\r\n      --target-cpu-utilization=0.4\r\n    \r\n    gcloud beta compute instance-groups managed set-autoscaling my-worker-group \\\r\n      --zone=europe-west3-a \\\r\n      --max-num-replicas=50 \\\r\n      --min-num-replicas=0 \\\r\n      --update-stackdriver-metric=pubsub.googleapis.com/subscription/num_undelivered_messages \\\r\n      --stackdriver-metric-filter=&quot;resource.type = pubsub_subscription AND resource.label.subscription_id = my-pubsub-subscription&quot; \\\r\n      --stackdriver-metric-single-instance-assignment=10\r\n\r\nSo far, so good. Option one scales up to about 8 instances while the second option will start the maximum number of instances. Now I figured out that some strange things happen and this is why I&#39;m posting here. Maybe you can help me out?!\r\n\r\n**Message duplicates:** It seems that the PubSub service in each instance (Python script inside the docker container within compute engine) reads a batch of messages (~10) in somewhat like a buffer and gives them to my code. Looks like all instances that spin up at the same time will read all the same messages (the first 10 of 2.000) and will start working on the same stuff. In my logs I see that most messages are processed 3 times by different machines. I was expecting that PubSub knows if some subscriber buffered 10 messages so that another subscriber will buffer 10 different messages and not the same ones.\r\n\r\n**Acknowledgement deadline:** Because of the buffering the messages that come in the end of the buffer (let&#39;s say message 8 or 9) had to wait in the buffer until the preceding messages (messages 1 to 7) have been processed. The sum of that waiting time plus its own processing time may run into the timeout of 600sec.\r\n\r\n**Load-Balancing:** Because each machine buffers so many messages, the load is consumed by just a few instances while other instances are completely idle. This happens for the scaling-option two that uses the PubSub stackdriver metric.\r\n\r\nPeople told me that I need to implement a manual synchronization service using Cloud SQL or something else in which each instance indicates on which message it is working, so that other instances won&#39;t start the same. But I feel that can&#39;t be true - because then I don&#39;t get the idea what PubSub is all about. \r\n\r\n[![pubsub behavior][5]][5]\r\n\r\n\r\n**Update:** I found a [nice explanation by Gregor Hohpe][3], co-author of the book Enterprise Integration Patterns from 2015. Actually my observation was wrong, but the observed side effects are real.\r\n \r\n&gt; Google Cloud Pub/Sub API actually implements both the\r\n&gt; Publish-Subscribe Channel and the Competing Consumers patterns. At the\r\n&gt; heart of the Cloud Pub/Sub is a classic Publish-Subscribe Channel,\r\n&gt; which delivers a single message published to it to multiple\r\n&gt; subscribers. One advantage of this pattern is that adding subscribers\r\n&gt; is side-effect free, which is one reason a Publish-Subscribe Channel\r\n&gt; is sometimes considered more loosely coupled than a Point-to-Point\r\n&gt; Channel, which delivers a message to exactly one subscriber. Adding\r\n&gt; consumers to a Point-to-Point Channel results in Competing Consumers\r\n&gt; and thus has a strong side effect.\r\n\r\n[![Copyright: Gregor Hohpe, co-author of the book Enterprise Integration Patterns. 2015.][4]][4]\r\n\r\nThe side effects I observed are about the message buffering and message flow control in each of the subscribers (who subscribed to the same subscription, point-to-point == competing consumers). The current version of the Python Client Lib wraps the PubSub REST API (and RPCs). If that wrapper is used, there is no control on:\r\n\r\n - How many containers are started on one VM; Multiple containers may be started if the CPU is not yet fully utilized\r\n - How many messages are pulled from the subscription at once (buffering); no control at all\r\n - How many threads, for processing the pulled messages, are started inside on container; flow_control(max_messages) has no effect if the value is below a fixed value. \r\n\r\nThe side effects we observed are:\r\n\r\n 1. One consumer pulls a high number of messages at once (approximately 100 to 1.000) and queues them in its client buffer. Therefore all other VM&#39;s that are started according to the auto-scaling rule, do not receive any message, because all messages are in the queue of the first few VM&#39;s\r\n 2. Messages are re-delivered either to the same VM or any other VM (or docker container) if it runs into the acknowledgement deadline. Therefore you need to modify the acknowledgement deadline while processing the message. The deadline counter starts when the processing starts.\r\n 3. Assuming that the processing of the message is a long running task (for instance machine learning), you may\r\n - Acknowledge the message upfront, but this will cause the VM to be shut down by the auto-scaling rule if there is no further message waiting. The rule does not care if the CPU utilization is still strong and the processing has not yet been finished.\r\n - Acknowledge the message after processing. In this case you need to modify the acknowledgement deadline of that specific message while processing that message. There must not be one single code block that breaks the deadline since the last modification.\r\n\r\nPossible solutions that haven&#39;t been looked into:\r\n\r\n - Using the Java Client Library since it comes with better controls on pulling and consuming messages\r\n - Using the underlying API calls and classes of the Python Client Library \r\n - Building a synchronization storage that orchestrates the competing consumers\r\n\r\n  [1]: https://cloud.google.com/sdk/gcloud/reference/alpha/compute/instances/create-with-container\r\n  [2]: https://cloud.google.com/compute/docs/autoscaler/?hl=de&amp;_ga=2.101834881.-1281645554.1517998144#autoscaling_options\r\n  [3]: http://www.enterpriseintegrationpatterns.com/ramblings/82_googlepubsub.html\r\n  [4]: https://i.stack.imgur.com/d5nOy.png\r\n  [5]: https://i.stack.imgur.com/HqoEt.png",
            "link": "https://stackoverflow.com/questions/49829467/google-pubsub-and-auto-scaling-compute-engine-instances-python",
            "title": "Google PubSub and auto-scaling Compute Engine instances (Python)",
            "body": "<p>In my scenario I'm scheduling tasks using PubSub. This is up to 2.000 PubSub messages that are than consumed by a Python script that runs inside a Docker Container within Google Compute Engine. That script consumes the PubSub messages. </p>\n\n<p>The processing of each message is about 30seconds to 5min. Therefore the acknowledgement deadline is 600sec (10min). </p>\n\n<pre><code>from google.cloud import pubsub_v1\nfrom google.cloud.pubsub_v1.subscriber.message import Message\n\ndef handle_message(message: Message):\n    # do your stuff here (max. 600sec)\n    message.ack()\n    return\n\ndef receive_messages(project, subscription_name):\n\n    subscriber = pubsub_v1.SubscriberClient()\n    subscription_path = subscriber.subscription_path(project, subscription_name)\n\n    flow_control = pubsub_v1.types.FlowControl(max_messages=5)\n    subscription = subscriber.subscribe(subscription_path, flow_control=flow_control)\n\n    future = subscription.open(handle_message)\n\n    # Blocks the thread while messages are coming in through the stream. Any\n    # exceptions that crop up on the thread will be set on the future.\n    # The subscriber is non-blocking, so we must keep the main thread from\n    # exiting to allow it to process messages in the background.\n    try:\n        future.result()\n    except Exception as e:\n        # do some logging\n        raise\n</code></pre>\n\n<p>Because I'm working on so many PubSub messages, I'm <a href=\"https://cloud.google.com/sdk/gcloud/reference/alpha/compute/instances/create-with-container\" rel=\"nofollow noreferrer\">creating a template</a> for a Compute Engine that uses <a href=\"https://cloud.google.com/compute/docs/autoscaler/?hl=de&amp;_ga=2.101834881.-1281645554.1517998144#autoscaling_options\" rel=\"nofollow noreferrer\">auto-scaling</a> in either of these two ways:</p>\n\n<pre><code>gcloud compute instance-groups managed create my-worker-group \\\n  --zone=europe-west3-a \\\n  --template=my-worker-template \\\n  --size=0\n\ngcloud beta compute instance-groups managed set-autoscaling my-worker-group \\\n  --zone=europe-west3-a \\\n  --max-num-replicas=50 \\\n  --min-num-replicas=0 \\\n  --target-cpu-utilization=0.4\n\ngcloud beta compute instance-groups managed set-autoscaling my-worker-group \\\n  --zone=europe-west3-a \\\n  --max-num-replicas=50 \\\n  --min-num-replicas=0 \\\n  --update-stackdriver-metric=pubsub.googleapis.com/subscription/num_undelivered_messages \\\n  --stackdriver-metric-filter=\"resource.type = pubsub_subscription AND resource.label.subscription_id = my-pubsub-subscription\" \\\n  --stackdriver-metric-single-instance-assignment=10\n</code></pre>\n\n<p>So far, so good. Option one scales up to about 8 instances while the second option will start the maximum number of instances. Now I figured out that some strange things happen and this is why I'm posting here. Maybe you can help me out?!</p>\n\n<p><strong>Message duplicates:</strong> It seems that the PubSub service in each instance (Python script inside the docker container within compute engine) reads a batch of messages (~10) in somewhat like a buffer and gives them to my code. Looks like all instances that spin up at the same time will read all the same messages (the first 10 of 2.000) and will start working on the same stuff. In my logs I see that most messages are processed 3 times by different machines. I was expecting that PubSub knows if some subscriber buffered 10 messages so that another subscriber will buffer 10 different messages and not the same ones.</p>\n\n<p><strong>Acknowledgement deadline:</strong> Because of the buffering the messages that come in the end of the buffer (let's say message 8 or 9) had to wait in the buffer until the preceding messages (messages 1 to 7) have been processed. The sum of that waiting time plus its own processing time may run into the timeout of 600sec.</p>\n\n<p><strong>Load-Balancing:</strong> Because each machine buffers so many messages, the load is consumed by just a few instances while other instances are completely idle. This happens for the scaling-option two that uses the PubSub stackdriver metric.</p>\n\n<p>People told me that I need to implement a manual synchronization service using Cloud SQL or something else in which each instance indicates on which message it is working, so that other instances won't start the same. But I feel that can't be true - because then I don't get the idea what PubSub is all about. </p>\n\n<p><a href=\"https://i.stack.imgur.com/HqoEt.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/HqoEt.png\" alt=\"pubsub behavior\"></a></p>\n\n<p><strong>Update:</strong> I found a <a href=\"http://www.enterpriseintegrationpatterns.com/ramblings/82_googlepubsub.html\" rel=\"nofollow noreferrer\">nice explanation by Gregor Hohpe</a>, co-author of the book Enterprise Integration Patterns from 2015. Actually my observation was wrong, but the observed side effects are real.</p>\n\n<blockquote>\n  <p>Google Cloud Pub/Sub API actually implements both the\n  Publish-Subscribe Channel and the Competing Consumers patterns. At the\n  heart of the Cloud Pub/Sub is a classic Publish-Subscribe Channel,\n  which delivers a single message published to it to multiple\n  subscribers. One advantage of this pattern is that adding subscribers\n  is side-effect free, which is one reason a Publish-Subscribe Channel\n  is sometimes considered more loosely coupled than a Point-to-Point\n  Channel, which delivers a message to exactly one subscriber. Adding\n  consumers to a Point-to-Point Channel results in Competing Consumers\n  and thus has a strong side effect.</p>\n</blockquote>\n\n<p><a href=\"https://i.stack.imgur.com/d5nOy.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/d5nOy.png\" alt=\"Copyright: Gregor Hohpe, co-author of the book Enterprise Integration Patterns. 2015.\"></a></p>\n\n<p>The side effects I observed are about the message buffering and message flow control in each of the subscribers (who subscribed to the same subscription, point-to-point == competing consumers). The current version of the Python Client Lib wraps the PubSub REST API (and RPCs). If that wrapper is used, there is no control on:</p>\n\n<ul>\n<li>How many containers are started on one VM; Multiple containers may be started if the CPU is not yet fully utilized</li>\n<li>How many messages are pulled from the subscription at once (buffering); no control at all</li>\n<li>How many threads, for processing the pulled messages, are started inside on container; flow_control(max_messages) has no effect if the value is below a fixed value. </li>\n</ul>\n\n<p>The side effects we observed are:</p>\n\n<ol>\n<li>One consumer pulls a high number of messages at once (approximately 100 to 1.000) and queues them in its client buffer. Therefore all other VM's that are started according to the auto-scaling rule, do not receive any message, because all messages are in the queue of the first few VM's</li>\n<li>Messages are re-delivered either to the same VM or any other VM (or docker container) if it runs into the acknowledgement deadline. Therefore you need to modify the acknowledgement deadline while processing the message. The deadline counter starts when the processing starts.</li>\n<li>Assuming that the processing of the message is a long running task (for instance machine learning), you may\n\n<ul>\n<li>Acknowledge the message upfront, but this will cause the VM to be shut down by the auto-scaling rule if there is no further message waiting. The rule does not care if the CPU utilization is still strong and the processing has not yet been finished.</li>\n<li>Acknowledge the message after processing. In this case you need to modify the acknowledgement deadline of that specific message while processing that message. There must not be one single code block that breaks the deadline since the last modification.</li>\n</ul></li>\n</ol>\n\n<p>Possible solutions that haven't been looked into:</p>\n\n<ul>\n<li>Using the Java Client Library since it comes with better controls on pulling and consuming messages</li>\n<li>Using the underlying API calls and classes of the Python Client Library </li>\n<li>Building a synchronization storage that orchestrates the competing consumers</li>\n</ul>\n"
        },
        {
            "tags": [
                "typescript",
                "enums",
                "undefined"
            ],
            "owner": {
                "reputation": 59,
                "user_id": 1764970,
                "user_type": "registered",
                "accept_rate": 100,
                "profile_image": "https://i.stack.imgur.com/4Jeu7.png?s=128&g=1",
                "display_name": "Yuri van Geffen",
                "link": "https://stackoverflow.com/users/1764970/yuri-van-geffen"
            },
            "is_answered": false,
            "view_count": 11,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1526458421,
            "creation_date": 1526458421,
            "question_id": 50365598,
            "body_markdown": "I have the following interface and enum in a file *RESTConfig.ts*:\r\n\r\n    export const enum RESTMethod {\r\n\t   POST = &quot;POST&quot;,\r\n\t   GET = &quot;GET&quot;\r\n    }\r\n\r\n    export interface RESTConfig {\r\n\t   url: string;\r\n\t   method: RESTMethod;\r\n\t   data: any;\r\n    }\r\n\r\nI want to import and use the enum in another class as such:\r\n    \r\n    import { RESTConfig, RESTMethod } from &#39;./RESTConfig&#39;;\r\n\r\n    class Pipelines {\r\n       ...\r\n       private someMethod() {\r\n          let rest: RESTConfig = {\r\n\t         url: &quot;&quot;,\r\n\t         method: RESTMethod.POST,\r\n\t         data: {}\r\n\t      }\r\n          ...\r\n\r\n       }\r\n       ...\r\n    }\r\nLinting and transpiling works fine, but at runtime I get the following error:\r\n\r\n&gt; TypeError: Cannot read property &#39;POST&#39; of undefined\r\n\r\non the line &quot;method: RESTMethod.POST&quot;.\r\n\r\nCan someone tell me what I&#39;m doing wrong?",
            "link": "https://stackoverflow.com/questions/50365598/typescript-runtime-error-cannot-read-property-of-undefined-enum",
            "title": "Typescript runtime error: cannot read property of undefined (enum)",
            "body": "<p>I have the following interface and enum in a file <em>RESTConfig.ts</em>:</p>\n\n<pre><code>export const enum RESTMethod {\n   POST = \"POST\",\n   GET = \"GET\"\n}\n\nexport interface RESTConfig {\n   url: string;\n   method: RESTMethod;\n   data: any;\n}\n</code></pre>\n\n<p>I want to import and use the enum in another class as such:</p>\n\n<pre><code>import { RESTConfig, RESTMethod } from './RESTConfig';\n\nclass Pipelines {\n   ...\n   private someMethod() {\n      let rest: RESTConfig = {\n         url: \"\",\n         method: RESTMethod.POST,\n         data: {}\n      }\n      ...\n\n   }\n   ...\n}\n</code></pre>\n\n<p>Linting and transpiling works fine, but at runtime I get the following error:</p>\n\n<blockquote>\n  <p>TypeError: Cannot read property 'POST' of undefined</p>\n</blockquote>\n\n<p>on the line \"method: RESTMethod.POST\".</p>\n\n<p>Can someone tell me what I'm doing wrong?</p>\n"
        },
        {
            "tags": [
                "python",
                "openstreetmap"
            ],
            "owner": {
                "reputation": 23,
                "user_id": 4884319,
                "user_type": "registered",
                "accept_rate": 80,
                "profile_image": "https://i.stack.imgur.com/bXoGh.png?s=128&g=1",
                "display_name": "Ebola",
                "link": "https://stackoverflow.com/users/4884319/ebola"
            },
            "is_answered": true,
            "view_count": 532,
            "accepted_answer_id": 35965176,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1526458415,
            "creation_date": 1457601225,
            "last_edit_date": 1457601788,
            "question_id": 35912060,
            "body_markdown": "I am trying to convert OSM to network for SUMO. I do exactly as the below:\r\nI installed SUMO, Python 3.4.4\r\nDownloaded OSM file from openstreetmap.com\r\nUsing the command below to convert osm to net, bet here is the ERROR:\r\n\r\n    Error: Could not open types-file &#39;G:\\Program Files\\DLR\\Sump /data/typemap/osmNetconvert.typ.xml&#39;.\r\n\r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: http://i.stack.imgur.com/gqpbc.jpg",
            "link": "https://stackoverflow.com/questions/35912060/can-not-find-osmnetconvert-xml-during-the-conversion",
            "title": "can not find osmNetConvert.xml during the conversion",
            "body": "<p>I am trying to convert OSM to network for SUMO. I do exactly as the below:\nI installed SUMO, Python 3.4.4\nDownloaded OSM file from openstreetmap.com\nUsing the command below to convert osm to net, bet here is the ERROR:</p>\n\n<pre><code>Error: Could not open types-file 'G:\\Program Files\\DLR\\Sump /data/typemap/osmNetconvert.typ.xml'.\n</code></pre>\n\n<p><a href=\"https://i.stack.imgur.com/gqpbc.jpg\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/gqpbc.jpg\" alt=\"enter image description here\"></a></p>\n"
        },
        {
            "tags": [
                "react-native",
                "reactcsstransitiongroup",
                "react-css-modules"
            ],
            "owner": {
                "reputation": 24,
                "user_id": 7962825,
                "user_type": "registered",
                "profile_image": "https://lh6.googleusercontent.com/-7iMIVaEfxqE/AAAAAAAAAAI/AAAAAAAAASY/pK2ov-FQUFM/photo.jpg?sz=128",
                "display_name": "Mugetsu",
                "link": "https://stackoverflow.com/users/7962825/mugetsu"
            },
            "is_answered": false,
            "view_count": 19,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526458400,
            "creation_date": 1526399160,
            "last_edit_date": 1526411696,
            "question_id": 50354356,
            "body_markdown": "How could I achieve this kind of background transparency\r\n\r\n[![enter image description here][1]][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/o2I5o.png\r\n\r\n\r\nI have tried with lineargradient but can&#39;t achieve transparency.even when I put gradients from transparent to some solid color I get solid white background in place where should be transparent \r\n\r\n\r\n    class PrivacyPolicy extends Component {\r\n    static navigatorStyle = {\r\n        navBarHidden: true\r\n    };\r\n\r\n    composePolicy(data) {\r\n        return (\r\n            &lt;View&gt;\r\n                {data.header.length ? &lt;Text style={styles.policyHeader}&gt;{data.header}&lt;/Text&gt; : null}\r\n                {data.text.map((textItem, index) =&gt; &lt;Text style={styles.policyText} key={index}&gt;{textItem}&lt;/Text&gt;)}\r\n            &lt;/View&gt;\r\n        )\r\n    }\r\n\r\n    render = () =&gt; {\r\n        return (\r\n            &lt;View style={styles.wrapper}&gt;\r\n                &lt;Text style={styles.header}&gt;Privacy Policy&lt;/Text&gt;\r\n                &lt;ScrollView showsVerticalScrollIndicator={true}&gt;\r\n                    &lt;View style={styles.contentContainer}&gt;\r\n                        {policyData.map((policy) =&gt; this.composePolicy(policy))}\r\n                    &lt;/View&gt;\r\n                &lt;/ScrollView&gt;\r\n                &lt;View style={styles.opa}&gt;\r\n                    &lt;LinearGradient colors={[&#39;transparent&#39;, &#39;rgba(0, 0, 0,0.4)&#39;, &#39;rgba(114, 110, 248,0.5)&#39;, &#39;rgb(79, 206, 249)&#39;]} style={styles.bottomDecoration}&gt;\r\n                    &lt;/LinearGradient&gt;\r\n                &lt;/View&gt;\r\n            &lt;/View&gt;\r\n        )\r\n    }\r\n}\r\n\r\n\r\n    const styles = StyleSheet.create({\r\n    wrapper: {\r\n        flex: 1,\r\n        flexDirection: &#39;column&#39;,\r\n        backgroundColor: AppColors.white\r\n    },\r\n    header: {\r\n        textAlign: &#39;center&#39;,\r\n        fontSize: 22,\r\n        fontWeight: &#39;normal&#39;,\r\n        marginTop: 25,\r\n        marginBottom: 30\r\n    },\r\n    contentContainer: {\r\n        marginRight: 30,\r\n        marginLeft: 30,\r\n    },\r\n    policyHeader: {\r\n        color: &#39;#162c57&#39;,\r\n        fontSize: 22,\r\n        fontWeight: &#39;bold&#39;,\r\n        marginBottom: 25\r\n    },\r\n    policyText: {\r\n        marginBottom: 15\r\n    },\r\n    bottomDecoration: {\r\n        height: 100,\r\n        // opacity: 0.3\r\n    },\r\n    opa: {\r\n\r\n    }\r\n});\r\n",
            "link": "https://stackoverflow.com/questions/50354356/semitransparent-background-from-top-to-bottom",
            "title": "Semitransparent background from top to bottom",
            "body": "<p>How could I achieve this kind of background transparency</p>\n\n<p><a href=\"https://i.stack.imgur.com/o2I5o.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/o2I5o.png\" alt=\"enter image description here\"></a></p>\n\n<p>I have tried with lineargradient but can't achieve transparency.even when I put gradients from transparent to some solid color I get solid white background in place where should be transparent </p>\n\n<pre><code>class PrivacyPolicy extends Component {\nstatic navigatorStyle = {\n    navBarHidden: true\n};\n\ncomposePolicy(data) {\n    return (\n        &lt;View&gt;\n            {data.header.length ? &lt;Text style={styles.policyHeader}&gt;{data.header}&lt;/Text&gt; : null}\n            {data.text.map((textItem, index) =&gt; &lt;Text style={styles.policyText} key={index}&gt;{textItem}&lt;/Text&gt;)}\n        &lt;/View&gt;\n    )\n}\n\nrender = () =&gt; {\n    return (\n        &lt;View style={styles.wrapper}&gt;\n            &lt;Text style={styles.header}&gt;Privacy Policy&lt;/Text&gt;\n            &lt;ScrollView showsVerticalScrollIndicator={true}&gt;\n                &lt;View style={styles.contentContainer}&gt;\n                    {policyData.map((policy) =&gt; this.composePolicy(policy))}\n                &lt;/View&gt;\n            &lt;/ScrollView&gt;\n            &lt;View style={styles.opa}&gt;\n                &lt;LinearGradient colors={['transparent', 'rgba(0, 0, 0,0.4)', 'rgba(114, 110, 248,0.5)', 'rgb(79, 206, 249)']} style={styles.bottomDecoration}&gt;\n                &lt;/LinearGradient&gt;\n            &lt;/View&gt;\n        &lt;/View&gt;\n    )\n}\n</code></pre>\n\n<p>}</p>\n\n<pre><code>const styles = StyleSheet.create({\nwrapper: {\n    flex: 1,\n    flexDirection: 'column',\n    backgroundColor: AppColors.white\n},\nheader: {\n    textAlign: 'center',\n    fontSize: 22,\n    fontWeight: 'normal',\n    marginTop: 25,\n    marginBottom: 30\n},\ncontentContainer: {\n    marginRight: 30,\n    marginLeft: 30,\n},\npolicyHeader: {\n    color: '#162c57',\n    fontSize: 22,\n    fontWeight: 'bold',\n    marginBottom: 25\n},\npolicyText: {\n    marginBottom: 15\n},\nbottomDecoration: {\n    height: 100,\n    // opacity: 0.3\n},\nopa: {\n\n}\n</code></pre>\n\n<p>});</p>\n"
        },
        {
            "tags": [
                "c++",
                "graph",
                "brute-force"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9779652,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Reena Kumari",
                "link": "https://stackoverflow.com/users/9779652/reena-kumari"
            },
            "is_answered": false,
            "view_count": 33,
            "closed_date": 1526115785,
            "answer_count": 0,
            "score": -5,
            "last_activity_date": 1526458395,
            "creation_date": 1526104988,
            "last_edit_date": 1526458395,
            "question_id": 50303348,
            "body_markdown": "Given a graph with n nodes and at most n^2 edges.\r\n\r\nEach vertex contains some people residing in it initially.\r\n\r\nEach vertex has a capacity to withstand total number of people who have visited it the whole time. When people go from a vertex A to B (they need not travel in groups) you can suppose that they have visited A and not B (the capacity of B doesn&#39;t decrease).\r\n\r\nThis means if there are 8 people on vertex x and it has capacity of 4 then no more than 4 people can go from vertex x to anywhere else. How many vertices are such that all people can visit it without breaking the constraints above?\r\n\r\nI am looking for something better or around O(N^4).\r\n\r\nI don&#39;t have any clue about the solution of this problem. Can anyone please help?",
            "link": "https://stackoverflow.com/questions/50303348/reachability-in-graph",
            "closed_reason": "off-topic",
            "title": "Reachability in Graph",
            "body": "<p>Given a graph with n nodes and at most n^2 edges.</p>\n\n<p>Each vertex contains some people residing in it initially.</p>\n\n<p>Each vertex has a capacity to withstand total number of people who have visited it the whole time. When people go from a vertex A to B (they need not travel in groups) you can suppose that they have visited A and not B (the capacity of B doesn't decrease).</p>\n\n<p>This means if there are 8 people on vertex x and it has capacity of 4 then no more than 4 people can go from vertex x to anywhere else. How many vertices are such that all people can visit it without breaking the constraints above?</p>\n\n<p>I am looking for something better or around O(N^4).</p>\n\n<p>I don't have any clue about the solution of this problem. Can anyone please help?</p>\n"
        },
        {
            "tags": [
                "azure",
                "azure-sql-database"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9796354,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "thediddlebandit",
                "link": "https://stackoverflow.com/users/9796354/thediddlebandit"
            },
            "is_answered": true,
            "view_count": 28,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526458371,
            "creation_date": 1526415049,
            "last_edit_date": 1526458371,
            "question_id": 50358452,
            "body_markdown": "Does anyone have any idea as to how I can restrict the IP addresses added to the SQL firewall rule via policy? \r\n\r\nI have been attempting it for a while now, my policy looks like the below... i have tried everything - is there something im overlooking? :\r\n\r\n\r\n        {\r\n      &quot;if&quot;: {\r\n        &quot;allOf&quot;: [\r\n          {\r\n            &quot;field&quot;: &quot;type&quot;,\r\n            &quot;equals&quot;: &quot;Microsoft.SQL/servers/firewallRules&quot;\r\n          },\r\n          {\r\n            &quot;Not&quot;: {\r\n              &quot;anyOf&quot;: [\r\n                {\r\n                  &quot;field&quot;: &quot;Microsoft.Sql/servers/firewallRules/startIpAddress&quot;,\r\n                  &quot;in&quot;: &quot;[parameters(&#39;StartIP&#39;)]&quot;\r\n                },\r\n                {\r\n                  &quot;field&quot;: &quot;Microsoft.Sql/servers/firewallRules/endIpAddress&quot;,\r\n                  &quot;in&quot;: &quot;[parameters(&#39;EndIP&#39;)]&quot;\r\n                }\r\n              ]\r\n            }\r\n          }\r\n        ]\r\n      },\r\n      &quot;then&quot;: {\r\n        &quot;effect&quot;: &quot;Deny&quot;\r\n      }\r\n    }\r\n\r\nBut it always throws a policy error when I update the firewall rules despite whats provided in the policy assignment. \r\n\r\nFor example, if my parameters are both &quot; 0.0.0.0;8.8.8.8 &quot;I would think i could have the access to Azure services enabled and 8.8.8.8 but that&#39;s not the case - I just get the same old denied due to policy error. \r\n\r\nIf I use just 0.0.0.0 as the parameter on the assignment I can provision new SQL servers, with it removed I cannot which leads me to believe that to some extent, the policy is working. \r\n\r\n\r\nI know I can do the whole vnet route and use NSGS to accomplish just about the same thing; however, my organization does not want to go this route and would rather it be done in policy.",
            "link": "https://stackoverflow.com/questions/50358452/azure-sql-paas-and-azure-policy-interactions",
            "title": "Azure SQL PaaS and Azure Policy interactions",
            "body": "<p>Does anyone have any idea as to how I can restrict the IP addresses added to the SQL firewall rule via policy? </p>\n\n<p>I have been attempting it for a while now, my policy looks like the below... i have tried everything - is there something im overlooking? :</p>\n\n<pre><code>    {\n  \"if\": {\n    \"allOf\": [\n      {\n        \"field\": \"type\",\n        \"equals\": \"Microsoft.SQL/servers/firewallRules\"\n      },\n      {\n        \"Not\": {\n          \"anyOf\": [\n            {\n              \"field\": \"Microsoft.Sql/servers/firewallRules/startIpAddress\",\n              \"in\": \"[parameters('StartIP')]\"\n            },\n            {\n              \"field\": \"Microsoft.Sql/servers/firewallRules/endIpAddress\",\n              \"in\": \"[parameters('EndIP')]\"\n            }\n          ]\n        }\n      }\n    ]\n  },\n  \"then\": {\n    \"effect\": \"Deny\"\n  }\n}\n</code></pre>\n\n<p>But it always throws a policy error when I update the firewall rules despite whats provided in the policy assignment. </p>\n\n<p>For example, if my parameters are both \" 0.0.0.0;8.8.8.8 \"I would think i could have the access to Azure services enabled and 8.8.8.8 but that's not the case - I just get the same old denied due to policy error. </p>\n\n<p>If I use just 0.0.0.0 as the parameter on the assignment I can provision new SQL servers, with it removed I cannot which leads me to believe that to some extent, the policy is working. </p>\n\n<p>I know I can do the whole vnet route and use NSGS to accomplish just about the same thing; however, my organization does not want to go this route and would rather it be done in policy.</p>\n"
        },
        {
            "tags": [
                "python",
                "pandas",
                "dataframe",
                "keyerror"
            ],
            "owner": {
                "reputation": 433,
                "user_id": 4945793,
                "user_type": "registered",
                "accept_rate": 65,
                "profile_image": "https://www.gravatar.com/avatar/b2850e14438ec7cc64635c0c017d8e1d?s=128&d=identicon&r=PG&f=1",
                "display_name": "jenryb",
                "link": "https://stackoverflow.com/users/4945793/jenryb"
            },
            "is_answered": true,
            "view_count": 15004,
            "accepted_answer_id": 31168092,
            "answer_count": 1,
            "score": 3,
            "last_activity_date": 1526458370,
            "creation_date": 1435771551,
            "last_edit_date": 1435785299,
            "question_id": 31167896,
            "body_markdown": "I have a dataframe that looks just how I want it when I export it to a csv file. \r\n\r\n    CompanyName\t1\t2\t3\t4\t5\t6\t7\t8\t9\t10\t11\t12\r\n    Company 1\t182\t270\t278\t314\t180\t152\t110\t127\t129\t117\t127\t81\r\n    Company 2\t163\t147\t192\t142\t186\t231\t214\t130\t112\t117\t93\t101\r\n    Company 3\t126\t88\t99\t139\t97\t97\t96\t37\t79\t116\t111\t95\r\n    Company 4\t84\t89\t71\t95\t80\t89\t83\t88\t104\t93\t78\t64\r\n\r\n\r\nHowever, when I try to pull from the key &#39;CompanyName&#39; I get a `KeyError: &#39;CompanyName&#39;` I suspect it&#39;s being overwritten somewhere but I&#39;m not sure how to fix it. \r\n\r\nif I print my dataframe I get:\r\n\r\n    pivot_table.head(2)\r\n    Out[62]: \r\n    Month                  1    2    3    4    5    6    7    8    9    10   11  CompanyName                                                                   \r\n    Company 1       182  270  278  314  180  152  110  127  129  117  127   \r\n    Company 2       163  147  192  142  186  231  214  130  112  117   93   \r\n    \r\n    Month                  12  \r\n    CompanyName                \r\n    Company 1        81  \r\n    Company 2       101  \r\n\r\n\r\nwhich is rather hard to read to be able to tell what&#39;s going on. The code that is throwing the error:\r\n\r\n    pivot_table[&#39;CompanyName&#39;] = [str(x) for x in pivot_table[&#39;CompanyName&#39;]]\r\n    Companies = list(pivot_table[&#39;CompanyName&#39;])\r\n    months = [&quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,&quot;7&quot;,&quot;8&quot;,&quot;9&quot;,&quot;10&quot;,&quot;11&quot;,&quot;12&quot;]\r\n    pivot_table = pivot_table.set_index(&#39;CompanyName&#39;)\r\n\r\n\r\nEDIT\r\n\r\nBleh&#39;s answer helped eliminate this KeyError. I needed to start the code by resetting the index, because it couldn&#39;t call a Key that had been made an index earlier.",
            "link": "https://stackoverflow.com/questions/31167896/keyerror-in-dataframe",
            "title": "KeyError in Dataframe",
            "body": "<p>I have a dataframe that looks just how I want it when I export it to a csv file. </p>\n\n<pre><code>CompanyName 1   2   3   4   5   6   7   8   9   10  11  12\nCompany 1   182 270 278 314 180 152 110 127 129 117 127 81\nCompany 2   163 147 192 142 186 231 214 130 112 117 93  101\nCompany 3   126 88  99  139 97  97  96  37  79  116 111 95\nCompany 4   84  89  71  95  80  89  83  88  104 93  78  64\n</code></pre>\n\n<p>However, when I try to pull from the key 'CompanyName' I get a <code>KeyError: 'CompanyName'</code> I suspect it's being overwritten somewhere but I'm not sure how to fix it. </p>\n\n<p>if I print my dataframe I get:</p>\n\n<pre><code>pivot_table.head(2)\nOut[62]: \nMonth                  1    2    3    4    5    6    7    8    9    10   11  CompanyName                                                                   \nCompany 1       182  270  278  314  180  152  110  127  129  117  127   \nCompany 2       163  147  192  142  186  231  214  130  112  117   93   \n\nMonth                  12  \nCompanyName                \nCompany 1        81  \nCompany 2       101  \n</code></pre>\n\n<p>which is rather hard to read to be able to tell what's going on. The code that is throwing the error:</p>\n\n<pre><code>pivot_table['CompanyName'] = [str(x) for x in pivot_table['CompanyName']]\nCompanies = list(pivot_table['CompanyName'])\nmonths = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\"]\npivot_table = pivot_table.set_index('CompanyName')\n</code></pre>\n\n<p>EDIT</p>\n\n<p>Bleh's answer helped eliminate this KeyError. I needed to start the code by resetting the index, because it couldn't call a Key that had been made an index earlier.</p>\n"
        },
        {
            "tags": [
                "javascript",
                "android",
                "reactjs",
                "react-native"
            ],
            "owner": {
                "reputation": 470,
                "user_id": 5088774,
                "user_type": "registered",
                "accept_rate": 6,
                "profile_image": "https://www.gravatar.com/avatar/e5d9d6b64946ab4aa2a61249eb76168b?s=128&d=identicon&r=PG&f=1",
                "display_name": "DIGITAL JEDI",
                "link": "https://stackoverflow.com/users/5088774/digital-jedi"
            },
            "is_answered": false,
            "view_count": 25,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526458370,
            "creation_date": 1526378121,
            "last_edit_date": 1526394542,
            "question_id": 50347250,
            "body_markdown": "My application contain drawer navigator and stack navigator. But issue is that when i tried to goback it takes me to first screen even if i am 2-3 stack deep. It don&#39;t show previous screen it always takes me to main screen. Below is my App.js code\r\n\r\n    import React from &#39;react&#39;;\r\n    import {\r\n        ActivityIndicator,\r\n        AsyncStorage,\r\n        Button,\r\n        StatusBar,\r\n        StyleSheet,\r\n        View,\r\n    } from &#39;react-native&#39;;\r\n    import {StackNavigator, SwitchNavigator, DrawerNavigator} from &#39;react-navigation&#39;;\r\n    \r\n    import Screen1 from &#39;./Screen/Screen1&#39;;\r\n    import Screen2 from &#39;./Screen/Screen2&#39;;\r\n    import Screen3 from &#39;./Screen/Screen3&#39;;\r\n    import Screen4 from &#39;./Screen/Screen4&#39;;\r\n    import Screen5 from &#39;./Screen/Screen5&#39;;\r\n    import ScreenList from &#39;./Screen/ScreenList&#39;;\r\n    \r\n    import Login from &#39;./Screen/Login&#39;;\r\n    \r\n    \r\n    class AuthLoadingScreen extends React.Component {\r\n        constructor() {\r\n            super();\r\n            this._bootstrapAsync();\r\n        }\r\n    \r\n        // Fetch the token from storage then navigate to our appropriate place\r\n        _bootstrapAsync = async () =&gt; {\r\n            const userToken = await AsyncStorage.getItem(&#39;user&#39;);\r\n    \r\n            // This will switch to the App screen or Auth screen and this loading\r\n            // screen will be unmounted and thrown away.\r\n            this.props.navigation.navigate(userToken ? &#39;App&#39; : &#39;Auth&#39;);\r\n        };\r\n    \r\n        // Render any loading content that you like here\r\n        render() {\r\n            return (\r\n                &lt;View style={styles.container}&gt;\r\n                    &lt;ActivityIndicator/&gt;\r\n                    &lt;StatusBar barStyle=&quot;default&quot;/&gt;\r\n                &lt;/View&gt;\r\n            );\r\n        }\r\n    }\r\n    \r\n    const styles = StyleSheet.create({\r\n        container: {\r\n            flex: 1,\r\n            alignItems: &#39;center&#39;,\r\n            justifyContent: &#39;center&#39;,\r\n        },\r\n    });\r\n    \r\n    const AppStack = DrawerNavigator({\r\n        Screen1: { screen: Screen1},\r\n        Screen2: { screen: Screen2},\r\n        Screen3: { screen: Screen3},\r\n        Screen4: { screen: Screen4},\r\n        Screen5: { screen: Screen5},\r\n        ScreenList: { screen: ScreenList},\r\n    }, {contentComponent: SideBar});\r\n    \r\n    \r\n    const AuthStack = StackNavigator({Login: { screen: Login}},{headerMode:&#39;none&#39;});\r\n    \r\n    const MyNavigator = SwitchNavigator(\r\n        {\r\n            AuthLoading: AuthLoadingScreen,\r\n            App: AppStack,\r\n            Auth: AuthStack,\r\n        },\r\n        {\r\n            initialRouteName: &#39;AuthLoading&#39;\r\n        }\r\n    );\r\n    \r\n    export default class App extends React.Component {\r\n        render() {\r\n            return &lt;MyNavigator /&gt;;\r\n        }\r\n    }\r\n\r\nFrom Screen 1, i click on button and go to screen 2 and screen 3 like:\r\n\r\n    onPress={() =&gt; navigate(&#39;Screen2&#39;, { })}\r\n\r\nAnd it works fine, but when i go back using bellow code from screen 3 it takes me to screen 1 not screen 2 \r\n\r\n    this.props.navigation.goBack();\r\n\r\nAm i missing something?\r\n",
            "link": "https://stackoverflow.com/questions/50347250/react-native-onback-takes-to-first-screen-issue",
            "title": "React Native onBack takes to First Screen issue",
            "body": "<p>My application contain drawer navigator and stack navigator. But issue is that when i tried to goback it takes me to first screen even if i am 2-3 stack deep. It don't show previous screen it always takes me to main screen. Below is my App.js code</p>\n\n<pre><code>import React from 'react';\nimport {\n    ActivityIndicator,\n    AsyncStorage,\n    Button,\n    StatusBar,\n    StyleSheet,\n    View,\n} from 'react-native';\nimport {StackNavigator, SwitchNavigator, DrawerNavigator} from 'react-navigation';\n\nimport Screen1 from './Screen/Screen1';\nimport Screen2 from './Screen/Screen2';\nimport Screen3 from './Screen/Screen3';\nimport Screen4 from './Screen/Screen4';\nimport Screen5 from './Screen/Screen5';\nimport ScreenList from './Screen/ScreenList';\n\nimport Login from './Screen/Login';\n\n\nclass AuthLoadingScreen extends React.Component {\n    constructor() {\n        super();\n        this._bootstrapAsync();\n    }\n\n    // Fetch the token from storage then navigate to our appropriate place\n    _bootstrapAsync = async () =&gt; {\n        const userToken = await AsyncStorage.getItem('user');\n\n        // This will switch to the App screen or Auth screen and this loading\n        // screen will be unmounted and thrown away.\n        this.props.navigation.navigate(userToken ? 'App' : 'Auth');\n    };\n\n    // Render any loading content that you like here\n    render() {\n        return (\n            &lt;View style={styles.container}&gt;\n                &lt;ActivityIndicator/&gt;\n                &lt;StatusBar barStyle=\"default\"/&gt;\n            &lt;/View&gt;\n        );\n    }\n}\n\nconst styles = StyleSheet.create({\n    container: {\n        flex: 1,\n        alignItems: 'center',\n        justifyContent: 'center',\n    },\n});\n\nconst AppStack = DrawerNavigator({\n    Screen1: { screen: Screen1},\n    Screen2: { screen: Screen2},\n    Screen3: { screen: Screen3},\n    Screen4: { screen: Screen4},\n    Screen5: { screen: Screen5},\n    ScreenList: { screen: ScreenList},\n}, {contentComponent: SideBar});\n\n\nconst AuthStack = StackNavigator({Login: { screen: Login}},{headerMode:'none'});\n\nconst MyNavigator = SwitchNavigator(\n    {\n        AuthLoading: AuthLoadingScreen,\n        App: AppStack,\n        Auth: AuthStack,\n    },\n    {\n        initialRouteName: 'AuthLoading'\n    }\n);\n\nexport default class App extends React.Component {\n    render() {\n        return &lt;MyNavigator /&gt;;\n    }\n}\n</code></pre>\n\n<p>From Screen 1, i click on button and go to screen 2 and screen 3 like:</p>\n\n<pre><code>onPress={() =&gt; navigate('Screen2', { })}\n</code></pre>\n\n<p>And it works fine, but when i go back using bellow code from screen 3 it takes me to screen 1 not screen 2 </p>\n\n<pre><code>this.props.navigation.goBack();\n</code></pre>\n\n<p>Am i missing something?</p>\n"
        },
        {
            "tags": [
                "graph",
                "nlp",
                "graph-theory",
                "keyword",
                "pagerank"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 8516025,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/2916bef5694200f043c1c4a63b460538?s=128&d=identicon&r=PG&f=1",
                "display_name": "Usman Ahmad",
                "link": "https://stackoverflow.com/users/8516025/usman-ahmad"
            },
            "is_answered": false,
            "view_count": 15,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526458369,
            "creation_date": 1526371806,
            "last_edit_date": 1526458369,
            "question_id": 50345319,
            "body_markdown": "I am trying to implement TextRank Algorithm and here is where i&#39;m stuck. I am unable to build the graph of words as described in the TextRank Research Paper here http://www.aclweb.org/anthology/W04-3252 .\r\nI am unable to find a pattern for building the graph according to paper. I think there is some problem with the graph that is shown as an example in the paper or maybe i am unable to find a pattern. Just somebody explain me that how the given text is converted into graph as shown in image here. Here is screenshot for example text and it&#39;s corresponding graph mentioned in TextRank Paper.[TextRank example Graph Image][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/lDd7X.png",
            "link": "https://stackoverflow.com/questions/50345319/building-graph-for-textrank-algorithm",
            "title": "Building graph for TextRank Algorithm",
            "body": "<p>I am trying to implement TextRank Algorithm and here is where i'm stuck. I am unable to build the graph of words as described in the TextRank Research Paper here <a href=\"http://www.aclweb.org/anthology/W04-3252\" rel=\"nofollow noreferrer\">http://www.aclweb.org/anthology/W04-3252</a> .\nI am unable to find a pattern for building the graph according to paper. I think there is some problem with the graph that is shown as an example in the paper or maybe i am unable to find a pattern. Just somebody explain me that how the given text is converted into graph as shown in image here. Here is screenshot for example text and it's corresponding graph mentioned in TextRank Paper.<a href=\"https://i.stack.imgur.com/lDd7X.png\" rel=\"nofollow noreferrer\">TextRank example Graph Image</a></p>\n"
        },
        {
            "tags": [
                "java",
                "junit",
                "mocking",
                "mockito",
                "powermock"
            ],
            "owner": {
                "reputation": 41,
                "user_id": 4148666,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/17903832443079c8a3ad4ec84ebecdaa?s=128&d=identicon&r=PG&f=1",
                "display_name": "Ravi Kiran Y",
                "link": "https://stackoverflow.com/users/4148666/ravi-kiran-y"
            },
            "is_answered": true,
            "view_count": 16077,
            "answer_count": 1,
            "score": 4,
            "last_activity_date": 1526458369,
            "creation_date": 1432021376,
            "last_edit_date": 1432021551,
            "question_id": 30319580,
            "body_markdown": "My Scenario is as below\r\n\r\n    class SuperClass{\r\n       public void run(){\r\n          System.out.println(&quot;I am running in Super class&quot;);\r\n       }\r\n    }\r\n\r\n    class ChildClass extends SuperClass{\r\n      public void childRunner(){\r\n         System.out.println(&quot;Step 1&quot;);\r\n         System.out.println(&quot;Step 2&quot;);\r\n         **run();**\r\n         System.out.println(&quot;Last Step&quot;);\r\n      }\r\n    }\r\n\r\n\r\nNow I want to mock the `childRunner()` method of `ChildClass` and since this method internally calls the super class method, i need some help/piece of code on how to mock the `run()` method which is present in the `childRunner()` method of `ChildClass`.",
            "link": "https://stackoverflow.com/questions/30319580/how-to-mock-super-class-method-using-mockito-or-anyother-relavent-java-framework",
            "title": "How to mock super class method using Mockito or anyother relavent java framework",
            "body": "<p>My Scenario is as below</p>\n\n<pre><code>class SuperClass{\n   public void run(){\n      System.out.println(\"I am running in Super class\");\n   }\n}\n\nclass ChildClass extends SuperClass{\n  public void childRunner(){\n     System.out.println(\"Step 1\");\n     System.out.println(\"Step 2\");\n     **run();**\n     System.out.println(\"Last Step\");\n  }\n}\n</code></pre>\n\n<p>Now I want to mock the <code>childRunner()</code> method of <code>ChildClass</code> and since this method internally calls the super class method, i need some help/piece of code on how to mock the <code>run()</code> method which is present in the <code>childRunner()</code> method of <code>ChildClass</code>.</p>\n"
        },
        {
            "tags": [
                "c#",
                "visual-studio",
                "resharper"
            ],
            "owner": {
                "reputation": 135,
                "user_id": 5447158,
                "user_type": "registered",
                "accept_rate": 82,
                "profile_image": "https://www.gravatar.com/avatar/d4fc1246cc3094b5562377623d3c3974?s=128&d=identicon&r=PG&f=1",
                "display_name": "Kaito Kid",
                "link": "https://stackoverflow.com/users/5447158/kaito-kid"
            },
            "is_answered": true,
            "view_count": 28,
            "accepted_answer_id": 50357730,
            "answer_count": 3,
            "score": -1,
            "last_activity_date": 1526458367,
            "creation_date": 1526408151,
            "question_id": 50356835,
            "body_markdown": "When programming, there are often, if not always, multiple ways to get the exact same behaviour.\r\n\r\nI know of a lot of Tools that allow literal line by line comparison of code files. What I&#39;m looking for is a tool that can help, or do the entire work, when comparing behaviour.\r\n\r\nI am well aware that side-effects, memory state, stack trace and many other things will be different in most cases at some point during execution. I&#39;m really looking for a top-level comparison that wouldn&#39;t take all that into account. Just like a literal comparison tool can easily ignore blank lines and comments.\r\n\r\nHere is an example:\r\n\r\n1:\r\n\r\n    static void main()\r\n    {\r\n        string i = &quot;Hello World!&quot;;\r\n        Console.Write(i);\r\n    }\r\n\r\n2:\r\n\r\n    static void main()\r\n    {\r\n        string helloWorldString = &quot;Hello World!&quot;;\r\n        Console.Write(helloWorldString);\r\n    }\r\n\r\n3:\r\n\r\n    static void main()\r\n    {\r\n        string myString = &quot;Hello World!&quot;;\r\n        WriteToConsole(myString);\r\n    }\r\n\r\n    static void WriteToConsole(string text)\r\n    {\r\n        Console.Write(text);\r\n    }\r\n\r\nThose 3 examples of simple Hello World programs **should** behave the same, at least from the user&#39;s point of view, extreme system configuration edge cases not included. I would expect the same machine to do exactly the same thing in all three cases.\r\n\r\nOf course, this looks like a very difficult task for a computer to do fast, at least from my point of view. I wouldn&#39;t expect such a tool to be perfect, especially when the project has multiple classes, forms, global variables, etc.\r\n\r\nBut when doing some refactoring, getting a quick heads up like &quot;With your changes, a behaviour has changed even though you hadn&#39;t noticed&quot; or &quot;The behaviour before and after your change stayed the same&quot; would go a long way when it comes to saving time.\r\n\r\nIs there such a tool in Visual Studio, Resharper, or available somewhere else?\r\n\r\nAs an extra exercise because I&#39;m curious, if it doesn&#39;t exist for C#, does it exist for other languages? Are there known projects in progress for this?",
            "link": "https://stackoverflow.com/questions/50356835/can-visual-studio-or-another-tool-compare-two-pieces-of-code-by-behaviour",
            "title": "Can Visual Studio, or another Tool, compare two pieces of code by behaviour?",
            "body": "<p>When programming, there are often, if not always, multiple ways to get the exact same behaviour.</p>\n\n<p>I know of a lot of Tools that allow literal line by line comparison of code files. What I'm looking for is a tool that can help, or do the entire work, when comparing behaviour.</p>\n\n<p>I am well aware that side-effects, memory state, stack trace and many other things will be different in most cases at some point during execution. I'm really looking for a top-level comparison that wouldn't take all that into account. Just like a literal comparison tool can easily ignore blank lines and comments.</p>\n\n<p>Here is an example:</p>\n\n<p>1:</p>\n\n<pre><code>static void main()\n{\n    string i = \"Hello World!\";\n    Console.Write(i);\n}\n</code></pre>\n\n<p>2:</p>\n\n<pre><code>static void main()\n{\n    string helloWorldString = \"Hello World!\";\n    Console.Write(helloWorldString);\n}\n</code></pre>\n\n<p>3:</p>\n\n<pre><code>static void main()\n{\n    string myString = \"Hello World!\";\n    WriteToConsole(myString);\n}\n\nstatic void WriteToConsole(string text)\n{\n    Console.Write(text);\n}\n</code></pre>\n\n<p>Those 3 examples of simple Hello World programs <strong>should</strong> behave the same, at least from the user's point of view, extreme system configuration edge cases not included. I would expect the same machine to do exactly the same thing in all three cases.</p>\n\n<p>Of course, this looks like a very difficult task for a computer to do fast, at least from my point of view. I wouldn't expect such a tool to be perfect, especially when the project has multiple classes, forms, global variables, etc.</p>\n\n<p>But when doing some refactoring, getting a quick heads up like \"With your changes, a behaviour has changed even though you hadn't noticed\" or \"The behaviour before and after your change stayed the same\" would go a long way when it comes to saving time.</p>\n\n<p>Is there such a tool in Visual Studio, Resharper, or available somewhere else?</p>\n\n<p>As an extra exercise because I'm curious, if it doesn't exist for C#, does it exist for other languages? Are there known projects in progress for this?</p>\n"
        },
        {
            "tags": [
                "sql-server",
                "database-schema",
                "sql-server-data-tools",
                "temporal-tables"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9385678,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e35791c4e343d2d9b5c3c22dbb431fb5?s=128&d=identicon&r=PG&f=1",
                "display_name": "s_rahlf",
                "link": "https://stackoverflow.com/users/9385678/s-rahlf"
            },
            "is_answered": false,
            "view_count": 11,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526458366,
            "creation_date": 1526456250,
            "last_edit_date": 1526458366,
            "question_id": 50364923,
            "body_markdown": "We have a project running on Azure SQL DB using temporal / system versioned tables. Database project is in VS 2015 Enterprise (14.0.25420.1), Data Tools (14.0.6172.50) and data tier application framework (14.0.3953.4).\r\n\r\nThe schema update script project-&gt;DB fails because the script tries to drop the currently empty table and history table without disabling the system versioning.\r\n\r\nThreads I found on this topic from last year where answered with &quot;issue fixed with latest data tools&quot; -&gt; am I missing something?",
            "link": "https://stackoverflow.com/questions/50364923/visual-studio-2015-data-tools-schema-update-on-system-versioned-tables-fails",
            "title": "Visual Studio 2015 Data Tools schema update on system versioned tables fails",
            "body": "<p>We have a project running on Azure SQL DB using temporal / system versioned tables. Database project is in VS 2015 Enterprise (14.0.25420.1), Data Tools (14.0.6172.50) and data tier application framework (14.0.3953.4).</p>\n\n<p>The schema update script project->DB fails because the script tries to drop the currently empty table and history table without disabling the system versioning.</p>\n\n<p>Threads I found on this topic from last year where answered with \"issue fixed with latest data tools\" -> am I missing something?</p>\n"
        },
        {
            "tags": [
                "json",
                "vba"
            ],
            "owner": {
                "reputation": 133,
                "user_id": 7986808,
                "user_type": "registered",
                "accept_rate": 72,
                "profile_image": "https://www.gravatar.com/avatar/bb9c7c2b8e8a67a276bbc476d48a102b?s=128&d=identicon&r=PG&f=1",
                "display_name": "khashashin",
                "link": "https://stackoverflow.com/users/7986808/khashashin"
            },
            "is_answered": true,
            "view_count": 12,
            "accepted_answer_id": 50365589,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526458366,
            "creation_date": 1526456863,
            "question_id": 50365126,
            "body_markdown": "It probably sounds simple, but I can not find a way out.\r\nI&#39;m trying to create a more or less dynamic json and I need to convert the content of object to a string between double quotes. Something like that  :\r\n`&quot;&quot;&quot; + object + &quot;&quot;&quot;` gives the following result `&quot;object&quot;` and the expected result would be `&quot;content of object&quot;`.\r\n\r\nHere is my code, will probably be more clear, about what it&#39;s about.\r\n\r\n    Dim jsTest As String\r\n    jsTest = &quot;&quot;&quot; + CStr(Msg.Subject) + &quot;&quot;&quot; + &quot;&quot;&quot; + CStr(Msg.Body) + &quot;&quot;&quot;\r\n\r\n`Msg.Subject` and `Msg.Body` are objects from Email. I can do that this way(with single quotes):\r\n\r\n    Dim smry, descrp, jsTest As String\r\n    smry = &quot;&quot;&quot;summary&quot;&quot;&quot;\r\n    descrp = &quot;&quot;&quot;description&quot;&quot;&quot;\r\n    jsTest = &quot;{&quot; + smry + &quot;:&quot; + &quot;&#39;&quot; + CStr(Msg.Subject) + &quot;&#39;&quot; + &quot;,&quot; + descrp + &quot;:&quot; + &quot;&#39;&quot; + CStr(Msg.Body) + &quot;&#39;&quot; + &quot;}&quot;\r\n\r\nbut then I get content of object as String with single quotes and I cant put it in my JSON like so:\r\n\r\n    {&quot;summary&quot;: &#39;Release 18.20 Produktion&#39;, &quot;description&quot;: &#39;Guten Tag Sie erhalten diese Terminanfrage&#39;}\r\n\r\nHow can I get result like (**Note** double quotes):\r\n\r\n    {&quot;summary&quot;: &quot;Release 18.20 Produktion&quot;, &quot;description&quot;: &quot;Guten Tag Sie erhalten diese Terminanfrage&quot;}\r\n                            ",
            "link": "https://stackoverflow.com/questions/50365126/enclosing-the-content-of-object-in-double-quotes-in-vba",
            "title": "Enclosing the content of object in double quotes in VBA",
            "body": "<p>It probably sounds simple, but I can not find a way out.\nI'm trying to create a more or less dynamic json and I need to convert the content of object to a string between double quotes. Something like that  :\n<code>\"\"\" + object + \"\"\"</code> gives the following result <code>\"object\"</code> and the expected result would be <code>\"content of object\"</code>.</p>\n\n<p>Here is my code, will probably be more clear, about what it's about.</p>\n\n<pre><code>Dim jsTest As String\njsTest = \"\"\" + CStr(Msg.Subject) + \"\"\" + \"\"\" + CStr(Msg.Body) + \"\"\"\n</code></pre>\n\n<p><code>Msg.Subject</code> and <code>Msg.Body</code> are objects from Email. I can do that this way(with single quotes):</p>\n\n<pre><code>Dim smry, descrp, jsTest As String\nsmry = \"\"\"summary\"\"\"\ndescrp = \"\"\"description\"\"\"\njsTest = \"{\" + smry + \":\" + \"'\" + CStr(Msg.Subject) + \"'\" + \",\" + descrp + \":\" + \"'\" + CStr(Msg.Body) + \"'\" + \"}\"\n</code></pre>\n\n<p>but then I get content of object as String with single quotes and I cant put it in my JSON like so:</p>\n\n<pre><code>{\"summary\": 'Release 18.20 Produktion', \"description\": 'Guten Tag Sie erhalten diese Terminanfrage'}\n</code></pre>\n\n<p>How can I get result like (<strong>Note</strong> double quotes):</p>\n\n<pre><code>{\"summary\": \"Release 18.20 Produktion\", \"description\": \"Guten Tag Sie erhalten diese Terminanfrage\"}\n</code></pre>\n"
        },
        {
            "tags": [
                "yii2"
            ],
            "owner": {
                "reputation": 9,
                "user_id": 5599711,
                "user_type": "registered",
                "accept_rate": 60,
                "profile_image": "https://www.gravatar.com/avatar/9defea0557c57fb6adc4b317277f9e6c?s=128&d=identicon&r=PG&f=1",
                "display_name": "Ruslan  Nasrutdinov",
                "link": "https://stackoverflow.com/users/5599711/ruslan-nasrutdinov"
            },
            "is_answered": true,
            "view_count": 25,
            "accepted_answer_id": 50365585,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526458353,
            "creation_date": 1526449516,
            "question_id": 50363218,
            "body_markdown": "i&#39;m using rbac in yii2 project. When i print\r\n\r\n    var_dump(\\Yii::$app-&gt;authManager-&gt;getRolesByUser(Yii::$app-&gt;user-&gt;id));\r\n\r\nI get an array with two elements: guest and user?\r\nWhy &quot;guest&quot; role stays at authorized user? Is it normal behavior or I did something wrong?",
            "link": "https://stackoverflow.com/questions/50363218/why-after-login-user-keeps-both-roles-guest-and-user-in-yii2",
            "title": "Why after login user keeps both roles guest and user in yii2?",
            "body": "<p>i'm using rbac in yii2 project. When i print</p>\n\n<pre><code>var_dump(\\Yii::$app-&gt;authManager-&gt;getRolesByUser(Yii::$app-&gt;user-&gt;id));\n</code></pre>\n\n<p>I get an array with two elements: guest and user?\nWhy \"guest\" role stays at authorized user? Is it normal behavior or I did something wrong?</p>\n"
        },
        {
            "tags": [
                "android",
                "android-architecture-navigation"
            ],
            "owner": {
                "reputation": 2023,
                "user_id": 423199,
                "user_type": "registered",
                "accept_rate": 99,
                "profile_image": "https://i.stack.imgur.com/OrFPh.jpg?s=128&g=1",
                "display_name": "Hector",
                "link": "https://stackoverflow.com/users/423199/hector"
            },
            "is_answered": false,
            "view_count": 29,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1526458334,
            "creation_date": 1526458334,
            "question_id": 50365581,
            "body_markdown": "I am using Android Studio version\r\n\r\n    Android Studio 3.2 Canary 14\r\n    Build #AI-181.4668.68.32.4763614, built on May 4, 2018\r\n    JRE: 1.8.0_152-release-1136-b02 x86_64\r\n    JVM: OpenJDK 64-Bit Server VM by JetBrains s.r.o\r\n    Mac OS X 10.11.6\r\n\r\nWhile investigating the new Architectural navigation components android.arch.navigation I have encountered this build failure.\r\n\r\n    AGPBI: {&quot;kind&quot;:&quot;error&quot;,&quot;text&quot;:&quot;Program type already present: android.support.v4.os.ResultReceiver$1&quot;,&quot;sources&quot;:[{}],&quot;tool&quot;:&quot;D8&quot;}\r\n    :app:transformDexArchiveWithExternalLibsDexMergerForDebug FAILED\r\n    FAILURE: Build failed with an exception.\r\n    * What went wrong:\r\n    Execution failed for task &#39;:app:transformDexArchiveWithExternalLibsDexMergerForDebug&#39;.\r\n    &gt; com.android.builder.dexing.DexArchiveMergerException: Error while merging dex archives: ...\r\n    ...\r\n      Program type already present: android.support.v4.os.ResultReceiver$1\r\n\r\n\r\nMy app gradle build resembles:-\r\n\r\n    apply plugin: &#39;com.android.application&#39;\r\n    apply plugin: &quot;androidx.navigation.safeargs&quot;\r\n    \r\n    android {\r\n        compileSdkVersion &#39;android-P&#39;\r\n        defaultConfig {\r\n            applicationId &quot;com.research.frager&quot;\r\n            minSdkVersion 19\r\n            targetSdkVersion 28\r\n            versionCode 1\r\n            versionName &quot;1.0&quot;\r\n            testInstrumentationRunner &quot;androidx.test.runner.AndroidJUnitRunner&quot;\r\n        }\r\n        buildTypes {\r\n            release {\r\n                minifyEnabled false\r\n                proguardFiles getDefaultProguardFile(&#39;proguard-android.txt&#39;), &#39;proguard-rules.pro&#39;\r\n            }\r\n        }\r\n    }\r\n    \r\n    dependencies {\r\n        def nav_version = &quot;1.0.0-alpha01&quot;\r\n    \r\n        implementation &quot;android.arch.navigation:navigation-fragment:$nav_version&quot;\r\n        implementation &quot;android.arch.navigation:navigation-ui:$nav_version&quot;\r\n    \r\n        // optional - Test helpers\r\n        androidTestImplementation &quot;android.arch.navigation:navigation-testing:$nav_version&quot;\r\n    \r\n        implementation fileTree(dir: &#39;libs&#39;, include: [&#39;*.jar&#39;])\r\n        implementation &#39;androidx.appcompat:appcompat:1.0.0-alpha1&#39;\r\n    \r\n        implementation &#39;androidx.constraintlayout:constraintlayout:1.1.0&#39;\r\n        implementation &#39;androidx.lifecycle:lifecycle-extensions:2.0.0-alpha1&#39;\r\n        testImplementation &#39;junit:junit:4.12&#39;\r\n    \r\n        androidTestImplementation &#39;androidx.test:runner:1.1.0-alpha2&#39;\r\n        androidTestImplementation &#39;androidx.test.espresso:espresso-core:3.1.0-alpha2&#39;\r\n    }\r\n\r\nand project level gradle build:-\r\n\r\n    buildscript {\r\n        \r\n        repositories {\r\n            google()\r\n            jcenter()\r\n        }\r\n        dependencies {\r\n            classpath &#39;com.android.tools.build:gradle:3.2.0-alpha14&#39;\r\n            classpath &quot;android.arch.navigation:navigation-safe-args-gradle-plugin:1.0.0-alpha01&quot;\r\n        }\r\n    }\r\n    \r\n    allprojects {\r\n        repositories {\r\n            google()\r\n            jcenter()\r\n        }\r\n    }\r\n    \r\n    task clean(type: Delete) {\r\n        delete rootProject.buildDir\r\n    }\r\n\r\nI have tried refactoring to AndroidX, however I get a message stating No usages found in project, so why is this &quot;v4&quot; class still being mentioned?\r\n\r\n\r\n\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50365581/why-does-android-arch-navigation-cause-program-type-already-present-android-sup",
            "title": "Why does android.arch.navigation cause Program type already present: android.support.v4.os.ResultReceiver$1?",
            "body": "<p>I am using Android Studio version</p>\n\n<pre><code>Android Studio 3.2 Canary 14\nBuild #AI-181.4668.68.32.4763614, built on May 4, 2018\nJRE: 1.8.0_152-release-1136-b02 x86_64\nJVM: OpenJDK 64-Bit Server VM by JetBrains s.r.o\nMac OS X 10.11.6\n</code></pre>\n\n<p>While investigating the new Architectural navigation components android.arch.navigation I have encountered this build failure.</p>\n\n<pre><code>AGPBI: {\"kind\":\"error\",\"text\":\"Program type already present: android.support.v4.os.ResultReceiver$1\",\"sources\":[{}],\"tool\":\"D8\"}\n:app:transformDexArchiveWithExternalLibsDexMergerForDebug FAILED\nFAILURE: Build failed with an exception.\n* What went wrong:\nExecution failed for task ':app:transformDexArchiveWithExternalLibsDexMergerForDebug'.\n&gt; com.android.builder.dexing.DexArchiveMergerException: Error while merging dex archives: ...\n...\n  Program type already present: android.support.v4.os.ResultReceiver$1\n</code></pre>\n\n<p>My app gradle build resembles:-</p>\n\n<pre><code>apply plugin: 'com.android.application'\napply plugin: \"androidx.navigation.safeargs\"\n\nandroid {\n    compileSdkVersion 'android-P'\n    defaultConfig {\n        applicationId \"com.research.frager\"\n        minSdkVersion 19\n        targetSdkVersion 28\n        versionCode 1\n        versionName \"1.0\"\n        testInstrumentationRunner \"androidx.test.runner.AndroidJUnitRunner\"\n    }\n    buildTypes {\n        release {\n            minifyEnabled false\n            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'\n        }\n    }\n}\n\ndependencies {\n    def nav_version = \"1.0.0-alpha01\"\n\n    implementation \"android.arch.navigation:navigation-fragment:$nav_version\"\n    implementation \"android.arch.navigation:navigation-ui:$nav_version\"\n\n    // optional - Test helpers\n    androidTestImplementation \"android.arch.navigation:navigation-testing:$nav_version\"\n\n    implementation fileTree(dir: 'libs', include: ['*.jar'])\n    implementation 'androidx.appcompat:appcompat:1.0.0-alpha1'\n\n    implementation 'androidx.constraintlayout:constraintlayout:1.1.0'\n    implementation 'androidx.lifecycle:lifecycle-extensions:2.0.0-alpha1'\n    testImplementation 'junit:junit:4.12'\n\n    androidTestImplementation 'androidx.test:runner:1.1.0-alpha2'\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.1.0-alpha2'\n}\n</code></pre>\n\n<p>and project level gradle build:-</p>\n\n<pre><code>buildscript {\n\n    repositories {\n        google()\n        jcenter()\n    }\n    dependencies {\n        classpath 'com.android.tools.build:gradle:3.2.0-alpha14'\n        classpath \"android.arch.navigation:navigation-safe-args-gradle-plugin:1.0.0-alpha01\"\n    }\n}\n\nallprojects {\n    repositories {\n        google()\n        jcenter()\n    }\n}\n\ntask clean(type: Delete) {\n    delete rootProject.buildDir\n}\n</code></pre>\n\n<p>I have tried refactoring to AndroidX, however I get a message stating No usages found in project, so why is this \"v4\" class still being mentioned?</p>\n"
        },
        {
            "tags": [
                "java",
                "amazon-web-services",
                "amazon-s3",
                "lucene",
                "aws-lambda"
            ],
            "owner": {
                "user_type": "does_not_exist",
                "display_name": "user1844306"
            },
            "is_answered": true,
            "view_count": 631,
            "accepted_answer_id": 38817492,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1526458316,
            "creation_date": 1470593229,
            "last_edit_date": 1470593373,
            "question_id": 38817050,
            "body_markdown": "I have a an existing index of lucene index files and the java code to perform search functions on it.\r\n\r\nWhat I would like to do is perform the same thing on a server so users of an app could simply pass a query that will be taken as an input parameter by the java program and run it against the existing index to return the document in which it occurs.\r\n\r\nAll the implementation has been tested on my local pc,but what I need to do is implement it in an Android app.\r\n\r\nSo far I have read around and concluded that porting the code in AWS lambda and using S3 to store the files and calling the s3 objects from lambda.\r\n\r\nIs this the right approach?Any resources that point to the this approach or alternative suggestions are also appreciated.\r\n\r\nThanks in advance.",
            "link": "https://stackoverflow.com/questions/38817050/integrating-lucene-index-and-amazon-aws",
            "title": "Integrating Lucene Index and Amazon AWS",
            "body": "<p>I have a an existing index of lucene index files and the java code to perform search functions on it.</p>\n\n<p>What I would like to do is perform the same thing on a server so users of an app could simply pass a query that will be taken as an input parameter by the java program and run it against the existing index to return the document in which it occurs.</p>\n\n<p>All the implementation has been tested on my local pc,but what I need to do is implement it in an Android app.</p>\n\n<p>So far I have read around and concluded that porting the code in AWS lambda and using S3 to store the files and calling the s3 objects from lambda.</p>\n\n<p>Is this the right approach?Any resources that point to the this approach or alternative suggestions are also appreciated.</p>\n\n<p>Thanks in advance.</p>\n"
        },
        {
            "tags": [
                "google-chrome",
                "redirect",
                "dns"
            ],
            "owner": {
                "reputation": 335,
                "user_id": 766263,
                "user_type": "registered",
                "accept_rate": 25,
                "profile_image": "https://www.gravatar.com/avatar/a728b30c77b226cd02589924621b768c?s=128&d=identicon&r=PG",
                "display_name": "Josue",
                "link": "https://stackoverflow.com/users/766263/josue"
            },
            "is_answered": false,
            "view_count": 34,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526458307,
            "creation_date": 1526391174,
            "last_edit_date": 1526394679,
            "question_id": 50351615,
            "body_markdown": "I&#39;ve bought an `.app` domain with GoDaddy. I only use it to redirect to another page. I try with some different `https://` pages (For example: https://www.deepl.com/translator).\r\n\r\nWith Firefox and Safari it works fine and destination web is opened. However, it seems to be a problem with Chrome (desktop and Android)\r\n\r\nThe error is:\r\n\r\n&gt; `ERR_CONNECTION_TIMED_OUT`\r\n\r\nIf it&#39;s needed, I can paste the `.app` domain if it helps.\r\n\r\nAny idea?",
            "link": "https://stackoverflow.com/questions/50351615/redirecting-app-domain-with-godaddy-and-chrome",
            "title": "Redirecting .app domain with GoDaddy and Chrome",
            "body": "<p>I've bought an <code>.app</code> domain with GoDaddy. I only use it to redirect to another page. I try with some different <code>https://</code> pages (For example: <a href=\"https://www.deepl.com/translator\" rel=\"nofollow noreferrer\">https://www.deepl.com/translator</a>).</p>\n\n<p>With Firefox and Safari it works fine and destination web is opened. However, it seems to be a problem with Chrome (desktop and Android)</p>\n\n<p>The error is:</p>\n\n<blockquote>\n  <p><code>ERR_CONNECTION_TIMED_OUT</code></p>\n</blockquote>\n\n<p>If it's needed, I can paste the <code>.app</code> domain if it helps.</p>\n\n<p>Any idea?</p>\n"
        },
        {
            "tags": [
                "html",
                "asp.net"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 3652172,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/66803005bb78d26affe665aac083d077?s=128&d=identicon&r=PG&f=1",
                "display_name": "user3652172",
                "link": "https://stackoverflow.com/users/3652172/user3652172"
            },
            "is_answered": false,
            "view_count": 16,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526458301,
            "creation_date": 1526457847,
            "last_edit_date": 1526458301,
            "question_id": 50365441,
            "body_markdown": "I want my HTML pages to use a local path as an image&#39;s source in my development environment.\r\n\r\nSomething like: \r\n    \r\n`&lt;img src=&quot;C:\\localPath.jpg&quot; alt=&quot;stf&quot;&gt;`\r\n\r\nIs there a configuration for the web.config to specify a specific folder as if it a CDN server?\r\n",
            "link": "https://stackoverflow.com/questions/50365441/how-to-specify-for-the-web-config-to-use-a-local-path-as-url-source",
            "title": "How to specify for the web.config to use a local path as URL source?",
            "body": "<p>I want my HTML pages to use a local path as an image's source in my development environment.</p>\n\n<p>Something like: </p>\n\n<p><code>&lt;img src=\"C:\\localPath.jpg\" alt=\"stf\"&gt;</code></p>\n\n<p>Is there a configuration for the web.config to specify a specific folder as if it a CDN server?</p>\n"
        },
        {
            "tags": [
                "vim",
                "cscope"
            ],
            "owner": {
                "reputation": 2,
                "user_id": 1604304,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/c408c320d2c8f6038fe92dfc915423b4?s=128&d=identicon&r=PG",
                "display_name": "kk9527",
                "link": "https://stackoverflow.com/users/1604304/kk9527"
            },
            "is_answered": false,
            "view_count": 23,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526458300,
            "creation_date": 1526401979,
            "last_edit_date": 1526402079,
            "question_id": 50355198,
            "body_markdown": "Once vim cscope search finishes, vim opens a new quickfix window to show result. Is it possible to appending the new results to existing result windows instead of opening a new quickfix window? \r\n(Source Insight supports this way, BTW)",
            "link": "https://stackoverflow.com/questions/50355198/is-it-possible-to-appending-the-new-results-to-existing-result-window",
            "title": "Is it possible to appending the new results to existing result window?",
            "body": "<p>Once vim cscope search finishes, vim opens a new quickfix window to show result. Is it possible to appending the new results to existing result windows instead of opening a new quickfix window? \n(Source Insight supports this way, BTW)</p>\n"
        },
        {
            "tags": [
                "mysql",
                "performance",
                "mariadb",
                "replication",
                "database-performance"
            ],
            "owner": {
                "reputation": 16,
                "user_id": 6399371,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/6f467c229e500fc3190a211f26104862?s=128&d=identicon&r=PG&f=1",
                "display_name": "Mike Patutin",
                "link": "https://stackoverflow.com/users/6399371/mike-patutin"
            },
            "is_answered": false,
            "view_count": 14,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526458297,
            "creation_date": 1526458297,
            "question_id": 50365569,
            "body_markdown": "I have MySQL (MariaDB 10.1.27) master that hold ~1900 databases. Total dbs size ~100GB\r\nUsed InnoDB engine with innodb_file_per_table = 1\r\n\r\nI&#39;m going to setup two slaves for this server (MariaDB 10.1.27).\r\nBoth slaves with identical hardware like master.\r\nmaster was stopeed at midnight, was made backup from /var/lib/mysql with tar\r\nand this tar was transferred and extracted on two separated servers.\r\n\r\nOne slave setted up fast, and catched up master (1 day delay) in ~1 hour.\r\nIn time of catching up, I got 100% CPU usage (LA 3-4) with log of disk activity (~20%wa)\r\n\r\nSecond master has some strange problem with replication performance.\r\nAfter setup it catching up master more than 2 days. And procees finished 20% only.\r\ncurrent show slave status:\r\n\r\n    show slave status\\Gshow processlist;\r\n    *************************** 1. row ***************************\r\n                   Slave_IO_State: Waiting for master to send event\r\n                      Master_Host: XXXXXXXXXX\r\n                      Master_User: XXXXXXXX\r\n                      Master_Port: 3306\r\n                    Connect_Retry: 60\r\n                  Master_Log_File: mysqld-bin.000572\r\n              Read_Master_Log_Pos: 524619108\r\n                   Relay_Log_File: relay-bin.000004\r\n                    Relay_Log_Pos: 916671538\r\n            Relay_Master_Log_File: mysqld-bin.000571\r\n                 Slave_IO_Running: Yes\r\n                Slave_SQL_Running: Yes\r\n                  Replicate_Do_DB:\r\n              Replicate_Ignore_DB:\r\n               Replicate_Do_Table:\r\n           Replicate_Ignore_Table:\r\n          Replicate_Wild_Do_Table:\r\n      Replicate_Wild_Ignore_Table: apsc.%,billing.%,information_schema.%,performance_schema.%,horde.%,mysql.%,phpmyadmin_gmRJC4rn_tom.%,psa.%,roundcubemail.%,sitebuilder5.%\r\n                       Last_Errno: 0\r\n                       Last_Error:\r\n                     Skip_Counter: 0\r\n              Exec_Master_Log_Pos: 916671245\r\n                  Relay_Log_Space: 1598365917\r\n                  Until_Condition: None\r\n                   Until_Log_File:\r\n                    Until_Log_Pos: 0\r\n               Master_SSL_Allowed: No\r\n               Master_SSL_CA_File:\r\n               Master_SSL_CA_Path:\r\n                  Master_SSL_Cert:\r\n                Master_SSL_Cipher:\r\n                   Master_SSL_Key:\r\n            Seconds_Behind_Master: 24730\r\n    Master_SSL_Verify_Server_Cert: No\r\n                    Last_IO_Errno: 0\r\n                    Last_IO_Error:\r\n                   Last_SQL_Errno: 0\r\n                   Last_SQL_Error:\r\n      Replicate_Ignore_Server_Ids:\r\n                 Master_Server_Id: 111\r\n                   Master_SSL_Crl:\r\n               Master_SSL_Crlpath:\r\n                       Using_Gtid: No\r\n                      Gtid_IO_Pos:\r\n          Replicate_Do_Domain_Ids:\r\n      Replicate_Ignore_Domain_Ids:\r\n                    Parallel_Mode: conservative\r\n    1 row in set (0.00 sec)\r\n\r\nNo serious activity present on CPU and on disk (see top screen later)\r\n\r\n    ======\r\n    top - 03:36:36 up 114 days, 12:26,  9 users,  load average: 1.82, 1.86, 1.89\r\n    Tasks: 364 total,   1 running, 362 sleeping,   0 stopped,   1 zombie\r\n    Cpu(s):  1.5%us,  0.7%sy,  0.0%ni, 87.7%id, 4.0%wa,  0.0%hi,  0.0%si,  0.0%st\r\n    Mem:  32993560k total, 32271192k used,   722368k free,   625464k buffers\r\n    Swap:  4194296k total,   229512k used,  3964784k free, 23100280k cached\r\n    \r\n      PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND\r\n    13809 mysql      1 -19 6819m 5.8g 7332 S 8.9 18.5 132:12.33 mysqld\r\n    ======\r\n\r\nAs I see, all bin logs transferred from master to slave currently, \r\nbut slave have slow performance in applying this logs to dbs.\r\n\r\nIn slow query log (2 seconds limit) I have no any records.\r\n\r\nGoogling problem not help. Already tried:\r\n\r\n    skip-name-resolve\r\n    \r\n    innodb_flush_log_at_trx_commit=0\r\n    innodb-flush-method=O_DIRECT\r\n    \r\n    #move innodb logs to SSD\r\n    nnodb_log_group_home_dir=/var/lib/mysql_logs\r\n\r\nSetup multithreaded replication attempt (2 and 4 threads) was failed, because slowing down process more that current state. Slave got increasing lag (Seconds_Behind_Master in show slave status)\r\n\r\nPlease advice me what can be source of problem and what can be made to make replication faster.",
            "link": "https://stackoverflow.com/questions/50365569/strange-slow-performance-in-mysql-replication",
            "title": "Strange slow performance in mysql replication",
            "body": "<p>I have MySQL (MariaDB 10.1.27) master that hold ~1900 databases. Total dbs size ~100GB\nUsed InnoDB engine with innodb_file_per_table = 1</p>\n\n<p>I'm going to setup two slaves for this server (MariaDB 10.1.27).\nBoth slaves with identical hardware like master.\nmaster was stopeed at midnight, was made backup from /var/lib/mysql with tar\nand this tar was transferred and extracted on two separated servers.</p>\n\n<p>One slave setted up fast, and catched up master (1 day delay) in ~1 hour.\nIn time of catching up, I got 100% CPU usage (LA 3-4) with log of disk activity (~20%wa)</p>\n\n<p>Second master has some strange problem with replication performance.\nAfter setup it catching up master more than 2 days. And procees finished 20% only.\ncurrent show slave status:</p>\n\n<pre><code>show slave status\\Gshow processlist;\n*************************** 1. row ***************************\n               Slave_IO_State: Waiting for master to send event\n                  Master_Host: XXXXXXXXXX\n                  Master_User: XXXXXXXX\n                  Master_Port: 3306\n                Connect_Retry: 60\n              Master_Log_File: mysqld-bin.000572\n          Read_Master_Log_Pos: 524619108\n               Relay_Log_File: relay-bin.000004\n                Relay_Log_Pos: 916671538\n        Relay_Master_Log_File: mysqld-bin.000571\n             Slave_IO_Running: Yes\n            Slave_SQL_Running: Yes\n              Replicate_Do_DB:\n          Replicate_Ignore_DB:\n           Replicate_Do_Table:\n       Replicate_Ignore_Table:\n      Replicate_Wild_Do_Table:\n  Replicate_Wild_Ignore_Table: apsc.%,billing.%,information_schema.%,performance_schema.%,horde.%,mysql.%,phpmyadmin_gmRJC4rn_tom.%,psa.%,roundcubemail.%,sitebuilder5.%\n                   Last_Errno: 0\n                   Last_Error:\n                 Skip_Counter: 0\n          Exec_Master_Log_Pos: 916671245\n              Relay_Log_Space: 1598365917\n              Until_Condition: None\n               Until_Log_File:\n                Until_Log_Pos: 0\n           Master_SSL_Allowed: No\n           Master_SSL_CA_File:\n           Master_SSL_CA_Path:\n              Master_SSL_Cert:\n            Master_SSL_Cipher:\n               Master_SSL_Key:\n        Seconds_Behind_Master: 24730\nMaster_SSL_Verify_Server_Cert: No\n                Last_IO_Errno: 0\n                Last_IO_Error:\n               Last_SQL_Errno: 0\n               Last_SQL_Error:\n  Replicate_Ignore_Server_Ids:\n             Master_Server_Id: 111\n               Master_SSL_Crl:\n           Master_SSL_Crlpath:\n                   Using_Gtid: No\n                  Gtid_IO_Pos:\n      Replicate_Do_Domain_Ids:\n  Replicate_Ignore_Domain_Ids:\n                Parallel_Mode: conservative\n1 row in set (0.00 sec)\n</code></pre>\n\n<p>No serious activity present on CPU and on disk (see top screen later)</p>\n\n<pre><code>======\ntop - 03:36:36 up 114 days, 12:26,  9 users,  load average: 1.82, 1.86, 1.89\nTasks: 364 total,   1 running, 362 sleeping,   0 stopped,   1 zombie\nCpu(s):  1.5%us,  0.7%sy,  0.0%ni, 87.7%id, 4.0%wa,  0.0%hi,  0.0%si,  0.0%st\nMem:  32993560k total, 32271192k used,   722368k free,   625464k buffers\nSwap:  4194296k total,   229512k used,  3964784k free, 23100280k cached\n\n  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND\n13809 mysql      1 -19 6819m 5.8g 7332 S 8.9 18.5 132:12.33 mysqld\n======\n</code></pre>\n\n<p>As I see, all bin logs transferred from master to slave currently, \nbut slave have slow performance in applying this logs to dbs.</p>\n\n<p>In slow query log (2 seconds limit) I have no any records.</p>\n\n<p>Googling problem not help. Already tried:</p>\n\n<pre><code>skip-name-resolve\n\ninnodb_flush_log_at_trx_commit=0\ninnodb-flush-method=O_DIRECT\n\n#move innodb logs to SSD\nnnodb_log_group_home_dir=/var/lib/mysql_logs\n</code></pre>\n\n<p>Setup multithreaded replication attempt (2 and 4 threads) was failed, because slowing down process more that current state. Slave got increasing lag (Seconds_Behind_Master in show slave status)</p>\n\n<p>Please advice me what can be source of problem and what can be made to make replication faster.</p>\n"
        },
        {
            "tags": [
                "windows-7",
                "windows-10",
                "sharing",
                "file-sharing"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 6189301,
                "user_type": "registered",
                "profile_image": "https://lh4.googleusercontent.com/-HIIPCLUuCv4/AAAAAAAAAAI/AAAAAAAAAvE/SEl6T7jp-78/photo.jpg?sz=128",
                "display_name": "Rizwan Shaikh",
                "link": "https://stackoverflow.com/users/6189301/rizwan-shaikh"
            },
            "is_answered": false,
            "view_count": 17,
            "answer_count": 0,
            "score": -2,
            "last_activity_date": 1526458282,
            "creation_date": 1526458282,
            "question_id": 50365565,
            "body_markdown": "I want to Share files from Windows 10 April Update to Windows 7 because HomeGroup feature in April Update is no longer exist and nearby sharing doesn&#39;t work for windows 7?",
            "link": "https://stackoverflow.com/questions/50365565/i-want-to-share-files-from-windows-10-april-update-to-windows-7",
            "title": "I want to Share files from Windows 10 April Update to Windows 7",
            "body": "<p>I want to Share files from Windows 10 April Update to Windows 7 because HomeGroup feature in April Update is no longer exist and nearby sharing doesn't work for windows 7?</p>\n"
        },
        {
            "tags": [
                "c++",
                "boost",
                "stl"
            ],
            "owner": {
                "reputation": 376,
                "user_id": 323058,
                "user_type": "registered",
                "accept_rate": 50,
                "profile_image": "https://www.gravatar.com/avatar/4486b103fdaec6a529467fc15710af8e?s=128&d=identicon&r=PG",
                "display_name": "mpipe3",
                "link": "https://stackoverflow.com/users/323058/mpipe3"
            },
            "is_answered": true,
            "view_count": 2536,
            "answer_count": 5,
            "score": 8,
            "last_activity_date": 1526458256,
            "creation_date": 1309942139,
            "last_edit_date": 1526458256,
            "question_id": 6593770,
            "body_markdown": "I&#39;m working on a mult-threaded program, but have a UI component that makes extensive use of std::shared_ptr to manage elements. I can guarantee that only one thread will ever use these shared_ptrs.\r\n\r\nIs there a way to define a shared_ptr that doesn&#39;t incur the overhead of thread safe reference counting?\r\n\r\nIt could be based on boost::shared_ptr or std::shared_ptr.\r\n\r\nEDIT: Thanks for answers mentioning intrusive_ptr. I neglected to mention that I also need weak_ptr functionality so that rules it out.\r\n\r\nUPDATE: The answer for me is to use local_shared_ptr from Boost. See comment from &#39;he rambled&#39;",
            "link": "https://stackoverflow.com/questions/6593770/creating-a-non-thread-safe-shared-ptr",
            "title": "Creating a non-thread safe shared_ptr",
            "body": "<p>I'm working on a mult-threaded program, but have a UI component that makes extensive use of std::shared_ptr to manage elements. I can guarantee that only one thread will ever use these shared_ptrs.</p>\n\n<p>Is there a way to define a shared_ptr that doesn't incur the overhead of thread safe reference counting?</p>\n\n<p>It could be based on boost::shared_ptr or std::shared_ptr.</p>\n\n<p>EDIT: Thanks for answers mentioning intrusive_ptr. I neglected to mention that I also need weak_ptr functionality so that rules it out.</p>\n\n<p>UPDATE: The answer for me is to use local_shared_ptr from Boost. See comment from 'he rambled'</p>\n"
        },
        {
            "tags": [
                "ruby-on-rails",
                "rubygems"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 8204428,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/9b61a76a79e2c8d0575c1c409a8003e4?s=128&d=identicon&r=PG&f=1",
                "display_name": "Mamadou Ali",
                "link": "https://stackoverflow.com/users/8204428/mamadou-ali"
            },
            "is_answered": false,
            "view_count": 25,
            "closed_date": 1526460517,
            "answer_count": 0,
            "score": -4,
            "last_activity_date": 1526458245,
            "creation_date": 1526457871,
            "last_edit_date": 1526458245,
            "question_id": 50365454,
            "body_markdown": "I&#39;m looking for a gem or a system to let my users ban or block each other like on facebook or instagram.",
            "link": "https://stackoverflow.com/questions/50365454/how-to-create-a-system-to-ban-or-block-a-user-in-rails",
            "closed_reason": "off-topic",
            "title": "How to create a system to ban or block a user in rails",
            "body": "<p>I'm looking for a gem or a system to let my users ban or block each other like on facebook or instagram.</p>\n"
        },
        {
            "tags": [
                "java",
                "html",
                "audio",
                "htmlunit"
            ],
            "owner": {
                "reputation": 383,
                "user_id": 2501213,
                "user_type": "registered",
                "accept_rate": 93,
                "profile_image": "https://i.stack.imgur.com/8Tu5N.jpg?s=128&g=1",
                "display_name": "Bruno BL",
                "link": "https://stackoverflow.com/users/2501213/bruno-bl"
            },
            "is_answered": true,
            "view_count": 177,
            "accepted_answer_id": 33369470,
            "answer_count": 2,
            "score": 0,
            "last_activity_date": 1526458240,
            "creation_date": 1438177592,
            "question_id": 31702323,
            "body_markdown": "before someone tells me that there&#39;s already this question here, i must say i&#39;ve tried basically every single example i&#39;ve found.\r\n\r\nThe url i&#39;m trying to download has a type of &#39;audio/wav&#39;, embedded in a video tag, or at least this is what i see when running Chrome&#39;s element inspector.\r\n\r\nThe matter is, the URL (which i can&#39;t post here) does not point to a .wav file nor anything, but to an ASP page, which seems to generate the audio.\r\n\r\nSo far so good, the problem here is that i can&#39;t really download the audio.\r\n\r\nBasically my webclient is created like:\r\n\r\n    WebClient webClient = new WebClient(BrowserVersion.FIREFOX_38); // Also tried Chrome here.\r\n    webClient.getOptions().setThrowExceptionOnScriptError(false);\r\n    webClient.getOptions().setUseInsecureSSL(true);\r\n    webClient.getOptions().setPopupBlockerEnabled(false);\r\n    webClient.setAjaxController(new NicelyResynchronizingAjaxController());\r\n    HtmlPage page = (HtmlPage)webClient.getPage(URL);\r\n\r\n\r\nI&#39;ve tried creating an anchor element that links to the page containing the audio file:\r\n\r\n    HtmlElement createdElement = (HtmlElement) page.createElement(&quot;a&quot;);\r\n    createdElement.setAttribute(&quot;id&quot;, &quot;link_som&quot;);\r\n    createdElement.setAttribute(&quot;href&quot;, &quot;../sound.asp?app=audio&quot;);\r\n    page.appendChild(createdElement);\r\n      \r\n    HtmlAnchor anc =(HtmlAnchor) page.getElementById(&quot;link_som&quot;, true); //tried this just to make sure it was returning the right anchor\r\n\r\n    InputStream inputStream = anc.click().getWebResponse().getContentAsStream();\r\n    //Writing the inputStream to a file generates a file which has 0 KB.\r\n\r\nAlso tried running the javascript that links to new URL through HtmlUnit:\r\n\r\n    ScriptResult resultado = page.executeJavaScript(&quot;window.open(&#39;../sound.asp?app=audio&#39;);&quot;);\r\n    webClient.waitForBackgroundJavaScript(5000);\r\n    HtmlPage paginaRes = (HtmlPage)resultado.getNewPage();\r\n\r\n    InputStream inputStream =paginaRes.getWebResponse().getContentAsStream(); //Here the inputStream also generates a 0 KB file\r\n\r\nInteresting though, is that in all those cases i tried, if i write the inputStream to the console, it returns the main page source, for example:\r\n\r\n    int binary = 0;\r\n    while ((binary = inputStream.read()) != -1)\r\n    {\r\n       System.out.print((char)binary); //prints the old page source, and in some other tests, prints nothing.\r\n    }\r\n\r\nPs.: When opening the URL on chrome manually, it has an embedded player, on FireFox, it asks for Quicktime.\r\n",
            "link": "https://stackoverflow.com/questions/31702323/download-wav-files-in-htmlunit",
            "title": "Download wav files in HTMLUnit",
            "body": "<p>before someone tells me that there's already this question here, i must say i've tried basically every single example i've found.</p>\n\n<p>The url i'm trying to download has a type of 'audio/wav', embedded in a video tag, or at least this is what i see when running Chrome's element inspector.</p>\n\n<p>The matter is, the URL (which i can't post here) does not point to a .wav file nor anything, but to an ASP page, which seems to generate the audio.</p>\n\n<p>So far so good, the problem here is that i can't really download the audio.</p>\n\n<p>Basically my webclient is created like:</p>\n\n<pre><code>WebClient webClient = new WebClient(BrowserVersion.FIREFOX_38); // Also tried Chrome here.\nwebClient.getOptions().setThrowExceptionOnScriptError(false);\nwebClient.getOptions().setUseInsecureSSL(true);\nwebClient.getOptions().setPopupBlockerEnabled(false);\nwebClient.setAjaxController(new NicelyResynchronizingAjaxController());\nHtmlPage page = (HtmlPage)webClient.getPage(URL);\n</code></pre>\n\n<p>I've tried creating an anchor element that links to the page containing the audio file:</p>\n\n<pre><code>HtmlElement createdElement = (HtmlElement) page.createElement(\"a\");\ncreatedElement.setAttribute(\"id\", \"link_som\");\ncreatedElement.setAttribute(\"href\", \"../sound.asp?app=audio\");\npage.appendChild(createdElement);\n\nHtmlAnchor anc =(HtmlAnchor) page.getElementById(\"link_som\", true); //tried this just to make sure it was returning the right anchor\n\nInputStream inputStream = anc.click().getWebResponse().getContentAsStream();\n//Writing the inputStream to a file generates a file which has 0 KB.\n</code></pre>\n\n<p>Also tried running the javascript that links to new URL through HtmlUnit:</p>\n\n<pre><code>ScriptResult resultado = page.executeJavaScript(\"window.open('../sound.asp?app=audio');\");\nwebClient.waitForBackgroundJavaScript(5000);\nHtmlPage paginaRes = (HtmlPage)resultado.getNewPage();\n\nInputStream inputStream =paginaRes.getWebResponse().getContentAsStream(); //Here the inputStream also generates a 0 KB file\n</code></pre>\n\n<p>Interesting though, is that in all those cases i tried, if i write the inputStream to the console, it returns the main page source, for example:</p>\n\n<pre><code>int binary = 0;\nwhile ((binary = inputStream.read()) != -1)\n{\n   System.out.print((char)binary); //prints the old page source, and in some other tests, prints nothing.\n}\n</code></pre>\n\n<p>Ps.: When opening the URL on chrome manually, it has an embedded player, on FireFox, it asks for Quicktime.</p>\n"
        },
        {
            "tags": [
                "elasticsearch",
                "logstash"
            ],
            "owner": {
                "reputation": 164,
                "user_id": 9073330,
                "user_type": "registered",
                "profile_image": "https://i.stack.imgur.com/lWmUw.png?s=128&g=1",
                "display_name": "Ashok",
                "link": "https://stackoverflow.com/users/9073330/ashok"
            },
            "is_answered": false,
            "view_count": 20,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1526458240,
            "creation_date": 1526448464,
            "last_edit_date": 1526458240,
            "question_id": 50363021,
            "body_markdown": "I have installed Logstash,elasticsearch and kibana in single instance and installed X-pack also for TLS communication. enabled ssl communication in elasticsearch and kibana working good but logstash unable to connect elasticsearch , but i can curl elasticsearch url https://localhost:9200 there is no firewall blocking also, \r\nI have generated open ssl certificate and key file  and kept in elasticsearch \r\n\r\n\r\n\r\n\r\n\r\n    input {\r\n      beats {\r\n         client_inactivity_timeout =&gt; 1000\r\n         port =&gt; 5044\r\n      }\r\n    }\r\n\r\n    filter {\r\n      grok {\r\n        match =&gt; [ &quot;message&quot;, &quot;%{TIMESTAMP_ISO8601} %{LOGLEVEL:loglevel} zeppelin IDExtractionService transactionId %{WORD:transaction_id} operation %{WORD:otype} received request duration %{NUMBER:duration} exception %{WORD:error}&quot; ]\r\n      }\r\n    }\r\n    filter {\r\n        if &quot;beats_input_codec_plain_applied&quot; in [tags] {\r\n            mutate {\r\n                remove_tag =&gt; [&quot;beats_input_codec_plain_applied&quot;]\r\n            }\r\n        }\r\n    }\r\n\r\n    filter {\r\n        if &quot;_grokparsefailure&quot; in [tags] {\r\n            mutate {\r\n                remove_tag =&gt; [&quot;_grokparsefailure&quot;]\r\n            }\r\n        }\r\n    }\r\n\r\n    xpack.monitoring.enabled: true\r\n    xpack.monitoring.elasticsearch.url: https://localhost:9200\r\n    output {\r\n      elasticsearch {\r\n        hosts =&gt; [&quot;http://localhost:9200&quot;]\r\n        user =&gt; elastic\r\n        password =&gt; password\r\n        manage_template =&gt; false\r\n    #    ssl_certificate_verification =&gt; false\r\n        ssl =&gt; true\r\n        cacert =&gt; &#39;/etc/elasticsearch/ca/key.pem&#39;\r\n        index =&gt; &quot;%{[@metadata][beat]}-%{+YYYY.MM.dd}&quot;\r\n\r\n      }\r\n    }\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nelastic search config file \r\n\r\n    cluster.name: my-application\r\n    network.host: 0.0.0.0\r\n    xpack.security.http.ssl.enabled: true\r\n    xpack.security.http.ssl.key:  /opt/elasticsearch/ca/ca.key\r\n    xpack.security.http.ssl.certificate: /opt/elasticsearch/ca/ca.crt\r\n\r\n\r\n\r\n\r\nlogstash log files\r\n\r\n    [2018-05-16T05:28:16,421][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;&quot;http://logstash_system:xxxxxx@localhost:9200/&quot;, :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;&quot;Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond&quot;}\r\n    [2018-05-16T05:28:17,201][WARN ][logstash.shutdownwatcher ] {&quot;inflight_count&quot;=&gt;1, &quot;stalling_thread_info&quot;=&gt;{&quot;other&quot;=&gt;[{&quot;thread_id&quot;=&gt;24, &quot;name&quot;=&gt;nil, &quot;current_call&quot;=&gt;&quot;[...]/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep&#39;&quot;}]}}\r\n    [2018-05-16T05:28:21,422][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://logstash_system:xxxxxx@localhost:9200/, :path=&gt;&quot;/&quot;}\r\n    [2018-05-16T05:28:21,422][INFO ][logstash.licensechecker.licensereader] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://logstash_system:xxxxxx@localhost:9200/, :path=&gt;&quot;/&quot;}\r\n    [2018-05-16T05:28:21,424][WARN ][logstash.licensechecker.licensereader] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;&quot;http://logstash_system:xxxxxx@localhost:9200/&quot;, :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;&quot;Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond&quot;}\r\n    [2018-05-16T05:28:21,425][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;&quot;http://logstash_system:xxxxxx@localhost:9200/&quot;, :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;&quot;Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond&quot;}\r\n    [2018-05-16T05:28:22,202][WARN ][logstash.shutdownwatcher ] {&quot;inflight_count&quot;=&gt;1, &quot;stalling_thread_info&quot;=&gt;{&quot;other&quot;=&gt;[{&quot;thread_id&quot;=&gt;24, &quot;name&quot;=&gt;nil, &quot;current_call&quot;=&gt;&quot;[...]/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep&#39;&quot;}]}}\r\n    [2018-05-16T05:28:26,425][INFO ][logstash.licensechecker.licensereader] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://logstash_system:xxxxxx@localhost:9200/, :path=&gt;&quot;/&quot;}\r\n    [2018-05-16T05:28:26,426][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://logstash_system:xxxxxx@localhost:9200/, :path=&gt;&quot;/&quot;}\r\n    [2018-05-16T05:28:26,427][WARN ][logstash.licensechecker.licensereader] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;&quot;http://logstash_system:xxxxxx@localhost:9200/&quot;, :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;&quot;Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond&quot;}\r\n    [2018-05-16T05:28:26,427][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;&quot;http://logstash_system:xxxxxx@localhost:9200/&quot;, :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;&quot;Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond&quot;}\r\n    [2018-05-16T05:28:27,201][WARN ][logstash.shutdownwatcher ] {&quot;inflight_count&quot;=&gt;1, &quot;stalling_thread_info&quot;=&gt;{&quot;other&quot;=&gt;[{&quot;thread_id&quot;=&gt;24, &quot;name&quot;=&gt;nil, &quot;current_call&quot;=&gt;&quot;[...]/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep&#39;&quot;}]}}\r\n    root@5c417caecc5f:/var/log/logstash#\r\n\r\n\r\n&lt;!-- end snippet --&gt;\r\n\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50363021/logstash-not-able-to-connect-secured-ssl-elastic-search-cluster",
            "title": "Logstash not able to connect secured (ssl) Elastic search cluster",
            "body": "<p>I have installed Logstash,elasticsearch and kibana in single instance and installed X-pack also for TLS communication. enabled ssl communication in elasticsearch and kibana working good but logstash unable to connect elasticsearch , but i can curl elasticsearch url <a href=\"https://localhost:9200\" rel=\"nofollow noreferrer\">https://localhost:9200</a> there is no firewall blocking also, \nI have generated open ssl certificate and key file  and kept in elasticsearch </p>\n\n<pre><code>input {\n  beats {\n     client_inactivity_timeout =&gt; 1000\n     port =&gt; 5044\n  }\n}\n\nfilter {\n  grok {\n    match =&gt; [ \"message\", \"%{TIMESTAMP_ISO8601} %{LOGLEVEL:loglevel} zeppelin IDExtractionService transactionId %{WORD:transaction_id} operation %{WORD:otype} received request duration %{NUMBER:duration} exception %{WORD:error}\" ]\n  }\n}\nfilter {\n    if \"beats_input_codec_plain_applied\" in [tags] {\n        mutate {\n            remove_tag =&gt; [\"beats_input_codec_plain_applied\"]\n        }\n    }\n}\n\nfilter {\n    if \"_grokparsefailure\" in [tags] {\n        mutate {\n            remove_tag =&gt; [\"_grokparsefailure\"]\n        }\n    }\n}\n\nxpack.monitoring.enabled: true\nxpack.monitoring.elasticsearch.url: https://localhost:9200\noutput {\n  elasticsearch {\n    hosts =&gt; [\"http://localhost:9200\"]\n    user =&gt; elastic\n    password =&gt; password\n    manage_template =&gt; false\n#    ssl_certificate_verification =&gt; false\n    ssl =&gt; true\n    cacert =&gt; '/etc/elasticsearch/ca/key.pem'\n    index =&gt; \"%{[@metadata][beat]}-%{+YYYY.MM.dd}\"\n\n  }\n}\n</code></pre>\n\n<p>elastic search config file </p>\n\n<pre><code>cluster.name: my-application\nnetwork.host: 0.0.0.0\nxpack.security.http.ssl.enabled: true\nxpack.security.http.ssl.key:  /opt/elasticsearch/ca/ca.key\nxpack.security.http.ssl.certificate: /opt/elasticsearch/ca/ca.crt\n</code></pre>\n\n<p>logstash log files</p>\n\n<pre><code>[2018-05-16T05:28:16,421][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;\"http://logstash_system:xxxxxx@localhost:9200/\", :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;\"Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond\"}\n[2018-05-16T05:28:17,201][WARN ][logstash.shutdownwatcher ] {\"inflight_count\"=&gt;1, \"stalling_thread_info\"=&gt;{\"other\"=&gt;[{\"thread_id\"=&gt;24, \"name\"=&gt;nil, \"current_call\"=&gt;\"[...]/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'\"}]}}\n[2018-05-16T05:28:21,422][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://logstash_system:xxxxxx@localhost:9200/, :path=&gt;\"/\"}\n[2018-05-16T05:28:21,422][INFO ][logstash.licensechecker.licensereader] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://logstash_system:xxxxxx@localhost:9200/, :path=&gt;\"/\"}\n[2018-05-16T05:28:21,424][WARN ][logstash.licensechecker.licensereader] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;\"http://logstash_system:xxxxxx@localhost:9200/\", :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;\"Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond\"}\n[2018-05-16T05:28:21,425][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;\"http://logstash_system:xxxxxx@localhost:9200/\", :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;\"Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond\"}\n[2018-05-16T05:28:22,202][WARN ][logstash.shutdownwatcher ] {\"inflight_count\"=&gt;1, \"stalling_thread_info\"=&gt;{\"other\"=&gt;[{\"thread_id\"=&gt;24, \"name\"=&gt;nil, \"current_call\"=&gt;\"[...]/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'\"}]}}\n[2018-05-16T05:28:26,425][INFO ][logstash.licensechecker.licensereader] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://logstash_system:xxxxxx@localhost:9200/, :path=&gt;\"/\"}\n[2018-05-16T05:28:26,426][INFO ][logstash.outputs.elasticsearch] Running health check to see if an Elasticsearch connection is working {:healthcheck_url=&gt;http://logstash_system:xxxxxx@localhost:9200/, :path=&gt;\"/\"}\n[2018-05-16T05:28:26,427][WARN ][logstash.licensechecker.licensereader] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;\"http://logstash_system:xxxxxx@localhost:9200/\", :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;\"Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond\"}\n[2018-05-16T05:28:26,427][WARN ][logstash.outputs.elasticsearch] Attempted to resurrect connection to dead ES instance, but got an error. {:url=&gt;\"http://logstash_system:xxxxxx@localhost:9200/\", :error_type=&gt;LogStash::Outputs::ElasticSearch::HttpClient::Pool::HostUnreachableError, :error=&gt;\"Elasticsearch Unreachable: [http://logstash_system:xxxxxx@localhost:9200/][Manticore::ClientProtocolException] localhost:9200 failed to respond\"}\n[2018-05-16T05:28:27,201][WARN ][logstash.shutdownwatcher ] {\"inflight_count\"=&gt;1, \"stalling_thread_info\"=&gt;{\"other\"=&gt;[{\"thread_id\"=&gt;24, \"name\"=&gt;nil, \"current_call\"=&gt;\"[...]/vendor/bundle/jruby/2.3.0/gems/stud-0.0.23/lib/stud/interval.rb:89:in `sleep'\"}]}}\nroot@5c417caecc5f:/var/log/logstash#\n</code></pre>\n\n\n"
        },
        {
            "tags": [
                "tfs",
                "vsts",
                "vstest",
                "vstest.console"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 6278274,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/bd23cd6f943f8eb9e806e29ec967fdaf?s=128&d=identicon&r=PG&f=1",
                "display_name": "Deividito",
                "link": "https://stackoverflow.com/users/6278274/deividito"
            },
            "is_answered": true,
            "view_count": 32,
            "closed_date": 1526458203,
            "accepted_answer_id": 50147458,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526458240,
            "creation_date": 1525261070,
            "last_edit_date": 1526458240,
            "question_id": 50133795,
            "body_markdown": "I&#39;m running test on vstest.console.exe. How to specify the location of results file?\r\n\r\n    vstest.console.exe [TestLocation] /Logger:trx /Platform:x64 /InIsolation /Tests:[Testname]\r\n\r\n**SOLUTION: Run tests from the folder, where I want my &quot;TestResults&quot; appear**",
            "link": "https://stackoverflow.com/questions/50133795/vstest-console-exe-specify-output-file-location-via-command-line",
            "closed_reason": "duplicate",
            "title": "vstest.console.exe - Specify output file location via command line",
            "body": "<p>I'm running test on vstest.console.exe. How to specify the location of results file?</p>\n\n<pre><code>vstest.console.exe [TestLocation] /Logger:trx /Platform:x64 /InIsolation /Tests:[Testname]\n</code></pre>\n\n<p><strong>SOLUTION: Run tests from the folder, where I want my \"TestResults\" appear</strong></p>\n"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 63
}