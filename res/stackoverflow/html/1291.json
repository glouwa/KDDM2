{
    "items": [
        {
            "tags": [
                "amazon-web-services",
                "aws-lambda",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 57,
                "user_id": 6518797,
                "user_type": "registered",
                "accept_rate": 0,
                "profile_image": "https://www.gravatar.com/avatar/70c0dce66cf0e9fd5a74407e2274bd69?s=128&d=identicon&r=PG&f=1",
                "display_name": "Sal",
                "link": "https://stackoverflow.com/users/6518797/sal"
            },
            "is_answered": false,
            "view_count": 60,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526449756,
            "creation_date": 1522782608,
            "last_edit_date": 1526449756,
            "question_id": 49637503,
            "body_markdown": "We are contemplating using Amazon web services for our project. Wherein the upstream flow will push the messages into the kinesis and later those messages will be fed into the lambdas, those messages before processing are going to be in order. As per my understanding, the AWS lambdas will scale out horizontally based on the volume of the messages.  We have a volume of 400 messages per second, which means AWS lambda will respond to message volume and will instantiate new processes on separate containers to leverage parallelism and in order to achieve parallelism, ordering has to be compromised. So in case of 10 messages, which were ordered, hit the lambda functions and one function takes more time than another, a new function will be provisioned in some container by the AWS to serve the request. \r\n\r\nIs the final output going to be in order after all of this processes?\r\nAny help is appreciated.\r\nThanks.",
            "link": "https://stackoverflow.com/questions/49637503/does-lambdas-execute-operations-in-sequence",
            "title": "Does lambdas execute operations in sequence.?",
            "body": "<p>We are contemplating using Amazon web services for our project. Wherein the upstream flow will push the messages into the kinesis and later those messages will be fed into the lambdas, those messages before processing are going to be in order. As per my understanding, the AWS lambdas will scale out horizontally based on the volume of the messages.  We have a volume of 400 messages per second, which means AWS lambda will respond to message volume and will instantiate new processes on separate containers to leverage parallelism and in order to achieve parallelism, ordering has to be compromised. So in case of 10 messages, which were ordered, hit the lambda functions and one function takes more time than another, a new function will be provisioned in some container by the AWS to serve the request. </p>\n\n<p>Is the final output going to be in order after all of this processes?\nAny help is appreciated.\nThanks.</p>\n"
        },
        {
            "tags": [
                "amazon-web-services",
                "amazon-s3",
                "amazon-redshift",
                "amazon-kinesis",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 56,
                "user_id": 2682394,
                "user_type": "registered",
                "accept_rate": 88,
                "profile_image": "https://graph.facebook.com/1832077718/picture?type=large",
                "display_name": "Krishnakanth Jc",
                "link": "https://stackoverflow.com/users/2682394/krishnakanth-jc"
            },
            "is_answered": true,
            "view_count": 32,
            "accepted_answer_id": 49535760,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526449750,
            "creation_date": 1522175577,
            "last_edit_date": 1526449750,
            "question_id": 49520128,
            "body_markdown": "Any suggested architecture ?\r\n\r\n 1. For the first full load, using Kinesis, how do I automate it so that it creates different streams for different tables. (Is this the way to do it?)\r\n 2. Incase if there is a new additional table, how do I create a new stream automatically.\r\n3.How do I load to Kinesis incrementally (whenever the data is populated )\r\n\r\nAny resources/ architectures will be definitely helpful. Using Kinesis because multiple other down stream consumers might access this data in future.\r\n ",
            "link": "https://stackoverflow.com/questions/49520128/migrate-from-oracle-rdbms-to-aws-s3-with-kinesis",
            "title": "Migrate from Oracle RDBMS to AWS S3 with Kinesis",
            "body": "<p>Any suggested architecture ?</p>\n\n<ol>\n<li>For the first full load, using Kinesis, how do I automate it so that it creates different streams for different tables. (Is this the way to do it?)</li>\n<li>Incase if there is a new additional table, how do I create a new stream automatically.\n3.How do I load to Kinesis incrementally (whenever the data is populated )</li>\n</ol>\n\n<p>Any resources/ architectures will be definitely helpful. Using Kinesis because multiple other down stream consumers might access this data in future.</p>\n"
        },
        {
            "tags": [
                "amazon-web-services",
                "amazon-s3",
                "aws-sdk",
                "amazon-kinesis",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 356,
                "user_id": 7926479,
                "user_type": "registered",
                "accept_rate": 73,
                "profile_image": "https://lh4.googleusercontent.com/-h0cTmvESd2U/AAAAAAAAAAI/AAAAAAAAAG0/AgASXHA7WdQ/photo.jpg?sz=128",
                "display_name": "Andres Angel",
                "link": "https://stackoverflow.com/users/7926479/andres-angel"
            },
            "is_answered": false,
            "view_count": 20,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526449736,
            "creation_date": 1521737753,
            "last_edit_date": 1526449736,
            "question_id": 49434313,
            "body_markdown": "Well, I have a web page (PHP) that is running on-premise and it&#39;s accessed from different countries. I would like to catch some data and store it somewhere. I can handle internally with the team the data and the format of the file to catch the info. But we would like to get leverage of AWS to store it in S3. So we notice that we need an intermedium layer to avoid use AWS credentials required for S3.\r\n\r\nas this page is on the internet and it&#39;s consumed by a user thru web for sure we don&#39;t want to include anything for credentials embedded in the site. So likely Kinesis data firehose as consumer role could just catch the data send by our page and then internally store it in S3.\r\n\r\n**Question**\r\n\r\nI see that exist an SDK for Kinesis but it requires AWS credentials. We really need a kind of link where we need the data produced and AWS handles the rest. But I don&#39;t know why I require to set up AWS credentials using the SDK. Does it mean then that our website will load and live with our credentials? I don&#39;t feel this approach secure. I appreciate the comments.",
            "link": "https://stackoverflow.com/questions/49434313/kinesis-data-firehose-set-with-a-web-page",
            "title": "Kinesis Data Firehose set with a web page",
            "body": "<p>Well, I have a web page (PHP) that is running on-premise and it's accessed from different countries. I would like to catch some data and store it somewhere. I can handle internally with the team the data and the format of the file to catch the info. But we would like to get leverage of AWS to store it in S3. So we notice that we need an intermedium layer to avoid use AWS credentials required for S3.</p>\n\n<p>as this page is on the internet and it's consumed by a user thru web for sure we don't want to include anything for credentials embedded in the site. So likely Kinesis data firehose as consumer role could just catch the data send by our page and then internally store it in S3.</p>\n\n<p><strong>Question</strong></p>\n\n<p>I see that exist an SDK for Kinesis but it requires AWS credentials. We really need a kind of link where we need the data produced and AWS handles the rest. But I don't know why I require to set up AWS credentials using the SDK. Does it mean then that our website will load and live with our credentials? I don't feel this approach secure. I appreciate the comments.</p>\n"
        },
        {
            "tags": [
                "node.js",
                "mongodb"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 8682933,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/44d629de4eb9767cf3ed4b736a5f2795?s=128&d=identicon&r=PG&f=1",
                "display_name": "Chaitanya",
                "link": "https://stackoverflow.com/users/8682933/chaitanya"
            },
            "is_answered": false,
            "view_count": 22,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449735,
            "creation_date": 1526449735,
            "question_id": 50363263,
            "body_markdown": "I have collection in Mongo Db Like this\r\n\r\n    ( [\r\n       { EmployeeId: &quot;123&quot;, qty: 100, status: &quot;A&quot;},\r\n       { EmployeeId: &quot;456&quot;, qty: 25, status: &quot;A&quot;},\r\n       { EmployeeId: &quot;789&quot;, qty: 85, status: &quot;A&quot;}\r\n    ]);\r\n\r\nNow i have other data coming from Json which contains EmployeeId in it Like below:\r\n\r\n    ( [\r\n      { EmployeeId: &quot;123&quot;, Designation: &quot;manager&quot;},\r\n      { EmployeeId: &quot;456&quot;, Designation: &quot;Lead&quot;},\r\n      { EmployeeId: &quot;789&quot;, Designation:&quot;Developer&quot;}\r\n    ]);\r\n\r\nI want to update all the records in the first collection at once based on the EmployeeId which is common in Json and MongodB collection.\r\n\r\nIs there any possibility to achieve that in NodeJs.\r\n",
            "link": "https://stackoverflow.com/questions/50363263/how-to-update-one-collection-in-mongodb-based-on-other-json-data",
            "title": "How to update one collection in Mongodb based on other Json data",
            "body": "<p>I have collection in Mongo Db Like this</p>\n\n<pre><code>( [\n   { EmployeeId: \"123\", qty: 100, status: \"A\"},\n   { EmployeeId: \"456\", qty: 25, status: \"A\"},\n   { EmployeeId: \"789\", qty: 85, status: \"A\"}\n]);\n</code></pre>\n\n<p>Now i have other data coming from Json which contains EmployeeId in it Like below:</p>\n\n<pre><code>( [\n  { EmployeeId: \"123\", Designation: \"manager\"},\n  { EmployeeId: \"456\", Designation: \"Lead\"},\n  { EmployeeId: \"789\", Designation:\"Developer\"}\n]);\n</code></pre>\n\n<p>I want to update all the records in the first collection at once based on the EmployeeId which is common in Json and MongodB collection.</p>\n\n<p>Is there any possibility to achieve that in NodeJs.</p>\n"
        },
        {
            "tags": [
                "angular",
                "angular5",
                "angular-forms"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 8374878,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/06cf610de7841e1ff059f9de17707a7e?s=128&d=identicon&r=PG&f=1",
                "display_name": "Dinesh Bade",
                "link": "https://stackoverflow.com/users/8374878/dinesh-bade"
            },
            "is_answered": false,
            "view_count": 22,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449734,
            "creation_date": 1526449734,
            "question_id": 50363262,
            "body_markdown": "I have been facing some issue on angular project on my project. Currently i am using angular 5 and template driven form method.\r\n I have created sample here. \r\nhttps://stackblitz.com/edit/angular-qzhncw\r\n\r\nThe second select field should be filled based on value select from first.\r\nthe list shows fine but while i change second select field value and the again change first field the second field get extra blank filed . How could i fix this issu?\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50363262/angular-5-template-drive-form-issue-of-dynamic-rendering-select-field-as-one-fie",
            "title": "Angular 5 template drive form issue of dynamic rendering select field as one field changes",
            "body": "<p>I have been facing some issue on angular project on my project. Currently i am using angular 5 and template driven form method.\n I have created sample here. \n<a href=\"https://stackblitz.com/edit/angular-qzhncw\" rel=\"nofollow noreferrer\">https://stackblitz.com/edit/angular-qzhncw</a></p>\n\n<p>The second select field should be filled based on value select from first.\nthe list shows fine but while i change second select field value and the again change first field the second field get extra blank filed . How could i fix this issu?</p>\n"
        },
        {
            "tags": [
                "vue.js",
                "iview"
            ],
            "owner": {
                "reputation": 583,
                "user_id": 7693832,
                "user_type": "registered",
                "accept_rate": 66,
                "profile_image": "https://www.gravatar.com/avatar/2c0da9e13f9bb292355a6d48bd9300f6?s=128&d=identicon&r=PG&f=1",
                "display_name": "244boy",
                "link": "https://stackoverflow.com/users/7693832/244boy"
            },
            "is_answered": false,
            "view_count": 15,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526449728,
            "creation_date": 1523514380,
            "question_id": 49789432,
            "body_markdown": "I use &lt;a href=&quot;https://www.iviewui.com/components/modal&quot;&gt;iView&#39;s Modal&lt;/a&gt;:\r\n\r\nI try to popup a more modal in the modal&#39;s function:\r\n\r\n         this.$Modal.confirm({\r\n          render: (h) =&gt; {\r\n            return h(&#39;Button&#39;, {\r\n              props: {\r\n                value: this.value,\r\n                type: &#39;primary&#39;,\r\n              },\r\n\r\n              on: {\r\n                click: function (e) {\r\n                  // There I want to popup a more Modal，but the `this`is `null` \r\n                  this.$Modal.confirm({\r\n                    render: (h) =&gt; {\r\n                      return h(&#39;Input&#39;, {\r\n\r\n                      })\r\n                    }\r\n                  })\r\n                }\r\n              }\r\n            })\r\n          }\r\n        })\r\n\r\nYou see, I use the `render` function to generate the modal content, but the button in it can not invoke my requirement code now, because I can not use the `this` in there.",
            "link": "https://stackoverflow.com/questions/49789432/whether-i-can-pop-up-a-more-modal-of-iview",
            "title": "Whether I can pop up a more modal of iView?",
            "body": "<p>I use <a href=\"https://www.iviewui.com/components/modal\" rel=\"nofollow noreferrer\">iView's Modal</a>:</p>\n\n<p>I try to popup a more modal in the modal's function:</p>\n\n<pre><code>     this.$Modal.confirm({\n      render: (h) =&gt; {\n        return h('Button', {\n          props: {\n            value: this.value,\n            type: 'primary',\n          },\n\n          on: {\n            click: function (e) {\n              // There I want to popup a more Modal，but the `this`is `null` \n              this.$Modal.confirm({\n                render: (h) =&gt; {\n                  return h('Input', {\n\n                  })\n                }\n              })\n            }\n          }\n        })\n      }\n    })\n</code></pre>\n\n<p>You see, I use the <code>render</code> function to generate the modal content, but the button in it can not invoke my requirement code now, because I can not use the <code>this</code> in there.</p>\n"
        },
        {
            "tags": [
                "json",
                "amazon-redshift",
                "amazon-kinesis",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "user_type": "does_not_exist",
                "display_name": "user9455355"
            },
            "is_answered": false,
            "view_count": 18,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449727,
            "creation_date": 1520592582,
            "last_edit_date": 1526449727,
            "question_id": 49192053,
            "body_markdown": "Below is the scenario I am trying to achieve.\r\nWrite twitter data to kinesis data stream . From the data stream write to redshift\r\n\r\nBelow is the content of the S3 file from intermediate location \r\n\r\n    {&quot;user&quot;: &quot;Jayant Baghel&quot;, &quot;created_at&quot;: &quot;Fri Mar 09 10:12:32 +0000 2018&quot;, &quot;text&quot;: &quot;RT @tehseenp: Live now on @TimesNow\\\\nWith @AnchorAnandN on #ChandrababuNaidu\\\\n#TDPPullsOut of the Union Cabinet .\\\\nTune in&quot;, &quot;sentiment&quot;: &quot;Positive&quot;, &quot;location&quot;: &quot;Dongargarh, India&quot;}{&quot;user&quot;: &quot;kulasekaran tamil&quot;, &quot;created_at&quot;: &quot;Fri Mar 09 10:14:24 +0000 2018&quot;, &quot;text&quot;: &quot;RT @republic: As #TDPPullsOut, is it an opportunity for the BJP in Andhra Pradesh? &quot;, &quot;sentiment&quot;: &quot;Neutral&quot;, &quot;location&quot;: null}  \r\n\r\nSo it has 2 rows with 5 columns each.\r\nThe below copy command is executing \r\n\r\n    COPY testing (user_name,created_at,text_user,sentiment,user_location) FROM &#39;s3://redshiftpratik/&lt;manifest&gt;&#39; CREDENTIALS &#39;aws_iam_role=arn:aws:iam::&lt;aws-account-id&gt;:role/&lt;role-name&gt;&#39; MANIFEST delimiter as &#39;,&#39;\r\n\r\nAnd it&#39;s failing with below error \r\n\r\n    Extra column(s) found  \r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49192053/json-data-to-redshift-load-error",
            "title": "Json Data to redshift load error",
            "body": "<p>Below is the scenario I am trying to achieve.\nWrite twitter data to kinesis data stream . From the data stream write to redshift</p>\n\n<p>Below is the content of the S3 file from intermediate location </p>\n\n<pre><code>{\"user\": \"Jayant Baghel\", \"created_at\": \"Fri Mar 09 10:12:32 +0000 2018\", \"text\": \"RT @tehseenp: Live now on @TimesNow\\\\nWith @AnchorAnandN on #ChandrababuNaidu\\\\n#TDPPullsOut of the Union Cabinet .\\\\nTune in\", \"sentiment\": \"Positive\", \"location\": \"Dongargarh, India\"}{\"user\": \"kulasekaran tamil\", \"created_at\": \"Fri Mar 09 10:14:24 +0000 2018\", \"text\": \"RT @republic: As #TDPPullsOut, is it an opportunity for the BJP in Andhra Pradesh? \", \"sentiment\": \"Neutral\", \"location\": null}  \n</code></pre>\n\n<p>So it has 2 rows with 5 columns each.\nThe below copy command is executing </p>\n\n<pre><code>COPY testing (user_name,created_at,text_user,sentiment,user_location) FROM 's3://redshiftpratik/&lt;manifest&gt;' CREDENTIALS 'aws_iam_role=arn:aws:iam::&lt;aws-account-id&gt;:role/&lt;role-name&gt;' MANIFEST delimiter as ','\n</code></pre>\n\n<p>And it's failing with below error </p>\n\n<pre><code>Extra column(s) found  \n</code></pre>\n"
        },
        {
            "tags": [
                "postgresql-9.3",
                "squirrel-sql"
            ],
            "owner": {
                "reputation": 3,
                "user_id": 8140939,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e7723de94184a878ee9cc4678df3b55b?s=128&d=identicon&r=PG&f=1",
                "display_name": "bollsg",
                "link": "https://stackoverflow.com/users/8140939/bollsg"
            },
            "is_answered": true,
            "view_count": 12,
            "accepted_answer_id": 50363085,
            "answer_count": 1,
            "score": -1,
            "last_activity_date": 1526449727,
            "creation_date": 1526443645,
            "last_edit_date": 1526447441,
            "question_id": 50362321,
            "body_markdown": "I am trying to run a function on Squirrel connected to PostgresDB. I am unable to execute functions or stored procedures. example: when i run \r\n\r\n    exec pglog_read(&#39;Thu&#39;);\r\n\r\nI get the following error\r\n\r\n    Error: ERROR: syntax error at or near &quot;exec&quot;\r\n      Position: 1\r\n    SQLState:  42601\r\n    ErrorCode: 0\r\n\r\nAm i Missing anything.\r\n\r\nI have checked for plugins and the following have been installed. [list of plugins on my squirrel client][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/Yjakb.png",
            "link": "https://stackoverflow.com/questions/50362321/exec-for-functions-and-stored-procedures-on-squirrel-sql",
            "title": "exec for functions and stored procedures on squirrel-sql",
            "body": "<p>I am trying to run a function on Squirrel connected to PostgresDB. I am unable to execute functions or stored procedures. example: when i run </p>\n\n<pre><code>exec pglog_read('Thu');\n</code></pre>\n\n<p>I get the following error</p>\n\n<pre><code>Error: ERROR: syntax error at or near \"exec\"\n  Position: 1\nSQLState:  42601\nErrorCode: 0\n</code></pre>\n\n<p>Am i Missing anything.</p>\n\n<p>I have checked for plugins and the following have been installed. <a href=\"https://i.stack.imgur.com/Yjakb.png\" rel=\"nofollow noreferrer\">list of plugins on my squirrel client</a></p>\n"
        },
        {
            "tags": [
                "vagrant",
                "homestead"
            ],
            "owner": {
                "reputation": 1462,
                "user_id": 589973,
                "user_type": "registered",
                "accept_rate": 54,
                "profile_image": "https://www.gravatar.com/avatar/483557a5f8b6fd52bef7c864204311c4?s=128&d=identicon&r=PG",
                "display_name": "jemz",
                "link": "https://stackoverflow.com/users/589973/jemz"
            },
            "is_answered": true,
            "view_count": 17892,
            "accepted_answer_id": 32731867,
            "answer_count": 3,
            "score": 12,
            "last_activity_date": 1526449725,
            "creation_date": 1442986127,
            "question_id": 32731629,
            "body_markdown": "Hi I want to edit the config.vm.boot_timeout in vagrant because I am having problem in booting up the vagrant. where i can find the config.vm.boot_timeout ?and what value should i put ? I am in windows8.1 x86\r\n\r\n[![enter image description here][1]][1]\r\nThank you in advance.\r\n\r\n\r\n  [1]: http://i.stack.imgur.com/sewLQ.png",
            "link": "https://stackoverflow.com/questions/32731629/where-to-find-config-vm-boot-timeout",
            "title": "where to find config.vm.boot_timeout?",
            "body": "<p>Hi I want to edit the config.vm.boot_timeout in vagrant because I am having problem in booting up the vagrant. where i can find the config.vm.boot_timeout ?and what value should i put ? I am in windows8.1 x86</p>\n\n<p><a href=\"https://i.stack.imgur.com/sewLQ.png\"><img src=\"https://i.stack.imgur.com/sewLQ.png\" alt=\"enter image description here\"></a>\nThank you in advance.</p>\n"
        },
        {
            "tags": [
                "aws-lambda",
                "amazon-kinesis",
                "aws-iam",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 66,
                "user_id": 2430002,
                "user_type": "registered",
                "accept_rate": 89,
                "profile_image": "https://www.gravatar.com/avatar/ac49166b460ba2e284ac636da21950c2?s=128&d=identicon&r=PG",
                "display_name": "Nathan Brown",
                "link": "https://stackoverflow.com/users/2430002/nathan-brown"
            },
            "is_answered": true,
            "view_count": 105,
            "accepted_answer_id": 49372897,
            "answer_count": 3,
            "score": 0,
            "last_activity_date": 1526449722,
            "creation_date": 1520536100,
            "last_edit_date": 1526449722,
            "question_id": 49180688,
            "body_markdown": "I&#39;m trying to set up Lambda transformations with a Firehose delivery stream. I have an IAM role defined for the Firehose which includes the following policy document:\r\n\r\n    {\r\n        &quot;Statement&quot;: {\r\n            &quot;Action&quot;: [\r\n                &quot;lambda:InvokeFunction&quot;,\r\n                &quot;lambda:GetFunctionConfiguration&quot;\r\n            ],\r\n            &quot;Resource&quot;: [&lt;Arn&gt;, ...],\r\n            &quot;Effect&quot;: &quot;Allow&quot;\r\n        }\r\n    }\r\n\r\nI&#39;ve also granted sts:AssumeRole access to the Lambda role from Firehose.\r\n\r\nThis should theoretically grant my Firehose &quot;Invoke&quot; access to the specified lambda ARNs. But the transforms are failing with\r\n\r\n    {\r\n      &quot;errorCode&quot;:&quot;Lambda.InvokeAccessDenied&quot;,\r\n      &quot;errorMessage&quot;:&quot;Access was denied. Ensure that the access policy allows access to the Lambda function.&quot;\r\n    }\r\n\r\nand no function invocations are apparent from the Lambda console. Do I have my IAM components configured correctly? Or could something else be going wrong here?\r\n",
            "link": "https://stackoverflow.com/questions/49180688/lambda-invokeaccessdenied-from-kinesis-firehose",
            "title": "Lambda.InvokeAccessDenied from Kinesis Firehose",
            "body": "<p>I'm trying to set up Lambda transformations with a Firehose delivery stream. I have an IAM role defined for the Firehose which includes the following policy document:</p>\n\n<pre><code>{\n    \"Statement\": {\n        \"Action\": [\n            \"lambda:InvokeFunction\",\n            \"lambda:GetFunctionConfiguration\"\n        ],\n        \"Resource\": [&lt;Arn&gt;, ...],\n        \"Effect\": \"Allow\"\n    }\n}\n</code></pre>\n\n<p>I've also granted sts:AssumeRole access to the Lambda role from Firehose.</p>\n\n<p>This should theoretically grant my Firehose \"Invoke\" access to the specified lambda ARNs. But the transforms are failing with</p>\n\n<pre><code>{\n  \"errorCode\":\"Lambda.InvokeAccessDenied\",\n  \"errorMessage\":\"Access was denied. Ensure that the access policy allows access to the Lambda function.\"\n}\n</code></pre>\n\n<p>and no function invocations are apparent from the Lambda console. Do I have my IAM components configured correctly? Or could something else be going wrong here?</p>\n"
        },
        {
            "tags": [
                "amazon-web-services",
                "amazon-iam",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 302,
                "user_id": 4079138,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/a452e097a5e178b3ab009c0bc3b05562?s=128&d=identicon&r=PG",
                "display_name": "Paladin",
                "link": "https://stackoverflow.com/users/4079138/paladin"
            },
            "is_answered": false,
            "view_count": 94,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526449714,
            "creation_date": 1520437140,
            "last_edit_date": 1526449714,
            "question_id": 49155806,
            "body_markdown": "I am trying to create a Firehose delivery stream from an EC2 micro instance. \r\n\r\nAWS CLI is configured with the access keys of an IAM user ABC. This user has AWS policies attached with full access to firehose (policy copied below). \r\n\r\nStill the stream creation fails with the error `AccessDeniedException: iam user ABC not authorized to perform: firehose:CreateDeliveryStream on resource xxxx with an explicit deny`\r\n\r\n\r\n\r\n    {\r\n        &quot;Version&quot;: &quot;2012-10-17&quot;,\r\n        &quot;Statement&quot;: [\r\n            {\r\n                &quot;Effect&quot;: &quot;Allow&quot;,\r\n                &quot;Action&quot;: [\r\n                    &quot;firehose:*&quot;,\r\n                    &quot;firehose:CreateDeliveryStream&quot;\r\n                ],\r\n                &quot;Resource&quot;: [\r\n                    &quot;arn:aws:firehose:us-east-1:&lt;ACC_ID&gt;:deliverystream/*&quot;,\r\n                    &quot;arn:aws:firehose:us-east-1:&lt;ACC_ID&gt;:*&quot;,\r\n                    &quot;arn:aws:firehose:*:&lt;ACC_ID&gt;:*&quot;,\r\n                    &quot;arn:aws:firehose:*:&lt;ACC_ID&gt;:deliverystream/*&quot;\r\n                ]\r\n            }\r\n        ]\r\n    }\r\n\r\nDo I need to add more permissions to this IAM user to allow it to create delivery streams? ",
            "link": "https://stackoverflow.com/questions/49155806/iam-user-not-authorized-to-perform-firehosecreatedeliverystream-on-resource-xx",
            "title": "Iam user not authorized to perform: firehose:CreateDeliveryStream on resource xxxx with an explicit deny",
            "body": "<p>I am trying to create a Firehose delivery stream from an EC2 micro instance. </p>\n\n<p>AWS CLI is configured with the access keys of an IAM user ABC. This user has AWS policies attached with full access to firehose (policy copied below). </p>\n\n<p>Still the stream creation fails with the error <code>AccessDeniedException: iam user ABC not authorized to perform: firehose:CreateDeliveryStream on resource xxxx with an explicit deny</code></p>\n\n<pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"firehose:*\",\n                \"firehose:CreateDeliveryStream\"\n            ],\n            \"Resource\": [\n                \"arn:aws:firehose:us-east-1:&lt;ACC_ID&gt;:deliverystream/*\",\n                \"arn:aws:firehose:us-east-1:&lt;ACC_ID&gt;:*\",\n                \"arn:aws:firehose:*:&lt;ACC_ID&gt;:*\",\n                \"arn:aws:firehose:*:&lt;ACC_ID&gt;:deliverystream/*\"\n            ]\n        }\n    ]\n}\n</code></pre>\n\n<p>Do I need to add more permissions to this IAM user to allow it to create delivery streams? </p>\n"
        },
        {
            "tags": [
                "amazon-web-services",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 7260071,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/e61d1013272b27308963dc28e1171450?s=128&d=identicon&r=PG&f=1",
                "display_name": "urian",
                "link": "https://stackoverflow.com/users/7260071/urian"
            },
            "is_answered": false,
            "view_count": 107,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526449707,
            "creation_date": 1519979695,
            "last_edit_date": 1526449707,
            "question_id": 49065384,
            "body_markdown": "Stuck with the this problem for a week now.\r\nI honestly think it is a bug somewhere in us-east-1 with Kinesis Firehose at the moment.\r\n\r\nAt least they automatically create role with wrong Trust Relationship.\r\nHere is what created by default:\r\n(I changed userID to 123456 everywhere)\r\n\r\n    {\r\n    &quot;Version&quot;: &quot;2012-10-17&quot;,\r\n    &quot;Statement&quot;: [\r\n    {\r\n    &quot;Sid&quot;: &quot;&quot;,\r\n    &quot;Effect&quot;: &quot;Allow&quot;,\r\n    &quot;Principal&quot;: {\r\n    &quot;Service&quot;: &quot;firehose.amazonaws.com&quot;\r\n    },\r\n    &quot;Action&quot;: &quot;sts:AssumeRole&quot;,\r\n    &quot;Condition&quot;: {\r\n    &quot;StringEquals&quot;: {\r\n    &quot;sts:ExternalId&quot;: &quot;123456&quot;\r\n    }\r\n    }\r\n    }\r\n    ]\r\n    }\r\n\r\nWhen I try to call assume_role from my account I always get:\r\n\r\n    botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the AssumeRole operation: User: arn:aws:iam::123456:user/fh is not authorized to perform: sts:AssumeRole on resource: arn:aws:iam::123456:role/firehose_delivery_role2\r\n\r\nUser fh has AdministratorAccess policy.\r\n\r\nInstead you need to use following trust relation which actually works:\r\n\r\n    {\r\n    &quot;Version&quot;: &quot;2012-10-17&quot;,\r\n    &quot;Statement&quot;: [\r\n    {\r\n    &quot;Sid&quot;: &quot;&quot;,\r\n    &quot;Effect&quot;: &quot;Allow&quot;,\r\n    &quot;Principal&quot;: {\r\n    &quot;AWS&quot;: &quot;arn:aws:iam::123456:root&quot;\r\n    },\r\n    &quot;Action&quot;: &quot;sts:AssumeRole&quot;\r\n    }\r\n    ]\r\n    }\r\n\r\nBut doesn&#39;t matter what I do, I always got following message when try to put anything to firehose:\r\n\r\n    botocore.errorfactory.ResourceNotFoundException: An error occurred (ResourceNotFoundException) when calling the PutRecord operation: Stream test3 under account 123456 not found.\r\n\r\nTrying to access it with admin account and without assume_role got me the same result.\r\n\r\nMy test3 stream delivers data to my elasticsearch.\r\n\r\nCan someone create new elasticsearch, kinesis firehose stream and test data delivery? Ideally from python/boto3.\r\n\r\nHere is example of code. do not look at variable names ;)\r\n\r\n    import boto3\r\n    import json\r\n    from datetime import datetime\r\n    import calendar\r\n    import random\r\n    import time\r\n    \r\n    my_stream_name = &#39;python-stream&#39;\r\n    \r\n    kinesis_client = boto3.client(&#39;sts&#39;, aws_access_key_id=&#39;key&#39;, aws_secret_access_key=&#39;secret&#39;, region_name=&#39;us-east-1&#39;)\r\n    \r\n    assumedRoleObject = kinesis_client.assume_role(\r\n    RoleArn=&quot;arn:aws:iam::123456:role/firehose_delivery_role3&quot;,\r\n    RoleSessionName=&quot;AssumeRoleSession1&quot;\r\n    )\r\n    \r\n    kinesis_session = boto3.Session(\r\n    aws_access_key_id=assumedRoleObject,\r\n    aws_secret_access_key=assumedRoleObject,\r\n    aws_session_token=assumedRoleObject)\r\n    \r\n    client = kinesis_session.client(&#39;kinesis&#39;, region_name=&#39;us-east-1&#39;)\r\n    \r\n    def put_to_stream(thing_id, property_value, property_timestamp):\r\n    payload = {\r\n    &#39;prop&#39;: str(property_value),\r\n    &#39;timestamp&#39;: str(property_timestamp),\r\n    &#39;thing_id&#39;: thing_id\r\n    }\r\n    \r\n    print payload\r\n    \r\n    put_response = client.put_record(\r\n    StreamName=&#39;test3&#39;,\r\n    Data=json.dumps(payload),\r\n    PartitionKey=thing_id)\r\n    \r\n    while True:\r\n    property_value = random.randint(40, 120)\r\n    property_timestamp = calendar.timegm(datetime.utcnow().timetuple())\r\n    thing_id = &#39;aa-bb&#39;\r\n    \r\n    put_to_stream(thing_id, property_value, property_timestamp)\r\n    \r\n    # wait for 5 second\r\n    time.sleep(5)\r\n\r\n\r\n\r\n",
            "link": "https://stackoverflow.com/questions/49065384/issues-with-streaming-data-to-aws-kinesis-firehose-from-python",
            "title": "Issues with streaming data to AWS Kinesis Firehose from Python",
            "body": "<p>Stuck with the this problem for a week now.\nI honestly think it is a bug somewhere in us-east-1 with Kinesis Firehose at the moment.</p>\n\n<p>At least they automatically create role with wrong Trust Relationship.\nHere is what created by default:\n(I changed userID to 123456 everywhere)</p>\n\n<pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"\",\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"Service\": \"firehose.amazonaws.com\"\n},\n\"Action\": \"sts:AssumeRole\",\n\"Condition\": {\n\"StringEquals\": {\n\"sts:ExternalId\": \"123456\"\n}\n}\n}\n]\n}\n</code></pre>\n\n<p>When I try to call assume_role from my account I always get:</p>\n\n<pre><code>botocore.exceptions.ClientError: An error occurred (AccessDenied) when calling the AssumeRole operation: User: arn:aws:iam::123456:user/fh is not authorized to perform: sts:AssumeRole on resource: arn:aws:iam::123456:role/firehose_delivery_role2\n</code></pre>\n\n<p>User fh has AdministratorAccess policy.</p>\n\n<p>Instead you need to use following trust relation which actually works:</p>\n\n<pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"\",\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"AWS\": \"arn:aws:iam::123456:root\"\n},\n\"Action\": \"sts:AssumeRole\"\n}\n]\n}\n</code></pre>\n\n<p>But doesn't matter what I do, I always got following message when try to put anything to firehose:</p>\n\n<pre><code>botocore.errorfactory.ResourceNotFoundException: An error occurred (ResourceNotFoundException) when calling the PutRecord operation: Stream test3 under account 123456 not found.\n</code></pre>\n\n<p>Trying to access it with admin account and without assume_role got me the same result.</p>\n\n<p>My test3 stream delivers data to my elasticsearch.</p>\n\n<p>Can someone create new elasticsearch, kinesis firehose stream and test data delivery? Ideally from python/boto3.</p>\n\n<p>Here is example of code. do not look at variable names ;)</p>\n\n<pre><code>import boto3\nimport json\nfrom datetime import datetime\nimport calendar\nimport random\nimport time\n\nmy_stream_name = 'python-stream'\n\nkinesis_client = boto3.client('sts', aws_access_key_id='key', aws_secret_access_key='secret', region_name='us-east-1')\n\nassumedRoleObject = kinesis_client.assume_role(\nRoleArn=\"arn:aws:iam::123456:role/firehose_delivery_role3\",\nRoleSessionName=\"AssumeRoleSession1\"\n)\n\nkinesis_session = boto3.Session(\naws_access_key_id=assumedRoleObject,\naws_secret_access_key=assumedRoleObject,\naws_session_token=assumedRoleObject)\n\nclient = kinesis_session.client('kinesis', region_name='us-east-1')\n\ndef put_to_stream(thing_id, property_value, property_timestamp):\npayload = {\n'prop': str(property_value),\n'timestamp': str(property_timestamp),\n'thing_id': thing_id\n}\n\nprint payload\n\nput_response = client.put_record(\nStreamName='test3',\nData=json.dumps(payload),\nPartitionKey=thing_id)\n\nwhile True:\nproperty_value = random.randint(40, 120)\nproperty_timestamp = calendar.timegm(datetime.utcnow().timetuple())\nthing_id = 'aa-bb'\n\nput_to_stream(thing_id, property_value, property_timestamp)\n\n# wait for 5 second\ntime.sleep(5)\n</code></pre>\n"
        },
        {
            "tags": [
                "amazon-web-services",
                "aws-elasticsearch",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9381591,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "kartik",
                "link": "https://stackoverflow.com/users/9381591/kartik"
            },
            "is_answered": false,
            "view_count": 35,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449701,
            "creation_date": 1519753940,
            "last_edit_date": 1526449701,
            "question_id": 49014964,
            "body_markdown": "I have created a AWS lambda function which has its logs to CloudWatch, from where I have added a subscription to Kinesis Stream and then added a Firehose to Elasticsearch.\r\nBut when I see the Elasticsearch, I see no logs there and also I have given IAM role appropriately.\r\nCan someone help me with the issue?\r\n\r\nThanks",
            "link": "https://stackoverflow.com/questions/49014964/aws-logs-flow-kinesis-to-firehose-then-elasticsearch",
            "title": "AWS Logs Flow (Kinesis to Firehose then ElasticSearch)",
            "body": "<p>I have created a AWS lambda function which has its logs to CloudWatch, from where I have added a subscription to Kinesis Stream and then added a Firehose to Elasticsearch.\nBut when I see the Elasticsearch, I see no logs there and also I have given IAM role appropriately.\nCan someone help me with the issue?</p>\n\n<p>Thanks</p>\n"
        },
        {
            "tags": [
                "excel",
                "vba",
                "excel-vba"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9794395,
                "user_type": "registered",
                "profile_image": "https://lh3.googleusercontent.com/-XdUIqdMkCWA/AAAAAAAAAAI/AAAAAAAAAAA/4252rscbv5M/photo.jpg?sz=128",
                "display_name": "Hannah ",
                "link": "https://stackoverflow.com/users/9794395/hannah"
            },
            "is_answered": false,
            "view_count": 27,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449697,
            "creation_date": 1526449697,
            "question_id": 50363258,
            "body_markdown": "[Excel Sheet Image][1]\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/hqiIF.png\r\n\r\nI have the above Excel sheet and have been trying to use VBA to delete rows based on the values in column B, provided they match values currently residing in column C. I&#39;m a coding novice and have so far only gotten to a point of managing to delete a row by selecting a single cell in column C (There was a row containing the value *331013* in column B and I managed to delete it by selecting the cell in column C with that that value (currently the first row) and it was deleted.\r\n\r\nWhat I want to do is to select the entire range of values in column C so I can delete all of the matching values in column B in a single batch.\r\n\r\nThe following is what I&#39;ve managed so far based on a lot of googling, it is working with just one selection, but when I manually select more than 1 row it just deletes the corresponding value of the first selection and if I select the entire column range I get a mismatch error. And I&#39;ve also previously gotten a stack overflow error\r\n\r\n    Sub DeleteRows()\r\n\r\n    Dim rng As Range\r\n    Dim InputRng As Range\r\n    Dim DeleteRng As Range\r\n    Dim DeleteStr As Range\r\n    \r\n    xTitleId = &quot;Input&quot;\r\n    \r\n    Set InputRng = Application.Selection\r\n    Set DeleteStr = Application.Selection\r\n    \r\n    Set InputRng = Application.InputBox(&quot;Range :&quot;, xTitleId, InputRng.Address, Type:=8)\r\n    Set DeleteStr = Application.InputBox(&quot;delete range :&quot;, xTitleId, DeleteStr.Address, Type:=8)\r\n    For Each rng In InputRng\r\n        If rng.Value = DeleteStr Then\r\n            If DeleteRng Is Nothing Then\r\n                Set DeleteRng = rng\r\n            Else\r\n                Set DeleteRng = Application.Union(DeleteRng, rng)\r\n            End If\r\n        End If\r\n    Next\r\n    DeleteRng.EntireRow.Delete\r\n    End Sub\r\n\r\nI&#39;d really appreciate whatever input can be given.",
            "link": "https://stackoverflow.com/questions/50363258/excel-vba-delete-rows-in-a-column-based-on-a-range-of-cells-in-another-column",
            "title": "Excel VBA: Delete Rows in a Column based on a Range of Cells in another Column",
            "body": "<p><a href=\"https://i.stack.imgur.com/hqiIF.png\" rel=\"nofollow noreferrer\">Excel Sheet Image</a></p>\n\n<p>I have the above Excel sheet and have been trying to use VBA to delete rows based on the values in column B, provided they match values currently residing in column C. I'm a coding novice and have so far only gotten to a point of managing to delete a row by selecting a single cell in column C (There was a row containing the value <em>331013</em> in column B and I managed to delete it by selecting the cell in column C with that that value (currently the first row) and it was deleted.</p>\n\n<p>What I want to do is to select the entire range of values in column C so I can delete all of the matching values in column B in a single batch.</p>\n\n<p>The following is what I've managed so far based on a lot of googling, it is working with just one selection, but when I manually select more than 1 row it just deletes the corresponding value of the first selection and if I select the entire column range I get a mismatch error. And I've also previously gotten a stack overflow error</p>\n\n<pre><code>Sub DeleteRows()\n\nDim rng As Range\nDim InputRng As Range\nDim DeleteRng As Range\nDim DeleteStr As Range\n\nxTitleId = \"Input\"\n\nSet InputRng = Application.Selection\nSet DeleteStr = Application.Selection\n\nSet InputRng = Application.InputBox(\"Range :\", xTitleId, InputRng.Address, Type:=8)\nSet DeleteStr = Application.InputBox(\"delete range :\", xTitleId, DeleteStr.Address, Type:=8)\nFor Each rng In InputRng\n    If rng.Value = DeleteStr Then\n        If DeleteRng Is Nothing Then\n            Set DeleteRng = rng\n        Else\n            Set DeleteRng = Application.Union(DeleteRng, rng)\n        End If\n    End If\nNext\nDeleteRng.EntireRow.Delete\nEnd Sub\n</code></pre>\n\n<p>I'd really appreciate whatever input can be given.</p>\n"
        },
        {
            "tags": [
                "web-applications",
                "cloud"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 9798088,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/c8cafd4e91ae43ba3a9245b036027c07?s=128&d=identicon&r=PG&f=1",
                "display_name": "Sfey",
                "link": "https://stackoverflow.com/users/9798088/sfey"
            },
            "is_answered": false,
            "view_count": 3,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449692,
            "creation_date": 1526449692,
            "question_id": 50363255,
            "body_markdown": "I&#39;m trying to delete some files of an ex that I have in Google Drive.  When I try to delete I get a message &#39;one removed file is still accessible by collaborators in Google Drive&#39;.  The files still remain very much visible in my Google Drive.  Why can I not delete these files from my Drive?\r\n",
            "link": "https://stackoverflow.com/questions/50363255/cannot-delete-file-in-my-google-drive-message-one-removed-file-is-still-acces",
            "title": "Cannot delete file in my Google Drive...message &#39;one removed file is still accessible by collaborators in Google Drive&#39;",
            "body": "<p>I'm trying to delete some files of an ex that I have in Google Drive.  When I try to delete I get a message 'one removed file is still accessible by collaborators in Google Drive'.  The files still remain very much visible in my Google Drive.  Why can I not delete these files from my Drive?</p>\n"
        },
        {
            "tags": [
                "amazon-web-services",
                "aws-lambda",
                "aws-api-gateway",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 410,
                "user_id": 1480894,
                "user_type": "registered",
                "accept_rate": 50,
                "profile_image": "https://www.gravatar.com/avatar/6f020302c223d13aa9bcb8eef1533d27?s=128&d=identicon&r=PG",
                "display_name": "BBios",
                "link": "https://stackoverflow.com/users/1480894/bbios"
            },
            "is_answered": false,
            "view_count": 100,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526449688,
            "creation_date": 1519156568,
            "last_edit_date": 1526449688,
            "question_id": 48893224,
            "body_markdown": "I am trying to save data in S3 through firehose proxied by API gateway. I have create an API gateway endpoint that uses the AWS service integration type and PutRecord action for firehose. I have the mapping template as \r\n\r\n    {\r\n    &quot;DeliveryStreamName&quot;: &quot;test-stream&quot;,\r\n    &quot;Records&quot;: [\r\n    #foreach($elem in $input.path(&#39;$.data&#39;))\r\n    {\r\n    &quot;Data&quot;: &quot;$elem&quot;\r\n    }\r\n    #if($foreach.hasNext),#end\r\n    #end\r\n    ]\r\n    }\r\nNow when I test the endpoint with below JSON\r\n\r\n    { \r\n    &quot;data&quot;: [ \r\n    {&quot;ticker_symbol&quot;:&quot;DemoAPIGTWY&quot;,&quot;sector&quot;:&quot;FINANCIAL&quot;,&quot;change&quot;:-0.42,&quot;price&quot;:50.43},{&quot;ticker_symbol&quot;:&quot;DemoAPIGTWY&quot;,&quot;sector&quot;:&quot;FINANCIAL&quot;,&quot;change&quot;:-0.42,&quot;price&quot;:50.43} \r\n    ]\r\n    }\r\n\r\nJSON gets modified and shows up as below after the transformation \r\n\r\n    {ticker_symbol=DemoAPIGTWY, sector=FINANCIAL, change=-0.42, price=50.43}\r\n\r\n**: is being converted to = which is not a valid JSON**\r\n\r\nNot sure if something is wrong in the above mapping template\r\n",
            "link": "https://stackoverflow.com/questions/48893224/aws-api-gateway-response-body-template-mapping-foreach",
            "title": "AWS API gateway response body template mapping (foreach)",
            "body": "<p>I am trying to save data in S3 through firehose proxied by API gateway. I have create an API gateway endpoint that uses the AWS service integration type and PutRecord action for firehose. I have the mapping template as </p>\n\n<pre><code>{\n\"DeliveryStreamName\": \"test-stream\",\n\"Records\": [\n#foreach($elem in $input.path('$.data'))\n{\n\"Data\": \"$elem\"\n}\n#if($foreach.hasNext),#end\n#end\n]\n}\n</code></pre>\n\n<p>Now when I test the endpoint with below JSON</p>\n\n<pre><code>{ \n\"data\": [ \n{\"ticker_symbol\":\"DemoAPIGTWY\",\"sector\":\"FINANCIAL\",\"change\":-0.42,\"price\":50.43},{\"ticker_symbol\":\"DemoAPIGTWY\",\"sector\":\"FINANCIAL\",\"change\":-0.42,\"price\":50.43} \n]\n}\n</code></pre>\n\n<p>JSON gets modified and shows up as below after the transformation </p>\n\n<pre><code>{ticker_symbol=DemoAPIGTWY, sector=FINANCIAL, change=-0.42, price=50.43}\n</code></pre>\n\n<p><strong>: is being converted to = which is not a valid JSON</strong></p>\n\n<p>Not sure if something is wrong in the above mapping template</p>\n"
        },
        {
            "tags": [
                "node.js",
                "express",
                "heroku",
                "production-environment"
            ],
            "owner": {
                "reputation": 8,
                "user_id": 9780778,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/92d95b8a862cf74720165a0d782a8643?s=128&d=identicon&r=PG&f=1",
                "display_name": "hackerl33t",
                "link": "https://stackoverflow.com/users/9780778/hackerl33t"
            },
            "is_answered": true,
            "view_count": 24,
            "accepted_answer_id": 50361311,
            "answer_count": 1,
            "score": 1,
            "last_activity_date": 1526449687,
            "creation_date": 1526434562,
            "last_edit_date": 1526449687,
            "question_id": 50361255,
            "body_markdown": "I&#39;m using the [reload](https://www.npmjs.com/package/reload) package in development.\r\n\r\nIt&#39;s saved under `devDependancies` in `package.json`.\r\n\r\nIn my `app.js` I have:\r\n\r\n    if (process.env.NODE_ENV !== &#39;production&#39;) {\r\n        reload(server, app)\r\n    }\r\n\r\nHeroku strips out all packages under `devDependancies` after building, and my `import reload from &#39;reload&#39;` is throwing an error. I&#39;m using `babel` to build it in production btw.\r\n\r\n**Heroku logs:**\r\n\r\n    Error: Cannot find module &#39;reload&#39;\r\n    2018-05-16T01:00:46.213772+00:00 app[web.1]:     at Function.Module._resolveFilename (internal/modules/cjs/loader.js:571:15)\r\n    2018-05-16T01:00:46.213773+00:00 app[web.1]:     at Function.Module._load (internal/modules/cjs/loader.js:497:25)\r\n    2018-05-16T01:00:46.213776+00:00 app[web.1]:     at Module.require (internal/modules/cjs/loader.js:626:17)\r\n\r\nI&#39;m aware I can [skip the &quot;pruning&quot; part](https://devcenter.heroku.com/articles/nodejs-support#skip-pruning), but would prefer to strip loading of `reload` module in production instead.\r\n\r\nHow do I conditionally import or require a package?",
            "link": "https://stackoverflow.com/questions/50361255/conditional-require-in-express",
            "title": "Conditional require in express?",
            "body": "<p>I'm using the <a href=\"https://www.npmjs.com/package/reload\" rel=\"nofollow noreferrer\">reload</a> package in development.</p>\n\n<p>It's saved under <code>devDependancies</code> in <code>package.json</code>.</p>\n\n<p>In my <code>app.js</code> I have:</p>\n\n<pre><code>if (process.env.NODE_ENV !== 'production') {\n    reload(server, app)\n}\n</code></pre>\n\n<p>Heroku strips out all packages under <code>devDependancies</code> after building, and my <code>import reload from 'reload'</code> is throwing an error. I'm using <code>babel</code> to build it in production btw.</p>\n\n<p><strong>Heroku logs:</strong></p>\n\n<pre><code>Error: Cannot find module 'reload'\n2018-05-16T01:00:46.213772+00:00 app[web.1]:     at Function.Module._resolveFilename (internal/modules/cjs/loader.js:571:15)\n2018-05-16T01:00:46.213773+00:00 app[web.1]:     at Function.Module._load (internal/modules/cjs/loader.js:497:25)\n2018-05-16T01:00:46.213776+00:00 app[web.1]:     at Module.require (internal/modules/cjs/loader.js:626:17)\n</code></pre>\n\n<p>I'm aware I can <a href=\"https://devcenter.heroku.com/articles/nodejs-support#skip-pruning\" rel=\"nofollow noreferrer\">skip the \"pruning\" part</a>, but would prefer to strip loading of <code>reload</code> module in production instead.</p>\n\n<p>How do I conditionally import or require a package?</p>\n"
        },
        {
            "tags": [
                "android",
                "animation",
                "android-recyclerview",
                "kotlin"
            ],
            "owner": {
                "reputation": 261,
                "user_id": 5507446,
                "user_type": "registered",
                "accept_rate": 56,
                "profile_image": "https://graph.facebook.com/882192545167735/picture?type=large",
                "display_name": "Marc Zaharescu",
                "link": "https://stackoverflow.com/users/5507446/marc-zaharescu"
            },
            "is_answered": false,
            "view_count": 32,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449686,
            "creation_date": 1526449686,
            "question_id": 50363254,
            "body_markdown": "I added on click animations on some button items from a recycle view. \r\n\r\nEverything works smoothly, however when I scroll down the list some buttons appear in a weird state like they were frozen during the animation phase even though the animation was not being triggered for these buttons while for others the their view is set to invisible/gone. \r\n\r\nThis is part of the shrinking animation code, where shrink is a ValueAnimator object.\r\n\r\n    \r\n\r\n    shrink.addUpdateListener { animation -&gt;\r\n            val animatedValue = animation.animatedValue as Int\r\n            v.layoutParams.width = animatedValue\r\n            v.requestLayout()\r\n        }\r\n        shrink.addListener(object : AnimatorListenerAdapter() {\r\n            override fun onAnimationStart(animation: Animator) {\r\n                super.onAnimationStart(animation)\r\n                v.visibility = View.VISIBLE\r\n                v.isEnabled = false\r\n            }\r\n            override fun onAnimationEnd(animation: Animator) {\r\n                super.onAnimationEnd(animation)\r\n                v.layoutParams.width = 0\r\n                v.visibility = View.GONE\r\n                v.isEnabled = false\r\n            }\r\n       }\r\n\r\nI have a `View` and `ViewHolder` class where I bind the visibility of the recycle view items when I scroll.\r\n\r\n Is there a step I missed in the animation lifecycle to work together with the recycle view items? I was thinking that maybe I have to take care of `onAnimationStop` or `onAnimationPause` cases but I am not sure.\r\n\r\nAny help would be much appreciated.",
            "link": "https://stackoverflow.com/questions/50363254/android-animation-issue-on-recycleview-items",
            "title": "Android Animation Issue on RecycleView Items",
            "body": "<p>I added on click animations on some button items from a recycle view. </p>\n\n<p>Everything works smoothly, however when I scroll down the list some buttons appear in a weird state like they were frozen during the animation phase even though the animation was not being triggered for these buttons while for others the their view is set to invisible/gone. </p>\n\n<p>This is part of the shrinking animation code, where shrink is a ValueAnimator object.</p>\n\n<pre><code>shrink.addUpdateListener { animation -&gt;\n        val animatedValue = animation.animatedValue as Int\n        v.layoutParams.width = animatedValue\n        v.requestLayout()\n    }\n    shrink.addListener(object : AnimatorListenerAdapter() {\n        override fun onAnimationStart(animation: Animator) {\n            super.onAnimationStart(animation)\n            v.visibility = View.VISIBLE\n            v.isEnabled = false\n        }\n        override fun onAnimationEnd(animation: Animator) {\n            super.onAnimationEnd(animation)\n            v.layoutParams.width = 0\n            v.visibility = View.GONE\n            v.isEnabled = false\n        }\n   }\n</code></pre>\n\n<p>I have a <code>View</code> and <code>ViewHolder</code> class where I bind the visibility of the recycle view items when I scroll.</p>\n\n<p>Is there a step I missed in the animation lifecycle to work together with the recycle view items? I was thinking that maybe I have to take care of <code>onAnimationStop</code> or <code>onAnimationPause</code> cases but I am not sure.</p>\n\n<p>Any help would be much appreciated.</p>\n"
        },
        {
            "tags": [
                "amazon-kinesis-kpl",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 5035,
                "user_id": 170966,
                "user_type": "registered",
                "accept_rate": 57,
                "profile_image": "https://www.gravatar.com/avatar/3b7e1bba8adaa852ee405d10a67f6b46?s=128&d=identicon&r=PG",
                "display_name": "feroze",
                "link": "https://stackoverflow.com/users/170966/feroze"
            },
            "is_answered": false,
            "view_count": 34,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449682,
            "creation_date": 1519072494,
            "last_edit_date": 1526449682,
            "question_id": 48873778,
            "body_markdown": "I have a setup as follows:\r\n\r\n - REST api server, writes a message to a kinesis stream using Kinesis Producer Library (KPL)\r\n - Lambda function reads from the kinesis stream, and writes record to a firehose stream.\r\n - Firehose stream puts the messages into an S3 bucket.\r\n\r\nNow, when we look at the S3 bucket, we do see the data there. But we also see control characters that are used by KPL (using protobuf) to delimit record boundaries.\r\n\r\nHas anybody else seen this? What we expect to see is data as it was written by the REST api server, and not any control characters.",
            "link": "https://stackoverflow.com/questions/48873778/getting-protobuf-control-characters-when-sending-data-to-firehose-from-kinesis-s",
            "title": "Getting protobuf control characters when sending data to firehose from kinesis stream",
            "body": "<p>I have a setup as follows:</p>\n\n<ul>\n<li>REST api server, writes a message to a kinesis stream using Kinesis Producer Library (KPL)</li>\n<li>Lambda function reads from the kinesis stream, and writes record to a firehose stream.</li>\n<li>Firehose stream puts the messages into an S3 bucket.</li>\n</ul>\n\n<p>Now, when we look at the S3 bucket, we do see the data there. But we also see control characters that are used by KPL (using protobuf) to delimit record boundaries.</p>\n\n<p>Has anybody else seen this? What we expect to see is data as it was written by the REST api server, and not any control characters.</p>\n"
        },
        {
            "tags": [
                "python-3.x",
                "pickle",
                "boto3",
                "python-multiprocessing",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 18,
                "user_id": 5075486,
                "user_type": "registered",
                "profile_image": "https://graph.facebook.com/656628983996/picture?type=large",
                "display_name": "stanimal21",
                "link": "https://stackoverflow.com/users/5075486/stanimal21"
            },
            "is_answered": false,
            "view_count": 44,
            "closed_date": 1518545101,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449677,
            "creation_date": 1518544931,
            "last_edit_date": 1526449677,
            "question_id": 48772903,
            "body_markdown": "I&#39;m trying to implement multiprocessing in my code and the start() method keeps throwing this message:\r\n\r\n&gt; _pickle.PicklingError occurred Message: Can&#39;t pickle class &#39;botocore.client.Firehose&#39;: attribute lookup Firehose on botocore.client failed\r\n\r\nHere&#39;s the code for the class and the initialize function:\r\n\r\n    import multiprocessing.context import Process\r\n    import boto3\r\n\r\n    class Document(Process):\r\n\r\n        def __init__(self):\r\n        \r\n            Process.__init__(self)\r\n            self.kf = boto3.client(&#39;firehose&#39;)\r\n        \r\n    class Word(Document):\r\n       \r\n        def __init__(self,log=Log(),lId=&quot;&quot;,az=&quot;&quot;,lclPth=&quot;&quot;):\r\n    \r\n            Document.__init__(self)\r\n            # more stuff to execute\r\n\r\n        def run(self):\r\n\r\n            # some stuff to execute\r\n\r\n    proc = Word(log,1234,&quot;&quot;,&quot;&quot;)\r\n    proc.start()\r\n\r\nWhat am I doing wrong? This was working before implementing multiprocessing and it did work when using Threading.",
            "link": "https://stackoverflow.com/questions/48772903/python-3-6-picklingerror-on-botocore-client-firehose",
            "closed_reason": "duplicate",
            "title": "Python 3.6 PicklingError on botocore.client.Firehose",
            "body": "<p>I'm trying to implement multiprocessing in my code and the start() method keeps throwing this message:</p>\n\n<blockquote>\n  <p>_pickle.PicklingError occurred Message: Can't pickle class 'botocore.client.Firehose': attribute lookup Firehose on botocore.client failed</p>\n</blockquote>\n\n<p>Here's the code for the class and the initialize function:</p>\n\n<pre><code>import multiprocessing.context import Process\nimport boto3\n\nclass Document(Process):\n\n    def __init__(self):\n\n        Process.__init__(self)\n        self.kf = boto3.client('firehose')\n\nclass Word(Document):\n\n    def __init__(self,log=Log(),lId=\"\",az=\"\",lclPth=\"\"):\n\n        Document.__init__(self)\n        # more stuff to execute\n\n    def run(self):\n\n        # some stuff to execute\n\nproc = Word(log,1234,\"\",\"\")\nproc.start()\n</code></pre>\n\n<p>What am I doing wrong? This was working before implementing multiprocessing and it did work when using Threading.</p>\n"
        },
        {
            "tags": [
                "encryption",
                "amazon-s3",
                "amazon-athena",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 1738,
                "user_id": 3002273,
                "user_type": "registered",
                "accept_rate": 86,
                "profile_image": "https://www.gravatar.com/avatar/14663c07f99bd2fdc191b05db9d3e900?s=128&d=identicon&r=PG&f=1",
                "display_name": "aidan.plenert.macdonald",
                "link": "https://stackoverflow.com/users/3002273/aidan-plenert-macdonald"
            },
            "is_answered": false,
            "view_count": 83,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449671,
            "creation_date": 1516920225,
            "last_edit_date": 1526449671,
            "question_id": 48453114,
            "body_markdown": "AWS Athena supports reading and writing CSE-KMS encrypted data in S3 (see [the first figure](https://aws.amazon.com/blogs/aws/launch-amazon-athena-adds-support-for-querying-encrypted-data/)). Athena uses the [first client-side encryption option](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html).\r\n\r\nKinesis Firehose offers the [ability to transform data](https://docs.aws.amazon.com/firehose/latest/dev/data-transformation.html), but this transformation occurs record wise and Athena needs the whole S3 object encrypted and for meta-data to be inserted into the S3 object.\r\n\r\nHow do I do write the file to S3 with a CSE-KMS encryption from Firehose?",
            "link": "https://stackoverflow.com/questions/48453114/writing-cse-kms-encrypted-data-to-s3-via-kinesis-firehose",
            "title": "Writing CSE-KMS encrypted data to S3 via Kinesis Firehose",
            "body": "<p>AWS Athena supports reading and writing CSE-KMS encrypted data in S3 (see <a href=\"https://aws.amazon.com/blogs/aws/launch-amazon-athena-adds-support-for-querying-encrypted-data/\" rel=\"nofollow noreferrer\">the first figure</a>). Athena uses the <a href=\"https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingClientSideEncryption.html\" rel=\"nofollow noreferrer\">first client-side encryption option</a>.</p>\n\n<p>Kinesis Firehose offers the <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/data-transformation.html\" rel=\"nofollow noreferrer\">ability to transform data</a>, but this transformation occurs record wise and Athena needs the whole S3 object encrypted and for meta-data to be inserted into the S3 object.</p>\n\n<p>How do I do write the file to S3 with a CSE-KMS encryption from Firehose?</p>\n"
        },
        {
            "tags": [
                "javascript",
                "php",
                "html",
                "qr-code",
                "barcode-scanner"
            ],
            "owner": {
                "reputation": 6,
                "user_id": 9797566,
                "user_type": "registered",
                "profile_image": "https://lh4.googleusercontent.com/-EEIHqU7K9Xk/AAAAAAAAAAI/AAAAAAAAA_s/r7r4WIx3sV4/photo.jpg?sz=128",
                "display_name": "Nabila Rozli",
                "link": "https://stackoverflow.com/users/9797566/nabila-rozli"
            },
            "is_answered": false,
            "view_count": 21,
            "answer_count": 0,
            "score": 1,
            "last_activity_date": 1526449669,
            "creation_date": 1526449669,
            "question_id": 50363252,
            "body_markdown": "I am currently working on my project and I have encountered a problem while building a QR code scanner for my website.\r\n\r\nThe problem is that whenever I have scanned the QR code, my latest javascript link is not updated even though I have tried so many approach in order to make the JavaScript file to force reload such as the getting version method using JavaScript, PHP and so on.\r\n\r\nThis is the code in my php file for the QR code scanner:\r\n\r\n    &lt;script type=&quot;text/javascript&quot; src=&quot;js/app.js?v=5&quot;&gt;&lt;/script&gt;\r\n\r\nOther methods like using time as the version:\r\n\r\n    &lt;?php echo &#39;&lt;script type=&quot;text/javascript&quot; src=&quot;js/app.js?v=&#39;.time().&#39;&quot;&gt;&lt;/script&gt;&#39;; ?&gt;\r\n\r\nAnd another method using PHP:\r\n\r\n    &lt;?php\r\n    function auto_version($file=&#39;&#39;) {\r\n        if(!file_exists($file))\r\n            return $file;\r\n \r\n        $mtime = filemtime($file);\r\n        return $file.&#39;?&#39;.$mtime;\r\n    }\r\n    ?&gt;\r\n\r\n    &lt;script type=&quot;text/javascript&quot; src=&quot;&lt;?php echo auto_version(&#39;js/app.js&#39;); ?&gt;&quot;&gt;&lt;/script&gt;\r\n\r\nBy the way, the library that I am using for the QR code scanner is InstaScan library.\r\n\r\nCan anyone suggest a method to make it work?\r\n\r\nThank you in advance.",
            "link": "https://stackoverflow.com/questions/50363252/link-in-javascript-file-cannot-be-updated",
            "title": "Link in JavaScript file cannot be updated",
            "body": "<p>I am currently working on my project and I have encountered a problem while building a QR code scanner for my website.</p>\n\n<p>The problem is that whenever I have scanned the QR code, my latest javascript link is not updated even though I have tried so many approach in order to make the JavaScript file to force reload such as the getting version method using JavaScript, PHP and so on.</p>\n\n<p>This is the code in my php file for the QR code scanner:</p>\n\n<pre><code>&lt;script type=\"text/javascript\" src=\"js/app.js?v=5\"&gt;&lt;/script&gt;\n</code></pre>\n\n<p>Other methods like using time as the version:</p>\n\n<pre><code>&lt;?php echo '&lt;script type=\"text/javascript\" src=\"js/app.js?v='.time().'\"&gt;&lt;/script&gt;'; ?&gt;\n</code></pre>\n\n<p>And another method using PHP:</p>\n\n<pre><code>&lt;?php\nfunction auto_version($file='') {\n    if(!file_exists($file))\n        return $file;\n\n    $mtime = filemtime($file);\n    return $file.'?'.$mtime;\n}\n?&gt;\n\n&lt;script type=\"text/javascript\" src=\"&lt;?php echo auto_version('js/app.js'); ?&gt;\"&gt;&lt;/script&gt;\n</code></pre>\n\n<p>By the way, the library that I am using for the QR code scanner is InstaScan library.</p>\n\n<p>Can anyone suggest a method to make it work?</p>\n\n<p>Thank you in advance.</p>\n"
        },
        {
            "tags": [
                "php",
                "codeigniter",
                "file-upload"
            ],
            "owner": {
                "reputation": 232,
                "user_id": 1313259,
                "user_type": "registered",
                "accept_rate": 74,
                "profile_image": "https://www.gravatar.com/avatar/d97af432f1b41a18302ce66a40a3e003?s=128&d=identicon&r=PG",
                "display_name": "Mikerizzo",
                "link": "https://stackoverflow.com/users/1313259/mikerizzo"
            },
            "is_answered": true,
            "view_count": 351,
            "accepted_answer_id": 26061370,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526449668,
            "creation_date": 1411739092,
            "last_edit_date": 1526449668,
            "question_id": 26061100,
            "body_markdown": "For some reason this block of code works on my local machine but when I upload it to my GoDaddy server it doesn&#39;t work, it tells me &quot;The filetype you are attempting to upload is not allowed.&quot;. This only happens when I try to upload csv and xlsx files, png and jpgs work no problem.\r\n\r\n        \r\n        $filename = &quot;classlist_&quot;.date(&quot;YmdHis&quot;).&quot;.csv&quot;;\r\n\t\t$config[&#39;upload_path&#39;] = APPPATH. &#39;../uploads/&#39;;\r\n\t\t$config[&#39;allowed_types&#39;] = &#39;xlsx|xls|jpg|png|csv&#39;;\r\n\t\t$config[&#39;max_size&#39;]\t= &#39;1000&#39;;\r\n\t\t$config[&#39;max_width&#39;]  = &#39;1024&#39;;\r\n\t\t$config[&#39;max_height&#39;]  = &#39;768&#39;;\r\n\r\n\t\t$this-&gt;load-&gt;library(&#39;upload&#39;, $config);\r\n\r\n\t\tif (!$this-&gt;upload-&gt;do_upload())\r\n\t\t{\r\n\t\t\tprint_r($this-&gt;upload);\r\n\r\n\t\t\techo &quot;error&lt;br/&gt;&quot;.$this-&gt;upload-&gt;display_errors();\r\n\t\t\texit;\r\n\t\t}\r\n\t\telse\r\n\t\t{\r\n\t\t\texit;",
            "link": "https://stackoverflow.com/questions/26061100/codeigniter-file-upload-and-godaddy",
            "title": "Codeigniter - File Upload and GoDaddy",
            "body": "<p>For some reason this block of code works on my local machine but when I upload it to my GoDaddy server it doesn't work, it tells me \"The filetype you are attempting to upload is not allowed.\". This only happens when I try to upload csv and xlsx files, png and jpgs work no problem.</p>\n\n<pre><code>    $filename = \"classlist_\".date(\"YmdHis\").\".csv\";\n    $config['upload_path'] = APPPATH. '../uploads/';\n    $config['allowed_types'] = 'xlsx|xls|jpg|png|csv';\n    $config['max_size'] = '1000';\n    $config['max_width']  = '1024';\n    $config['max_height']  = '768';\n\n    $this-&gt;load-&gt;library('upload', $config);\n\n    if (!$this-&gt;upload-&gt;do_upload())\n    {\n        print_r($this-&gt;upload);\n\n        echo \"error&lt;br/&gt;\".$this-&gt;upload-&gt;display_errors();\n        exit;\n    }\n    else\n    {\n        exit;\n</code></pre>\n"
        },
        {
            "tags": [
                "node.js",
                "elasticsearch",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 217,
                "user_id": 4912993,
                "user_type": "registered",
                "accept_rate": 46,
                "profile_image": "https://lh5.googleusercontent.com/-pp4594nLDXk/AAAAAAAAAAI/AAAAAAAAt0w/Z5lDiKLNMmg/photo.jpg?sz=128",
                "display_name": "Lior Goldemberg",
                "link": "https://stackoverflow.com/users/4912993/lior-goldemberg"
            },
            "is_answered": false,
            "view_count": 55,
            "answer_count": 0,
            "score": 2,
            "last_activity_date": 1526449666,
            "creation_date": 1516787256,
            "last_edit_date": 1526449666,
            "question_id": 48419280,
            "body_markdown": "I&#39;m trying to understand if it&#39;s possible to index data to elasticsearch using kinesis firehose to multiple indices, by passing it the index name and type (similar to elasticsaerch bulk api)\r\n\r\nAWS documentation ([here][1]) says:\r\n\r\n&gt; .... Also, the rest.action.multi.allow_explicit_index option for your\r\n&gt; Elasticsearch cluster must be set to true (default) **in order to take\r\n&gt; bulk requests with an explicit index that is set per record**. For more\r\n&gt; information, see Amazon ES Configure Advanced Options in the Amazon\r\n&gt; Elasticsearch Service Developer Guide.\r\n\r\nbut i can&#39;t find any documentation of how to do it, and moreover firehose configuration requires index name.\r\n\r\nthis try didnt work:\r\n\r\n     const data = [\r\n        {\r\n            &quot;value&quot;: &quot;1&quot;,\r\n            &quot;_index&quot;: &quot;index1&quot;,\r\n            &quot;_type&quot;: &quot;type1&quot;\r\n        }];\r\n\r\n    const params = {\r\n        DeliveryStreamName: &#39;XXX&#39;, /* required */\r\n        Records: [/* required */\r\n            {\r\n                Data: JSON.stringify(data[0]) //new Buffer(&#39;...&#39;) || &#39;STRING_VALUE&#39; /* Strings will be Base-64 encoded on your behalf */ /* required */\r\n            }\r\n        ]\r\n    };\r\n    firehose.putRecordBatch(params, (err, data) =&gt; {\r\n        if (err) console.log(err, err.stack); // an error occurred\r\n        else console.log(data);           // successful response\r\n    });\r\n\r\n\r\nassistance will be appreciated \r\n\r\n\r\n  [1]: https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html",
            "link": "https://stackoverflow.com/questions/48419280/index-data-to-multiple-indices-using-single-firehose",
            "title": "index data to multiple indices using single firehose",
            "body": "<p>I'm trying to understand if it's possible to index data to elasticsearch using kinesis firehose to multiple indices, by passing it the index name and type (similar to elasticsaerch bulk api)</p>\n\n<p>AWS documentation (<a href=\"https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html\" rel=\"nofollow noreferrer\">here</a>) says:</p>\n\n<blockquote>\n  <p>.... Also, the rest.action.multi.allow_explicit_index option for your\n  Elasticsearch cluster must be set to true (default) <strong>in order to take\n  bulk requests with an explicit index that is set per record</strong>. For more\n  information, see Amazon ES Configure Advanced Options in the Amazon\n  Elasticsearch Service Developer Guide.</p>\n</blockquote>\n\n<p>but i can't find any documentation of how to do it, and moreover firehose configuration requires index name.</p>\n\n<p>this try didnt work:</p>\n\n<pre><code> const data = [\n    {\n        \"value\": \"1\",\n        \"_index\": \"index1\",\n        \"_type\": \"type1\"\n    }];\n\nconst params = {\n    DeliveryStreamName: 'XXX', /* required */\n    Records: [/* required */\n        {\n            Data: JSON.stringify(data[0]) //new Buffer('...') || 'STRING_VALUE' /* Strings will be Base-64 encoded on your behalf */ /* required */\n        }\n    ]\n};\nfirehose.putRecordBatch(params, (err, data) =&gt; {\n    if (err) console.log(err, err.stack); // an error occurred\n    else console.log(data);           // successful response\n});\n</code></pre>\n\n<p>assistance will be appreciated </p>\n"
        },
        {
            "tags": [
                "vue.js",
                "error-handling",
                "visual-studio-code",
                "vuejs2",
                "vetur"
            ],
            "owner": {
                "reputation": 797,
                "user_id": 3025289,
                "user_type": "registered",
                "accept_rate": 94,
                "profile_image": "https://i.stack.imgur.com/GSUaE.png?s=128&g=1",
                "display_name": "Lonely",
                "link": "https://stackoverflow.com/users/3025289/lonely"
            },
            "is_answered": true,
            "view_count": 68,
            "accepted_answer_id": 50143845,
            "answer_count": 1,
            "score": 2,
            "last_activity_date": 1526449660,
            "creation_date": 1525290406,
            "last_edit_date": 1525405418,
            "question_id": 50142430,
            "body_markdown": "As you know `@` is a placeholder for `/src` and the application compiles and runs properly if I use it so. But my VSCode thinks the module is not there and show me an error message:\r\n\r\n[![Visual Studio Code: cannot find module][1]][1]\r\n\r\n**Question 1: How can I teach VSCode how to find the modules?**\r\n\r\nA similar situation is the following:\r\n\r\n    export default class HelloWorld extends Vue {\r\n      @Prop() private msg!: string;\r\n    }\r\n\r\nThere are two errors in the IDE (while the application compiles and runs properly):\r\n\r\n1) `!:` is red underlined -&gt; *Expression expected*\r\n\r\n[![enter image description here][2]][2]\r\n\r\n2) `string` is red underlined -&gt; *Member &#39;string&#39; implicitly has an &#39;any&#39; type.*\r\n\r\n[![enter image description here][3]][3]\r\n\r\n\r\nBut these are not really errors, that&#39;s the normal syntax and VSCode cannot deal with it. Vetur Extension (Vue Tooling for VSCode) is already installed.\r\n\r\n**Question 2: How can I deal with Vue + TypeScript in VSCode at all? What (all) do I have to consider?**\r\n\r\n\r\n  [1]: https://i.stack.imgur.com/SXGLn.png\r\n  [2]: https://i.stack.imgur.com/NilGf.png\r\n  [3]: https://i.stack.imgur.com/dqOOA.png",
            "link": "https://stackoverflow.com/questions/50142430/visual-studio-code-initial-vuejs-setup-cannot-find-module",
            "title": "Visual Studio Code: Initial VueJS setup cannot find module &quot;@/..&quot;",
            "body": "<p>As you know <code>@</code> is a placeholder for <code>/src</code> and the application compiles and runs properly if I use it so. But my VSCode thinks the module is not there and show me an error message:</p>\n\n<p><a href=\"https://i.stack.imgur.com/SXGLn.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/SXGLn.png\" alt=\"Visual Studio Code: cannot find module\"></a></p>\n\n<p><strong>Question 1: How can I teach VSCode how to find the modules?</strong></p>\n\n<p>A similar situation is the following:</p>\n\n<pre><code>export default class HelloWorld extends Vue {\n  @Prop() private msg!: string;\n}\n</code></pre>\n\n<p>There are two errors in the IDE (while the application compiles and runs properly):</p>\n\n<p>1) <code>!:</code> is red underlined -> <em>Expression expected</em></p>\n\n<p><a href=\"https://i.stack.imgur.com/NilGf.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/NilGf.png\" alt=\"enter image description here\"></a></p>\n\n<p>2) <code>string</code> is red underlined -> <em>Member 'string' implicitly has an 'any' type.</em></p>\n\n<p><a href=\"https://i.stack.imgur.com/dqOOA.png\" rel=\"nofollow noreferrer\"><img src=\"https://i.stack.imgur.com/dqOOA.png\" alt=\"enter image description here\"></a></p>\n\n<p>But these are not really errors, that's the normal syntax and VSCode cannot deal with it. Vetur Extension (Vue Tooling for VSCode) is already installed.</p>\n\n<p><strong>Question 2: How can I deal with Vue + TypeScript in VSCode at all? What (all) do I have to consider?</strong></p>\n"
        },
        {
            "tags": [
                "python",
                "amazon-web-services",
                "aws-lambda",
                "amazon-cloudformation",
                "amazon-kinesis-firehose"
            ],
            "owner": {
                "reputation": 61,
                "user_id": 8834415,
                "user_type": "registered",
                "accept_rate": 55,
                "profile_image": "https://www.gravatar.com/avatar/7afeb1ea0ccbe5331bb4cd7bd37a14af?s=128&d=identicon&r=PG&f=1",
                "display_name": "Louis",
                "link": "https://stackoverflow.com/users/8834415/louis"
            },
            "is_answered": false,
            "view_count": 332,
            "answer_count": 1,
            "score": 0,
            "last_activity_date": 1526449658,
            "creation_date": 1516738116,
            "last_edit_date": 1526449658,
            "question_id": 48409989,
            "body_markdown": "I found [this guide][1] on the AWS blog that illustrates an example of what I am trying to accomplish. I currently have a workflow that looks like Kinesis Stream --&gt; Kinesis Firehose --&gt; S3 bucket, and I want to introduce a Lambda where I can transform the data before it reaches the final destination.\r\n\r\nFirst, the links for the Lambda blueprints don&#39;t work on that article. Nor the official [documentation for the data transformation in Firehose][2]. Does anyone have a working Python blueprint for this case?\r\n\r\nSecondly, the guide shows that when creating a Firehose Delivery Stream in the AWS Console, there is an option to &quot;Enable&quot; data transformation in Lambda. However, I do not see any property for AWS::KinesisFirehose::DeliveryStream in the [CloudFormation documentation][3] that would accomplish the same thing. How would I enable this in my CloudFormation template?\r\n\r\nThanks!\r\n\r\n\r\n  [1]: https://aws.amazon.com/blogs/compute/amazon-kinesis-firehose-data-transformation-with-aws-lambda/\r\n  [2]: https://docs.aws.amazon.com/firehose/latest/dev/data-transformation.html#lambda-blueprints\r\n  [3]: https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kinesisfirehose-deliverystream.html",
            "link": "https://stackoverflow.com/questions/48409989/transforming-data-in-aws-kinesis-firehose-with-aws-lambda-cloudformation",
            "title": "Transforming data in AWS Kinesis Firehose with AWS Lambda / CloudFormation",
            "body": "<p>I found <a href=\"https://aws.amazon.com/blogs/compute/amazon-kinesis-firehose-data-transformation-with-aws-lambda/\" rel=\"nofollow noreferrer\">this guide</a> on the AWS blog that illustrates an example of what I am trying to accomplish. I currently have a workflow that looks like Kinesis Stream --> Kinesis Firehose --> S3 bucket, and I want to introduce a Lambda where I can transform the data before it reaches the final destination.</p>\n\n<p>First, the links for the Lambda blueprints don't work on that article. Nor the official <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/data-transformation.html#lambda-blueprints\" rel=\"nofollow noreferrer\">documentation for the data transformation in Firehose</a>. Does anyone have a working Python blueprint for this case?</p>\n\n<p>Secondly, the guide shows that when creating a Firehose Delivery Stream in the AWS Console, there is an option to \"Enable\" data transformation in Lambda. However, I do not see any property for AWS::KinesisFirehose::DeliveryStream in the <a href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-kinesisfirehose-deliverystream.html\" rel=\"nofollow noreferrer\">CloudFormation documentation</a> that would accomplish the same thing. How would I enable this in my CloudFormation template?</p>\n\n<p>Thanks!</p>\n"
        },
        {
            "tags": [
                "codeigniter"
            ],
            "owner": {
                "reputation": 890,
                "user_id": 1905947,
                "user_type": "registered",
                "accept_rate": 67,
                "profile_image": "https://www.gravatar.com/avatar/a74e7d8382199c6858fcf8af636f75de?s=128&d=identicon&r=PG",
                "display_name": "mridul",
                "link": "https://stackoverflow.com/users/1905947/mridul"
            },
            "is_answered": true,
            "view_count": 5864,
            "accepted_answer_id": 20524564,
            "answer_count": 2,
            "score": 3,
            "last_activity_date": 1526449653,
            "creation_date": 1386775511,
            "last_edit_date": 1526449653,
            "question_id": 20523033,
            "body_markdown": "I am trying to remove index.php from url. But its not working!\r\n\r\nUsing ubuntu 12.04 ( LAMP).\r\n\r\nCodeIgniter_2.1.2\r\n \r\n .htaccess file \r\n  \r\n\r\n    &lt;IfModule mod_rewrite.c&gt;\r\n        \tRewriteEngine On\r\n        \tRewriteBase /cms1\r\n        \r\n        \r\n        \r\n        \tRewriteCond %{REQUEST_FILENAME} !-f\r\n        \tRewriteCond %{REQUEST_FILENAME} !-d\r\n        \tRewriteRule ^(.*)$ index.php/$1 [L] \r\n        &lt;/IfModule&gt;\r\n\r\nin config.php :\r\n   \r\n       \r\n\r\n    $config[&#39;index_page&#39;] = &#39;index.php&#39;; to $config[&#39;index_page&#39;] = &#39;&#39;;\r\n\r\nDirectory structure:\r\n\r\n    /var/www/cms1\r\n\r\n    -&gt;cms1\r\n        -&gt;application\r\n        -&gt;system\r\n        -&gt;user_guide\r\n        -&gt;index.php\r\n        -&gt;license.txt\r\n        -&gt;.htaccess",
            "link": "https://stackoverflow.com/questions/20523033/codeigniter-remove-index-php-not-working",
            "title": "codeigniter: Remove index.php not working",
            "body": "<p>I am trying to remove index.php from url. But its not working!</p>\n\n<p>Using ubuntu 12.04 ( LAMP).</p>\n\n<p>CodeIgniter_2.1.2</p>\n\n<p>.htaccess file </p>\n\n<pre><code>&lt;IfModule mod_rewrite.c&gt;\n        RewriteEngine On\n        RewriteBase /cms1\n\n\n\n        RewriteCond %{REQUEST_FILENAME} !-f\n        RewriteCond %{REQUEST_FILENAME} !-d\n        RewriteRule ^(.*)$ index.php/$1 [L] \n    &lt;/IfModule&gt;\n</code></pre>\n\n<p>in config.php :</p>\n\n<pre><code>$config['index_page'] = 'index.php'; to $config['index_page'] = '';\n</code></pre>\n\n<p>Directory structure:</p>\n\n<pre><code>/var/www/cms1\n\n-&gt;cms1\n    -&gt;application\n    -&gt;system\n    -&gt;user_guide\n    -&gt;index.php\n    -&gt;license.txt\n    -&gt;.htaccess\n</code></pre>\n"
        },
        {
            "tags": [
                "c++",
                "multithreading",
                "std",
                "stdthread",
                "perfect-forwarding"
            ],
            "owner": {
                "reputation": 596,
                "user_id": 3600304,
                "user_type": "registered",
                "accept_rate": 63,
                "profile_image": "https://www.gravatar.com/avatar/582e17ff0889a21f8b0f39315e064e76?s=128&d=identicon&r=PG&f=1",
                "display_name": "Kapil",
                "link": "https://stackoverflow.com/users/3600304/kapil"
            },
            "is_answered": false,
            "view_count": 57,
            "answer_count": 0,
            "score": 3,
            "last_activity_date": 1526449641,
            "creation_date": 1526447512,
            "last_edit_date": 1526449641,
            "question_id": 50362849,
            "body_markdown": "In below code I could not understand why move constructor of class is called twice considering that my thread function is taking argument by rvalue reference and so I was hoping move constructor will be called only once when arguments will be moved to thread constructor.Can somebody give insights on how thread constructor works and how it passes argument to thread function.\r\n\r\n    #include &lt;iostream&gt;\r\n    #include &lt;thread&gt;\r\n    #include &lt;chrono&gt;\r\n    class Test {\r\n      public:\r\n      Test() {}\r\n      Test(Test&amp;&amp;)\r\n      {\r\n        std::cout&lt;&lt;&quot;Move Constructor Called...&quot;&lt;&lt;std::endl;\r\n      }\r\n    };\r\n    void my_thread_func(Test&amp;&amp; obj)\r\n    {\r\n      using namespace std::chrono_literals;\r\n      std::cout&lt;&lt;&quot;Inside thread function...&quot;&lt;&lt;std::endl;\r\n      std::this_thread::sleep_for(2s);\r\n    }\r\n    int main() {\r\n      std::thread t(my_thread_func,Test());\r\n      std::cout &lt;&lt; &quot;Hello World!\\n&quot;;\r\n      t.join();\r\n      return 0;\r\n    }\r\nThis question is not concerned with that thread constructor arguments are passed by value and it is more concerned with why move constructor is called twice ?",
            "link": "https://stackoverflow.com/questions/50362849/why-move-constructor-is-called-twice-when-passing-temporaries-to-thread-function",
            "title": "Why move constructor is called twice when passing temporaries to thread function?",
            "body": "<p>In below code I could not understand why move constructor of class is called twice considering that my thread function is taking argument by rvalue reference and so I was hoping move constructor will be called only once when arguments will be moved to thread constructor.Can somebody give insights on how thread constructor works and how it passes argument to thread function.</p>\n\n<pre><code>#include &lt;iostream&gt;\n#include &lt;thread&gt;\n#include &lt;chrono&gt;\nclass Test {\n  public:\n  Test() {}\n  Test(Test&amp;&amp;)\n  {\n    std::cout&lt;&lt;\"Move Constructor Called...\"&lt;&lt;std::endl;\n  }\n};\nvoid my_thread_func(Test&amp;&amp; obj)\n{\n  using namespace std::chrono_literals;\n  std::cout&lt;&lt;\"Inside thread function...\"&lt;&lt;std::endl;\n  std::this_thread::sleep_for(2s);\n}\nint main() {\n  std::thread t(my_thread_func,Test());\n  std::cout &lt;&lt; \"Hello World!\\n\";\n  t.join();\n  return 0;\n}\n</code></pre>\n\n<p>This question is not concerned with that thread constructor arguments are passed by value and it is more concerned with why move constructor is called twice ?</p>\n"
        },
        {
            "tags": [
                "php",
                "codeigniter",
                "inode"
            ],
            "owner": {
                "reputation": 1,
                "user_id": 1291803,
                "user_type": "registered",
                "profile_image": "https://www.gravatar.com/avatar/ae61e1d8b74b7b6334cdaa2103dc9c64?s=128&d=identicon&r=PG",
                "display_name": "Falcon99",
                "link": "https://stackoverflow.com/users/1291803/falcon99"
            },
            "is_answered": false,
            "view_count": 18,
            "answer_count": 0,
            "score": -1,
            "last_activity_date": 1526449641,
            "creation_date": 1525779623,
            "last_edit_date": 1526449641,
            "question_id": 50232723,
            "body_markdown": "We have a developer building a website for us, but today the website went down... doing some digging with our host, we found that our Inode was full at 2.1m files\r\n\r\nim asking our developer to look into it, but i wanted to understand the issue a bit more (bare with me, im not a programmer)\r\n\r\nthis directory had over 800k files in them\r\n\r\nfeast-includes/application/cache/sessions\r\n\r\nwhen we backup these directories the amount doubles (obviously) and fills up Inode quickly.\r\n\r\nwhat can we do to ensure this doesnt happen again?\r\n\r\n",
            "link": "https://stackoverflow.com/questions/50232723/codeigniter-cache-filling-up-inode",
            "title": "Codeigniter cache filling up inode",
            "body": "<p>We have a developer building a website for us, but today the website went down... doing some digging with our host, we found that our Inode was full at 2.1m files</p>\n\n<p>im asking our developer to look into it, but i wanted to understand the issue a bit more (bare with me, im not a programmer)</p>\n\n<p>this directory had over 800k files in them</p>\n\n<p>feast-includes/application/cache/sessions</p>\n\n<p>when we backup these directories the amount doubles (obviously) and fills up Inode quickly.</p>\n\n<p>what can we do to ensure this doesnt happen again?</p>\n"
        },
        {
            "tags": [
                "validation",
                "keycode",
                "onkeypress"
            ],
            "owner": {
                "user_type": "does_not_exist",
                "display_name": "user9798071"
            },
            "is_answered": false,
            "view_count": 4,
            "answer_count": 0,
            "score": 0,
            "last_activity_date": 1526449638,
            "creation_date": 1526449638,
            "question_id": 50363247,
            "body_markdown": "how can validate the text-box by using key-code by allow the text first two letter should be uppercase alphabets remaining all will be numeric . event should be done in on click event\r\n\r\n1. doing **onkeypress** event restrict the keys as follow.\r\n            (i) allow only first two letters should be upper alphabets \r\n            (ii) reaming will be numbers",
            "link": "https://stackoverflow.com/questions/50363247/allow-first-two-letters-uppercase-and-remaining-should-numbers-in-onkeypress-eve",
            "title": "allow first two letters uppercase and remaining should numbers in onkeypress event",
            "body": "<p>how can validate the text-box by using key-code by allow the text first two letter should be uppercase alphabets remaining all will be numeric . event should be done in on click event</p>\n\n<ol>\n<li>doing <strong>onkeypress</strong> event restrict the keys as follow.\n        (i) allow only first two letters should be upper alphabets \n        (ii) reaming will be numbers</li>\n</ol>\n"
        }
    ],
    "has_more": true,
    "quota_max": 300,
    "quota_remaining": 243
}